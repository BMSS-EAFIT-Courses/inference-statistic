[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inferencia Estad√≠stica",
    "section": "",
    "text": "1 INTRODUCCI√ìN\nEste libro ha sido concebido como un recurso integral para el estudio riguroso y aplicado de la inferencia estad√≠stica. Est√° dirigido a estudiantes de programas de estad√≠stica, matem√°ticas aplicadas y disciplinas afines, y busca fortalecer la comprensi√≥n conceptual y t√©cnica de los fundamentos que sustentan el an√°lisis estad√≠stico moderno.\nA lo largo de sus cap√≠tulos, el lector encontrar√° un desarrollo progresivo de los siguientes temas:\nEl material combina el rigor formal con ejemplos y aplicaciones que ilustran c√≥mo los m√©todos estad√≠sticos permiten extraer conclusiones v√°lidas a partir de datos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#c√≥mo-navegar-este-libro",
    "href": "index.html#c√≥mo-navegar-este-libro",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.1 ¬øC√≥mo navegar este libro?",
    "text": "1.1 ¬øC√≥mo navegar este libro?\n\nUsa el √≠ndice lateral izquierdo para acceder a cada cap√≠tulo y subcap√≠tulo.\nHaz uso del buscador para encontrar conceptos o t√©rminos clave.\nRevisa los apartados de ‚ÄúLista de problemas‚Äù incluidos al final de cada secci√≥n para practicar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#bienvenidao",
    "href": "index.html#bienvenidao",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.2 ¬°Bienvenida/o!",
    "text": "1.2 ¬°Bienvenida/o!\nTe invito a recorrer este texto con atenci√≥n, curiosidad y sentido cr√≠tico.\nEspero que este libro te acompa√±e, rete y apoye en tu formaci√≥n como profesional en ciencias de datos o √°reas relacionadas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#fen√≥meno-aleatorio-y-variable-observada",
    "href": "index.html#fen√≥meno-aleatorio-y-variable-observada",
    "title": "Inferencia Estad√≠stica",
    "section": "\n2.1 Fen√≥meno aleatorio y variable observada",
    "text": "2.1 Fen√≥meno aleatorio y variable observada\n‚ÄúSe observa una realizaci√≥n de un fen√≥meno aleatorio, digamos X. Este puede ser un elemento aleatorio de varios tipos: n√∫mero (variable aleatoria), un vector de dimensi√≥n finita (vector aleatorio), una funci√≥n, etc.\nLa premisa principal es que el car√°cter aleatorio de X se concibe como una realizaci√≥n de un fen√≥meno aleatorio que tiene una distribuci√≥n de probabilidad P, donde la distribuci√≥n P es desconocida ya sea en su totalidad o en alg√∫n detalle espec√≠fico (por ejemplo, su soporte, su media, etc.). Es de inter√©s conocer P. Si la medida de probabilidad P fuese conocida, entonces no hay problema estad√≠stico propiamente, pues el problema estad√≠stico tiene que ver con inferir la propiedad desconocida de P con base en X.‚Äù [Ver referencia 1]\n\n\nDefinici√≥n de X\n\n\nX puede ser un valor real \\(X \\in \\mathbb{R}\\), un vector en \\(\\mathbb{R}^n\\), o incluso una funci√≥n \\(\\;X: [0,1]\\to\\mathbb{R}\\).\n\n\n\n\nMedida de probabilidad P\n\nDesconocida: soporte, media, varianza, etc.\n\nObjetivo estad√≠stico: inferir caracter√≠sticas de (P) a partir de la muestra (la realizaci√≥n de X).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#incertidumbre-inductiva-vs.-estoc√°stica",
    "href": "index.html#incertidumbre-inductiva-vs.-estoc√°stica",
    "title": "Inferencia Estad√≠stica",
    "section": "\n2.2 Incertidumbre inductiva vs.¬†estoc√°stica",
    "text": "2.2 Incertidumbre inductiva vs.¬†estoc√°stica\n‚ÄúLa observaci√≥n X est√° dada, por lo que no hay incertidumbre tal como la hay en la teor√≠a de probabilidad desarrollada anteriormente en el curso. Antes, fue concebida una estructura \\((\\Omega, \\mathcal{F}, P)\\) para enfrentar el que haya incertidumbre acerca del valor de X. En el problema estad√≠stico, el valor de X ha sido observado, y la incertidumbre radica en otro punto: radica en que existe duda acerca de cu√°l P es la que produjo el valor X. En algunas ocasiones se utilizan los t√©rminos incertidumbre estoc√°stica e incertidumbre inductiva para distinguir estos dos tipos. Es com√∫n que estos se confundan entre s√≠, porque en estad√≠stica matem√°tica la teor√≠a de probabilidad constituye tambi√©n una de las maneras naturales de afrontar la cuantificaci√≥n de incertidumbre inductiva. En cualquier caso, el concebir a P como medida de probabilidad es la base para formular soluciones a la incertidumbre inductiva. Con este lenguaje, probabilidad y estad√≠stica son problemas diferentes y de cierta manera inversos. Teor√≠a de probabilidad tiene que ver con cuantificar incertidumbre acerca de X y teor√≠a estad√≠stica con cuantificar incertidumbre acerca de P a la luz de haber ya observado X.‚Äù[Ver referencia 1]\n\n\nIncertidumbre estoc√°stica: duda previa sobre el valor de X, modelada por \\((\\Omega,\\mathcal{F},P)\\).\n\n\nIncertidumbre inductiva: tras observar X, la incertidumbre se desplaza a la ley generadora P.\n\n\n\n2.2.0.1 Ejemplos en Matem√°tica Aplicada e Ingenier√≠a de Sistemas\n\n\nModelado de tiempos de respuesta en redes\n\n\n\\(X\\): tiempo de llegada de paquetes (variable continua).\n\n\n\\(P\\): distribuci√≥n de retardo desconocida; objetivo: estimar par√°metros de una ley de colas M/M/1.\n\n\n\nEstimaci√≥n de par√°metros en ecuaciones diferenciales estoc√°sticas\n\n\n\\(X(t)\\): trayectoria observada de un proceso de It√¥.\n\n\n\\(P\\): ley del proceso (por ejemplo, coeficientes de difusi√≥n y deriva), inferidos a partir de trayectorias discretas.\n\n\n\nCalibraci√≥n de sensores en sistemas de control\n\n\n\\(X\\): lecturas del sensor (vector aleatorio).\n\n\n\\(P\\): distribuci√≥n conjunta desconocida de ruido; se estima para dise√±ar filtros de Kalman √≥ptimos.\n\n\n\n\nCon esta distinci√≥n clara entre dato observado y modelo probabil√≠stico, estamos listos para construir estimadores y desarrollar la inferencia estad√≠stica en las secciones siguientes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#variables-y-vectores-aleatorios",
    "href": "index.html#variables-y-vectores-aleatorios",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.1 Variables y vectores aleatorios",
    "text": "3.1 Variables y vectores aleatorios\nConsideramos un experimento aleatorio cuyos resultados pertenecen al espacio muestral Œ©. Modelamos este proceso suponiendo que existe una terna \\((\\Omega, \\mathcal{A}, P),\\) donde:\n\n\n\\(\\Omega\\) es el espacio muestra,\n\n\n\\(\\mathcal{P}(\\Omega)\\) es el conjunto de partes de Œ©,\n\n\n\\(\\mathcal{A}\\in\\mathcal{P}(\\Omega)\\) es una œÉ-√°lgebra,\n\n\n\\(P\\colon \\mathcal{A} \\to [0,1]\\) es una medida de probabilidad que refleja las caracter√≠sticas aleatorias del experimento realizado.\n\nA esta terna se le llama espacio de probabilidad.\nLos resultados de un experimento aleatorio no son analizados ‚Äúen bruto‚Äù, sino que se les da una representaci√≥n num√©rica que facilita su tratamiento. Esto se logra introduciendo variables aleatorias, que asocian cada resultado \\(\\omega\\in \\Omega\\) con un valor num√©rico o vectorial, y sobre las cuales luego aplicamos t√©cnicas de inferencia estad√≠stica.\nEn todo estudio estad√≠stico partimos de un experimento aleatorio cuyo conjunto de resultados posibles se denomina espacio muestral Œ©. Para cuantificar dichos resultados definimos las siguientes estructuras:\n\nDefinition 3.1 (Variables Aleatorias) Sea \\((\\Omega,\\mathcal{A},P)\\) un espacio de probabilidad. Una variable aleatoria es una funci√≥n \\(X\\colon (\\Omega,\\mathcal{A})\\;\\longrightarrow\\; (\\mathbb{R},\\mathcal{B}),\\) tal que para todo \\(B\\in\\mathcal{B}\\) (la \\(\\sigma\\)-√°lgebra de Borel en ‚Ñù), \\(X^{-1}(B)\\;=\\;\\{\\omega\\in\\Omega : X(\\omega)\\in B\\}\\;\\in\\;\\mathcal{A}.\\)\n\nSi el espacio muestral \\(\\Omega\\) es finito o numerable, diremos que es un espacio discreto y las variables aleatorias asociadas al experimento normalmente estar√°n definidas como \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{Z}.\\)\nSi \\(\\Omega\\) es no numerable, entonces diremos que es un espacio continuo y \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{R}.\\)\n\n\nDefinition 3.2 Un vector aleatorio de dimensi√≥n \\(n\\) es \\(\\mathbf{X} = (X_1,\\dots,X_n)\\colon(\\Omega,\\mathcal{A})\\longrightarrow(\\mathbb{R}^n,\\mathcal{B}^n),\\) donde cada componente \\(X_i\\) es variable aleatoria y \\(\\mathcal{B}^n\\) la \\(\\sigma\\)-√°lgebra de Borel en ‚Ñù‚Åø.\n\n\nEjemplos Lanzamiento de dos monedas\nSea \\(\\Omega =\\{\\,CC,\\;C-,\\;-C,\\;--\\},\\) donde \\(C\\) = ‚Äúcara‚Äù y \\(-\\) = ‚Äúcruz‚Äù. Podemos definir:\\(X_1(\\omega) = \\text{n√∫mero de caras en }\\omega.\\) \\(X_2(\\omega) = 2 - X_1(\\omega)\\;=\\; \\text{n√∫mero de cruces}.\\) \\(X_3(\\omega) = \\bigl(X_1(\\omega)\\bigr)^2.\\)\nEntonces \\((X_1,X_2,X_3)\\) es un vector aleatorio de dimensi√≥n 3.\nTiempos de servicio en un servidor\nSean \\(T_i\\) los tiempos de servicio (en segundos) de las peticiones \\(i=1,2,3\\). Definimos\\(\\mathbf{T}=(T_1,T_2,T_3),\\quad S = T_1 + T_2 + T_3,\\quad M = \\max\\{T_1,T_2,T_3\\}.\\)\nLecturas de sensores en red distribuida\nEn tres nodos \\(i=1,2,3\\) medimos temperatura \\(X_{i,1}\\), presi√≥n \\(X_{i,2}\\) y humedad \\(X_{i,3}\\). El vector global es \\(\\mathbf{X} = (X_{1,1},X_{1,2},X_{1,3},\\,X_{2,1},\\dots,X_{3,3}) \\in \\mathbb{R}^9.\\)\n\nCon estas definiciones rigurosas disponemos ya de los objetos b√°sicos para, en las siguientes secciones, construir estimadores, estudiar su comportamiento asint√≥tico y contrastar hip√≥tesis sobre la distribuci√≥n subyacente \\(P\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#distribuci√≥n-de-una-variable-aleatoria.-funciones-de-distribuci√≥n-de-probabilidad-y-de-densidad",
    "href": "index.html#distribuci√≥n-de-una-variable-aleatoria.-funciones-de-distribuci√≥n-de-probabilidad-y-de-densidad",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.2 Distribuci√≥n de una variable aleatoria. Funciones de distribuci√≥n, de probabilidad y de densidad",
    "text": "3.2 Distribuci√≥n de una variable aleatoria. Funciones de distribuci√≥n, de probabilidad y de densidad\nDistribuci√≥n de una Variable Aleatoria\nLa realizaci√≥n de un experimento aleatorio da lugar a un resultado \\(\\omega\\in\\Omega\\) que es aleatorio. Por lo tanto, \\(X(\\omega)\\) es un valor de \\(\\mathbb{R}\\) tambi√©n aleatorio. Es decir, la variable aleatoria \\(X\\) induce una medida de probabilidad en \\(\\mathbb{R}\\). A esa medida de probabilidad se le llama distribuci√≥n de \\(X\\) o ley de \\(X\\). Una de las formas de caracterizar la distribuci√≥n de una variable aleatoria es dar su funci√≥n de distribuci√≥n \\(F_X\\), que est√° definida as√≠:\n\\(F_X(x) \\;=\\; P(X \\le x)\\;=\\; P\\bigl(\\{\\omega \\in \\Omega : X(\\omega) \\le x\\}\\bigr)\\;=\\; P\\bigl(X^{-1}((-\\infty, x])\\bigr).\\)$\nEn el caso de que \\(X\\) sea una variable aleatoria discreta, es decir, en el caso de que \\(X\\) solo tome una cantidad finita o numerable de valores de \\(\\mathbb{R}\\), su distribuci√≥n tambi√©n puede caracterizarse por su funci√≥n de probabilidad (o funci√≥n de masa de probabilidad) \\(f_X\\), definida como\n\\[f_X : \\mathbb{R} \\longrightarrow [0,1],\\qquad f_X(x) = P(X = x).\\]\nEsa funci√≥n solo es no nula en un conjunto finito o numerable. Supondremos en adelante, sin p√©rdida de generalidad, que ese conjunto est√° contenido en \\(\\mathbb{Z}\\). A partir de la funci√≥n de masa de probabilidad se puede calcular la probabilidad de que la variable aleatoria \\(X\\) tome valores en cualquier elemento \\(A \\subseteq \\mathbb{B}\\):\n\\(P(X \\in A) = \\sum_{x \\in A} f_X(x).\\) me\nLa funci√≥n de distribuci√≥n y la funci√≥n de masa de probabilidad se relacionan de la siguiente forma:\n\\(F_X(x) = \\sum_{u \\leq x} f_X(u), \\quad f_X(x) = F_X(x) - F_X(x^-),\\) donde \\(F_X(x^-) = \\lim_{h \\to 0^+} F_X(x - h)\\).\nUna clase relevante de variables aleatorias no discretas son las que poseen funci√≥n de densidad, es decir, aquellas cuya distribuci√≥n de probabilidad puede caracterizarse por una funci√≥n \\(f_X(x) \\geq 0\\) que cumple que:\n\\(P(X \\in A) = \\int_{x \\in A} f_X(x) \\, dx, \\quad \\text{para todo } A \\subseteq \\mathbb{B}.\\)\nLa relaci√≥n entre \\(F_X\\) y \\(f_X\\) es la siguiente:\n\\(F_X(x) = \\int_{-\\infty}^{x} f_X(u) \\, du, \\quad f_X(x) = \\frac{d}{dx} F_X(x),\\)\nsalvo quiz√°s en un n√∫mero finito de puntos \\(x \\in \\mathbb{R}\\). Las variables aleatorias que poseen funci√≥n de densidad se llaman variables aleatorias absolutamente continuas. Abusando del lenguaje, aqu√≠ nos referiremos a ellas como variables aleatorias continuas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#esperanza-y-varianza",
    "href": "index.html#esperanza-y-varianza",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.3 Esperanza y varianza",
    "text": "3.3 Esperanza y varianza\nSi se desea describir totalmente la distribuci√≥n de probabilidad de una variable aleatoria \\(X\\) acabamos de ver que podemos dar su funci√≥n de distribuci√≥n o su funci√≥n de masa o de densidad, seg√∫n el caso. Una descripci√≥n parcial puede efectuarse calculando algunas caracter√≠sticas de la variable aleatoria \\(X\\), como por ejemplo medidas de posici√≥n o de dispersi√≥n. Estudiaremos algunas de ellas.\nSe define la esperanza de una variable aleatoria \\(X\\) como la integral de Lebesgue de \\(X\\):\n\\(E(X) = \\int_{\\Omega} X(w) dP(w).\\)\nEn el caso de variables aleatorias discretas la esperanza puede calcularse como:\n\\(E(X) = \\sum_{w \\in \\Omega} X(w) P(w) = \\sum_{k \\in \\mathbb{Z}} k P(X = k) = \\sum_{k \\in \\mathbb{Z}} k f_X(k).\\)\nPor otro lado, la esperanza de una variable aleatoria continua se puede calcular as√≠:\n\\(E(X) = \\int_{\\mathbb{R}} x f_X(x) dx.\\)\nLa esperanza de una variable aleatoria \\(X\\) es una medida de posici√≥n de \\(X\\): es el centro de gravedad de la distribuci√≥n de probabilidad de \\(X\\).\nSi \\(h\\) es una funci√≥n medible \\(h : \\mathbb{R} \\rightarrow \\mathbb{R}\\), entonces \\(Y = h(X)\\) es tambi√©n variable aleatoria y su esperanza se puede calcular a partir de la distribuci√≥n de \\(X\\):\n\\(E(h(X)) = \\int_{\\Omega} h(X(w)) dP(w)\\) que en el caso de que \\(X\\) sea discreta puede reescribirse como\n\\(E(h(X)) = \\sum_{k \\in \\mathbb{Z}} h(k) f_X(k).\\)\nSi \\(X\\) es una variable aleatoria continua entonces\n\\(E(h(X)) = \\int_{\\mathbb{R}} h(x) f_X(x) dx.\\)\nSi existe \\(\\mu = E(X)\\) y es finita puede definirse una medida de dispersi√≥n de la variable aleatoria \\(X\\) a partir de una transformaci√≥n \\(h\\) de \\(X\\). Es lo que se denomina varianza de \\(X\\) y se define as√≠:\n\\(V(X) = E((X - \\mu)^2) = E(X^2) - \\mu^2 = E(X^2) - (E(X))^2.\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#funci√≥n-generadora-de-momentos",
    "href": "index.html#funci√≥n-generadora-de-momentos",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.4 Funci√≥n generadora de momentos",
    "text": "3.4 Funci√≥n generadora de momentos\nDada una variable aleatoria \\(X\\), o su funci√≥n de distribuci√≥n \\(F\\), vamos a definir otra funci√≥n generadora, como\n\\(M_X(t) = \\mathbb{E}(e^{tX}),\\) siempre que este valor esperado exista.\nNotemos que cuando \\(X\\) toma valores en los enteros no-negativos, \\(M_X(t) = \\phi_X(e^t)\\), donde \\(\\phi_X(s)=E[s^X]=\\sum_{k=0}^{\\infty}p_ks^k\\) para \\(s\\in[0,1]\\) es la funci√≥n generadora de probabilidad (f.g.p.) de la variable \\(X\\), con \\(p_k=P(X=k)\\). Si \\(X\\) est√° acotada, \\(M_X\\) est√° bien definida para todo \\(t\\) real; en cambio, si \\(X\\) no est√° acotada, es posible que el dominio de \\(M_X\\) no sea el conjunto de todos los reales. En todo caso, \\(\\phi\\) siempre est√° definida en cero, y \\(M(0) = 1\\).\nEs posible demostrar que si la f.g.m. de la v.a. \\(X\\) existe en un entorno de 0, entonces para todo \\(k &gt; 0\\),\n\\(\\mathbb{E}[|X|^k] &lt; \\infty.\\)\nM√°s a√∫n, la serie\n\\(M_X(t) =\n\\mathbb{E}(e^{tX})\n= \\mathbb{E}\\left(1 + \\sum_{k=1}^{\\infty} \\frac{t^k X^k}{k!}\\right)\n= 1 + \\sum_{n=1}^{\\infty} \\frac{t^k}{k!} \\mathbb{E}(X^k)\n\\tag{5.1}\\)\nes convergente y se puede derivar t√©rmino a t√©rmino. Obtenemos\n\\(M'_X(0) = \\mathbb{E}(X); \\quad M''_X(0) = \\mathbb{E}(X^2)\\)\ny en general\n\\(M_X^{(k)}(0) = \\mathbb{E}(X^k).\\)\nEs por esta √∫ltima propiedad que esta funci√≥n se conoce como funci√≥n generadora de momentos (f.g.m.).\nüé≤ Ejemplo: f.g.m. de la distribuci√≥n Binomial\nSea \\(X \\sim \\text{Binomial}(n, p)\\), es decir, la suma de \\(n\\) ensayos de Bernoulli con probabilidad de √©xito \\(p\\). La funci√≥n generadora de momentos es: Ejemplo fgm binomial\n\\(M_X(t) = \\mathbb{E}[e^{tX}] = (1 - p + p e^t)^n\\)\n ```` \nüìà Ejemplo: f.g.m. de la distribuci√≥n Normal Est√°ndar\nSea \\(X \\sim \\mathcal{N}(0, 1)\\). Su funci√≥n generadora de momentos es:\n\\(M_X(t) = \\mathbb{E}[e^{tX}] = e^{\\frac{t^2}{2}}\\)\nEsta expresi√≥n se obtiene usando la forma cerrada del momento de una normal est√°ndar.\n ```` \n‚ùì Preguntas gu√≠a sobre la gr√°fica de la funci√≥n generadora de momentos\nüìå ¬øQu√© representa la gr√°fica de la f.g.m. \\(M_X(t)\\)?\nLa gr√°fica muestra c√≥mo evoluciona el valor esperado de \\(e^{tX}\\) cuando \\(t\\) var√≠a. Esta funci√≥n codifica todos los momentos de la variable aleatoria \\(X\\), y por tanto, contiene informaci√≥n completa sobre su distribuci√≥n (si existe un entorno donde la f.g.m. es finita).\n\nüß≠ ¬øQu√© se observa en la f.g.m. de una distribuci√≥n Binomial? \n![Gr√°fica MGF Binomial]\n#Preguntas y respuestas\n\n\n¬øC√≥mo es el comportamiento de la f.g.m. cerca de \\(t = 0\\)?\nEn \\(t = 0\\), siempre se cumple que \\(M_X(0) = 1\\), ya que:\n\\(M_X(0) = \\mathbb{E}[e^{0 \\cdot X}] = \\mathbb{E}[1] = 1\\)\n\n\n¬øQu√© indica la curvatura de la gr√°fica?\nLa curvatura refleja el crecimiento exponencial de los momentos. Si la curva crece r√°pidamente hacia la derecha, significa que los momentos (media, varianza, etc.) tambi√©n crecen con rapidez.\n\n\n¬øPor qu√© la gr√°fica es convexa?\nTodas las funciones generadoras de momentos son estrictamente convexas en el intervalo donde est√°n definidas. Esto es una consecuencia de que derivadas sucesivas representan momentos positivos.\n\n\n¬øQu√© pasa si cambio los par√°metros \\(n\\) y \\(p\\)?\nAumentar $ n $ o \\(p\\) tiende a elevar la f.g.m. en el lado derecho, reflejando una mayor media y varianza.\n\n\n\nüìà ¬øC√≥mo se comporta la f.g.m. para la Normal Est√°ndar? \n![Gr√°fica MGF Normal]\nPreguntas y respuestas\n\n\n¬øPor qu√© es sim√©trica respecto al eje $ t = 0 $?\nPorque la normal est√°ndar es sim√©trica alrededor de su media $ = 0 $, y su f.g.m. tiene la forma:\n\n\n\\(M_X(t) = e^{t^2 / 2}\\)\nlo cual es una funci√≥n par: \\(M_X(-t)= M_X(t)\\).\n\n\n¬øQu√© tan r√°pido crece la funci√≥n?\nMuy r√°pido. El crecimiento es exponencial cuadr√°tico. Esto implica que los momentos de la normal crecen r√°pidamente en magnitud.\n\n\n¬øC√≥mo se relaciona esta gr√°fica con los momentos de la normal?\nDerivando sucesivamente la f.g.m. en $ t = 0 $, se obtiene:\n\\(\\mathbb{E}[X^k] = M_X^{(k)}(0)\\)\nPor tanto, la gr√°fica ‚Äúencierra‚Äù toda la informaci√≥n sobre los momentos.\n\n\n\nüß† Conclusi√≥n\nEstas gr√°ficas te permiten visualizar la informaci√≥n estad√≠stica codificada en una variable aleatoria. La f.g.m. no es solo una herramienta algebraica para obtener momentos, sino una forma poderosa de describir el comportamiento global de la variable.\n\n¬øQu√© pasa si dos variables tienen la misma f.g.m.?\n¬°Tienen la misma distribuci√≥n! (si la f.g.m. est√° definida en un entorno de 0).\n\nEjemplo: Distribuci√≥n uniforme \\(U(a,b)\\)\nSi \\[X \\sim U(a,b),\\]\nsu densidad es\\[f(x) = \\frac{1}{b - a}\\quad\\text{para }a &lt; x &lt; b,\\]\ny su funci√≥n generadora de momentos viene dada por\n\n\n\n\\[M(t)= \\int_a^b \\frac{e^{t x}}{b - a}\\,dx= \\frac{e^{b t} - e^{a t}}{t\\,(b - a)}.\\]\n\n\n(5.2)\n\n\nEn el caso particular de la distribuci√≥n uniforme en \\((0,1)\\) se obtiene\\[M(t) = \\frac{e^t - 1}{t}.\\]\n\nPara derivar la f√≥rmula #(5.2) y obtener los momentos, podemos usar el desarrollo en serie de la funci√≥n exponencial:\n\\[M(t)= \\frac{1}{t\\,(b - a)}\\bigl(e^{b t} - e^{a t}\\bigr) \\\\\n= \\frac{1}{t\\,(b - a)}\\Bigl[\\bigl(1 + \\sum_{n=1}^\\infty \\tfrac{(b t)^n}{n!}\\bigr)\n                    -\\bigl(1 + \\sum_{n=1}^\\infty \\tfrac{(a t)^n}{n!}\\bigr)\\Bigr] \\\\\n= \\frac{1}{b - a}\\sum_{n=1}^\\infty \\frac{b^n - a^n}{n!}\\,t^{n-1}.\n\\]\nEste es el desarrollo de Maclaurin de \\(M(t)\\) en \\(t=0\\); por tanto, sus derivadas en cero satisfacen\n\n\n\\[M^{(k)}(0)= \\frac{b^{k+1} - a^{k+1}}{(k+1)\\,(b - a)}.\\]\n\n\n(5.3)\n\n\nEn particular:\n\n\\[M'(0)= \\frac{b^2 - a^2}{2\\,(b - a)}= \\frac{a + b}{2},\\] que coincide con \\(\\mathbb{E}(X)\\).\n\\[M''(0)= \\frac{b^3 - a^3}{3\\,(b - a)}= \\frac{a^2 + a b + b^2}{3},\\]\n\ny un c√°lculo directo muestra que la varianza es\n\\[\\mathrm{Var}(X)= \\mathbb{E}(X^2) - \\bigl(\\mathbb{E}(X)\\bigr)^2= \\frac{(a + b)^2}{12}.\\]\nObservaci√≥n importante Sea \\(X\\) una v.a. con f.g.m. \\(M_X\\) y sea \\(Y=aX+b\\) una transformaci√≥n lineal de \\(X\\), entonces\n\\[M_Y(t)=E(e^{tY})=E(e^{t(aX+b)})=E(e^{taX}e^{tb})=e^{tb}E(e^{taX})=e^{tb}M_X(at)\\]\n\nTheorem 3.1 (fgm de suma de v.a.s) Si \\(X\\) tiene funci√≥n generadora de momentos \\(M(t)\\) que est√° definida en un entorno \\((-a,a)\\) de 0, entonces \\(M(t)\\) caracteriza a la distribuci√≥n de \\(X\\); es decir, si otra variable \\(Y\\) tiene la misma funci√≥n generadora de momentos, las distribuciones de \\(X\\) e \\(Y\\) coinciden.\n\n\nSi \\(X,Y\\) son variables aleatorias con funciones generadoras de momentos respectivas \\(M_X\\) y \\(M_Y\\) que existen en un dominio com√∫n \\(|t| &lt; d\\), entonces la f.g.m. de la suma \\(X+Y\\) est√° dada por     \\[\n\\begin{align}\nM_{X+Y}(t)&= \\mathbb{E}\\bigl[e^{t(X+Y)}\\bigr]\\\\\n&= \\mathbb{E}\\bigl[e^{tX}\\,e^{tY}\\bigr]\\\\\n&=\\mathbb{E}\\bigl[e^{tX}\\bigr]\\mathbb{E}\\bigl[e^{tY}\\bigr]\\\\\n&= M_X(t)\\,M_Y(t).\n\\end{align}\n\\tag{1}\n\\]      \nEste resultado se extiende a la suma de \\(n\\) variables aleatorias independientes. Si\n\\[S_n = X_1 + \\cdots + X_n,\\]\nentonces\n\\[M_{S_n}(t)= \\mathbb{E}\\bigl[e^{tS_n}\\bigr]= \\mathbb{E}\\Bigl[e^{t\\sum_{i=1}^n X_i}\\Bigr]= \\prod_{i=1}^n\\mathbb{E}\\bigl[e^{tX_i}\\bigr]= \\prod_{i=1}^n M_{X_i}(t).\\]\nLa funci√≥n generadora de momentos resulta particularmente √∫til cuando consideramos sucesiones de variables aleatorias, como lo muestra el siguiente teorema que enunciamos sin demostraci√≥n:\n\n\nTheorem 3.2 (de Continuidad) Sea \\(F_n(x)\\), \\(n\\ge1\\), una sucesi√≥n de funciones de distribuci√≥n con funciones generadoras de momentos respectivas \\(M_n(t)\\), definidas en \\(|t|&lt;b\\). Supongamos que cuando \\(n\\to\\infty\\),\n\\[\nM_n(t)\\,\\longrightarrow\\,M(t)\n\\quad\\text{para }|t|\\le a,\n\\]\ndonde \\(M(t)\\) es la funci√≥n generadora de momentos de la distribuci√≥n l√≠mite \\(F(x)\\). Entonces\n\\[\nF_n(x)\\,\\longrightarrow\\,F(x)\n\\quad\\text{cuando }n\\to\\infty\n\\]\npara todo punto \\(x\\) en el cual \\(F\\) es continua.\n\n\nTheorem 3.3 Laplace‚ÄìMoivre Sea \\(X_1, X_2, \\ldots, X_n\\) una sucesi√≥n de variables aleatorias i.i.d. con distribuci√≥n ( (p) ), donde ( 0 &lt; p &lt; 1 ). Sea:\n\\[\nS_n = X_1 + X_2 + \\cdots + X_n \\sim \\text{Binomial}(n, p)\n\\]\ny consideremos la variable tipificada:\n\\[\nZ_n = \\frac{S_n - np}{\\sqrt{np(1 - p)}}\n\\]\nEntonces, cuando ( n ), se tiene convergencia en distribuci√≥n a una normal est√°ndar:\n\\[\nZ_n \\xrightarrow{d} \\mathcal{N}(0, 1)\n\\]\nes decir,\n\\[\n\\lim_{n \\to \\infty} \\mathbb{P}(Z_n \\leq z) = \\Phi(z), \\quad \\text{para todo } z \\in \\mathbb{R}\n\\]\ndonde ( (z) ) es la funci√≥n de distribuci√≥n acumulada de la normal est√°ndar.\n\n\nProof. Demostraci√≥n usando funciones generadoras de momentos\nLa funci√≥n generadora de momentos (mgf) de \\(S_n \\sim \\text{Binomial}(n, p)\\) es:\n\\[\nM_{S_n}(t) = \\left(1 - p + p e^t\\right)^n\n\\]\nQueremos obtener la mgf de la variable tipificada ( Z_n ). Usamos la propiedad de cambio de variable de la mgf:\n\\[\nM_{Z_n}(t) = \\mathbb{E}\\left[ e^{t Z_n} \\right]\n= \\mathbb{E}\\left[ e^{t \\cdot \\frac{S_n - np}{\\sqrt{np(1 - p)}}} \\right]\n= e^{-t \\cdot \\frac{np}{\\sqrt{np(1 - p)}}} \\cdot M_{S_n}\\left( \\frac{t}{\\sqrt{np(1 - p)}} \\right)\n\\]\nSustituimos la mgf de ( S_n ):\n\\[\nM_{Z_n}(t) = \\exp\\left( -t \\cdot \\frac{np}{\\sqrt{np(1 - p)}} \\right)\n\\cdot \\left( 1 - p + p e^{t / \\sqrt{np(1 - p)}} \\right)^n\n\\]\nAproximaci√≥n por series de Taylor\nExpandimos \\(e^{t / \\sqrt{np(1 - p)}}\\) para \\(n\\) grande:\n\\[\ne^{t / \\sqrt{np(1 - p)}} = 1 + \\frac{t}{\\sqrt{np(1 - p)}} + \\frac{t^2}{2np(1 - p)} + \\cdots\n\\]\nEntonces:\n\\[\n1 - p + p e^{t / \\sqrt{np(1 - p)}} \\approx 1 + \\frac{pt}{\\sqrt{np(1 - p)}} + \\frac{pt^2}{2np(1 - p)} + \\cdots\n\\]\nUsamos que \\(\\log(1 + x) \\approx x - \\frac{x^2}{2} + \\cdots\\) para \\(x \\approx 0\\):\n\\[\\log M_{Z_n}(t) \\approx -t \\cdot \\frac{np}{\\sqrt{np(1 - p)}}+ n \\left( \\frac{pt}{\\sqrt{np(1 - p)}} + \\frac{pt^2}{2np(1 - p)} \\right)\\]\nSimplificamos:\n\nEl t√©rmino lineal se cancela:\n\n\\[\n-t \\cdot \\frac{np}{\\sqrt{np(1 - p)}} + n \\cdot \\frac{pt}{\\sqrt{np(1 - p)}} = 0\n\\]\n\nQueda:\n\n\\[\n\\log M_{Z_n}(t) \\to \\frac{t^2}{2}, \\quad \\text{cuando } n \\to \\infty\n\\]\nPor tanto:\n\\[\nM_{Z_n}(t) \\to e^{t^2 / 2}\n\\] Conclusi√≥n\nComo \\(e^{t^2/2}\\) es la mgf de \\(\\mathcal{N}(0, 1)\\), y por el teorema de unicidad de la funci√≥n generadora de momentos:\n\\[\nZ_n \\xrightarrow{d} \\mathcal{N}(0, 1)\n\\]\nEsto concluye la demostraci√≥n del Teorema de Laplace‚ÄìMoivre utilizando funciones generadoras de momentos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#muestra-aleatoria-simple",
    "href": "index.html#muestra-aleatoria-simple",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.5 Muestra aleatoria simple",
    "text": "3.5 Muestra aleatoria simple\nSea \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) un vector aleatorio. Se dice que sus componentes \\(X_1 ,..., X_n\\) son si \\(P(X_1\\leq x_1 ,..., X_n\\leq x_n)=P(X_1\\leq x_1)...P(X_n\\leq x_n)\\) para cualesquiera valores \\(x_1,..., x_n\\) .\nSi adem√°s la distribuci√≥n de las \\(n\\) variables aleatorias \\(X_i\\) es la misma, se dice que \\(X_1 ,...,X_n\\) son variables aleatorias independientes e id√©nticamente distribuidas, o bien que son v.a.i.i.d o simplemente i.i.d.\nSi \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) y \\(X_1 ,..., X_n\\) son i.i.d. con funci√≥n de densidad (en su caso, de masa) \\(f_X\\) , la distribuci√≥n conjunta de \\(\\underset{\\sim}{X}\\) viene dada por la funci√≥n de densidad (en su caso, de masa) conjunta \\[\n\\begin{align*}\nf_{\\underset{\\sim}{X}}(\\underset{\\sim}{x})&=f_{(X_1 ,..., X_n)}(x_1 ,..., x_n)\\\\\n&=f_{(X_1)}(x_1)...f_{(X_n)}(x_n)\\\\\n&=\\prod_{i=1}^{n}f_{(X_i)}(x_i)\n\\end{align*}\n\\]\nA un vector \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) de v.a.i.i.d. con distribuci√≥n igual a la de la variable aleatoria \\(X\\) se le denomina tambi√©n muestra aleatoria simple de \\(X\\) (m.a.s de \\(X\\)).\nEsto responde al hecho siguiente. Supongamos que se desea estudiar la caracter√≠stica \\(X\\) de los individuos de una poblaci√≥n de tama√±o infinito. Definimos el experimento consistente en elegir aleatoriamente un individuo de la poblaci√≥n y llamamos \\(X\\) al valor de la caracter√≠stica de inter√©s en ese individuo. X es una variable aleatoria.\nSi definimos un nuevo experimento consistente en elegir una muestra aleatoria de n individuos y se anota \\(X_i\\), el valor de la caracter√≠stica en el individuo i-√©simo, entonces X \\(=(X_1 ,..., X_n)\\) es una colecci√≥n de n v.a.i.i.d. con distribuci√≥n igual a la de la variable aleatoria \\(X\\), es decir, \\(X_1 ,..., X_n\\) es una m.a.s. de X.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#modelo-param√©trico",
    "href": "index.html#modelo-param√©trico",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.6 Modelo param√©trico",
    "text": "3.6 Modelo param√©trico\nUsualmente la ley de probabilidad de una variable aleatoria se supone perteneciente a un modelo matem√°tico que depende s√≥lo de un n√∫mero finito de par√°metros: \\(f_X \\in\\{f(x|\\theta):\\theta \\in \\Theta \\subseteq \\mathbb{R}^k\\}\\). Escribiremos alternativamente \\(f(x;\\theta)\\), \\(f(x|\\theta)\\) o \\(f_\\theta(x)\\).\n\nDefinition 3.3 El conjunto de distribuciones dadas por \\(f_\\theta(x)\\), \\(\\theta \\in \\Theta\\) se llama familia param√©trica de distribuciones. \\(\\Theta\\) es el conjunto de par√°metros.\n\n\nDefinition 3.4 La correspondiente distribuci√≥n conjunta de una muestra aleatoria simple de \\(X\\) viene dada por la funci√≥n de densidad (o funci√≥n de masa de probabilidad, seg√∫n el caso)\n\\[\nf_{\\underset{\\sim}{X}}(\\underset{\\sim}{x} \\mid \\theta) = \\prod_{i=1}^{n} f_{\\theta}(x_i)\n\\]\nA esta funci√≥n la llamaremos funci√≥n de verosimilitud de la muestra \\(X_{\\sim}\\). Utilizaremos este t√©rmino para referirnos indistintamente a la funci√≥n de densidad conjunta (si las variables aleatorias son continuas) o a la funci√≥n de masa conjunta (si son discretas).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#sumas-de-variables-aleatorias",
    "href": "index.html#sumas-de-variables-aleatorias",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.7 Sumas de variables aleatorias",
    "text": "3.7 Sumas de variables aleatorias\nCuando se obtiene una muestra aleatoria simple \\(X_{1},X_{2},\\ldots,X_{n}\\) normalmente se calculan a partir de ellas cantidades que resumen los valores observados. Cualquiera de estos res√∫menes se puede expresar como una funci√≥n \\(T(x_1,\\ldots,x_n)\\) definida en el espacio \\(\\mathcal{X}^n\\subseteq\\mathbb{R}^n\\) donde est√°n las im√°genes del vector \\((X_{1},X_{2},\\ldots,X_{n})\\).\nEsta funci√≥n \\(T\\) puede devolver valores de \\(\\mathbb{R}\\), \\(\\mathbb{R}^2\\) o, en general, \\(\\mathbb{R}^k\\).\n\\[T(X_1 , \\ldots, X_n)=\\sum_{i=1}^{n}X_i,\\bar{X},\\bar{X}+3, \\min{X_1 , \\ldots, X_n},\\] \\[T(X_1 , \\ldots, X_n)=\\left(\\sum_{i=1}^{n}X_i,\\sum_{i=1}^{n}(X_i-\\bar{X})^2\\right),\\] \\[T(X_1 , \\ldots, X_n)=\\left(\\min\\{X_1 , \\ldots, X_n\\},\\sum_{i=1}^{n}X_i,\\sum_{i=1}^{n}(X_i-\\bar{X})^2\\right),\\] \\[T(X_1 , \\ldots, X_n)= (X_1 , \\ldots, X_n)\\]\n\nDefinition 3.5 (Definici√≥n de estad√≠sticos) Las funciones \\(T\\) que dependen de una muestra aleatoria simple \\(X_1 , \\ldots, X_n\\) se llaman estad√≠sticos. Dependen de los valores observados, pero no de los par√°metros desconocidos que determinan la distribuci√≥n de \\(X_i\\) .\n\nCuando un estad√≠stico \\(T\\) es utilizado con el prop√≥sito de estimar un par√°metro \\(\\theta\\) diremos que \\(T\\) es un estimador de \\(\\theta\\).\nEjemplo de estad√≠stico\n\\(T(X_1 , \\ldots, X_n)=\\bar{X}\\) es un estimador de \\(E(X)=\\mu\\).\nEn inferencia estad√≠stica interesa saber qu√© estad√≠sticos son suficientes para recoger toda la informaci√≥n que la muestra aporta sobre la distribuci√≥n de la variable aleatoria X muestreada. La respuesta depende de la distribuci√≥n de X.\n\nDefinition 3.6 (Definici√≥n distribuci√≥n en el muestreo) Dado que \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) es una variable aleatoria, se tiene que \\(Y=T(\\underset{\\sim}{X})=T(X_1 ,..., X_n)\\) ser√° tambi√©n una variable aleatoria. La ley de probabilidad de \\(Y\\) se denomina distribuci√≥n en el muestreo de \\(Y\\) (o distribuci√≥n muestral). Los siguientes resultados dan informaci√≥n sobre algunas caracter√≠sticas de estad√≠sticos definidos a partir de sumas de variables aleatorias.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#estad√≠sticos-definidos-a-partir-de-sumas-de-variables-aleatorias",
    "href": "index.html#estad√≠sticos-definidos-a-partir-de-sumas-de-variables-aleatorias",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.8 Estad√≠sticos definidos a partir de sumas de variables aleatorias",
    "text": "3.8 Estad√≠sticos definidos a partir de sumas de variables aleatorias\n\nTheorem 3.4 Sean \\(X_1,\\ldots, X_n\\),n n√∫meros reales, sea \\(\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n}x_i\\) su media aritm√©tica y sea \\(S_n^2=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n-1}\\) su varianza muestral.\n\n\\(\\min_a\\sum_{i=1}^{n}(x_i-a)^2=\\sum_{i=1}^{n}(x_i-\\bar{x})^2\\)\n\\((n-1)S_n^2=\\sum_{i=1}^{n}(x_i-\\bar{x})^2=\\sum_{i=1}^{n}x_i^2-n\\bar{x}^2\\)\n\n\n\nLemma 3.1 Sea \\(X_1,\\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) y sea \\(g(x)\\) una funci√≥n tal que \\(E(g(X))\\) y \\(Var(g(X))\\) existen. Entonces,\n\n\n\\(E(\\sum_{i=1}^{n}g(X_i))=nE(g(X))\\),\n\n\\(Var(\\sum_{i=1}^{n}g(X_i))=nVar(g(X))\\).\n\n\n\nProof. Para la demostraci√≥n ver G√≥mez et al.¬†(2006)\n\n\nTheorem 3.5 Sea \\(X 1,\\ldots, X_n\\) una muestra aleatoria simple de una poblaci√≥n \\(X\\) con esperanza \\(\\mu\\) y varianza \\(\\sigma^2 &lt; \\infty\\). Sean \\[\n        \\begin{align*}\n        &\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_i,\\ \\\n        S^2=\\frac{\\sum_{i=1}^{n}(X_i-\\bar{X})^2}{n-1},\n        \\end{align*}    \n\\] la media y la varianza muestrales, respectivamente. Entonces,\n\n\\(E(\\bar{X}) = \\mu,\\)\n\\(Var(\\bar{X}) = \\frac{\\sigma^2}{n},\\)\n\n\\(E(S^2) = \\sigma^2\\).\n\n\n\nTheorem 3.6 Sea \\(X 1,\\ldots, X_n\\) una muestra aleatoria simple de una poblaci√≥n \\(X\\) con funci√≥n generadora de momentos \\(M_X(t)\\). La funci√≥n generatriz de momentos de \\(X\\) es \\[\\begin{align*}\n        &M_{\\bar{X}}(t)=\\left(M_X\\left(\\frac{t}{n}\\right)\\right)^n\n        \\end{align*}\n\\]\n\n\nTheorem 3.7 (Combinaci√≥n lineal de normales es normal) (Wackerly et al.¬†(2008)) Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) variables aleatorias independientes normalmente distribuidas \\(E(Y_i)=\\mu_i\\) y \\(V(Y_i)=\\sigma_i^2\\)ara \\(i=1,\\cdots,\\,n\\) y sean \\(a_1,\\,a_2,\\cdots,\\,a_n\\) constantes. Si \\[U=\\sum_{i=1}^na_iY_i\\]\nentonces \\(U\\) es una variable aleatoria normalmente distribuida con \\[E(U)=\\sum_{i=1}^na_i\\mu_i\\] y \\[V(U)=\\sum_{i=1}^na_i^2\\sigma^2_i\\]\n\nEjemplo \\(X 1,\\ldots, X_n\\) m.a.s. de \\(X \\sim N(\\mu,\\sigma^2)\\). Entonces, \\(M_{X}(t)=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2}\\right\\}\\). De ah√≠ que\n\\[\n    \\begin{align*}\n    M_{\\bar{X}}(t)\n    &=\\left(\\exp\\left\\{\\mu \\frac{t}{n}+ \\frac{\\sigma^2\\left(\\frac{t}{n}\\right)^2}{2}\\right\\}\\right)^n\n    \\end{align*}\n\\]\n\\(X 1,\\ldots, X_n\\) m.a.s. de \\(X \\sim N(\\mu,\\sigma^2)\\). Entonces, \\(M_{X}(t)=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2}\\right\\}\\). De ah√≠ que \\[\n        \\begin{align*}\n        M_{\\bar{X}}(t)&=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2n}\\right\\}\n        \\end{align*}\n\\] De ah√≠ que \\(\\bar{X}\\sim N(\\mu,\\frac{\\sigma^2}{n})\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#muestreo-de-una-distribuci√≥n-normal",
    "href": "index.html#muestreo-de-una-distribuci√≥n-normal",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.9 Muestreo de una distribuci√≥n normal",
    "text": "3.9 Muestreo de una distribuci√≥n normal\n\n3.9.1 Definici√≥n de distribuci√≥n Chi cuadrada\n\nDefinition 3.7 (Wackerly et al.¬†(2008)) Sea \\(\\nu\\) un entero positivo. Se dice que una v.a \\(Y\\) tiene distribuci'on chi cuadrada con \\(\\nu\\) grados de libertad si y s√≥lo si \\(Y\\) es una vriable aleatoria con distribuci√≥n gamma y par√°metros \\(\\alpha=\\nu/2\\) y \\(\\beta=2\\).\n\n\nTheorem 3.8 (Teorema de Fisher) En el resto del tema supondremos que \\(X 1,\\ldots, X_n\\) m.a.s. de una \\(N(\\mu, \\sigma^2)\\).\n\n\n\\(\\bar{X}\\) y \\(S_n^2\\) son variables aleatorias independientes.\n\\(\\bar{X}\\sim N(\\mu, \\frac{\\sigma^2}{n})\\)\n\\(\\frac{(n-1)S_n^2}{\\sigma^2}\\sim \\mathcal{X}^2_{n-1}.\\)\n\n\n\n3.9.2 Distribuciones asociadas a la normal\n\nTheorem 3.9 (Wackerly et al.¬†(2008)) Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) definidas como en el Teorema Theorem¬†3.7 de Wackerly et al.¬†(2008) y definimos \\(Z_i\\) por \\[Z_i=\\frac{Y_i-\\mu_i}{\\sigma_i}\\] con \\(i=1,\\,2,\\cdots,\\,n\\). Entonces \\(\\sum_{i=1}^nZ_i^2\\) tiene distribuici'on \\(\\chi^2\\) con \\(n\\) grados de libertad.\n\n\nTheorem 3.10 (Wackerly et al.¬†(2008)) Si \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) es una muestra aleatoria de una distribuci'on normal con media \\(\\mu\\) y varianza \\(\\sigma^2\\), \\(Y_i\\), \\(i=1,\\,2,\\cdots,n\\) son v.a‚Äôs independientes distribu'idas normalmente, con \\(E(Y_i)=\\mu\\) y \\(V(Y_i)=\\sigma^2\\).\nEntonces \\[Z_i=\\frac{Y_i-\\mu}{\\sigma}\\] son v.a‚Äôs independientes, \\(i=1,\\,2,\\cdots,n\\) y \\[\\sum_{i=1}^nZ_i^2=\\sum_{i=1}^n\\left(\\frac{Y_i-\\mu}{\\sigma}\\right)^2\\]tienen una distribuci'on \\(\\chi^2\\) con \\(n\\) grados de libertad (gl).\n\n\nTheorem 3.11 (Wackerly et al.¬†(2008)) Sea \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) una muestra aleatoria con media \\(\\mu\\) y varianza \\(\\sigma^2\\). Entonces \\[\\frac{(n-1)S^2}{\\sigma^2}=\\frac{1}{\\sigma^2}\\sum_{i=1}^n(Y_i-\\overline{Y})^2\\] tiene una distribuci'on \\(\\chi^2\\) con \\((n-1)\\) gl. \\(\\overline{Y}\\) y \\(S^2\\) son v.a independientes.\n\n\nDefinition 3.8 (Wackerly et al.¬†(2008)) Sea \\(Z\\) una v.a normal est'andar y sea \\(W\\) una v.a con distribuci'on \\(\\chi^2_\\nu\\). Entonces, si \\(W\\) y \\(Z\\) son ind \\[T=\\frac{Z}{\\sqrt{W/\\nu}}\\] se dice que tiene una distribuci'on \\(t\\) con \\(\\nu\\) grados de libertad.\n\n\n\n\n\n\n\nObservaci√≥n 1\n\n\n\nSi \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\sim N(\\mu,\\sigma^2)\\) del Teorema (Combinaci√≥n lineal de normales es normal) \\[Z=\\frac{\\sqrt{n}(\\overline{Y}-\\mu)}{\\sigma}\\sim N(0,1)\\] El teorema Observaci√≥n 1 nos dice que \\[W=\\frac{(n-1)S^2}{\\sigma^2}\\sim\\chi^2_{n-1}\\] y que \\(Z\\) y \\(W\\) son ind.\n\n\n\n\n\n\n\n\nObservaci√≥n 2\n\n\n\nPor tanto, de la definici√≥n 7.2 se tiene la siguiente expresi√≥n: \\[\n\\begin{aligned}\nT &= \\frac{Z}{\\sqrt{W/\\nu}} \\\\\n  &= \\frac{\\sqrt{n}(\\overline{Y}-\\mu)/\\sigma}{\\sqrt{\\left[\\frac{(n-1)S^2}{\\sigma^2}\\right]/(n-1)}} \\\\\n  &= \\sqrt{n}\\left(\\frac{\\overline{Y}-\\mu}{S}\\right)\n\\end{aligned}\n\\]\nTiene distribuci√≥n \\(t\\) con \\((n-1)\\) grados de libertad.\n\n\nComo se indica en la Observaci√≥n 7.1, esta propiedad‚Ä¶\n\nDefinition 3.9 Sean \\(W_1\\) y \\(W_2\\) v.a‚Äôs independientes con distribuci√≥n \\(\\chi^2\\), con \\(\\nu_1\\) y \\(\\nu_2\\) grados de libertad respectivamente. Entonces se dice que: \\[F=\\frac{W_1/\\nu_1}{W_2/\\nu_2}\\] tiene una distribuc'on \\(F\\) con \\(\\nu_1\\) grados de libertad en el numerador y \\(\\nu_2\\) grados de libertad en el denominador.\n\n\nRemark 3.1. Considerando dos muestras aleatorias independientes tomadas de distribuiciones normales \\[W_1=\\frac{(n_1-1)S_1^2}{\\sigma_1^2}\\sim\\chi^2_{n_1-1}\\] \\[W_1=\\frac{(n_2-1)S_2^2}{\\sigma_2^2}\\sim\\chi^2_{n_2-1}\\] \\(W_1\\bot W_2\\).\n\n\nRemark 3.2. \\[\n\\begin{eqnarray*}\n            F&=&\\frac{W_1/\\nu_1}{W_2/\\nu_2}\\\\\n            &=&\\frac{[(n_1-1)S_1^2/\\sigma_1^2]/(n_1-1)}{[(n_2-1)S_2^2/\\sigma_2^2]/(n_2-1)}\\\\\n            &=&\\frac{S_1^2/\\sigma_1^2}{S_2^2/\\sigma_2^2}\n        \\end{eqnarray*}\n\\] tiene distribuci'on \\(F\\) con \\((n_1-1)\\) gl en el numerador y \\((n_2-1)\\) gl en el denominador\n\n\nlibrary(ggplot2)\n\nfigura_densidad_asimetrica &lt;- function(alpha = 0.05) {\n  shape &lt;- 2\n  rate &lt;- 1\n  \n  # Cuantil de inter√©s\n  F_alpha &lt;- qgamma(1 - alpha, shape = shape, rate = rate)\n  \n  # Datos para la densidad\n  x_vals &lt;- seq(0, 10, length.out = 1000)\n  df &lt;- data.frame(\n    x = x_vals,\n    y = dgamma(x_vals, shape = shape, rate = rate)\n  )\n  \n  # Datos para el sombreado\n  df_shaded &lt;- subset(df, x &gt;= F_alpha)\n  \n  # Altura de la flecha\n  y_arrow &lt;- dgamma(F_alpha, shape, rate)\n  \n  ggplot(df, aes(x, y)) +\n    geom_line(linewidth = 1.2) +\n    geom_area(data = df_shaded, aes(x, y), fill = \"black\", alpha = 0.3) +\n    \n    # Flecha vertical\n    annotate(\"segment\", x = F_alpha, xend = F_alpha, y = 0, yend = y_arrow,\n             arrow = arrow(length = unit(0.15, \"cm\")), color = \"black\") +\n    \n    # Etiqueta F_Œ±\n    annotate(\"text\", x = F_alpha, y = 0, label = expression(F[alpha]),\n             vjust = 1.5, hjust = 1.1, size = 5) +\n    \n    # Etiqueta Œ±\n    annotate(\"text\", x = F_alpha, y = y_arrow, label = expression(alpha),\n             vjust = -1, size = 5) +\n    \n    labs(x = \"u\", y = expression(f(u))) +\n    theme_minimal(base_size = 14)\n}\nfigura_densidad_asimetrica()\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\n\n\n\n\n\n\nEjercicios con la distribuci√≥n F en R\nA continuaci√≥n se presentan dos ejercicios t√≠picos en los que anteriormente se utilizaban tablas de valores cr√≠ticos de la distribuci√≥n F. Ahora, gracias a funciones como qf() y var.test() en R, estos an√°lisis pueden hacerse de manera precisa y autom√°tica.\n\nEjercicio 1: Contrastar dos varianzas\nEnunciado:\nSe tienen dos muestras independientes con: - Tama√±os: \\(n_1 = 6\\), \\(n_2 = 10\\) - Varianzas muestrales: \\(s_1^2 = 25\\), \\(s_2^2 = 10\\)\n¬øExiste evidencia para afirmar que las varianzas poblacionales son diferentes al nivel de significancia del 5%?\nSoluci√≥n en R:\n\n# Datos\ns1_sq &lt;- 25\ns2_sq &lt;- 10\nn1 &lt;- 6\nn2 &lt;- 10\n\n# Estad√≠stico F observado (mayor varianza sobre menor)\nF_obs &lt;- s1_sq / s2_sq\ngl1 &lt;- n1 - 1\ngl2 &lt;- n2 - 1\n\n# Cuantiles cr√≠ticos para prueba bilateral al 5%\nalpha &lt;- 0.05\nF_inf &lt;- qf(alpha / 2, df1 = gl1, df2 = gl2)\nF_sup &lt;- qf(1 - alpha / 2, df1 = gl1, df2 = gl2)\n\n# Decisi√≥n\ncat(\"F observado:\", round(F_obs, 3), \"\\n\")\n\nF observado: 2.5 \n\ncat(\"Intervalo de aceptaci√≥n: [\", round(F_inf, 3), \",\", round(F_sup, 3), \"]\\n\")\n\nIntervalo de aceptaci√≥n: [ 0.15 , 4.484 ]\n\nif (F_obs &lt; F_inf || F_obs &gt; F_sup) {\n  cat(\"Se rechaza H0: las varianzas son significativamente diferentes.\\n\")\n} else {\n  cat(\"No se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.\\n\")\n}\n\nNo se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.\n\n\nEjercicio 2: Obtener un valor cr√≠tico F directamente\nEnunciado:\nCalcular el valor cr√≠tico \\(F_{0.05,\\,5,\\,9}\\) para una prueba unilateral con nivel de significancia del 5%.\nEste valor se usa, por ejemplo, cuando se contrasta si una varianza es significativamente mayor que otra, con: - \\(\\alpha = 0.05\\) - \\(\\text{gl}_1 = 5\\) (grados de libertad del numerador) - \\(\\text{gl}_2 = 9\\) (grados de libertad del denominador)\nC√°lculo en R:\n\n# Valor cr√≠tico F para prueba unilateral con alpha = 0.05\nqf(0.95, df1 = 5, df2 = 9)\n\n[1] 3.481659\n\n\nEl valor cr√≠tico es \\(F_{0.05,\\,5,\\,9}=3.478\\). Si el estad√≠stico F observado es mayor que este valor, se rechaza la hip√≥tesis nula de igualdad de varianzas a favor de que la varianza del numerador es mayor.\n\nExample 3.1 \\[Y_1^1,\\,Y_2^1\\,\\cdots,\\,Y_{n_1}^1\\sim N(\\mu_1,\\,\\sigma^2)\\] \\[Y_1^2,\\,Y_2^2\\,\\cdots,\\,Y_{n_2}^2\\sim N(\\mu_2,\\,\\sigma^2)\\] \\(P\\left(\\frac{S_1^2}{S_2^2}\\leq b\\right)=0.95\\) con \\(n_1=6\\) y \\(n_2=10\\), ?`\\(b\\)?\nComo \\(n_1=6\\) y \\(n_2=10\\) y las varianzas poblacionales son iguales, entonces \\(\\frac{S_1^2/\\sigma_1^2}{S_2^2/\\sigma_2^2}=\\frac{S_1^2}{S_2^2}\\sim F_{5,9}\\) \\[P\\left(\\frac{S_1^2}{S_2^2}\\leq b\\right)= F_{5,9}(b)=0.95\\] entonces \\(qf(0.95,\\,5,\\,9)=b\\), \\(b=3.48\\).\n\nSimulaci√≥n del comportamiento del promedio muestral\nSimulamos 1000 repeticiones del promedio muestral a partir de una distribuci√≥n exponencial con media ( = 10 ), para distintos tama√±os de muestra ( n ).\n\nsimular_promedios &lt;- function(n, repeticiones = 1000, media = 10) {\n  promedios &lt;- replicate(repeticiones, mean(rexp(n, rate = 1 / media)))\n  data.frame(\n    `n` = n,\n    `Promedio repetido` = mean(promedios),\n    `Media te√≥rica` = media,\n    `Varianza repetida` = var(promedios),\n    `Varianza te√≥rica` = media^2 / n\n  )\n}\n\n# Evaluar para varios tama√±os\ntama√±os &lt;- c(5, 10, 25, 50, 100)\nresultados &lt;- do.call(rbind, lapply(tama√±os, simular_promedios))\nknitr::kable(resultados, digits = 5)\n\n\n\n\n\n\n\n\n\n\nn\nPromedio.repetido\nMedia.te√≥rica\nVarianza.repetida\nVarianza.te√≥rica\n\n\n\n5\n10.05745\n10\n20.54672\n20\n\n\n10\n10.03966\n10\n9.68542\n10\n\n\n25\n9.96320\n10\n3.94066\n4\n\n\n50\n10.04156\n10\n2.12393\n2\n\n\n100\n9.98516\n10\n0.98940\n1\n\n\n\n\n\n\nTheorem 3.12 Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) v.a‚Äôs con funciones generadoras de momentos \\(m(t)\\) y \\(m_1(t),\\,m_2(t),\\cdots,\\) respectivamente. Si \\[\\lim_{n\\rightarrow\\infty}m_n(t)=m(t)\\mbox{ para toda $t$ real,}\\] entonces la funci'on de distribuci'on de \\(Y_n\\) converge hacia la funci'on de distribuci'on de \\(Y\\) cuando \\(n\\rightarrow\\infty\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#leyes-de-los-grandes-n√∫meros-y-teorema-central-del-l√≠mite",
    "href": "index.html#leyes-de-los-grandes-n√∫meros-y-teorema-central-del-l√≠mite",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.10 Leyes de los Grandes N√∫meros y Teorema Central del L√≠mite",
    "text": "3.10 Leyes de los Grandes N√∫meros y Teorema Central del L√≠mite\n\n3.10.1 Leyes de los grandes n√∫meros\n\nDefinition 3.10 Una sucesi√≥n de variables aleatorias converge en media a \\(X\\), y se denota por \\(X_{n}\\xrightarrow{cm}X\\) , si para cualquier \\(\\epsilon&gt;0\\) se tiene que:\n[{n}E(|X{n}-X|)=0,] siempre que dicha esperanza exista.\\\nDe forma an√°loga se define convergencia en media de orden r si: \\[\\lim _{n\\to \\infty }E(\\left|X_{n}-X\\right|^r)=0,\\]\nCuando \\(r=2\\) se dice que se tiene convergencia en media cuadr√°tica\n\\[\\lim _{n\\to \\infty }E(\\left|X_{n}-X\\right|^2)=0,\\]\n\n\n3.10.2 Relaciones entre tipos de convergencias",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#diagrama-de-convergencias",
    "href": "index.html#diagrama-de-convergencias",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.11 Diagrama de convergencias",
    "text": "3.11 Diagrama de convergencias\n\n3.11.1 Diagrama de relaciones entre tipos de convergencia\n\nDiagrama de convergencias\n\n\n\n3.11.2 Ley d√©bil de los grandes n√∫meros\n\nTheorem 3.13 Sea \\(X 1,\\ldots, X_n\\) una sucesi√≥n de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante \\(C\\), independiente de \\(n\\). Sea \\(S_n = \\sum_{i=1  }^{n}X_i\\). Entonces \\[\n\\begin{align}\nE\\left(\\left|\\frac{S_n-E(S_n)}{n}\\right|^2\\right)\\leq \\frac{C}{n}\n\\end{align}\n\\] y, como consecuencia \\[\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}=0\\] en el sentido de la convergencia en media cuadr√°tica.\n\nLos resultados que garantizan la convergencia casi segura de la media muestral se conocen como leyes fuertes de los grandes n√∫meros. Se enuncia a continuaci√≥n una ley fuerte para variables con segundos momentos finitos e incorreladas.\n\n3.11.3 Ley fuerte de los grandes n√∫meros\n\nTheorem 3.14 Sea \\(X 1,\\ldots, X_n\\) una sucesi√≥n de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante \\(C\\), independiente de \\(n\\). Sea \\(S_n = \\sum_{i=1  }^{n}X_i\\). Entonces \\[\n        \\begin{align}\n        E\\left(\\left|\\frac{S_n-E(S_n)}{n}\\right|^2\\right)\\leq \\frac{C}{n}\n        \\end{align}\n        \\] y, como consecuencia \\[\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}=0\\] en el sentido de la casi segura.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#teorema-central-del-l√≠mite",
    "href": "index.html#teorema-central-del-l√≠mite",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.12 Teorema central del l√≠mite",
    "text": "3.12 Teorema central del l√≠mite\n\nTheorem 3.15 Central de L√≠mite Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) v.a‚Äôs iid ( no se precisa de que distribuci'on se generan) con \\(E[Y_i]=\\mu\\) y \\(V[Y_i]=\\sigma^2&lt;\\infty\\). Definamos \\[U_n=\\frac{\\sum_{i=1}^nY_i-n\\mu}{\\sigma\\sqrt{n}}=\\frac{\\overline{Y}-\\mu}{\\sigma/\\sqrt{n}}\\mbox{ donde} \\overline{Y}=\\frac{1}{n}\\sum_{i=1}^nY_i\\] Entonces la funci√≥n de distribuci√≥n de \\(U_n\\) converge hacia la funci√≥n de distribuci√≥n normal est√°ndar cuando n tiende a infinito . Esto es, \\[\\lim_{n\\rightarrow\\infty}P(U_n\\leq u)=\\int_{-\\infty}^u\\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2}dt, \\forall u\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#referencias",
    "href": "index.html#referencias",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.13 Referencias",
    "text": "3.13 Referencias\n\nG√≥mez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisi√≥n. Departament d‚ÄôEstad√≠stica i Investigaci√≥ Operativa, Universitat Polit√®cnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estad√≠stica matem√°tica con aplicaciones (7¬™ ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "2¬† Principios para reducir los datos",
    "section": "",
    "text": "2.1 Principio de suficiencia",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#principio-de-suficiencia",
    "href": "chapter1.html#principio-de-suficiencia",
    "title": "2¬† Principios para reducir los datos",
    "section": "",
    "text": "2.1.1 Estad√≠sticos suficientes minimales\n¬øEste proceso de resumir los datos a los dos estad√≠sticos \\(\\overline{Y}\\) y \\(S^2\\) conserva la informaci√≥n de \\(\\mu\\) y \\(\\sigma^2\\) en el conjunto original de \\(n\\) observaciones muestrales? O bien ¬øSe ha perdido u ocultado alguna informaci√≥n acerca de estos par√°metros en el proceso de reducir los datos?\nPresentamos m√©todos para hallar estad√≠sticos que en cierto sentido resumen toda la informaci√≥n de una muestra acerca de un par√°metro objetivo. Se dice que estos estad√≠sticos tienen la propiedad de suficiencia o son estad√≠sticos suficientes.\n\nExample 2.1 Sean \\(n\\) experimentos binomiales, \\(X_1,\\,X_2,\\cdots,\\,X_n\\), donde \\[\n\\begin{eqnarray*}\n        X_i&=&\\left\\{\\begin{array}{ll}1,&\\mbox{si el $i$-\\'esimo intento es un \\'exito,}\\\\0,&\\mbox{si el $i$-\\'esimo intento es un fracaso.}\\end{array}\\right.\\\\\n        X_i&=&\\left\\{\\begin{array}{ll}1,&\\mbox{con probabilidad $p$,}\\\\0,&\\mbox{con probabilidad $q=1-p$.}\\end{array}\\right.\n    \\end{eqnarray*}\n\\] Sea \\(Y=\\sum_{i=1}^n X_i\\) el n√∫mero de √©xitos en los \\(n\\) intentos. Si conocemos el valor de \\(Y\\), ¬øPodemos obtener alguna informaci√≥n adicional acerca de \\(p\\) al ver otras funciones de \\(X_1,\\,X_2,\\cdots,\\,X_n\\)?\n\\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n|Y=y)\\\\\n&=\\frac{P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)}{P(Y=y)}\n\\end{align*}\n\\] El numerador es \\(0\\) si \\(\\sum_{i=1}^nx_i\\neq y\\) dado que no pueden suceder los eventos al mismo tiempo.\nSi \\(\\sum_{i=1}^nx_i= y\\) entonces \\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)\\\\\n&=P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n)\n\\end{align*}\n\\] Por tanto el numerador queda \\(p^y(1-p)^{n-y}\\), dado que hay \\(y\\) unos y \\(n-y\\) ceros.\nEl denominador \\[P(Y=y)=\\displaystyle{a\\choose b} p^y(1-p)^{n-y}\\] porque \\(Y\\sim Bin(n,p)\\). \\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)\\\\\n&=\\left\\{\\begin{array}{ll}\\frac{p^y(1-p)^{n-y}}{\\left({n \\atop y}\\right) p^y(1-p)^{n-y}}=\\frac{1}{\\left({n \\atop y}\\right)},& si\\sum_{i=1}^nx_i= y\\\\0,&\\mbox{ en cualquier otro punto.}\\end{array}\\right.\n\\end{align*}\n\\] \\(\\frac{1}{\\left({n \\atop y}\\right)}\\) no depende de \\(p\\)\n\nUna vez que se conozca \\(Y\\), ninguna otra funci√≥n de \\(X_1,\\,X_2,\\cdots,\\,X_n\\) proporcionara m√°s informaci√≥n sobre el posible valor de \\(p\\). En este sentido, \\(Y\\) contiene toda la informaci√≥n acerca de \\(p\\).\n\nDefinition 2.1 Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) una muestra aleatoria de una distribuci√≥n de probabilidad con par√°metro desconocido \\(\\theta\\). Entonces se dice que el estad√≠stico \\(U = T(Y_1,\\, Y_2,\\cdots,\\, Y_n)\\) es suficiente para \\(\\theta\\) si la distribuci√≥n condicional de \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\), dada \\(U\\), no depende de \\(\\theta\\).\n\n\nRemark 2.1. El uso de cualquier estad√≠stico \\(T(\\underset{\\sim}{X})\\) implica una reducci√≥n de los datos muestrales. Sea \\(\\underset{\\sim}{X} =(X_1 ,\\ldots, X_n)\\) una muestra aleatoria simple (un vector aleatorio) y sean \\(\\underset{\\sim}{x} = (x_1 ,\\ldots, x_n)\\), y \\(\\underset{\\sim}{y} = (y_1 ,\\ldots, y_n)\\) muestras observadas (realizaciones de \\(X\\)). Si decidimos usar el estad√≠stico \\(T(\\underset{\\sim}{X})\\) en vez de toda la muestra, ser√°n tratadas igual dos muestras observadas cualesquiera \\(\\underset{\\sim}{x}\\), \\(\\underset{\\sim}{y}\\), siempre que \\(T(\\underset{\\sim}{x})=T(\\underset{\\sim}{y})\\). Es decir, al usar el estad√≠stico \\(T\\), en lugar de toda la muestra, se pierde informaci√≥n.\nSe plantea as√≠ el problema de buscar estad√≠sticos \\(T\\) tales que la informaci√≥n que se pierde al usarlos sea irrelevante para los fines que nos hayamos marcado.\n\n\nRemark 2.2. Igualdad de estad√≠sticos = Tratamiento indistinguible\nLa afirmaci√≥n:\n\n‚ÄúSer√°n tratadas igual dos muestras observadas cualesquiera \\(\\underset{\\sim}{x}\\) y \\(\\underset{\\sim}{y}\\), siempre que \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\)‚Äù\n\nsignifica que si solo observamos el valor de \\(T\\), entonces no podemos distinguir entre dos muestras diferentes que arrojen el mismo valor de ese estad√≠stico.\nPor ejemplo:\nSupongamos que \\(\\bar{x} = \\bar{y} = 5\\), pero los vectores muestrales son diferentes:\n\\[\n\\underset{\\sim}{x} = (3,\\ 5,\\ 7), \\quad \\underset{\\sim}{y} = (4,\\ 5,\\ 6).\n\\]\nAmbos tienen la misma media, pero claramente no son la misma muestra. Sin embargo, si solo usamos la media como resumen, tratamos a ambas muestras como si fueran ‚Äúiguales‚Äù.\n\n¬øQu√© se pierde?\nSe pierde la estructura interna de la muestra, incluyendo:\n\nLa variabilidad.\nEl sesgo o simetr√≠a.\nLa existencia de valores extremos.\nLa informaci√≥n sobre la distribuci√≥n conjunta de los datos.\n\nTodo eso queda oculto si solo consideramos el estad√≠stico \\(T(\\underset{\\sim}{X})\\).\n\nTodo estad√≠stico implica una compresi√≥n de la muestra, y con ello una p√©rdida de informaci√≥n.\nPor eso, en inferencia estad√≠stica buscamos estad√≠sticos que sean:\n\nSuficientes: capturan toda la informaci√≥n relevante sobre un par√°metro.\nEficientes: minimizan la p√©rdida de informaci√≥n.\nInsesgados: representan fielmente el par√°metro que estiman.\n\n\nNotaci√≥n \\[\n    \\begin{eqnarray*}\n        p(y|\\theta)&:&\\mbox{ funci√≥n de masa de probabilidad}\\\\\n        f(y|\\theta)&:&\\mbox{ funci√≥n de densidad}\n    \\end{eqnarray*}\n\\]\n\nLa definicion Definition¬†2.1 nos dice como comprobar que un estad√≠stico es suficiente pero no nos dice c√≥mo calcularlo.\n\n\n\n\n\n\nTip¬†2.1\n\n\n\n\\(p(y_1,\\, y_2,\\cdots,\\, y_n)\\) funci√≥n de probabilidad de v.a‚Äôs discretas.\n\\(p(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) funci√≥n de probabilidad o verosimilitud de observar el evento \\(Y_1=y_1,\\, Y_2=y_2,\\cdots,\\, Y_n=y_n\\) cuando el valor del par'ametro es \\(\\theta\\).\n\\(f(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) caso continuo.\n\n\n\nDefinition 2.2 Sean \\(y_1,\\, y_2,\\cdots,\\, y_n\\) observaciones muestrales tomadas de variables aleatorias correspondientes \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) cuya distribuci√≥n depende de un par√°metro \\(\\theta\\). Entonces, si \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) son variables aleatorias discretas, la verosimilitud de la muestra, \\(L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\), se define como la probabilidad conjunta de \\(y_1,\\, y_2,\\cdots,\\, y_n\\).\nSi \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) son v.a‚Äôs continuas, la verosimilitud \\(L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) se define como la densidad conjunta evaluada en \\(y_1,\\, y_2,\\cdots,\\, y_n\\)\n\n\n\n\n\n\n\nImportant¬†2.1\n\n\n\nSi el conjunto de v.a‚Äôs iid \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) denota una muestra aleatoria de distribuci√≥n discreta con funci√≥n de probabilidad \\(p(y|\\theta)\\) entonces \\[\n\\begin{eqnarray*}\n    L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&p (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\\\\n    &=&p(y_1|\\theta)p(y_2|\\theta)\\cdots p(y_n|\\theta)\n\\end{eqnarray*}\n\\] Mientras que si \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) iid tienen distribuci√≥n continua con funci√≥n de densidad \\(f(y|\\theta)\\) entonces \\[\\begin{eqnarray*}\n    L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&f (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\\\\n    &=&f(y_1|\\theta)f(y_2|\\theta)\\cdots f(y_n|\\theta)\n\\end{eqnarray*}\\]\n\n\n\nTheorem 2.1 Si \\(f(\\underset{\\sim}{x}|\\theta)\\) es la verosimilitud de un vector aleatorio \\(X\\) y \\(q(t|\\theta)\\) es la verosimilitud (funci√≥n de densidad o de masa) de un estad√≠stico \\(T(\\underset{\\sim}{X})\\), se tiene la siguiente equivalencia. \\(T(\\underset{\\sim}{X})\\) es un estad√≠stico suficiente para \\(\\theta\\) si y s√≥lo si para cada \\(\\underset{\\sim}{x}\\) del espacio muestral \\(\\mathcal{X}\\) el cociente \\[\\begin{align}\n\\frac{f(\\underset{\\sim}{x}|\\theta)}{q(T(\\underset{\\sim}{x})|\\theta)}\n\\end{align}\\] no depende de \\(\\theta\\).\n\n\nRemark. El cociente del teorema\nEl cociente\n\\[\n\\frac{f(\\underset{\\sim}{x} \\mid \\theta)}{q(T(\\underset{\\sim}{x}) \\mid \\theta)}\n\\]\ncompara cu√°nta verosimilitud aporta la muestra completa respecto a la verosimilitud que se concentra solamente en el estad√≠stico.\nüîÅ Si este cociente no depende de \\(\\theta\\), eso significa que toda la informaci√≥n sobre \\(\\theta\\) contenida en \\(f(\\underset{\\sim}{x} \\mid \\theta)\\) ya est√° contenida en \\(q(T(\\underset{\\sim}{x}) \\mid \\theta)\\).\n\n\nTheorem 2.2 Sea \\(U\\) un estad√≠stico basado en la muestra aleatoria \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\). Entonces \\(U\\) es un estad√≠stico suficiente para la estimaci√≥n de un par√°metro \\(\\theta\\) s√≠ y s√≥lo si la verosimilitud \\(L(\\theta)=L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) se puede factorizar en dos funciones no negativas, \\[L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)=g(u,\\,\\theta)\\times h(y_1,\\, y_2,\\cdots,\\, y_n)\\] donde \\(g(u,\\,\\theta)\\) es una funci√≥n s√≥lo de \\(u\\) y \\(\\theta\\) y \\(h(y_1,\\, y_2,\\cdots,\\, y_n)\\) no es una funci√≥n de \\(\\theta\\)\n\n\nRemark (Interpretaci√≥n: ¬øPor qu√© esto implica suficiencia?). Cuando se cumple la factorizaci√≥n:\n\nLa funci√≥n \\(g(u, \\theta)\\) contiene toda la informaci√≥n sobre \\(\\theta\\).\nEl resto de la muestra solo afecta a \\(h(\\cdot)\\), que no contiene ninguna informaci√≥n sobre \\(\\theta\\).\n\nPor lo tanto, si ya conocemos \\(u\\), no necesitamos el resto de la muestra para inferir \\(\\theta\\).\n\nüß© Conclusi√≥n:\n\\(U\\) es suficiente ‚áî no se pierde informaci√≥n sobre \\(\\theta\\) al reemplazar la muestra por \\(U\\).\n\n\nExample 2.2 Sean \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) una muestra aleatoria en la que \\(Y_i\\) posee la funci√≥n de densidad de probabilidad \\[f(y_i|\\theta)=\\left\\{\\begin{array}{ll}(1/\\theta)e^{-y_i/\\theta},& 0\\leq y_i&lt;\\infty\\\\0,&\\mbox{ en cualquier otro punto.}\\end{array}\\right.\\] donde \\(\\theta&gt;0,\\,i=1,\\cdots,\\,n\\). Demuestre que \\(\\overline{Y}\\) es un estad√≠stico suficiente para el par√°metro \\(\\theta\\).\n\n\nProof. \\[\\begin{eqnarray*}\n    L(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&f(y_1|\\theta)f(y_2|\\theta)\\cdots f(y_n|\\theta)\\\\\n    &=&\\frac{1}{\\theta}e^{-y_1/\\theta}\\frac{1}{\\theta}e^{-y_2/\\theta}\\cdots\\frac{1}{\\theta}e^{-y_n/\\theta}\\\\\n    &=&\\left(\\frac{1}{\\theta}\\right)^ne^{-\\sum_{i=1}^ny_i/\\theta}\\\\\n    &=&\\left(\\frac{1}{\\theta}\\right)^ne^{-n\\overline{y}/\\theta}\\\\\n\\end{eqnarray*}\\] As√≠ que \\(g(\\overline{y},\\,\\theta)=\\frac{e^{-n\\overline{y}/\\theta}}{\\theta^n}\\) y \\(h(y_1,\\, y_2,\\cdots,\\, y_n)=1\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#notaci√≥n",
    "href": "chapter1.html#notaci√≥n",
    "title": "2¬† Principios para reducir los datos",
    "section": "2.2 Notaci√≥n",
    "text": "2.2 Notaci√≥n\n\\[\n    \\begin{eqnarray*}\n        p(y|\\theta)&:&\\mbox{ funci√≥n de masa de probabilidad}\\\\\n        f(y|\\theta)&:&\\mbox{ funci√≥n de densidad}\n    \\end{eqnarray*}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#estad√≠sticos-suficientes-minimales-1",
    "href": "chapter1.html#estad√≠sticos-suficientes-minimales-1",
    "title": "2¬† Principios para reducir los datos",
    "section": "2.2 Estad√≠sticos suficientes minimales",
    "text": "2.2 Estad√≠sticos suficientes minimales\nLa factorizaci√≥n de la funci√≥n de verosimilitud no es √∫nica y como consecuencia de ello, tampoco es √∫nico el estad√≠stico suficiente para un par√°metro.\nYa vimos que cualquier transformaci√≥n biyectiva de un estad√≠stico suficiente da lugar a otro estad√≠stico suficiente. Pero a√∫n hay muchos m√°s estad√≠sticos suficientes. Por ejemplo, la muestra completa \\(X\\) tambi√©n es estad√≠stico suficiente para el par√°metro: \\[\n\\begin{align*}\nf(x|\\theta)=g(x|\\theta)h(x)\n\\end{align*}\n\\]\ndonde \\(h( x )=1\\), \\(T(x)=x\\) y \\(g(x|\\theta)=f(x|\\theta)\\).\n\n2.2.1 Estad√≠stico minimal\nUn estad√≠stico suficiente \\(T(\\underset{\\sim}{X})\\) se llama minimal si para cualquier otro estad√≠stico \\(S(\\underset{\\sim}{X})\\) se tiene que \\(T(\\underset{\\sim}{X})\\) es funci√≥n de \\(S(\\underset{\\sim}{X})\\). Es decir, si ocurre que \\(S( \\underset{\\sim}{x}) = S(\\underset{\\sim}{y})\\) entonces forzosamente se tiene que \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\).\nEl siguiente teorema proporciona un m√©todo para encontrar el estad√≠stico suficiente minimal.\n\nTheorem 2.3 Sea \\(f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)\\) la funci√≥n de verosimilitud conjunta de \\(\\underset{\\sim}{X}\\) (discreta o continua). Supongamos que existe una funci√≥n \\(T(\\underset{\\sim}{x})\\) tal que para cualquier par de elementos del espacio muestral \\(\\underset{\\sim}{x}\\) , \\(\\underset{\\sim}{y}\\) , el cociente \\[\n\\begin{align}\n\\frac{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)}{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{y}|\\theta)}\n\\end{align}\n\\] es constante como funci√≥n de \\(\\theta\\), si y s√≥lo si \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\). Entonces \\(T(\\underset{\\sim}{x})\\) es estad√≠stico suficiente minimal para \\(\\theta\\).\n\n\nExample 2.3 Determinar un estad√≠stico minimal para el par√°metro \\(\\theta\\), cuando \\(X_1,\\, X_2,\\cdots,\\, X_n\\) es una muestra aleatoria de una poblaci√≥n con distribuci√≥n de Poisson. \\[\n\\begin{align*}\n\\frac{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)}{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{y}|\\theta)}\n&=\\frac{\\prod_{i=1}^{n}\\frac{\\theta^{x_i} e^{-\\theta}}{x_i!}}{\\prod_{i=1}^{n}\\frac{\\theta^{y_i} e^{-\\theta}}{y_i!}}\\\\\n&=\\frac{e^{-n\\theta}\\prod_{i=1}^{n}\\frac{\\theta^{x_i} }{x_i!}}{e^{-n\\theta}\\prod_{i=1}^{n}\\frac{\\theta^{y_i} }{y_i!}}\\\\\n&=\\frac{\\frac{\\theta^{\\sum_{i=1}^{n}x_i} }{\\prod_{i=1}^{n}x_i!}}{\\frac{\\theta^{\\sum_{i=1}^{n}y_i} }{\\prod_{i=1}^{n}y_i!}}\\\\\n&=\\frac{\\frac{\\theta^{n\\bar{x}} }{\\prod_{i=1}^{n}x_i!}}{\\frac{\\theta^{n\\bar{y}} }{\\prod_{i=1}^{n}y_i!}}\\\\\n&=\\theta^{n(\\bar{x}-\\bar{y})}\\frac{\\prod_{i=1}^{n}y_i!}{\\prod_{i=1}^{n}x_i!}\n\\end{align*}\n\\]\n\nEl cociente de la √∫ltima igualdad no depende de \\(\\theta\\), s√≠ y s√≥lo si \\(\\bar{x}-\\bar{y}=0\\); es decir si \\(\\bar{X}_n\\) es un estad√≠stica suficiente minimal para \\(\\theta\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  }
]