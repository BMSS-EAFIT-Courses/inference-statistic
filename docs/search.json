[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inferencia Estadística",
    "section": "",
    "text": "1 INTRODUCCIÓN\nEste libro ha sido concebido como un recurso integral para el estudio riguroso y aplicado de la inferencia estadística. Está dirigido a estudiantes de programas de estadística, matemáticas aplicadas y disciplinas afines, y busca fortalecer la comprensión conceptual y técnica de los fundamentos que sustentan el análisis estadístico moderno.\nA lo largo de sus capítulos, el lector encontrará un desarrollo progresivo de los siguientes temas:\nEl material combina el rigor formal con ejemplos y aplicaciones que ilustran cómo los métodos estadísticos permiten extraer conclusiones válidas a partir de datos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#cómo-navegar-este-libro",
    "href": "index.html#cómo-navegar-este-libro",
    "title": "Inferencia Estadística",
    "section": "\n1.1 ¿Cómo navegar este libro?",
    "text": "1.1 ¿Cómo navegar este libro?\n\nUsa el índice lateral izquierdo para acceder a cada capítulo y subcapítulo.\nHaz uso del buscador para encontrar conceptos o términos clave.\nRevisa los apartados de “Lista de problemas” incluidos al final de cada sección para practicar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#bienvenidao",
    "href": "index.html#bienvenidao",
    "title": "Inferencia Estadística",
    "section": "\n1.2 ¡Bienvenida/o!",
    "text": "1.2 ¡Bienvenida/o!\nTe invito a recorrer este texto con atención, curiosidad y sentido crítico.\nEspero que este libro te acompañe, rete y apoye en tu formación como profesional en ciencias de datos o áreas relacionadas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#fenómeno-aleatorio-y-variable-observada",
    "href": "index.html#fenómeno-aleatorio-y-variable-observada",
    "title": "Inferencia Estadística",
    "section": "\n2.1 Fenómeno aleatorio y variable observada",
    "text": "2.1 Fenómeno aleatorio y variable observada\n“Se observa una realización de un fenómeno aleatorio, digamos X. Este puede ser un elemento aleatorio de varios tipos: número (variable aleatoria), un vector de dimensión finita (vector aleatorio), una función, etc.\nLa premisa principal es que el carácter aleatorio de X se concibe como una realización de un fenómeno aleatorio que tiene una distribución de probabilidad P, donde la distribución P es desconocida ya sea en su totalidad o en algún detalle específico (por ejemplo, su soporte, su media, etc.). Es de interés conocer P. Si la medida de probabilidad P fuese conocida, entonces no hay problema estadístico propiamente, pues el problema estadístico tiene que ver con inferir la propiedad desconocida de P con base en X.” [Ver referencia 1]\n\n\nDefinición de X\n\n\nX puede ser un valor real \\(X \\in \\mathbb{R}\\), un vector en \\(\\mathbb{R}^n\\), o incluso una función \\(\\;X: [0,1]\\to\\mathbb{R}\\).\n\n\n\n\nMedida de probabilidad P\n\nDesconocida: soporte, media, varianza, etc.\n\nObjetivo estadístico: inferir características de (P) a partir de la muestra (la realización de X).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#incertidumbre-inductiva-vs.-estocástica",
    "href": "index.html#incertidumbre-inductiva-vs.-estocástica",
    "title": "Inferencia Estadística",
    "section": "\n2.2 Incertidumbre inductiva vs. estocástica",
    "text": "2.2 Incertidumbre inductiva vs. estocástica\n“La observación X está dada, por lo que no hay incertidumbre tal como la hay en la teoría de probabilidad desarrollada anteriormente en el curso. Antes, fue concebida una estructura \\((\\Omega, \\mathcal{F}, P)\\) para enfrentar el que haya incertidumbre acerca del valor de X. En el problema estadístico, el valor de X ha sido observado, y la incertidumbre radica en otro punto: radica en que existe duda acerca de cuál P es la que produjo el valor X. En algunas ocasiones se utilizan los términos incertidumbre estocástica e incertidumbre inductiva para distinguir estos dos tipos. Es común que estos se confundan entre sí, porque en estadística matemática la teoría de probabilidad constituye también una de las maneras naturales de afrontar la cuantificación de incertidumbre inductiva. En cualquier caso, el concebir a P como medida de probabilidad es la base para formular soluciones a la incertidumbre inductiva. Con este lenguaje, probabilidad y estadística son problemas diferentes y de cierta manera inversos. Teoría de probabilidad tiene que ver con cuantificar incertidumbre acerca de X y teoría estadística con cuantificar incertidumbre acerca de P a la luz de haber ya observado X.”[Ver referencia 1]\n\n\nIncertidumbre estocástica: duda previa sobre el valor de X, modelada por \\((\\Omega,\\mathcal{F},P)\\).\n\n\nIncertidumbre inductiva: tras observar X, la incertidumbre se desplaza a la ley generadora P.\n\n\n\n2.2.0.1 Ejemplos en Matemática Aplicada e Ingeniería de Sistemas\n\n\nModelado de tiempos de respuesta en redes\n\n\n\\(X\\): tiempo de llegada de paquetes (variable continua).\n\n\n\\(P\\): distribución de retardo desconocida; objetivo: estimar parámetros de una ley de colas M/M/1.\n\n\n\nEstimación de parámetros en ecuaciones diferenciales estocásticas\n\n\n\\(X(t)\\): trayectoria observada de un proceso de Itô.\n\n\n\\(P\\): ley del proceso (por ejemplo, coeficientes de difusión y deriva), inferidos a partir de trayectorias discretas.\n\n\n\nCalibración de sensores en sistemas de control\n\n\n\\(X\\): lecturas del sensor (vector aleatorio).\n\n\n\\(P\\): distribución conjunta desconocida de ruido; se estima para diseñar filtros de Kalman óptimos.\n\n\n\n\nCon esta distinción clara entre dato observado y modelo probabilístico, estamos listos para construir estimadores y desarrollar la inferencia estadística en las secciones siguientes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#variables-y-vectores-aleatorios",
    "href": "index.html#variables-y-vectores-aleatorios",
    "title": "Inferencia Estadística",
    "section": "\n3.1 Variables y vectores aleatorios",
    "text": "3.1 Variables y vectores aleatorios\nConsideramos un experimento aleatorio cuyos resultados pertenecen al espacio muestral Ω. Modelamos este proceso suponiendo que existe una terna \\((\\Omega, \\mathcal{A}, P),\\) donde:\n\n\n\\(\\Omega\\) es el espacio muestra,\n\n\n\\(\\mathcal{P}(\\Omega)\\) es el conjunto de partes de Ω,\n\n\n\\(\\mathcal{A}\\in\\mathcal{P}(\\Omega)\\) es una σ-álgebra,\n\n\n\\(P\\colon \\mathcal{A} \\to [0,1]\\) es una medida de probabilidad que refleja las características aleatorias del experimento realizado.\n\nA esta terna se le llama espacio de probabilidad.\nLos resultados de un experimento aleatorio no son analizados “en bruto”, sino que se les da una representación numérica que facilita su tratamiento. Esto se logra introduciendo variables aleatorias, que asocian cada resultado \\(\\omega\\in \\Omega\\) con un valor numérico o vectorial, y sobre las cuales luego aplicamos técnicas de inferencia estadística.\nEn todo estudio estadístico partimos de un experimento aleatorio cuyo conjunto de resultados posibles se denomina espacio muestral Ω. Para cuantificar dichos resultados definimos las siguientes estructuras:\n\nDefinition 3.1 (Variables Aleatorias) Sea \\((\\Omega,\\mathcal{A},P)\\) un espacio de probabilidad. Una variable aleatoria es una función \\(X\\colon (\\Omega,\\mathcal{A})\\;\\longrightarrow\\; (\\mathbb{R},\\mathcal{B}),\\) tal que para todo \\(B\\in\\mathcal{B}\\) (la \\(\\sigma\\)-álgebra de Borel en ℝ), \\(X^{-1}(B)\\;=\\;\\{\\omega\\in\\Omega : X(\\omega)\\in B\\}\\;\\in\\;\\mathcal{A}.\\)\n\nSi el espacio muestral \\(\\Omega\\) es finito o numerable, diremos que es un espacio discreto y las variables aleatorias asociadas al experimento normalmente estarán definidas como \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{Z}.\\)\nSi \\(\\Omega\\) es no numerable, entonces diremos que es un espacio continuo y \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{R}.\\)\n\n\nDefinition 3.2 Un vector aleatorio de dimensión \\(n\\) es \\(\\mathbf{X} = (X_1,\\dots,X_n)\\colon(\\Omega,\\mathcal{A})\\longrightarrow(\\mathbb{R}^n,\\mathcal{B}^n),\\) donde cada componente \\(X_i\\) es variable aleatoria y \\(\\mathcal{B}^n\\) la \\(\\sigma\\)-álgebra de Borel en ℝⁿ.\n\n\nEjemplos Lanzamiento de dos monedas\nSea \\(\\Omega =\\{\\,CC,\\;C-,\\;-C,\\;--\\},\\) donde \\(C\\) = “cara” y \\(-\\) = “cruz”. Podemos definir:\\(X_1(\\omega) = \\text{número de caras en }\\omega.\\) \\(X_2(\\omega) = 2 - X_1(\\omega)\\;=\\; \\text{número de cruces}.\\) \\(X_3(\\omega) = \\bigl(X_1(\\omega)\\bigr)^2.\\)\nEntonces \\((X_1,X_2,X_3)\\) es un vector aleatorio de dimensión 3.\nTiempos de servicio en un servidor\nSean \\(T_i\\) los tiempos de servicio (en segundos) de las peticiones \\(i=1,2,3\\). Definimos\\(\\mathbf{T}=(T_1,T_2,T_3),\\quad S = T_1 + T_2 + T_3,\\quad M = \\max\\{T_1,T_2,T_3\\}.\\)\nLecturas de sensores en red distribuida\nEn tres nodos \\(i=1,2,3\\) medimos temperatura \\(X_{i,1}\\), presión \\(X_{i,2}\\) y humedad \\(X_{i,3}\\). El vector global es \\(\\mathbf{X} = (X_{1,1},X_{1,2},X_{1,3},\\,X_{2,1},\\dots,X_{3,3}) \\in \\mathbb{R}^9.\\)\n\nCon estas definiciones rigurosas disponemos ya de los objetos básicos para, en las siguientes secciones, construir estimadores, estudiar su comportamiento asintótico y contrastar hipótesis sobre la distribución subyacente \\(P\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#distribución-de-una-variable-aleatoria.-funciones-de-distribución-de-probabilidad-y-de-densidad",
    "href": "index.html#distribución-de-una-variable-aleatoria.-funciones-de-distribución-de-probabilidad-y-de-densidad",
    "title": "Inferencia Estadística",
    "section": "\n1.5 Distribución de una variable aleatoria. Funciones de distribución, de probabilidad y de densidad",
    "text": "1.5 Distribución de una variable aleatoria. Funciones de distribución, de probabilidad y de densidad\nDistribución de una Variable Aleatoria\nLa realización de un experimento aleatorio da lugar a un resultado \\(\\omega\\in\\Omega\\) que es aleatorio. Por lo tanto, \\(X(\\omega)\\) es un valor de \\(\\mathbb{R}\\) también aleatorio. Es decir, la variable aleatoria \\(X\\) induce una medida de probabilidad en \\(\\mathbb{R}\\). A esa medida de probabilidad se le llama distribución de \\(X\\) o ley de \\(X\\). Una de las formas de caracterizar la distribución de una variable aleatoria es dar su función de distribución \\(F_X\\), que está definida así:\n\\(F_X(x) \\;=\\; P(X \\le x)\\;=\\; P\\bigl(\\{\\omega \\in \\Omega : X(\\omega) \\le x\\}\\bigr)\\;=\\; P\\bigl(X^{-1}((-\\infty, x])\\bigr).\\)$\nEn el caso de que \\(X\\) sea una variable aleatoria discreta, es decir, en el caso de que \\(X\\) solo tome una cantidad finita o numerable de valores de \\(\\mathbb{R}\\), su distribución también puede caracterizarse por su función de probabilidad (o función de masa de probabilidad) \\(f_X\\), definida como\n\\[f_X : \\mathbb{R} \\longrightarrow [0,1],\\qquad f_X(x) = P(X = x).\\]\nEsa función solo es no nula en un conjunto finito o numerable. Supondremos en adelante, sin pérdida de generalidad, que ese conjunto está contenido en \\(\\mathbb{Z}\\). A partir de la función de masa de probabilidad se puede calcular la probabilidad de que la variable aleatoria \\(X\\) tome valores en cualquier elemento \\(A \\subseteq \\mathbb{B}\\):\n\\(P(X \\in A) = \\sum_{x \\in A} f_X(x).\\) me\nLa función de distribución y la función de masa de probabilidad se relacionan de la siguiente forma:\n\\(F_X(x) = \\sum_{u \\leq x} f_X(u), \\quad f_X(x) = F_X(x) - F_X(x^-),\\) donde \\(F_X(x^-) = \\lim_{h \\to 0^+} F_X(x - h)\\).\nUna clase relevante de variables aleatorias no discretas son las que poseen función de densidad, es decir, aquellas cuya distribución de probabilidad puede caracterizarse por una función \\(f_X(x) \\geq 0\\) que cumple que:\n\\(P(X \\in A) = \\int_{x \\in A} f_X(x) \\, dx, \\quad \\text{para todo } A \\subseteq \\mathbb{B}.\\)\nLa relación entre \\(F_X\\) y \\(f_X\\) es la siguiente:\n\\(F_X(x) = \\int_{-\\infty}^{x} f_X(u) \\, du, \\quad f_X(x) = \\frac{d}{dx} F_X(x),\\)\nsalvo quizás en un número finito de puntos \\(x \\in \\mathbb{R}\\). Las variables aleatorias que poseen función de densidad se llaman variables aleatorias absolutamente continuas. Abusando del lenguaje, aquí nos referiremos a ellas como variables aleatorias continuas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#esperanza-y-varianza",
    "href": "index.html#esperanza-y-varianza",
    "title": "Inferencia Estadística",
    "section": "\n1.6 Esperanza y varianza",
    "text": "1.6 Esperanza y varianza\nSi se desea describir totalmente la distribución de probabilidad de una variable aleatoria \\(X\\) acabamos de ver que podemos dar su función de distribución o su función de masa o de densidad, según el caso. Una descripción parcial puede efectuarse calculando algunas características de la variable aleatoria \\(X\\), como por ejemplo medidas de posición o de dispersión. Estudiaremos algunas de ellas.\nSe define la esperanza de una variable aleatoria \\(X\\) como la integral de Lebesgue de \\(X\\):\n\\(E(X) = \\int_{\\Omega} X(w) dP(w).\\)\nEn el caso de variables aleatorias discretas la esperanza puede calcularse como:\n\\(E(X) = \\sum_{w \\in \\Omega} X(w) P(w) = \\sum_{k \\in \\mathbb{Z}} k P(X = k) = \\sum_{k \\in \\mathbb{Z}} k f_X(k).\\)\nPor otro lado, la esperanza de una variable aleatoria continua se puede calcular así:\n\\(E(X) = \\int_{\\mathbb{R}} x f_X(x) dx.\\)\nLa esperanza de una variable aleatoria \\(X\\) es una medida de posición de \\(X\\): es el centro de gravedad de la distribución de probabilidad de \\(X\\).\nSi \\(h\\) es una función medible \\(h : \\mathbb{R} \\rightarrow \\mathbb{R}\\), entonces \\(Y = h(X)\\) es también variable aleatoria y su esperanza se puede calcular a partir de la distribución de \\(X\\):\n\\(E(h(X)) = \\int_{\\Omega} h(X(w)) dP(w)\\) que en el caso de que \\(X\\) sea discreta puede reescribirse como\n\\(E(h(X)) = \\sum_{k \\in \\mathbb{Z}} h(k) f_X(k).\\)\nSi \\(X\\) es una variable aleatoria continua entonces\n\\(E(h(X)) = \\int_{\\mathbb{R}} h(x) f_X(x) dx.\\)\nSi existe \\(\\mu = E(X)\\) y es finita puede definirse una medida de dispersión de la variable aleatoria \\(X\\) a partir de una transformación \\(h\\) de \\(X\\). Es lo que se denomina varianza de \\(X\\) y se define así:\n\\(V(X) = E((X - \\mu)^2) = E(X^2) - \\mu^2 = E(X^2) - (E(X))^2.\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#función-generadora-de-momentos",
    "href": "index.html#función-generadora-de-momentos",
    "title": "Inferencia Estadística",
    "section": "\n1.7 Función generadora de momentos",
    "text": "1.7 Función generadora de momentos\nDada una variable aleatoria \\(X\\), o su función de distribución \\(F\\), vamos a definir otra función generadora, como\n\\(M_X(t) = \\mathbb{E}(e^{tX}),\\) siempre que este valor esperado exista.\nNotemos que cuando \\(X\\) toma valores en los enteros no-negativos, \\(M_X(t) = \\phi_X(e^t)\\), donde \\(\\phi_X(s)=E[s^X]=\\sum_{k=0}^{\\infty}p_ks^k\\) para \\(s\\in[0,1]\\) es la función generadora de probabilidad (f.g.p.) de la variable \\(X\\), con \\(p_k=P(X=k)\\). Si \\(X\\) está acotada, \\(M_X\\) está bien definida para todo \\(t\\) real; en cambio, si \\(X\\) no está acotada, es posible que el dominio de \\(M_X\\) no sea el conjunto de todos los reales. En todo caso, \\(\\phi\\) siempre está definida en cero, y \\(M(0) = 1\\).\nEs posible demostrar que si la f.g.m. de la v.a. \\(X\\) existe en un entorno de 0, entonces para todo \\(k &gt; 0\\),\n\\(\\mathbb{E}[|X|^k] &lt; \\infty.\\)\nMás aún, la serie\n\\(M_X(t) =\n\\mathbb{E}(e^{tX})\n= \\mathbb{E}\\left(1 + \\sum_{k=1}^{\\infty} \\frac{t^k X^k}{k!}\\right)\n= 1 + \\sum_{n=1}^{\\infty} \\frac{t^k}{k!} \\mathbb{E}(X^k)\n\\tag{5.1}\\)\nes convergente y se puede derivar término a término. Obtenemos\n\\(M'_X(0) = \\mathbb{E}(X); \\quad M''_X(0) = \\mathbb{E}(X^2)\\)\ny en general\n\\(M_X^{(k)}(0) = \\mathbb{E}(X^k).\\)\nEs por esta última propiedad que esta función se conoce como función generadora de momentos (f.g.m.).\n🎲 Ejemplo: f.g.m. de la distribución Binomial\nSea \\(X \\sim \\text{Binomial}(n, p)\\), es decir, la suma de \\(n\\) ensayos de Bernoulli con probabilidad de éxito \\(p\\). La función generadora de momentos es: Ejemplo fgm binomial\n\\(M_X(t) = \\mathbb{E}[e^{tX}] = (1 - p + p e^t)^n\\)\n ```` \n📈 Ejemplo: f.g.m. de la distribución Normal Estándar\nSea \\(X \\sim \\mathcal{N}(0, 1)\\). Su función generadora de momentos es:\n\\(M_X(t) = \\mathbb{E}[e^{tX}] = e^{\\frac{t^2}{2}}\\)\nEsta expresión se obtiene usando la forma cerrada del momento de una normal estándar.\n ```` \n❓ Preguntas guía sobre la gráfica de la función generadora de momentos\n📌 ¿Qué representa la gráfica de la f.g.m. \\(M_X(t)\\)?\nLa gráfica muestra cómo evoluciona el valor esperado de \\(e^{tX}\\) cuando \\(t\\) varía. Esta función codifica todos los momentos de la variable aleatoria \\(X\\), y por tanto, contiene información completa sobre su distribución (si existe un entorno donde la f.g.m. es finita).\n\n🧭 ¿Qué se observa en la f.g.m. de una distribución Binomial? \n![Gráfica MGF Binomial]\n#Preguntas y respuestas\n\n\n¿Cómo es el comportamiento de la f.g.m. cerca de \\(t = 0\\)?\nEn \\(t = 0\\), siempre se cumple que \\(M_X(0) = 1\\), ya que:\n\\(M_X(0) = \\mathbb{E}[e^{0 \\cdot X}] = \\mathbb{E}[1] = 1\\)\n\n\n¿Qué indica la curvatura de la gráfica?\nLa curvatura refleja el crecimiento exponencial de los momentos. Si la curva crece rápidamente hacia la derecha, significa que los momentos (media, varianza, etc.) también crecen con rapidez.\n\n\n¿Por qué la gráfica es convexa?\nTodas las funciones generadoras de momentos son estrictamente convexas en el intervalo donde están definidas. Esto es una consecuencia de que derivadas sucesivas representan momentos positivos.\n\n\n¿Qué pasa si cambio los parámetros \\(n\\) y \\(p\\)?\nAumentar $ n $ o \\(p\\) tiende a elevar la f.g.m. en el lado derecho, reflejando una mayor media y varianza.\n\n\n\n📈 ¿Cómo se comporta la f.g.m. para la Normal Estándar? \n![Gráfica MGF Normal]\nPreguntas y respuestas\n\n\n¿Por qué es simétrica respecto al eje $ t = 0 $?\nPorque la normal estándar es simétrica alrededor de su media $ = 0 $, y su f.g.m. tiene la forma:\n\n\n\\(M_X(t) = e^{t^2 / 2}\\)\nlo cual es una función par: \\(M_X(-t)= M_X(t)\\).\n\n\n¿Qué tan rápido crece la función?\nMuy rápido. El crecimiento es exponencial cuadrático. Esto implica que los momentos de la normal crecen rápidamente en magnitud.\n\n\n¿Cómo se relaciona esta gráfica con los momentos de la normal?\nDerivando sucesivamente la f.g.m. en $ t = 0 $, se obtiene:\n\\(\\mathbb{E}[X^k] = M_X^{(k)}(0)\\)\nPor tanto, la gráfica “encierra” toda la información sobre los momentos.\n\n\n\n🧠 Conclusión\nEstas gráficas te permiten visualizar la información estadística codificada en una variable aleatoria. La f.g.m. no es solo una herramienta algebraica para obtener momentos, sino una forma poderosa de describir el comportamiento global de la variable.\n\n¿Qué pasa si dos variables tienen la misma f.g.m.?\n¡Tienen la misma distribución! (si la f.g.m. está definida en un entorno de 0).\n\nEjemplo: Distribución uniforme \\(U(a,b)\\)\nSi \\[X \\sim U(a,b),\\]\nsu densidad es\\[f(x) = \\frac{1}{b - a}\\quad\\text{para }a &lt; x &lt; b,\\]\ny su función generadora de momentos viene dada por\n\n\n\n\\[M(t)= \\int_a^b \\frac{e^{t x}}{b - a}\\,dx= \\frac{e^{b t} - e^{a t}}{t\\,(b - a)}.\\]\n\n\n(5.2)\n\n\nEn el caso particular de la distribución uniforme en \\((0,1)\\) se obtiene\\[M(t) = \\frac{e^t - 1}{t}.\\]\n\nPara derivar la fórmula #(5.2) y obtener los momentos, podemos usar el desarrollo en serie de la función exponencial:\n\\[\n\\begin{align}\nM(t)&= \\frac{1}{t\\,(b - a)}\\bigl(e^{b t} - e^{a t}\\bigr) \\\\\n&= \\frac{1}{t\\,(b - a)}\\Bigl[\\bigl(1 + \\sum_{n=1}^\\infty \\tfrac{(b t)^n}{n!}\\bigr)\n                    -\\bigl(1 + \\sum_{n=1}^\\infty \\tfrac{(a t)^n}{n!}\\bigr)\\Bigr] \\\\\n&= \\frac{1}{b - a}\\sum_{n=1}^\\infty \\frac{b^n - a^n}{n!}\\,t^{n-1}.\n\\end{align}\n\\]\nEste es el desarrollo de Maclaurin de \\(M(t)\\) en \\(t=0\\); por tanto, sus derivadas en cero satisfacen\n\n\n\\[M^{(k)}(0)= \\frac{b^{k+1} - a^{k+1}}{(k+1)\\,(b - a)}.\\]\n\n\n(5.3)\n\n\nEn particular:\n\n\\[M'(0)= \\frac{b^2 - a^2}{2\\,(b - a)}= \\frac{a + b}{2},\\] que coincide con \\(\\mathbb{E}(X)\\).\n\\[M''(0)= \\frac{b^3 - a^3}{3\\,(b - a)}= \\frac{a^2 + a b + b^2}{3},\\]\n\ny un cálculo directo muestra que la varianza es\n\\[\\mathrm{Var}(X)= \\mathbb{E}(X^2) - \\bigl(\\mathbb{E}(X)\\bigr)^2= \\frac{(a + b)^2}{12}.\\]\nObservación importante Sea \\(X\\) una v.a. con f.g.m. \\(M_X\\) y sea \\(Y=aX+b\\) una transformación lineal de \\(X\\), entonces\n\\[M_Y(t)=E(e^{tY})=E(e^{t(aX+b)})=E(e^{taX}e^{tb})=e^{tb}E(e^{taX})=e^{tb}M_X(at)\\]\n\nTheorem 1.1 (fgm de suma de v.a.s) Si \\(X\\) tiene función generadora de momentos \\(M(t)\\) que está definida en un entorno \\((-a,a)\\) de 0, entonces \\(M(t)\\) caracteriza a la distribución de \\(X\\); es decir, si otra variable \\(Y\\) tiene la misma función generadora de momentos, las distribuciones de \\(X\\) e \\(Y\\) coinciden.\n\n\nSi \\(X,Y\\) son variables aleatorias con funciones generadoras de momentos respectivas \\(M_X\\) y \\(M_Y\\) que existen en un dominio común \\(|t| &lt; d\\), entonces la f.g.m. de la suma \\(X+Y\\) está dada por     \\[\n\\begin{align}\nM_{X+Y}(t)&= \\mathbb{E}\\bigl[e^{t(X+Y)}\\bigr]\\\\\n&= \\mathbb{E}\\bigl[e^{tX}\\,e^{tY}\\bigr]\\\\\n&=\\mathbb{E}\\bigl[e^{tX}\\bigr]\\mathbb{E}\\bigl[e^{tY}\\bigr]\\\\\n&= M_X(t)\\,M_Y(t).\n\\end{align}\n\\tag{1}\n\\]      \nEste resultado se extiende a la suma de \\(n\\) variables aleatorias independientes. Si\n\\[S_n = X_1 + \\cdots + X_n,\\]\nentonces\n\\[M_{S_n}(t)= \\mathbb{E}\\bigl[e^{tS_n}\\bigr]= \\mathbb{E}\\Bigl[e^{t\\sum_{i=1}^n X_i}\\Bigr]= \\prod_{i=1}^n\\mathbb{E}\\bigl[e^{tX_i}\\bigr]= \\prod_{i=1}^n M_{X_i}(t).\\]\nLa función generadora de momentos resulta particularmente útil cuando consideramos sucesiones de variables aleatorias, como lo muestra el siguiente teorema que enunciamos sin demostración:\n\n\nTheorem 1.2 (de Continuidad) Sea \\(F_n(x)\\), \\(n\\ge1\\), una sucesión de funciones de distribución con funciones generadoras de momentos respectivas \\(M_n(t)\\), definidas en \\(|t|&lt;b\\). Supongamos que cuando \\(n\\to\\infty\\),\n\\[\nM_n(t)\\,\\longrightarrow\\,M(t)\n\\quad\\text{para }|t|\\le a,\n\\]\ndonde \\(M(t)\\) es la función generadora de momentos de la distribución límite \\(F(x)\\). Entonces\n\\[\nF_n(x)\\,\\longrightarrow\\,F(x)\n\\quad\\text{cuando }n\\to\\infty\n\\]\npara todo punto \\(x\\) en el cual \\(F\\) es continua.\n\n\nTheorem 1.3 Laplace–Moivre Sea \\(X_1, X_2, \\ldots, X_n\\) una sucesión de variables aleatorias i.i.d. con distribución ( (p) ), donde ( 0 &lt; p &lt; 1 ). Sea:\n\\[\nS_n = X_1 + X_2 + \\cdots + X_n \\sim \\text{Binomial}(n, p)\n\\]\ny consideremos la variable tipificada:\n\\[\nZ_n = \\frac{S_n - np}{\\sqrt{np(1 - p)}}\n\\]\nEntonces, cuando ( n ), se tiene convergencia en distribución a una normal estándar:\n\\[\nZ_n \\xrightarrow{d} \\mathcal{N}(0, 1)\n\\]\nes decir,\n\\[\n\\lim_{n \\to \\infty} \\mathbb{P}(Z_n \\leq z) = \\Phi(z), \\quad \\text{para todo } z \\in \\mathbb{R}\n\\]\ndonde ( (z) ) es la función de distribución acumulada de la normal estándar.\n\n\nProof. Demostración usando funciones generadoras de momentos\nLa función generadora de momentos (mgf) de \\(S_n \\sim \\text{Binomial}(n, p)\\) es:\n\\[\nM_{S_n}(t) = \\left(1 - p + p e^t\\right)^n\n\\]\nQueremos obtener la mgf de la variable tipificada ( Z_n ). Usamos la propiedad de cambio de variable de la mgf:\n\\[\nM_{Z_n}(t) = \\mathbb{E}\\left[ e^{t Z_n} \\right]\n= \\mathbb{E}\\left[ e^{t \\cdot \\frac{S_n - np}{\\sqrt{np(1 - p)}}} \\right]\n= e^{-t \\cdot \\frac{np}{\\sqrt{np(1 - p)}}} \\cdot M_{S_n}\\left( \\frac{t}{\\sqrt{np(1 - p)}} \\right)\n\\]\nSustituimos la mgf de ( S_n ):\n\\[\nM_{Z_n}(t) = \\exp\\left( -t \\cdot \\frac{np}{\\sqrt{np(1 - p)}} \\right)\n\\cdot \\left( 1 - p + p e^{t / \\sqrt{np(1 - p)}} \\right)^n\n\\]\nAproximación por series de Taylor\nExpandimos \\(e^{t / \\sqrt{np(1 - p)}}\\) para \\(n\\) grande:\n\\[\ne^{t / \\sqrt{np(1 - p)}} = 1 + \\frac{t}{\\sqrt{np(1 - p)}} + \\frac{t^2}{2np(1 - p)} + \\cdots\n\\]\nEntonces:\n\\[\n1 - p + p e^{t / \\sqrt{np(1 - p)}} \\approx 1 + \\frac{pt}{\\sqrt{np(1 - p)}} + \\frac{pt^2}{2np(1 - p)} + \\cdots\n\\]\nUsamos que \\(\\log(1 + x) \\approx x - \\frac{x^2}{2} + \\cdots\\) para \\(x \\approx 0\\):\n\\[\\log M_{Z_n}(t) \\approx -t \\cdot \\frac{np}{\\sqrt{np(1 - p)}}+ n \\left( \\frac{pt}{\\sqrt{np(1 - p)}} + \\frac{pt^2}{2np(1 - p)} \\right)\\]\nSimplificamos:\n\nEl término lineal se cancela:\n\n\\[\n-t \\cdot \\frac{np}{\\sqrt{np(1 - p)}} + n \\cdot \\frac{pt}{\\sqrt{np(1 - p)}} = 0\n\\]\n\nQueda:\n\n\\[\n\\log M_{Z_n}(t) \\to \\frac{t^2}{2}, \\quad \\text{cuando } n \\to \\infty\n\\]\nPor tanto:\n\\[\nM_{Z_n}(t) \\to e^{t^2 / 2}\n\\] Conclusión\nComo \\(e^{t^2/2}\\) es la mgf de \\(\\mathcal{N}(0, 1)\\), y por el teorema de unicidad de la función generadora de momentos:\n\\[\nZ_n \\xrightarrow{d} \\mathcal{N}(0, 1)\n\\]\nEsto concluye la demostración del Teorema de Laplace–Moivre utilizando funciones generadoras de momentos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#muestra-aleatoria-simple",
    "href": "index.html#muestra-aleatoria-simple",
    "title": "Inferencia Estadística",
    "section": "\n1.8 Muestra aleatoria simple",
    "text": "1.8 Muestra aleatoria simple\nSea \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) un vector aleatorio. Se dice que sus componentes \\(X_1 ,..., X_n\\) son si \\(P(X_1\\leq x_1 ,..., X_n\\leq x_n)=P(X_1\\leq x_1)...P(X_n\\leq x_n)\\) para cualesquiera valores \\(x_1,..., x_n\\) .\nSi además la distribución de las \\(n\\) variables aleatorias \\(X_i\\) es la misma, se dice que \\(X_1 ,...,X_n\\) son variables aleatorias independientes e idénticamente distribuidas, o bien que son v.a.i.i.d o simplemente i.i.d.\nSi \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) y \\(X_1 ,..., X_n\\) son i.i.d. con función de densidad (en su caso, de masa) \\(f_X\\) , la distribución conjunta de \\(\\underset{\\sim}{X}\\) viene dada por la función de densidad (en su caso, de masa) conjunta \\[\n\\begin{align*}\nf_{\\underset{\\sim}{X}}(\\underset{\\sim}{x})&=f_{(X_1 ,..., X_n)}(x_1 ,..., x_n)\\\\\n&=f_{(X_1)}(x_1)...f_{(X_n)}(x_n)\\\\\n&=\\prod_{i=1}^{n}f_{(X_i)}(x_i)\n\\end{align*}\n\\]\nA un vector \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) de v.a.i.i.d. con distribución igual a la de la variable aleatoria \\(X\\) se le denomina también muestra aleatoria simple de \\(X\\) (m.a.s de \\(X\\)).\nEsto responde al hecho siguiente. Supongamos que se desea estudiar la característica \\(X\\) de los individuos de una población de tamaño infinito. Definimos el experimento consistente en elegir aleatoriamente un individuo de la población y llamamos \\(X\\) al valor de la característica de interés en ese individuo. X es una variable aleatoria.\nSi definimos un nuevo experimento consistente en elegir una muestra aleatoria de n individuos y se anota \\(X_i\\), el valor de la característica en el individuo i-ésimo, entonces X \\(=(X_1 ,..., X_n)\\) es una colección de n v.a.i.i.d. con distribución igual a la de la variable aleatoria \\(X\\), es decir, \\(X_1 ,..., X_n\\) es una m.a.s. de X.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#modelo-paramétrico",
    "href": "index.html#modelo-paramétrico",
    "title": "Inferencia Estadística",
    "section": "\n1.9 Modelo paramétrico",
    "text": "1.9 Modelo paramétrico\nUsualmente la ley de probabilidad de una variable aleatoria se supone perteneciente a un modelo matemático que depende sólo de un número finito de parámetros: \\(f_X \\in\\{f(x|\\theta):\\theta \\in \\Theta \\subseteq \\mathbb{R}^k\\}\\). Escribiremos alternativamente \\(f(x;\\theta)\\), \\(f(x|\\theta)\\) o \\(f_\\theta(x)\\).\n\nDefinition 1.3 El conjunto de distribuciones dadas por \\(f_\\theta(x)\\), \\(\\theta \\in \\Theta\\) se llama familia paramétrica de distribuciones. \\(\\Theta\\) es el conjunto de parámetros.\n\n\nDefinition 1.4 La correspondiente distribución conjunta de una muestra aleatoria simple de \\(X\\) viene dada por la función de densidad (o función de masa de probabilidad, según el caso)\n\\[\nf_{\\underset{\\sim}{X}}(\\underset{\\sim}{x} \\mid \\theta) = \\prod_{i=1}^{n} f_{\\theta}(x_i)\n\\]\nA esta función la llamaremos función de verosimilitud de la muestra \\(X_{\\sim}\\). Utilizaremos este término para referirnos indistintamente a la función de densidad conjunta (si las variables aleatorias son continuas) o a la función de masa conjunta (si son discretas).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#sumas-de-variables-aleatorias",
    "href": "index.html#sumas-de-variables-aleatorias",
    "title": "Inferencia Estadística",
    "section": "\n1.10 Sumas de variables aleatorias",
    "text": "1.10 Sumas de variables aleatorias\nCuando se obtiene una muestra aleatoria simple \\(X_{1},X_{2},\\ldots,X_{n}\\) normalmente se calculan a partir de ellas cantidades que resumen los valores observados. Cualquiera de estos resúmenes se puede expresar como una función \\(T(x_1,\\ldots,x_n)\\) definida en el espacio \\(\\mathcal{X}^n\\subseteq\\mathbb{R}^n\\) donde están las imágenes del vector \\((X_{1},X_{2},\\ldots,X_{n})\\).\nEsta función \\(T\\) puede devolver valores de \\(\\mathbb{R}\\), \\(\\mathbb{R}^2\\) o, en general, \\(\\mathbb{R}^k\\).\n\\[T(X_1 , \\ldots, X_n)=\\sum_{i=1}^{n}X_i,\\bar{X},\\bar{X}+3, \\min{X_1 , \\ldots, X_n},\\] \\[T(X_1 , \\ldots, X_n)=\\left(\\sum_{i=1}^{n}X_i,\\sum_{i=1}^{n}(X_i-\\bar{X})^2\\right),\\] \\[T(X_1 , \\ldots, X_n)=\\left(\\min\\{X_1 , \\ldots, X_n\\},\\sum_{i=1}^{n}X_i,\\sum_{i=1}^{n}(X_i-\\bar{X})^2\\right),\\] \\[T(X_1 , \\ldots, X_n)= (X_1 , \\ldots, X_n)\\]\n\nDefinition 1.5 (Definición de estadísticos) Las funciones \\(T\\) que dependen de una muestra aleatoria simple \\(X_1 , \\ldots, X_n\\) se llaman estadísticos. Dependen de los valores observados, pero no de los parámetros desconocidos que determinan la distribución de \\(X_i\\) .\n\nCuando un estadístico \\(T\\) es utilizado con el propósito de estimar un parámetro \\(\\theta\\) diremos que \\(T\\) es un estimador de \\(\\theta\\).\nEjemplo de estadístico\n\\(T(X_1 , \\ldots, X_n)=\\bar{X}\\) es un estimador de \\(E(X)=\\mu\\).\nEn inferencia estadística interesa saber qué estadísticos son suficientes para recoger toda la información que la muestra aporta sobre la distribución de la variable aleatoria X muestreada. La respuesta depende de la distribución de X.\n\nDefinition 1.6 (Definición distribución en el muestreo) Dado que \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) es una variable aleatoria, se tiene que \\(Y=T(\\underset{\\sim}{X})=T(X_1 ,..., X_n)\\) será también una variable aleatoria. La ley de probabilidad de \\(Y\\) se denomina distribución en el muestreo de \\(Y\\) (o distribución muestral). Los siguientes resultados dan información sobre algunas características de estadísticos definidos a partir de sumas de variables aleatorias.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#estadísticos-definidos-a-partir-de-sumas-de-variables-aleatorias",
    "href": "index.html#estadísticos-definidos-a-partir-de-sumas-de-variables-aleatorias",
    "title": "Inferencia Estadística",
    "section": "\n1.11 Estadísticos definidos a partir de sumas de variables aleatorias",
    "text": "1.11 Estadísticos definidos a partir de sumas de variables aleatorias\n\nTheorem 1.4 Sean \\(X_1,\\ldots, X_n\\),n números reales, sea \\(\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n}x_i\\) su media aritmética y sea \\(S_n^2=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n-1}\\) su varianza muestral.\n\n\\(\\min_a\\sum_{i=1}^{n}(x_i-a)^2=\\sum_{i=1}^{n}(x_i-\\bar{x})^2\\)\n\\((n-1)S_n^2=\\sum_{i=1}^{n}(x_i-\\bar{x})^2=\\sum_{i=1}^{n}x_i^2-n\\bar{x}^2\\)\n\n\n\nLemma 1.1 Sea \\(X_1,\\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) y sea \\(g(x)\\) una función tal que \\(E(g(X))\\) y \\(Var(g(X))\\) existen. Entonces,\n\n\n\\(E(\\sum_{i=1}^{n}g(X_i))=nE(g(X))\\),\n\n\\(Var(\\sum_{i=1}^{n}g(X_i))=nVar(g(X))\\).\n\n\n\nProof. Para la demostración ver Gómez et al. (2006)\n\n\nTheorem 1.5 Sea \\(X 1,\\ldots, X_n\\) una muestra aleatoria simple de una población \\(X\\) con esperanza \\(\\mu\\) y varianza \\(\\sigma^2 &lt; \\infty\\). Sean \\[\n        \\begin{align*}\n        &\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_i,\\ \\\n        S^2=\\frac{\\sum_{i=1}^{n}(X_i-\\bar{X})^2}{n-1},\n        \\end{align*}    \n\\] la media y la varianza muestrales, respectivamente. Entonces,\n\n\\(E(\\bar{X}) = \\mu,\\)\n\\(Var(\\bar{X}) = \\frac{\\sigma^2}{n},\\)\n\n\\(E(S^2) = \\sigma^2\\).\n\n\n\nTheorem 1.6 Sea \\(X 1,\\ldots, X_n\\) una muestra aleatoria simple de una población \\(X\\) con función generadora de momentos \\(M_X(t)\\). La función generatriz de momentos de \\(X\\) es \\[\\begin{align*}\n        &M_{\\bar{X}}(t)=\\left(M_X\\left(\\frac{t}{n}\\right)\\right)^n\n        \\end{align*}\n\\]\n\n\nTheorem 1.7 (Combinación lineal de normales es normal) (Wackerly et al. (2008)) Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) variables aleatorias independientes normalmente distribuidas \\(E(Y_i)=\\mu_i\\) y \\(V(Y_i)=\\sigma_i^2\\)ara \\(i=1,\\cdots,\\,n\\) y sean \\(a_1,\\,a_2,\\cdots,\\,a_n\\) constantes. Si \\[U=\\sum_{i=1}^na_iY_i\\]\nentonces \\(U\\) es una variable aleatoria normalmente distribuida con \\[E(U)=\\sum_{i=1}^na_i\\mu_i\\] y \\[V(U)=\\sum_{i=1}^na_i^2\\sigma^2_i\\]\n\nEjemplo \\(X 1,\\ldots, X_n\\) m.a.s. de \\(X \\sim N(\\mu,\\sigma^2)\\). Entonces, \\(M_{X}(t)=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2}\\right\\}\\). De ahí que\n\\[\n    \\begin{align*}\n    M_{\\bar{X}}(t)\n    &=\\left(\\exp\\left\\{\\mu \\frac{t}{n}+ \\frac{\\sigma^2\\left(\\frac{t}{n}\\right)^2}{2}\\right\\}\\right)^n\n    \\end{align*}\n\\]\n\\(X 1,\\ldots, X_n\\) m.a.s. de \\(X \\sim N(\\mu,\\sigma^2)\\). Entonces, \\(M_{X}(t)=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2}\\right\\}\\). De ahí que \\[\n        \\begin{align*}\n        M_{\\bar{X}}(t)&=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2n}\\right\\}\n        \\end{align*}\n\\] De ahí que \\(\\bar{X}\\sim N(\\mu,\\frac{\\sigma^2}{n})\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#muestreo-de-una-distribución-normal",
    "href": "index.html#muestreo-de-una-distribución-normal",
    "title": "Inferencia Estadística",
    "section": "\n1.12 Muestreo de una distribución normal",
    "text": "1.12 Muestreo de una distribución normal\n\n1.12.1 Definición de distribución Chi cuadrada\n\nDefinition 1.7 (Wackerly et al. (2008)) Sea \\(\\nu\\) un entero positivo. Se dice que una v.a \\(Y\\) tiene distribuci'on chi cuadrada con \\(\\nu\\) grados de libertad si y sólo si \\(Y\\) es una vriable aleatoria con distribución gamma y parámetros \\(\\alpha=\\nu/2\\) y \\(\\beta=2\\).\n\n\nTheorem 1.8 (Teorema de Fisher) En el resto del tema supondremos que \\(X 1,\\ldots, X_n\\) m.a.s. de una \\(N(\\mu, \\sigma^2)\\).\n\n\n\\(\\bar{X}\\) y \\(S_n^2\\) son variables aleatorias independientes.\n\\(\\bar{X}\\sim N(\\mu, \\frac{\\sigma^2}{n})\\)\n\\(\\frac{(n-1)S_n^2}{\\sigma^2}\\sim \\mathcal{X}^2_{n-1}.\\)\n\n\n\n1.12.2 Distribuciones asociadas a la normal\n\nTheorem 1.9 (Wackerly et al. (2008)) Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) definidas como en el Teorema Theorem 1.7 de Wackerly et al. (2008) y definimos \\(Z_i\\) por \\[Z_i=\\frac{Y_i-\\mu_i}{\\sigma_i}\\] con \\(i=1,\\,2,\\cdots,\\,n\\). Entonces \\(\\sum_{i=1}^nZ_i^2\\) tiene distribuici'on \\(\\chi^2\\) con \\(n\\) grados de libertad.\n\n\nTheorem 1.10 (Wackerly et al. (2008)) Si \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) es una muestra aleatoria de una distribuci'on normal con media \\(\\mu\\) y varianza \\(\\sigma^2\\), \\(Y_i\\), \\(i=1,\\,2,\\cdots,n\\) son v.a’s independientes distribu'idas normalmente, con \\(E(Y_i)=\\mu\\) y \\(V(Y_i)=\\sigma^2\\).\nEntonces \\[Z_i=\\frac{Y_i-\\mu}{\\sigma}\\] son v.a’s independientes, \\(i=1,\\,2,\\cdots,n\\) y \\[\\sum_{i=1}^nZ_i^2=\\sum_{i=1}^n\\left(\\frac{Y_i-\\mu}{\\sigma}\\right)^2\\]tienen una distribuci'on \\(\\chi^2\\) con \\(n\\) grados de libertad (gl).\n\n\nTheorem 1.11 (Wackerly et al. (2008)) Sea \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) una muestra aleatoria con media \\(\\mu\\) y varianza \\(\\sigma^2\\). Entonces \\[\\frac{(n-1)S^2}{\\sigma^2}=\\frac{1}{\\sigma^2}\\sum_{i=1}^n(Y_i-\\overline{Y})^2\\] tiene una distribuci'on \\(\\chi^2\\) con \\((n-1)\\) gl. \\(\\overline{Y}\\) y \\(S^2\\) son v.a independientes.\n\n\nDefinition 1.8 (Wackerly et al. (2008)) Sea \\(Z\\) una v.a normal est'andar y sea \\(W\\) una v.a con distribuci'on \\(\\chi^2_\\nu\\). Entonces, si \\(W\\) y \\(Z\\) son ind \\[T=\\frac{Z}{\\sqrt{W/\\nu}}\\] se dice que tiene una distribuci'on \\(t\\) con \\(\\nu\\) grados de libertad.\n\n\n\n\n\n\n\nObservación 1\n\n\n\nSi \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\sim N(\\mu,\\sigma^2)\\) del Teorema (Combinación lineal de normales es normal) \\[Z=\\frac{\\sqrt{n}(\\overline{Y}-\\mu)}{\\sigma}\\sim N(0,1)\\] El teorema Observación 1 nos dice que \\[W=\\frac{(n-1)S^2}{\\sigma^2}\\sim\\chi^2_{n-1}\\] y que \\(Z\\) y \\(W\\) son ind.\n\n\n\n\n\n\n\n\nObservación 2\n\n\n\nPor tanto, de la definición 7.2 se tiene la siguiente expresión: \\[\n\\begin{aligned}\nT &= \\frac{Z}{\\sqrt{W/\\nu}} \\\\\n  &= \\frac{\\sqrt{n}(\\overline{Y}-\\mu)/\\sigma}{\\sqrt{\\left[\\frac{(n-1)S^2}{\\sigma^2}\\right]/(n-1)}} \\\\\n  &= \\sqrt{n}\\left(\\frac{\\overline{Y}-\\mu}{S}\\right)\n\\end{aligned}\n\\]\nTiene distribución \\(t\\) con \\((n-1)\\) grados de libertad.\n\n\nComo se indica en la Observación 7.1, esta propiedad…\n\nDefinition 1.9 Sean \\(W_1\\) y \\(W_2\\) v.a’s independientes con distribución \\(\\chi^2\\), con \\(\\nu_1\\) y \\(\\nu_2\\) grados de libertad respectivamente. Entonces se dice que: \\[F=\\frac{W_1/\\nu_1}{W_2/\\nu_2}\\] tiene una distribuc'on \\(F\\) con \\(\\nu_1\\) grados de libertad en el numerador y \\(\\nu_2\\) grados de libertad en el denominador.\n\n\nRemark 1.1. Considerando dos muestras aleatorias independientes tomadas de distribuiciones normales \\[W_1=\\frac{(n_1-1)S_1^2}{\\sigma_1^2}\\sim\\chi^2_{n_1-1}\\] \\[W_1=\\frac{(n_2-1)S_2^2}{\\sigma_2^2}\\sim\\chi^2_{n_2-1}\\] \\(W_1\\bot W_2\\).\n\n\nRemark 1.2. \\[\n\\begin{eqnarray*}\n            F&=&\\frac{W_1/\\nu_1}{W_2/\\nu_2}\\\\\n            &=&\\frac{[(n_1-1)S_1^2/\\sigma_1^2]/(n_1-1)}{[(n_2-1)S_2^2/\\sigma_2^2]/(n_2-1)}\\\\\n            &=&\\frac{S_1^2/\\sigma_1^2}{S_2^2/\\sigma_2^2}\n        \\end{eqnarray*}\n\\] tiene distribuci'on \\(F\\) con \\((n_1-1)\\) gl en el numerador y \\((n_2-1)\\) gl en el denominador\n\n\nlibrary(ggplot2)\n\nfigura_densidad_asimetrica &lt;- function(alpha = 0.05) {\n  shape &lt;- 2\n  rate &lt;- 1\n  \n  # Cuantil de interés\n  F_alpha &lt;- qgamma(1 - alpha, shape = shape, rate = rate)\n  \n  # Datos para la densidad\n  x_vals &lt;- seq(0, 10, length.out = 1000)\n  df &lt;- data.frame(\n    x = x_vals,\n    y = dgamma(x_vals, shape = shape, rate = rate)\n  )\n  \n  # Datos para el sombreado\n  df_shaded &lt;- subset(df, x &gt;= F_alpha)\n  \n  # Altura de la flecha\n  y_arrow &lt;- dgamma(F_alpha, shape, rate)\n  \n  ggplot(df, aes(x, y)) +\n    geom_line(linewidth = 1.2) +\n    geom_area(data = df_shaded, aes(x, y), fill = \"black\", alpha = 0.3) +\n    \n    # Flecha vertical\n    annotate(\"segment\", x = F_alpha, xend = F_alpha, y = 0, yend = y_arrow,\n             arrow = arrow(length = unit(0.15, \"cm\")), color = \"black\") +\n    \n    # Etiqueta F_α\n    annotate(\"text\", x = F_alpha, y = 0, label = expression(F[alpha]),\n             vjust = 1.5, hjust = 1.1, size = 5) +\n    \n    # Etiqueta α\n    annotate(\"text\", x = F_alpha, y = y_arrow, label = expression(alpha),\n             vjust = -1, size = 5) +\n    \n    labs(x = \"u\", y = expression(f(u))) +\n    theme_minimal(base_size = 14)\n}\nfigura_densidad_asimetrica()\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\n\n\n\n\n\n\nEjercicios con la distribución F en R\nA continuación se presentan dos ejercicios típicos en los que anteriormente se utilizaban tablas de valores críticos de la distribución F. Ahora, gracias a funciones como qf() y var.test() en R, estos análisis pueden hacerse de manera precisa y automática.\n\nEjercicio 1: Contrastar dos varianzas\nEnunciado:\nSe tienen dos muestras independientes con: - Tamaños: \\(n_1 = 6\\), \\(n_2 = 10\\) - Varianzas muestrales: \\(s_1^2 = 25\\), \\(s_2^2 = 10\\)\n¿Existe evidencia para afirmar que las varianzas poblacionales son diferentes al nivel de significancia del 5%?\nSolución en R:\n\n# Datos\ns1_sq &lt;- 25\ns2_sq &lt;- 10\nn1 &lt;- 6\nn2 &lt;- 10\n\n# Estadístico F observado (mayor varianza sobre menor)\nF_obs &lt;- s1_sq / s2_sq\ngl1 &lt;- n1 - 1\ngl2 &lt;- n2 - 1\n\n# Cuantiles críticos para prueba bilateral al 5%\nalpha &lt;- 0.05\nF_inf &lt;- qf(alpha / 2, df1 = gl1, df2 = gl2)\nF_sup &lt;- qf(1 - alpha / 2, df1 = gl1, df2 = gl2)\n\n# Decisión\ncat(\"F observado:\", round(F_obs, 3), \"\\n\")\n\nF observado: 2.5 \n\ncat(\"Intervalo de aceptación: [\", round(F_inf, 3), \",\", round(F_sup, 3), \"]\\n\")\n\nIntervalo de aceptación: [ 0.15 , 4.484 ]\n\nif (F_obs &lt; F_inf || F_obs &gt; F_sup) {\n  cat(\"Se rechaza H0: las varianzas son significativamente diferentes.\\n\")\n} else {\n  cat(\"No se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.\\n\")\n}\n\nNo se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.\n\n\nEjercicio 2: Obtener un valor crítico F directamente\nEnunciado:\nCalcular el valor crítico \\(F_{0.05,\\,5,\\,9}\\) para una prueba unilateral con nivel de significancia del 5%.\nEste valor se usa, por ejemplo, cuando se contrasta si una varianza es significativamente mayor que otra, con: - \\(\\alpha = 0.05\\) - \\(\\text{gl}_1 = 5\\) (grados de libertad del numerador) - \\(\\text{gl}_2 = 9\\) (grados de libertad del denominador)\nCálculo en R:\n\n# Valor crítico F para prueba unilateral con alpha = 0.05\nqf(0.95, df1 = 5, df2 = 9)\n\n[1] 3.481659\n\n\nEl valor crítico es \\(F_{0.05,\\,5,\\,9}=3.478\\). Si el estadístico F observado es mayor que este valor, se rechaza la hipótesis nula de igualdad de varianzas a favor de que la varianza del numerador es mayor.\n\nExample 1.1 \\[Y_1^1,\\,Y_2^1\\,\\cdots,\\,Y_{n_1}^1\\sim N(\\mu_1,\\,\\sigma^2)\\] \\[Y_1^2,\\,Y_2^2\\,\\cdots,\\,Y_{n_2}^2\\sim N(\\mu_2,\\,\\sigma^2)\\] \\(P\\left(\\frac{S_1^2}{S_2^2}\\leq b\\right)=0.95\\) con \\(n_1=6\\) y \\(n_2=10\\), ?`\\(b\\)?\nComo \\(n_1=6\\) y \\(n_2=10\\) y las varianzas poblacionales son iguales, entonces \\(\\frac{S_1^2/\\sigma_1^2}{S_2^2/\\sigma_2^2}=\\frac{S_1^2}{S_2^2}\\sim F_{5,9}\\) \\[P\\left(\\frac{S_1^2}{S_2^2}\\leq b\\right)= F_{5,9}(b)=0.95\\] entonces \\(qf(0.95,\\,5,\\,9)=b\\), \\(b=3.48\\).\n\nSimulación del comportamiento del promedio muestral\nSimulamos 1000 repeticiones del promedio muestral a partir de una distribución exponencial con media ( = 10 ), para distintos tamaños de muestra ( n ).\n\nsimular_promedios &lt;- function(n, repeticiones = 1000, media = 10) {\n  promedios &lt;- replicate(repeticiones, mean(rexp(n, rate = 1 / media)))\n  data.frame(\n    `n` = n,\n    `Promedio repetido` = mean(promedios),\n    `Media teórica` = media,\n    `Varianza repetida` = var(promedios),\n    `Varianza teórica` = media^2 / n\n  )\n}\n\n# Evaluar para varios tamaños\ntamaños &lt;- c(5, 10, 25, 50, 100)\nresultados &lt;- do.call(rbind, lapply(tamaños, simular_promedios))\nknitr::kable(resultados, digits = 5)\n\n\n\n\n\n\n\n\n\n\nn\nPromedio.repetido\nMedia.teórica\nVarianza.repetida\nVarianza.teórica\n\n\n\n5\n10.09576\n10\n20.62900\n20\n\n\n10\n10.11620\n10\n10.25720\n10\n\n\n25\n9.97786\n10\n3.89759\n4\n\n\n50\n9.97908\n10\n1.89860\n2\n\n\n100\n10.00337\n10\n1.06474\n1\n\n\n\n\n\n\nTheorem 1.12 Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) v.a’s con funciones generadoras de momentos \\(m(t)\\) y \\(m_1(t),\\,m_2(t),\\cdots,\\) respectivamente. Si \\[\\lim_{n\\rightarrow\\infty}m_n(t)=m(t)\\mbox{ para toda $t$ real,}\\] entonces la funci'on de distribuci'on de \\(Y_n\\) converge hacia la funci'on de distribuci'on de \\(Y\\) cuando \\(n\\rightarrow\\infty\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#leyes-de-los-grandes-números-y-teorema-central-del-límite",
    "href": "index.html#leyes-de-los-grandes-números-y-teorema-central-del-límite",
    "title": "Inferencia Estadística",
    "section": "\n1.13 Leyes de los Grandes Números y Teorema Central del Límite",
    "text": "1.13 Leyes de los Grandes Números y Teorema Central del Límite\n\n1.13.1 Leyes de los grandes números\n\nDefinition 1.10 Una sucesión de variables aleatorias converge en media a \\(X\\), y se denota por \\(X_{n}\\xrightarrow{cm}X\\) , si para cualquier \\(\\epsilon&gt;0\\) se tiene que:\n[{n}E(|X{n}-X|)=0,] siempre que dicha esperanza exista.\\\nDe forma análoga se define convergencia en media de orden r si: \\[\\lim _{n\\to \\infty }E(\\left|X_{n}-X\\right|^r)=0,\\]\nCuando \\(r=2\\) se dice que se tiene convergencia en media cuadrática\n\\[\\lim _{n\\to \\infty }E(\\left|X_{n}-X\\right|^2)=0,\\]\n\n\n1.13.2 Relaciones entre tipos de convergencias",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#diagrama-de-convergencias",
    "href": "index.html#diagrama-de-convergencias",
    "title": "Inferencia Estadística",
    "section": "\n1.14 Diagrama de convergencias",
    "text": "1.14 Diagrama de convergencias\n\n1.14.1 Diagrama de relaciones entre tipos de convergencia\n\nDiagrama de convergencias\n\n\n\n1.14.2 Ley débil de los grandes números\n\nTheorem 1.13 Sea \\(X 1,\\ldots, X_n\\) una sucesión de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante \\(C\\), independiente de \\(n\\). Sea \\(S_n = \\sum_{i=1  }^{n}X_i\\). Entonces \\[\n\\begin{align}\nE\\left(\\left|\\frac{S_n-E(S_n)}{n}\\right|^2\\right)\\leq \\frac{C}{n}\n\\end{align}\n\\] y, como consecuencia \\[\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}=0\\] en el sentido de la convergencia en media cuadrática.\n\nLos resultados que garantizan la convergencia casi segura de la media muestral se conocen como leyes fuertes de los grandes números. Se enuncia a continuación una ley fuerte para variables con segundos momentos finitos e incorreladas.\n\n1.14.3 Ley fuerte de los grandes números\n\nTheorem 1.14 Sea \\(X 1,\\ldots, X_n\\) una sucesión de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante \\(C\\), independiente de \\(n\\). Sea \\(S_n = \\sum_{i=1  }^{n}X_i\\). Entonces \\[\n        \\begin{align}\n        E\\left(\\left|\\frac{S_n-E(S_n)}{n}\\right|^2\\right)\\leq \\frac{C}{n}\n        \\end{align}\n        \\] y, como consecuencia \\[\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}=0\\] en el sentido de la casi segura.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#teorema-central-del-límite",
    "href": "index.html#teorema-central-del-límite",
    "title": "Inferencia Estadística",
    "section": "\n1.15 Teorema central del límite",
    "text": "1.15 Teorema central del límite\n\nTheorem 1.15 Central de Límite Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) v.a’s iid ( no se precisa de que distribuci'on se generan) con \\(E[Y_i]=\\mu\\) y \\(V[Y_i]=\\sigma^2&lt;\\infty\\). Definamos \\[U_n=\\frac{\\sum_{i=1}^nY_i-n\\mu}{\\sigma\\sqrt{n}}=\\frac{\\overline{Y}-\\mu}{\\sigma/\\sqrt{n}}\\mbox{ donde} \\overline{Y}=\\frac{1}{n}\\sum_{i=1}^nY_i\\] Entonces la función de distribución de \\(U_n\\) converge hacia la función de distribución normal estándar cuando n tiende a infinito . Esto es, \\[\\lim_{n\\rightarrow\\infty}P(U_n\\leq u)=\\int_{-\\infty}^u\\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2}dt, \\forall u\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#referencias",
    "href": "index.html#referencias",
    "title": "Inferencia Estadística",
    "section": "\n1.16 Referencias",
    "text": "1.16 Referencias\n\nGómez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisión. Departament d’Estadística i Investigació Operativa, Universitat Politècnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estadística matemática con aplicaciones (7ª ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "2  Principios para reducir los datos",
    "section": "",
    "text": "2.1 Principio de suficiencia",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#principio-de-suficiencia",
    "href": "chapter1.html#principio-de-suficiencia",
    "title": "2  Principios para reducir los datos",
    "section": "",
    "text": "2.1.1 Estadísticos suficientes minimales\n¿Este proceso de resumir los datos a los dos estadísticos \\(\\overline{Y}\\) y \\(S^2\\) conserva la información de \\(\\mu\\) y \\(\\sigma^2\\) en el conjunto original de \\(n\\) observaciones muestrales? O bien ¿Se ha perdido u ocultado alguna información acerca de estos parámetros en el proceso de reducir los datos?\nPresentamos métodos para hallar estadísticos que en cierto sentido resumen toda la información de una muestra acerca de un parámetro objetivo. Se dice que estos estadísticos tienen la propiedad de suficiencia o son estadísticos suficientes.\n\nExample 2.1 Sean \\(n\\) experimentos binomiales, \\(X_1,\\,X_2,\\cdots,\\,X_n\\), donde \\[\n\\begin{eqnarray*}\n        X_i&=&\\left\\{\\begin{array}{ll}1,&\\mbox{si el $i$-\\'esimo intento es un \\'exito,}\\\\0,&\\mbox{si el $i$-\\'esimo intento es un fracaso.}\\end{array}\\right.\\\\\n        X_i&=&\\left\\{\\begin{array}{ll}1,&\\mbox{con probabilidad $p$,}\\\\0,&\\mbox{con probabilidad $q=1-p$.}\\end{array}\\right.\n    \\end{eqnarray*}\n\\] Sea \\(Y=\\sum_{i=1}^n X_i\\) el número de éxitos en los \\(n\\) intentos. Si conocemos el valor de \\(Y\\), ¿Podemos obtener alguna información adicional acerca de \\(p\\) al ver otras funciones de \\(X_1,\\,X_2,\\cdots,\\,X_n\\)?\n\\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n|Y=y)\\\\\n&=\\frac{P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)}{P(Y=y)}\n\\end{align*}\n\\] El numerador es \\(0\\) si \\(\\sum_{i=1}^nx_i\\neq y\\) dado que no pueden suceder los eventos al mismo tiempo.\nSi \\(\\sum_{i=1}^nx_i= y\\) entonces \\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)\\\\\n&=P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n)\n\\end{align*}\n\\] Por tanto el numerador queda \\(p^y(1-p)^{n-y}\\), dado que hay \\(y\\) unos y \\(n-y\\) ceros.\nEl denominador \\[P(Y=y)=\\displaystyle{a\\choose b} p^y(1-p)^{n-y}\\] porque \\(Y\\sim Bin(n,p)\\). \\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)\\\\\n&=\\left\\{\\begin{array}{ll}\\frac{p^y(1-p)^{n-y}}{\\left({n \\atop y}\\right) p^y(1-p)^{n-y}}=\\frac{1}{\\left({n \\atop y}\\right)},& si\\sum_{i=1}^nx_i= y\\\\0,&\\mbox{ en cualquier otro punto.}\\end{array}\\right.\n\\end{align*}\n\\] \\(\\frac{1}{\\left({n \\atop y}\\right)}\\) no depende de \\(p\\)\n\nUna vez que se conozca \\(Y\\), ninguna otra función de \\(X_1,\\,X_2,\\cdots,\\,X_n\\) proporcionara más información sobre el posible valor de \\(p\\). En este sentido, \\(Y\\) contiene toda la información acerca de \\(p\\).\n\nDefinition 2.1 Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) una muestra aleatoria de una distribución de probabilidad con parámetro desconocido \\(\\theta\\). Entonces se dice que el estadístico \\(U = T(Y_1,\\, Y_2,\\cdots,\\, Y_n)\\) es suficiente para \\(\\theta\\) si la distribución condicional de \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\), dada \\(U\\), no depende de \\(\\theta\\).\n\n\nRemark 2.1. El uso de cualquier estadístico \\(T(\\underset{\\sim}{X})\\) implica una reducción de los datos muestrales. Sea \\(\\underset{\\sim}{X} =(X_1 ,\\ldots, X_n)\\) una muestra aleatoria simple (un vector aleatorio) y sean \\(\\underset{\\sim}{x} = (x_1 ,\\ldots, x_n)\\), y \\(\\underset{\\sim}{y} = (y_1 ,\\ldots, y_n)\\) muestras observadas (realizaciones de \\(X\\)). Si decidimos usar el estadístico \\(T(\\underset{\\sim}{X})\\) en vez de toda la muestra, serán tratadas igual dos muestras observadas cualesquiera \\(\\underset{\\sim}{x}\\), \\(\\underset{\\sim}{y}\\), siempre que \\(T(\\underset{\\sim}{x})=T(\\underset{\\sim}{y})\\). Es decir, al usar el estadístico \\(T\\), en lugar de toda la muestra, se pierde información.\nSe plantea así el problema de buscar estadísticos \\(T\\) tales que la información que se pierde al usarlos sea irrelevante para los fines que nos hayamos marcado.\n\n\nRemark 2.2. Igualdad de estadísticos = Tratamiento indistinguible\nLa afirmación:\n\n“Serán tratadas igual dos muestras observadas cualesquiera \\(\\underset{\\sim}{x}\\) y \\(\\underset{\\sim}{y}\\), siempre que \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\)”\n\nsignifica que si solo observamos el valor de \\(T\\), entonces no podemos distinguir entre dos muestras diferentes que arrojen el mismo valor de ese estadístico.\nPor ejemplo:\nSupongamos que \\(\\bar{x} = \\bar{y} = 5\\), pero los vectores muestrales son diferentes:\n\\[\n\\underset{\\sim}{x} = (3,\\ 5,\\ 7), \\quad \\underset{\\sim}{y} = (4,\\ 5,\\ 6).\n\\]\nAmbos tienen la misma media, pero claramente no son la misma muestra. Sin embargo, si solo usamos la media como resumen, tratamos a ambas muestras como si fueran “iguales”.\n\n¿Qué se pierde?\nSe pierde la estructura interna de la muestra, incluyendo:\n\nLa variabilidad.\nEl sesgo o simetría.\nLa existencia de valores extremos.\nLa información sobre la distribución conjunta de los datos.\n\nTodo eso queda oculto si solo consideramos el estadístico \\(T(\\underset{\\sim}{X})\\).\n\nTodo estadístico implica una compresión de la muestra, y con ello una pérdida de información.\nPor eso, en inferencia estadística buscamos estadísticos que sean:\n\nSuficientes: capturan toda la información relevante sobre un parámetro.\nEficientes: minimizan la pérdida de información.\nInsesgados: representan fielmente el parámetro que estiman.\n\n\nNotación \\[\n    \\begin{eqnarray*}\n        p(y|\\theta)&:&\\mbox{ función de masa de probabilidad}\\\\\n        f(y|\\theta)&:&\\mbox{ función de densidad}\n    \\end{eqnarray*}\n\\]\n\nLa definicion Definition 2.1 nos dice como comprobar que un estadístico es suficiente pero no nos dice cómo calcularlo.\n\n\n\n\n\n\nTip 2.1\n\n\n\n\\(p(y_1,\\, y_2,\\cdots,\\, y_n)\\) función de probabilidad de v.a’s discretas.\n\\(p(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) función de probabilidad o verosimilitud de observar el evento \\(Y_1=y_1,\\, Y_2=y_2,\\cdots,\\, Y_n=y_n\\) cuando el valor del par'ametro es \\(\\theta\\).\n\\(f(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) caso continuo.\n\n\n\nDefinition 2.2 Sean \\(y_1,\\, y_2,\\cdots,\\, y_n\\) observaciones muestrales tomadas de variables aleatorias correspondientes \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) cuya distribución depende de un parámetro \\(\\theta\\). Entonces, si \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) son variables aleatorias discretas, la verosimilitud de la muestra, \\(L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\), se define como la probabilidad conjunta de \\(y_1,\\, y_2,\\cdots,\\, y_n\\).\nSi \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) son v.a’s continuas, la verosimilitud \\(L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) se define como la densidad conjunta evaluada en \\(y_1,\\, y_2,\\cdots,\\, y_n\\)\n\n\n\n\n\n\n\nImportant 2.1\n\n\n\nSi el conjunto de v.a’s iid \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) denota una muestra aleatoria de distribución discreta con función de probabilidad \\(p(y|\\theta)\\) entonces \\[\n\\begin{eqnarray*}\n    L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&p (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\\\\n    &=&p(y_1|\\theta)p(y_2|\\theta)\\cdots p(y_n|\\theta)\n\\end{eqnarray*}\n\\] Mientras que si \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) iid tienen distribución continua con función de densidad \\(f(y|\\theta)\\) entonces \\[\\begin{eqnarray*}\n    L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&f (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\\\\n    &=&f(y_1|\\theta)f(y_2|\\theta)\\cdots f(y_n|\\theta)\n\\end{eqnarray*}\\]\n\n\n\nTheorem 2.1 Si \\(f(\\underset{\\sim}{x}|\\theta)\\) es la verosimilitud de un vector aleatorio \\(X\\) y \\(q(t|\\theta)\\) es la verosimilitud (función de densidad o de masa) de un estadístico \\(T(\\underset{\\sim}{X})\\), se tiene la siguiente equivalencia. \\(T(\\underset{\\sim}{X})\\) es un estadístico suficiente para \\(\\theta\\) si y sólo si para cada \\(\\underset{\\sim}{x}\\) del espacio muestral \\(\\mathcal{X}\\) el cociente \\[\\begin{align}\n\\frac{f(\\underset{\\sim}{x}|\\theta)}{q(T(\\underset{\\sim}{x})|\\theta)}\n\\end{align}\\] no depende de \\(\\theta\\).\n\n\nRemark. El cociente del teorema\nEl cociente\n\\[\n\\frac{f(\\underset{\\sim}{x} \\mid \\theta)}{q(T(\\underset{\\sim}{x}) \\mid \\theta)}\n\\]\ncompara cuánta verosimilitud aporta la muestra completa respecto a la verosimilitud que se concentra solamente en el estadístico.\n🔁 Si este cociente no depende de \\(\\theta\\), eso significa que toda la información sobre \\(\\theta\\) contenida en \\(f(\\underset{\\sim}{x} \\mid \\theta)\\) ya está contenida en \\(q(T(\\underset{\\sim}{x}) \\mid \\theta)\\).\n\n\nTheorem 2.2 Sea \\(U\\) un estadístico basado en la muestra aleatoria \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\). Entonces \\(U\\) es un estadístico suficiente para la estimación de un parámetro \\(\\theta\\) sí y sólo si la verosimilitud \\(L(\\theta)=L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) se puede factorizar en dos funciones no negativas, \\[L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)=g(u,\\,\\theta)\\times h(y_1,\\, y_2,\\cdots,\\, y_n)\\] donde \\(g(u,\\,\\theta)\\) es una función sólo de \\(u\\) y \\(\\theta\\) y \\(h(y_1,\\, y_2,\\cdots,\\, y_n)\\) no es una función de \\(\\theta\\)\n\n\nRemark (Interpretación: ¿Por qué esto implica suficiencia?). Cuando se cumple la factorización:\n\nLa función \\(g(u, \\theta)\\) contiene toda la información sobre \\(\\theta\\).\nEl resto de la muestra solo afecta a \\(h(\\cdot)\\), que no contiene ninguna información sobre \\(\\theta\\).\n\nPor lo tanto, si ya conocemos \\(u\\), no necesitamos el resto de la muestra para inferir \\(\\theta\\).\n\n🧩 Conclusión:\n\\(U\\) es suficiente ⇔ no se pierde información sobre \\(\\theta\\) al reemplazar la muestra por \\(U\\).\n\n\nExample 2.2 Sean \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) una muestra aleatoria en la que \\(Y_i\\) posee la función de densidad de probabilidad \\[f(y_i|\\theta)=\\left\\{\\begin{array}{ll}(1/\\theta)e^{-y_i/\\theta},& 0\\leq y_i&lt;\\infty\\\\0,&\\mbox{ en cualquier otro punto.}\\end{array}\\right.\\] donde \\(\\theta&gt;0,\\,i=1,\\cdots,\\,n\\). Demuestre que \\(\\overline{Y}\\) es un estadístico suficiente para el parámetro \\(\\theta\\).\n\n\nProof. \\[\\begin{eqnarray*}\n    L(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&f(y_1|\\theta)f(y_2|\\theta)\\cdots f(y_n|\\theta)\\\\\n    &=&\\frac{1}{\\theta}e^{-y_1/\\theta}\\frac{1}{\\theta}e^{-y_2/\\theta}\\cdots\\frac{1}{\\theta}e^{-y_n/\\theta}\\\\\n    &=&\\left(\\frac{1}{\\theta}\\right)^ne^{-\\sum_{i=1}^ny_i/\\theta}\\\\\n    &=&\\left(\\frac{1}{\\theta}\\right)^ne^{-n\\overline{y}/\\theta}\\\\\n\\end{eqnarray*}\\] Así que \\(g(\\overline{y},\\,\\theta)=\\frac{e^{-n\\overline{y}/\\theta}}{\\theta^n}\\) y \\(h(y_1,\\, y_2,\\cdots,\\, y_n)=1\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#notación",
    "href": "chapter1.html#notación",
    "title": "2  Principios para reducir los datos",
    "section": "2.2 Notación",
    "text": "2.2 Notación\n\\[\n    \\begin{eqnarray*}\n        p(y|\\theta)&:&\\mbox{ función de masa de probabilidad}\\\\\n        f(y|\\theta)&:&\\mbox{ función de densidad}\n    \\end{eqnarray*}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#estadísticos-suficientes-minimales-1",
    "href": "chapter1.html#estadísticos-suficientes-minimales-1",
    "title": "2  Principios para reducir los datos",
    "section": "2.2 Estadísticos suficientes minimales",
    "text": "2.2 Estadísticos suficientes minimales\nLa factorización de la función de verosimilitud no es única y como consecuencia de ello, tampoco es único el estadístico suficiente para un parámetro.\nYa vimos que cualquier transformación biyectiva de un estadístico suficiente da lugar a otro estadístico suficiente. Pero aún hay muchos más estadísticos suficientes. Por ejemplo, la muestra completa \\(X\\) también es estadístico suficiente para el parámetro: \\[\n\\begin{align*}\nf(x|\\theta)=g(x|\\theta)h(x)\n\\end{align*}\n\\]\ndonde \\(h( x )=1\\), \\(T(x)=x\\) y \\(g(x|\\theta)=f(x|\\theta)\\).\n\n2.2.1 Estadístico minimal\nUn estadístico suficiente \\(T(\\underset{\\sim}{X})\\) se llama minimal si para cualquier otro estadístico \\(S(\\underset{\\sim}{X})\\) se tiene que \\(T(\\underset{\\sim}{X})\\) es función de \\(S(\\underset{\\sim}{X})\\). Es decir, si ocurre que \\(S( \\underset{\\sim}{x}) = S(\\underset{\\sim}{y})\\) entonces forzosamente se tiene que \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\).\nEl siguiente teorema proporciona un método para encontrar el estadístico suficiente minimal.\n\nTheorem 2.3 Sea \\(f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)\\) la función de verosimilitud conjunta de \\(\\underset{\\sim}{X}\\) (discreta o continua). Supongamos que existe una función \\(T(\\underset{\\sim}{x})\\) tal que para cualquier par de elementos del espacio muestral \\(\\underset{\\sim}{x}\\) , \\(\\underset{\\sim}{y}\\) , el cociente \\[\n\\begin{align}\n\\frac{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)}{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{y}|\\theta)}\n\\end{align}\n\\] es constante como función de \\(\\theta\\), si y sólo si \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\). Entonces \\(T(\\underset{\\sim}{x})\\) es estadístico suficiente minimal para \\(\\theta\\).\n\n\nExample 2.3 Determinar un estadístico minimal para el parámetro \\(\\theta\\), cuando \\(X_1,\\, X_2,\\cdots,\\, X_n\\) es una muestra aleatoria de una población con distribución de Poisson. \\[\n\\begin{align*}\n\\frac{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)}{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{y}|\\theta)}\n&=\\frac{\\prod_{i=1}^{n}\\frac{\\theta^{x_i} e^{-\\theta}}{x_i!}}{\\prod_{i=1}^{n}\\frac{\\theta^{y_i} e^{-\\theta}}{y_i!}}\\\\\n&=\\frac{e^{-n\\theta}\\prod_{i=1}^{n}\\frac{\\theta^{x_i} }{x_i!}}{e^{-n\\theta}\\prod_{i=1}^{n}\\frac{\\theta^{y_i} }{y_i!}}\\\\\n&=\\frac{\\frac{\\theta^{\\sum_{i=1}^{n}x_i} }{\\prod_{i=1}^{n}x_i!}}{\\frac{\\theta^{\\sum_{i=1}^{n}y_i} }{\\prod_{i=1}^{n}y_i!}}\\\\\n&=\\frac{\\frac{\\theta^{n\\bar{x}} }{\\prod_{i=1}^{n}x_i!}}{\\frac{\\theta^{n\\bar{y}} }{\\prod_{i=1}^{n}y_i!}}\\\\\n&=\\theta^{n(\\bar{x}-\\bar{y})}\\frac{\\prod_{i=1}^{n}y_i!}{\\prod_{i=1}^{n}x_i!}\n\\end{align*}\n\\]\n\nEl cociente de la última igualdad no depende de \\(\\theta\\), sí y sólo si \\(\\bar{x}-\\bar{y}=0\\); es decir si \\(\\bar{X}_n\\) es un estadística suficiente minimal para \\(\\theta\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "\n3  Estimación puntual\n",
    "section": "",
    "text": "3.1 La función de distribución empírica y el método de los momentos\nSea la variable aleatoria \\(X\\) con función de distribución \\(F\\). Consideramos una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\), es decir, \\(X_1 ,\\ldots, X_n\\) v.a.i.i.d. con distribución dada por \\(F\\) . Sea \\(x_1 ,\\ldots, x_n\\) una realización de esa m.a.s. Se llama función de distribución empírica a la función \\[\n\\begin{align}\nF_{n}(x)=\\dfrac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\mathbf{I}_{(-\\infty,x]}(x_{i})¸\n\\end{align}\n\\] que a cada número real x le asigna la proporción de valores observados que son menores o iguales que x.\nEs inmediato comprobar que la función \\(F_n\\) así definida es una función de distribución:\nConcretamente, \\(F_n\\) es la función de distribución de una variable aleatoria discreta (que podemos llamar \\(X_e\\) ) que pone masa \\(\\frac{1}{n}\\) en cada uno de los n puntos \\(x_i\\) observados:\nA la distribución de \\(X_e\\) e se le llama distribución empírica asociada al conjunto de valores \\({x_1 ,\\ldots, x_n}\\).\nObsérvese que si fijamos el valor de \\(x\\) y dejamos variar la muestra, lo que obtenemos es una variable aleatoria. En efecto, se tiene entonces que\n\\[\n\\begin{align}\nF_{n}(x)=\\dfrac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\mathbf{I}_{(-\\infty,x]}(x_{i})¸\n\\end{align}\n\\]\ndonde\n\\[\n\\begin{align}\n\\mathbf{I}_{(-\\infty,x]}(X_{i})= \\left\\{ \\begin{array}{lcc}\n1 &   si  & X_{i}\\leq x \\\\\n\\\\ 0 &  si &X_{i}&gt; x\\\\\n\\end{array}\n\\right.\n\\end{align}\n\\] y, por lo tanto, cada término \\(\\mathbf{I}_{(-\\infty,x]}(X_{i})\\) es una variable aleatoria de Bernoulli con probabilidad de éxito\n\\[\n\\begin{align}\np&=P(\\mathbf{I}_{(-\\infty,x]}(X_{i})=1)\\\\\n&=P(X_{i}\\leq x)\\\\\n&=F(x)\n\\end{align}\n\\] De ahí se deduce que \\(F_n\\) es una variable aleatoria y que \\(nF_n(x)\\) tiene distribución binomial con parámetros \\(n\\) y \\(p = F(x)\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#la-función-de-distribución-empírica-y-el-método-de-los-momentos",
    "href": "chapter2.html#la-función-de-distribución-empírica-y-el-método-de-los-momentos",
    "title": "\n3  Estimación puntual\n",
    "section": "",
    "text": "\\(F_n(x) \\in [0, 1]\\) para todo \\(x \\in \\mathbb{R}\\).\n\n\\(F_n\\) es continua por la derecha.\n\n\\(F_n\\) es no decreciente.\n\\(\\lim _{x\\to -\\infty }F_{n}(x)=0\\)\n\\(\\lim _{x\\to \\infty }F_{n}(x)=1\\)\n\n\n\n\n\\(x_i\\)\n\\(1\\)\n\\(2\\)\n\\(\\ldots\\)\n\\(n\\)\n\n\n\\(p_i = P(X_e = x_i)\\)\n\\(1/n\\)\n\\(1/n\\)\n\\(\\ldots\\)\n\\(1/n\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#teorema-de-glivenko-cantelli",
    "href": "chapter2.html#teorema-de-glivenko-cantelli",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.2 Teorema de Glivenko-Cantelli",
    "text": "3.2 Teorema de Glivenko-Cantelli\nEl siguiente teorema recoge algunas de las propiedades de la función de distribución empírica.\n\nTheorem 3.1 Sea \\(\\{X_n\\}\\) para \\(n\\geq 1\\) , sucesión de variables aleatorias independientes e idénticamente distribuidas definidas en el espacio de probabilidad \\((\\Omega, \\mathcal{A}, P)\\) con función de distribución común \\(F\\) . Se denota por \\(F_n\\) la función de distribución empírica obtenida de las \\(n\\) primeras variables aleatorias \\(X_1 ,\\ldots, X_n\\) . Sea \\(x\\in\\mathbb{R}\\). Se verifica lo siguiente:\n\n\n\n\\(P(nF_n(x)=j)=P(F_n(x)=\\frac{j}{n})=\\binom{n}{j}(F(x))^j(1-F(x))^{n-j}\\), \\(j=1,\\ldots,n\\)\\\n\n\\(E(F_n(x))=F(x)\\); \\(Var(F_n(x))=\\frac{1}{n}F(x)(1-F(x))\\).\n\\(\\lim _{n\\to \\infty }F_{n}(x)=F(x)\\)\n\n\\(\\lim _{n\\to \\infty }\\frac{F_{n}(x)-F(x)}{\\sqrt{\\frac{F(x)(1-F(x))}{n}}}=Z\\), donde \\(Z\\) es una variable aleatoria con distribución normal estándar y la convergencia es convergencia en distribución.\n\nEl siguiente teorema refuerza el resultado (c) anterior, puesto que afirma que la convergencia de \\(F_n(x)\\) a \\(F(x)\\) se da uniformemente.\n\nTheorem 3.2 Sea \\(\\{X_n\\}\\) para \\(n\\geq 1\\) , sucesión de variables aleatorias independientes e idénticamente distribuidas definidas en el espacio de probabilidad \\((\\Omega, \\mathcal{A}, P)\\) con función de distribución común \\(F\\) . Se denota por \\(F_n\\) la función de distribución empírica obtenida de las \\(n\\) primeras variables aleatorias \\(X_1 ,\\ldots, X_n\\) . Sea \\(x\\in\\mathbb{R}\\). Entonces \\[Sup_{x\\in\\mathbb{R}} |F_{n}(x)-F(x)|\\xrightarrow{c.s}0\\]\n\n\n\n\n\n\n\nNote 3.1\n\n\n\nObsérvese que según el apartado (c) del teorema Theorem 3.1, las distribuciones empíricas asociadas a muestras de tamaño n convergen débilmente a la distribución de probabilidad teórica identificada por \\(F\\), para casi todas las muestras de tamaño infinito que se extraigan de \\(F\\) . Ésta es una de las consecuencias más importantes del citado teorema: la distribución empírica converge débilmente con probabilidad 1 a la poblacional cuando el tamaño de la muestra tiende a infinito: \\[F_{n}(x)\\xrightarrow{c.s}F(x)\\] Esto garantiza la posibilidad de realizar inferencia estadística:\n\nLos aspectos probabilísticos de una característica \\(X\\), medida en una población, se resumen de forma estilizada en una distribución de probabilidad \\(F\\).\nLa distribución de probabilidad \\(F\\), puede ser aproximada mediante las distribuciones empíricas \\(F_n\\) obtenidas por muestreo de la población en estudio.\nEl teorema de Glivenko-Cantelli afirma que esas aproximaciones son uniformes en x.\nPor esta razón el teorema de Glivenko-Cantelli se llama a veces Teorema Fundamental de la Estadística Matemática.\n\n\n\nPodemos ver a continuación cómo, a medida que aumentamos el tamaño de la muestra (n=10,30,100,1000), la función de distribución empírica se ajusta cada vez mejor a la distribución teórica normal estándar N(0,1), tal como afirma el teorema.\n\n# Cargar librería para gráficos\nlibrary(ggplot2)\n\n# Definir función para graficar ECDF vs distribución teórica\ncomparar_ecdf_teorica &lt;- function(n, distribucion = \"normal\") {\n  set.seed(123)  # Para reproducibilidad\n\n  # Muestra de tamaño n desde N(0,1)\n  muestra &lt;- rnorm(n)\n  \n  # Dominio común\n  x_vals &lt;- seq(-3, 3, length.out = 1000)\n\n  # Distribución teórica\n  F_teorica &lt;- pnorm(x_vals)\n\n  # Distribución empírica\n  ecdf_muestra &lt;- ecdf(muestra)\n  F_empirica &lt;- ecdf_muestra(x_vals)\n\n  # Construir data frame para ggplot\n  df &lt;- data.frame(\n    x = rep(x_vals, 2),\n    F = c(F_empirica, F_teorica),\n    Tipo = rep(c(\"Empírica\", \"Teórica\"), each = length(x_vals))\n  )\n\n  # Graficar\n  ggplot(df, aes(x = x, y = F, color = Tipo, linetype = Tipo)) +\n    geom_line(size = 1) +\n    labs(\n      title = paste(\"ECDF vs F(x) — Tamaño de muestra n =\", n),\n      x = \"x\", y = \"Probabilidad acumulada\"\n    ) +\n    theme_minimal() +\n    scale_color_manual(values = c(\"Empírica\" = \"red\", \"Teórica\" = \"black\")) +\n    scale_linetype_manual(values = c(\"Empírica\" = \"dashed\", \"Teórica\" = \"solid\"))\n}\n\n# Generar gráficos para diferentes tamaños de muestra\ncomparar_ecdf_teorica(10)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\ncomparar_ecdf_teorica(30)\n\n\n\n\n\n\ncomparar_ecdf_teorica(100)\n\n\n\n\n\n\ncomparar_ecdf_teorica(1000)\n\n\n\n\n\n\n\nEl Teorema Fundamental de la Estadística Matemática: da una fundamentación de la inferencia estadística, cuyo objetivo principal consiste en extraer información sobre \\(F\\) a partir de las observaciones muestrales.\n¿Por qué esto es importante?\nPorque sin conocer \\(F(x)\\) explícitamente, podemos estimarla a partir de los datos.\nEsto es la base de:\n\nlos histogramas acumulados,\nlas pruebas no paramétricas,\nlos intervalos de confianza empíricos, y\ntoda la inferencia estadística basada en datos reales.\n\n🎯 Ejemplo: Estimación del percentil 90 del ingreso mensual\n📌 Contexto Supón que quieres estimar el ingreso mensual por debajo del cual se encuentran el 90% de las personas en una ciudad.\nNo conoces la distribución real del ingreso $ F(x) $, pero tienes una muestra de datos.\n\nPaso a paso\n\nSimulamos una población Vamos a suponer que el ingreso sigue una distribución log-normal:\n\n\nset.seed(123)\npoblacion &lt;- rlnorm(1e6, meanlog = 10, sdlog = 0.5)\n\n\nTomamos una muestra aleatoria\n\n\nmuestra &lt;- sample(poblacion, size = 20000, replace = FALSE)\n\n\nEstimamos la distribución empírica\n\n\nFn &lt;- ecdf(muestra)\n\n\nEstimamos el percentil 90 (cuantil 0.9)\n\n\ncuantil_90_empirico &lt;- quantile(muestra, probs = 0.9)\n\n\nComparamos con el valor verdadero en la población\n\n\ncuantil_90_real &lt;- quantile(poblacion, probs = 0.9)\n\n\nResultado\n\n\ncat(\"Cuantil 90 estimado (empírico):\", round(cuantil_90_empirico, 2), \"\\n\")\n\nCuantil 90 estimado (empírico): 41926.83 \n\ncat(\"Cuantil 90 real (poblacional):\", round(cuantil_90_real, 2), \"\\n\")\n\nCuantil 90 real (poblacional): 41805.56",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#ejemplo-estimación-del-percentil-90-del-ingreso-mensual",
    "href": "chapter2.html#ejemplo-estimación-del-percentil-90-del-ingreso-mensual",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.3 🎯 Ejemplo: Estimación del percentil 90 del ingreso mensual",
    "text": "3.3 🎯 Ejemplo: Estimación del percentil 90 del ingreso mensual\n\n3.3.1 📌 Contexto\nSupón que quieres estimar el ingreso mensual por debajo del cual se encuentran el 90% de las personas en una ciudad.\nNo conoces la distribución real del ingreso ( F(x) ), pero tienes una muestra de datos.\n\n3.3.2 ⚙️ Paso a paso\n\n3.3.2.1 1. Simulamos una población\nVamos a suponer que el ingreso sigue una distribución log-normal:\n\nset.seed(123)\npoblacion &lt;- rlnorm(1e6, meanlog = 10, sdlog = 0.5)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#la-función-de-distribución-empírica-y-el-método-de-los-momentos-1",
    "href": "chapter2.html#la-función-de-distribución-empírica-y-el-método-de-los-momentos-1",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.3 La función de distribución empírica y el método de los momentos",
    "text": "3.3 La función de distribución empírica y el método de los momentos\n\n3.3.1 Principio de sustitución\nEn esta sección presentamos una consecuencia importante de la convergencia de \\(F_n\\) a \\(F\\) , la definición de estimadores mediante el principio de sustitución.\n\nLa convergencia de \\(F_n\\) a \\(F\\) permite construir versiones factibles de características poblacionales desconocidas.\nSupongamos que estudiamos una característica \\(X\\) en una población y que el resultado de la observación de \\(X\\) puede ser modelado como una variable aleatoria con distribución desconocida, digamos \\(F\\).\nMuchas de las preguntas relevantes acerca de la característica \\(X\\) podrían ser contestadas si su función de distribución \\(F\\) fuese conocida.\n\n\n\n\n\n\n\nImportant 3.1\n\n\n\nPreguntas sobre \\(X\\)\n\nel valor esperado,\nel número de modas de la distribución o\nla probabilidad de que \\(X\\) sea negativa\n\nPara fijar ideas podemos pensar que nos interesa conocer cantidades numéricas (parámetros) que dependen únicamente de la función de distribución desconocida \\(F\\):\n\\[\n    \\begin{align}\n    \\theta=\\psi(F)\n    \\end{align}\n\\] El teorema de Glivenko-Cantelli nos dice que \\(F_n\\) se acerca a \\(F\\), a medida que el tamaño muestral crece. Así, podemos esperar que también se verifique que \\[\n    \\begin{align}\n    \\hat{\\theta}_n=\\psi(F_n)\\rightarrow\\theta=\\psi(F)\n    \\end{align}\n    \\]\nEs decir, esperamos que las cantidades numéricas calculadas para la distribución empírica (estimadores) se aproximen a las cantidades desconocidas a medida que el tamaño muestral crezca.\nEsta forma de obtener estimadores de parámetros poblacionales desconocidos se denomina principio de sustitución (plug-in principle en inglés). Es un procedimiento muy general de obtención de estimadores.\n\n\nSea \\(X\\sim U(0,\\theta)\\). Se toma una m.a.s. de \\(X\\) de tamaño n para estimar \\(\\theta\\). Un estimador razonable de \\(\\theta\\) es el máximo de las observaciones, que es estadístico minimal suficiente para \\(\\theta\\): \\[\n\\begin{align}\n    \\hat{\\theta}_2 = \\max_i {X_i}.\n\\end{align}\n\\] El siguiente código muestra:\n\nPara cada tamaño de muestra n, simula valores de \\(X_i\\)∼U(0,θ),\nCalcula \\[\\hat{\\theta} = \\max_i {X_i}\\]\nCompara con el valor real de \\(\\theta=10\\).\nMuestra cómo, al aumentar n, el estimador se acerca a \\(\\theta\\).\n\n\n# Simulación para estimar theta en una uniforme (0, theta)\nset.seed(42)\ntheta_real &lt;- 10\n\n# Tamaños de muestra\nn_vals &lt;- c(5, 10, 30, 100)\n\n# Simular y comparar\nestimadores &lt;- sapply(n_vals, function(n) {\n  muestra &lt;- runif(n, min = 0, max = theta_real)\n  max(muestra)\n})\n\n# Mostrar resultados\ndata.frame(\n  Tamaño_muestra = n_vals,\n  Estimador_maximo = round(estimadores, 3),\n  Error = round(theta_real - estimadores, 3)\n)\n\n  Tamaño_muestra Estimador_maximo Error\n1              5            9.371 0.629\n2             10            9.347 0.653\n3             30            9.889 0.111\n4            100            9.828 0.172\n\n\nConvergencia del estimador plug-in en la distribución uniforme\nEn este ejemplo, estimamos el parámetro \\(\\theta\\) de una distribución \\(X \\sim \\mathcal{U}(0, \\theta)\\) usando el estimador \\(\\hat{\\theta}_n = \\max(X_i)\\). Este es un estimador tipo plug-in: se usa la distribución empírica para estimar una característica de la distribución teórica.\nA continuación, simulamos cómo este estimador converge al verdadero valor \\(\\theta = 10\\) a medida que el tamaño de muestra \\(n\\) crece.\n\n# Chunk de R — solo código\n#| label: fig-convergencia-max\n#| fig-cap: 'Convergencia del estimador plug-in $ \\hat{\\theta}_n = \\max X_i $ hacia el valor real $ \\theta = 10 $'\n#| fig-align: center\n#| message: false\n#| warning: false\n\nset.seed(42)\ntheta_real &lt;- 10\n\n# Vector de tamaños de muestra crecientes\nn_seq &lt;- seq(5, 500, by = 5)\n\n# Calcular el estimador para cada n\nestimadores &lt;- sapply(n_seq, function(n) {\n  muestra &lt;- runif(n, min = 0, max = theta_real)\n  max(muestra)\n})\n\n# Crear data frame para graficar\ndf_estimacion &lt;- data.frame(\n  n = n_seq,\n  estimador = estimadores\n)\n\n# Graficar\nlibrary(ggplot2)\nggplot(df_estimacion, aes(x = n, y = estimador)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_hline(yintercept = theta_real, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = expression(\"Convergencia de \" * hat(theta)[n] * \" al valor real \" * theta),\n    x = \"Tamaño de muestra (n)\",\n    y = expression(hat(theta)[n])\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#convergencia-del-estimador-plug-in-en-la-distribución-uniforme",
    "href": "chapter2.html#convergencia-del-estimador-plug-in-en-la-distribución-uniforme",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.4 📊 Convergencia del estimador plug-in en la distribución uniforme",
    "text": "3.4 📊 Convergencia del estimador plug-in en la distribución uniforme\nEn este ejemplo, estimamos el parámetro () de una distribución (X (0, )) usando el estimador (_n = (X_i)). Este es un estimador tipo plug-in: se usa la distribución empírica para estimar una característica de la distribución teórica.\nA continuación, simulamos cómo este estimador converge al verdadero valor (= 10) a medida que el tamaño de muestra (n) crece.\n\n# Chunk de R — solo código\n#| label: fig-convergencia-max\n#| fig-cap: 'Convergencia del estimador plug-in $ \\hat{\\theta}_n = \\max X_i $ hacia el valor real $ \\theta = 10 $'\n#| fig-align: center\n#| message: false\n#| warning: false\n\nset.seed(42)\ntheta_real &lt;- 10\n\n# Vector de tamaños de muestra crecientes\nn_seq &lt;- seq(5, 200, by = 5)\n\n# Calcular el estimador para cada n\nestimadores &lt;- sapply(n_seq, function(n) {\n  muestra &lt;- runif(n, min = 0, max = theta_real)\n  max(muestra)\n})\n\n# Crear data frame para graficar\ndf_estimacion &lt;- data.frame(\n  n = n_seq,\n  estimador = estimadores\n)\n\n# Graficar\nlibrary(ggplot2)\nggplot(df_estimacion, aes(x = n, y = estimador)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_hline(yintercept = theta_real, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = expression(\"Convergencia de \" * hat(theta)[n] * \" al valor real \" * theta),\n    x = \"Tamaño de muestra (n)\",\n    y = expression(hat(theta)[n])\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#método-de-momentos",
    "href": "chapter2.html#método-de-momentos",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.4 Método de momentos",
    "text": "3.4 Método de momentos\nUna aplicación del principio de sustitución es la definición de los estimadores basados en momentos. El momento no centrado de orden \\(k\\) de una variable aleatoria \\(X\\) con distribución \\(F\\) se define como \\[\n\\begin{align}\n\\mu_k=E_F(X^k)=\\int x^kdF(x)\n    \\end{align}\n\\] Si \\(X_e\\) es una variable aleatoria con función de distribución igual a \\(F_n\\) , la función de distribución empírica de una m.a.s. de tamaño \\(n\\) de \\(X\\), se tiene que sus (a los que llamaremos \\(m_{k,n}\\)) son de la forma \\[\\begin{align}\n    m_{k,n}=E_{F_n}(X_e^k)=\\int x^kdF_n(x)=\\frac{1}{n}\\sum_{i=1}^{n}X_i^k,\n    \\end{align}\\] y se denominan momentos muestrales no centrados de orden \\(k\\). Por ejemplo, \\(µ_1\\) es la esperanza poblacional y \\(m_{1,n}\\) la media muestral.\nLa siguiente proposición garantiza que los momentos muestrales convergen a los poblacionales.\n\nProposition 3.1 Sea \\(X\\) variable aleatoria con \\(E(X^{2k}) &lt; \\infty\\). Entonces se verifica que \\(m_{k,n} \\rightarrow \\mu_k\\) casi seguro. Además, \\[\n\\begin{align}\n\\frac{\\sqrt{n}(m_{k,n}-\\mu_k)}{\\sqrt{\\mu_{2k}-\\mu_k^2}}\\xrightarrow{d}Z,\n\\end{align}\n\\] con \\(Z\\sim N(0,1)\\).\n\n\nProof. Si \\(Y_i=X_i^k\\) entonces \\(m_{k,n}=E_{k,n}(Y_i)=E_{n}(X_i^k)=\\frac{1}{n}\\sum_{i=1}^{n}X_i^k=\\frac{1}{n}\\sum_{i=1}^{n}Y_i=\\bar{Y}_n\\).\\\nAplicando la ley fuerte de los grandes números se tiene que \\[\\begin{align}\n\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}&=\\lim _{n\\to \\infty }\\frac{\\sum_{i=1}^{n}X_i^k-E(\\sum_{i=1}^{n}X_i^k)}{n}\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\frac{\\sum_{i=1}^{n}X_i^k}{n}-\\frac{E(\\sum_{i=1}^{n}X_i^k)}{n}\\right]\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\bar{Y}_n-\\frac{\\sum_{i=1}^{n}E(X_i^k)}{n}\\right]\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\bar{Y}_n-\\frac{nE(X^k)}{n}\\right]\\mbox{Por ser las $X_i$ una mas de X}\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\bar{Y}_n-\\bar{Y}\\right]=0   \\mbox{ Aplicando L.F.G.N}\n\\end{align}\\]\nPor lo anterior, se tiene que \\(m_{k,n}=\\bar{Y}_n\\xrightarrow{c.s} \\mu_k=\\bar{Y}=E_F(X^k)\\). Por otro lado, veamos \\[\\begin{align}\n\\frac{S_n-E(S_n)}{\\sqrt{Var(S_n)}}=\\frac{m_{k,n}-E(X^k)}{\\sqrt{\\frac{Var(X^k)}{n}}}\\xrightarrow{d}Z\n\\end{align}\\] donde \\(S_n=\\sum_{i=1}^{n}X_i^k\\). Sabemos que \\(E(X^k)=\\mu_k\\) y que \\(Var(X^k)=E[(X^k)^2]-[E(X^k)]^2=\\mu_{2k}-\\mu_k^2\\), de ahí se sigue el resultado.\n\nMuchas características poblacionales de interés se pueden expresar como función de los momentos no centrados de órdenes \\(1,\\ldots, k\\): \\(\\theta=h(\\mu_1, \\ldots, \\mu_k)\\). Por ejemplo, la varianza de \\(X\\) se expresa como \\(\\sigma^2 = h(\\mu_1, \\mu_2) = \\mu_2-\\mu_1^2\\).\nEl estimador de \\(\\theta\\) basado en el principio de sustitución se conoce como estimador de los momentos de \\(\\theta\\) y será \\[\\begin{align}\n\\hat{\\theta}_n = h(m_{1,n} ,\\ldots, m_{k,n}).\n    \\end{align}\\] Obsérvese que el estimador de los momentos de \\(\\theta\\) puede no ser único, porque diferentes funciones \\(h\\) pueden conducir al mismo valor \\(\\theta\\).\n\nProposition 3.2 Consideremos la variable aleatoria \\(X\\) con \\(E(X_{2k})&lt; \\infty\\). Sea \\(\\theta=h(\\mu_{n} ,\\ldots, \\mu_{n})\\). Si \\(h\\) es continua en \\((\\mu_{n} ,\\ldots, \\mu_{n})\\), entonces \\(\\hat{\\theta}_n=h(m_{1,n} ,\\ldots, m_{k,n})\\) converge a \\(\\theta\\) casi seguro. Además, si \\(h\\) es derivable en \\((\\mu_{n} ,\\ldots, \\mu_{n})\\), entonces la distribución límite de \\(\\hat{\\theta}_n\\) es normal: \\[\\begin{align}\n\\sqrt{n}(\\hat{\\theta}_n-\\theta)\\xrightarrow{d} N(0, \\sigma_{h,\\theta}^2)\n\\end{align}\\]\n\n\nExample 3.1 Sea \\(X\\sim U(0,\\theta)\\). Se toma una m.a.s. de \\(X\\) de tamaño n para estimar \\(\\theta\\). Un estimador de momentos \\(\\hat{\\theta}_M\\) de \\(\\theta\\) viene dado por la siguiente relación \\[\\begin{align}\n    E(X)=\\frac{\\theta}{2}\\Longrightarrow m_{1,n}=\\frac{\\hat{\\theta}_M}{2}\\Longrightarrow 2m_{1,n}=\\hat{\\theta}_M\\Longrightarrow 2\\bar{X}=\\hat{\\theta}_M\n    \\end{align}\\]\n\n\nExample 3.2  \nPara la variable aleatoria \\(X\\) con varianza finita, un estimador para \\(\\theta=Var(X)\\) es \\[\\begin{align}\n\\hat{\\theta}=h(m_{1,n}, m_{2,n})&=m_{2,n}-m_{1,n}^2\\nonumber\\\\\n&=\\frac{1}{n}\\sum_{i=1}^{n}x_i^2-\\bar{x}^2\\nonumber\\\\\n&=\\frac{\\sum_{i=1}^{n}x_i^2-n\\bar{x}^2}{n}\\nonumber\\\\\n&=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n}\\nonumber\\\\\n&=\\frac{(n-1)S_n^2}{n}\\nonumber\\\\\n\\end{align}\\]\n\n\nExample 3.3  \nSi \\(X\\sim Exp(\\lambda)\\) con \\(E(X)=\\frac{1}{\\lambda}\\), entonces \\(m_{1,n}=\\frac{1}{\\hat{\\lambda}_M}\\) \\(\\Longrightarrow \\hat{\\lambda}_M=\\frac{1}{m_{1,n}}\\Longrightarrow \\hat{\\lambda}_M=\\frac{1}{\\bar{X}}\\).\nSi \\(X\\sim B(n,p)\\), con \\(E(X)=np\\) y \\(Var(X)=npq\\), entonces \\(m_{1,n}=n\\hat{p}\\) \\(\\Longrightarrow\\) \\(\\frac{m_{1,n}}{n}=\\hat{p}\\) \\(\\Longrightarrow\\) \\(\\frac{\\bar{X}}{n}=\\hat{p}\\) \\(\\Longrightarrow\\) \\(\\hat{Var(X)}=n\\hat{p}(1-\\hat{p})\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "index.html#variable-aleatoria",
    "href": "index.html#variable-aleatoria",
    "title": "Inferencia Estadística",
    "section": "\n1.4 VARIABLE ALEATORIA",
    "text": "1.4 VARIABLE ALEATORIA\n\n1.4.1 Variables y vectores aleatorios\nConsideramos un experimento aleatorio cuyos resultados pertenecen al espacio muestral Ω. Modelamos este proceso suponiendo que existe una terna \\((\\Omega, \\mathcal{A}, P),\\) donde:\n\n\n\\(\\Omega\\) es el espacio muestra,\n\n\n\\(\\mathcal{P}(\\Omega)\\) es el conjunto de partes de Ω,\n\n\n\\(\\mathcal{A}\\in\\mathcal{P}(\\Omega)\\) es una σ-álgebra,\n\n\n\\(P\\colon \\mathcal{A} \\to [0,1]\\) es una medida de probabilidad que refleja las características aleatorias del experimento realizado.\n\nA esta terna se le llama espacio de probabilidad.\nLos resultados de un experimento aleatorio no son analizados “en bruto”, sino que se les da una representación numérica que facilita su tratamiento. Esto se logra introduciendo variables aleatorias, que asocian cada resultado \\(\\omega\\in \\Omega\\) con un valor numérico o vectorial, y sobre las cuales luego aplicamos técnicas de inferencia estadística.\nEn todo estudio estadístico partimos de un experimento aleatorio cuyo conjunto de resultados posibles se denomina espacio muestral Ω. Para cuantificar dichos resultados definimos las siguientes estructuras:\n\nDefinition 1.1 (Variables Aleatorias) Sea \\((\\Omega,\\mathcal{A},P)\\) un espacio de probabilidad. Una variable aleatoria es una función \\(X\\colon (\\Omega,\\mathcal{A})\\;\\longrightarrow\\; (\\mathbb{R},\\mathcal{B}),\\) tal que para todo \\(B\\in\\mathcal{B}\\) (la \\(\\sigma\\)-álgebra de Borel en ℝ), \\(X^{-1}(B)\\;=\\;\\{\\omega\\in\\Omega : X(\\omega)\\in B\\}\\;\\in\\;\\mathcal{A}.\\)\n\nSi el espacio muestral \\(\\Omega\\) es finito o numerable, diremos que es un espacio discreto y las variables aleatorias asociadas al experimento normalmente estarán definidas como \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{Z}.\\)\nSi \\(\\Omega\\) es no numerable, entonces diremos que es un espacio continuo y \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{R}.\\)\n\n\nDefinition 1.2 Un vector aleatorio de dimensión \\(n\\) es \\(\\mathbf{X} = (X_1,\\dots,X_n)\\colon(\\Omega,\\mathcal{A})\\longrightarrow(\\mathbb{R}^n,\\mathcal{B}^n),\\) donde cada componente \\(X_i\\) es variable aleatoria y \\(\\mathcal{B}^n\\) la \\(\\sigma\\)-álgebra de Borel en ℝⁿ.\n\n\nEjemplos Lanzamiento de dos monedas\nSea \\(\\Omega =\\{\\,CC,\\;C-,\\;-C,\\;--\\},\\) donde \\(C\\) = “cara” y \\(-\\) = “cruz”. Podemos definir:\\(X_1(\\omega) = \\text{número de caras en }\\omega.\\) \\(X_2(\\omega) = 2 - X_1(\\omega)\\;=\\; \\text{número de cruces}.\\) \\(X_3(\\omega) = \\bigl(X_1(\\omega)\\bigr)^2.\\)\nEntonces \\((X_1,X_2,X_3)\\) es un vector aleatorio de dimensión 3.\nTiempos de servicio en un servidor\nSean \\(T_i\\) los tiempos de servicio (en segundos) de las peticiones \\(i=1,2,3\\). Definimos\\(\\mathbf{T}=(T_1,T_2,T_3),\\quad S = T_1 + T_2 + T_3,\\quad M = \\max\\{T_1,T_2,T_3\\}.\\)\nLecturas de sensores en red distribuida\nEn tres nodos \\(i=1,2,3\\) medimos temperatura \\(X_{i,1}\\), presión \\(X_{i,2}\\) y humedad \\(X_{i,3}\\). El vector global es \\(\\mathbf{X} = (X_{1,1},X_{1,2},X_{1,3},\\,X_{2,1},\\dots,X_{3,3}) \\in \\mathbb{R}^9.\\)\n\nCon estas definiciones rigurosas disponemos ya de los objetos básicos para, en las siguientes secciones, construir estimadores, estudiar su comportamiento asintótico y contrastar hipótesis sobre la distribución subyacente \\(P\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#datos-y-modelos",
    "href": "index.html#datos-y-modelos",
    "title": "Inferencia Estadística",
    "section": "\n1.3 DATOS Y MODELOS",
    "text": "1.3 DATOS Y MODELOS\nEn esta sección establecemos la base conceptual para el análisis estadístico, diferenciando claramente entre el fenómeno aleatorio observado y la medida de probabilidad que lo describe.\n\n1.3.1 Fenómeno aleatorio y variable observada\n“Se observa una realización de un fenómeno aleatorio, digamos X. Este puede ser un elemento aleatorio de varios tipos: número (variable aleatoria), un vector de dimensión finita (vector aleatorio), una función, etc.\nLa premisa principal es que el carácter aleatorio de X se concibe como una realización de un fenómeno aleatorio que tiene una distribución de probabilidad P, donde la distribución P es desconocida ya sea en su totalidad o en algún detalle específico (por ejemplo, su soporte, su media, etc.). Es de interés conocer P. Si la medida de probabilidad P fuese conocida, entonces no hay problema estadístico propiamente, pues el problema estadístico tiene que ver con inferir la propiedad desconocida de P con base en X.” [Ver referencia 1]\n\n\nDefinición de X\n\n\nX puede ser un valor real \\(X \\in \\mathbb{R}\\), un vector en \\(\\mathbb{R}^n\\), o incluso una función \\(\\;X: [0,1]\\to\\mathbb{R}\\).\n\n\n\n\nMedida de probabilidad P\n\nDesconocida: soporte, media, varianza, etc.\n\nObjetivo estadístico: inferir características de (P) a partir de la muestra (la realización de X).\n\n\n\n1.3.2 Incertidumbre inductiva vs. estocástica\n“La observación X está dada, por lo que no hay incertidumbre tal como la hay en la teoría de probabilidad desarrollada anteriormente en el curso. Antes, fue concebida una estructura \\((\\Omega, \\mathcal{F}, P)\\) para enfrentar el que haya incertidumbre acerca del valor de X. En el problema estadístico, el valor de X ha sido observado, y la incertidumbre radica en otro punto: radica en que existe duda acerca de cuál P es la que produjo el valor X. En algunas ocasiones se utilizan los términos incertidumbre estocástica e incertidumbre inductiva para distinguir estos dos tipos. Es común que estos se confundan entre sí, porque en estadística matemática la teoría de probabilidad constituye también una de las maneras naturales de afrontar la cuantificación de incertidumbre inductiva. En cualquier caso, el concebir a P como medida de probabilidad es la base para formular soluciones a la incertidumbre inductiva. Con este lenguaje, probabilidad y estadística son problemas diferentes y de cierta manera inversos. Teoría de probabilidad tiene que ver con cuantificar incertidumbre acerca de X y teoría estadística con cuantificar incertidumbre acerca de P a la luz de haber ya observado X.”[Ver referencia 1]\n\n\nIncertidumbre estocástica: duda previa sobre el valor de X, modelada por \\((\\Omega,\\mathcal{F},P)\\).\n\n\nIncertidumbre inductiva: tras observar X, la incertidumbre se desplaza a la ley generadora P.\n\n\n\n1.3.2.1 Ejemplos en Matemática Aplicada e Ingeniería de Sistemas\n\n\nModelado de tiempos de respuesta en redes\n\n\n\\(X\\): tiempo de llegada de paquetes (variable continua).\n\n\n\\(P\\): distribución de retardo desconocida; objetivo: estimar parámetros de una ley de colas M/M/1.\n\n\n\nEstimación de parámetros en ecuaciones diferenciales estocásticas\n\n\n\\(X(t)\\): trayectoria observada de un proceso de Itô.\n\n\n\\(P\\): ley del proceso (por ejemplo, coeficientes de difusión y deriva), inferidos a partir de trayectorias discretas.\n\n\n\nCalibración de sensores en sistemas de control\n\n\n\\(X\\): lecturas del sensor (vector aleatorio).\n\n\n\\(P\\): distribución conjunta desconocida de ruido; se estima para diseñar filtros de Kalman óptimos.\n\n\n\n\nCon esta distinción clara entre dato observado y modelo probabilístico, estamos listos para construir estimadores y desarrollar la inferencia estadística en las secciones siguientes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "chapter2.html#estimadores-de-máxima-verosimilitud",
    "href": "chapter2.html#estimadores-de-máxima-verosimilitud",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.5 Estimadores de máxima verosimilitud",
    "text": "3.5 Estimadores de máxima verosimilitud",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#cálculo-del-estimador-máximo-verosímil",
    "href": "chapter2.html#cálculo-del-estimador-máximo-verosímil",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.6 Cálculo del estimador máximo verosímil",
    "text": "3.6 Cálculo del estimador máximo verosímil\nSea \\(\\underset{\\sim}{X} =(X_1,\\ldots, X_n)\\) una muestra aleatoria simple de una variable aleatoria \\(X\\) con función de densidad (o de masa de probabilidad) \\(f(\\underset{\\sim}{x}|\\theta)\\), con \\(\\theta = (\\theta_1,\\ldots,\\theta_k) \\in \\Theta \\subseteq \\mathbb{R}^k\\) . Sea \\(\\mathcal{X}\\) el espacio muestral, es decir, el conjunto de todos los posibles valores de \\(\\underset{\\sim}{X}\\) . Hemos definido la para \\(\\underset{\\sim}{x} =(x_1,\\ldots, x_n )\\in \\mathcal{X}\\) como \\[\n    \\begin{align}\n    L(\\cdot|\\underset{\\sim}{x}):&\\Theta\\rightarrow \\mathbb{R}^+\\nonumber\\\\\n    &\\theta\\rightarrow L(\\theta|\\underset{\\sim}{x})=f(\\underset{\\sim}{x}|\\theta)=\\prod_{i=1}^{n}f(x_i|\\theta)\n    \\end{align}\n\\]\n\n3.6.1 Preguntas sobre \\(X\\)\n\nPara cada muestra \\(\\underset{\\sim}{x} \\in \\underset{\\sim}{X}\\) , el estimador de máxima verosimilitud \\(\\hat{\\theta}\\) de \\(\\theta\\) es el valor de \\(\\Theta\\) que hace máxima la verosimilitud \\(L(\\cdot|\\underset{\\sim}{x})\\): \\[\n\\begin{align}\nL(\\hat{\\theta}| \\underset{\\sim}{x} ) = \\max_{\\theta \\in \\Theta} L(\\theta|\\underset{\\sim}{x}).\n\\end{align}\n\\] Intuitivamente \\(\\hat{\\theta}\\) es el valor del parámetro que hace más verosímil la muestra observada. Veremos más adelante que los estimadores de máxima verosimilitud son muy buenos estimadores y que en general tienen propiedades de optimalidad. Además, en muchas ocasiones el estimador máximo verosímil es el que el sentido común nos llevaría a proponer.\n\nExample 3.4 Si \\(X\\sim Exp(\\lambda)\\Longrightarrow f(x|\\lambda)=\\lambda\\exp\\{-\\lambda x\\}I_{[0,\\infty)}(x)\\), \\(\\lambda&gt;0\\)\nSe toma una muestra de tamaño \\(n=1\\) y se observa que \\(x=3\\). Estudiamos la función de verosimilitud \\(L(\\lambda|3)=\\lambda\\exp\\{-3\\lambda\\}\\) y buscamos su máximo para \\(\\lambda&gt;0\\).\nBuscamos los valores de \\(\\lambda\\) que hacen la derivada cero de \\(L(\\lambda|3)\\): \\[  \n\\begin{align}\n\\label{maxver_exp}\nL^{'}(\\lambda|3)&=\\exp\\{-3\\lambda\\}(1-3\\lambda)\n\\end{align}\n\\tag{3.1}\\] Igualando a cero la expresión (Equation 3.1) se tiene que \\(\\lambda=\\frac{1}{3}\\). Como \\(L^{'}(\\lambda|3)\\geq 0\\) y \\[\n\\begin{align}\n\\lim _{\\lambda\\to 0}L(\\lambda|3)=\\lim _{\\lambda\\to \\infty}L(\\lambda|3)=0\n\\end{align}\n\\] Se sigue que el punto crítico de \\(L(\\lambda|3)\\) es un máximo. Así, \\(\\hat{\\lambda}=\\frac{1}{3}\\)\n\n\nExample 3.5 Suponga que deseamos estimar \\(\\theta\\), la proporción de personas con tuberulosis en una gran población homogénea. Para hacer esto, seleccionamos de manera aleatoria \\(n\\) personas para hacer pruebas y encontrar \\(x\\) de estos que tienen la enfermedad.\nYa que la población es grande y homogénea, asumimos que los \\(n\\) individuos observados son independiente y que cada uno tiene probabilidad \\(\\theta\\) de tener tuberculosis.\nSi \\(E\\) es el evento tiene tuberculosis \\[\n\\begin{align}\nP(E;\\theta)&=P(\\mbox{x entre n tienen tuberculosis})\\nonumber\\\\\n&=\\binom{n}{x}\\theta^x(1-\\theta)^{n-x}\n\\end{align}\n\\tag{3.2}\\] Observe que \\(\\binom{n}{x}\\) es un factor constante no tendrá efecto sobre la maximización de la expresión (Equation 3.2) sobre \\(\\theta\\), ver (kalbfleisch et al. (1985)). La función de verosimilitud de \\(\\theta\\) es definida como sigue: \\[\n\\begin{align}\nL(\\theta)=cP(E;\\theta)\n\\end{align}\n\\tag{3.3}\\] Acá \\(c\\) es alguna constante positiva con respecto a \\(\\theta\\); esto es, \\(c\\) no es función de \\(\\theta\\), sin embargo esta debe ser función de los datos. Escogemos \\(c\\) para obtener una expresión simple para \\(L(\\theta)\\), y resultados subsecuentes no dependerán de la escogencia específica hecha.\nUsualmente \\(P(E;\\theta)\\) y \\(L(\\theta)\\) son productos de términos y será más conveniente trabajar con logaritmos. La función logverosimilitud es el logaritmo de \\(L\\):\n\\[\n\\begin{align}\nl(\\theta)=log L(\\theta)\n\\end{align}\n\\tag{3.4}\\] Observe que, por (Equation 3.3) \\[\n\\begin{align}\nl(\\theta)=c^{'}+log P(E;\\theta)\n\\end{align}\n\\tag{3.5}\\] donde \\(c^{'}=log c\\) no es una función de \\(\\theta\\).\nPor la expresión (Equation 3.2) se tiene que\n\\[\n\\begin{align}\nc=\\frac{1}{\\binom{n}{x}},\n\\end{align}\n\\] entonces \\[\n\\begin{align}\nL(\\theta)=\\theta^x(1-\\theta)^{n-x}, \\mbox{para } 0\\leq\\theta\\leq1\n\\end{align}\n\\tag{3.6}\\] La función de log verosimilitud es ahora \\[\n\\begin{align}\nl(\\theta)=xlog(\\theta)+(n-x)log(1-\\theta), \\mbox{para } 0\\leq\\theta\\leq1\n\\end{align}\n\\tag{3.7}\\] El estimador de máxima verosimilitud (MDL) \\(\\hat{\\theta}\\) es el valor de \\(\\theta\\) el cual maximiza \\(l(\\theta)\\).\nTomando la derivada respecto a \\(\\theta\\) de (Equation 3.4) se tiene que \\[\n    \\begin{align}\n    S(\\theta)&=\\frac{dl(\\theta)}{d\\theta}\\nonumber\\\\\n    &=\\frac{x}{\\theta}-\\frac{n-x}{1-\\theta}\n    \\end{align}\n\\tag{3.8}\\] Haciendo cero a \\(S(\\theta)\\) tiene una única solución \\(\\theta=\\frac{x}{n}\\), para \\(1\\leq x\\leq n-1\\). Bajo estas mismas condiciones tomamos la segunda derivada y la multiplicamos por \\(-1\\) en la siguiente expresión\n\\[\n\\begin{align}\n\\mathscr{I}(\\theta)&=-\\frac{dS(\\theta)}{d\\theta}\\nonumber\\\\\n&=\\frac{x}{\\theta^2}+\\frac{n-x}{(1-\\theta)^2}\n\\end{align}\n\\tag{3.9}\\]\nYa que \\(\\mathscr{I}(\\theta)&gt;0\\) en \\(\\theta=\\frac{x}{n}\\), la función de verosimilitud tiene un máximo relativo en \\(\\theta=\\frac{x}{n}\\). Más aún, \\(L(\\theta)=0\\) para \\(\\theta=0\\) y para \\(\\theta=1\\), hemos encontrado con esto un máximo global en \\(\\hat{\\theta}=\\frac{x}{n}\\).\nA las funciones \\(S(\\theta)\\) y \\(\\mathscr{I}(\\theta)\\) definidas en (Equation 3.8}) y (Equation 3.9), se les llama función Score y función de información respectivamente.\n\n\n3.6.2 Principio de invarianza del estimador máximo verosímil\nSea \\(X_1,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim f(x|\\theta)\\) y sea \\(\\hat{\\theta}\\) el estimador máximo verosímil de \\(\\theta\\). Si estamos interesados en estimar una función \\(\\tau(\\theta)\\) del parámetro, podemos hacerlo mediante \\(\\tau(\\hat{\\theta})\\). Éste es el resultado que garantiza el siguiente teorema y se conoce como principio de invariancia.\n\nTheorem 3.3 Si \\(\\hat{\\theta}\\) es el estimador de máxima verosimilitud de \\(\\theta\\), entonces para cualquier función \\(\\tau\\) el estimador de máxima verosimilitud de \\(\\tau(\\theta)\\) es \\(\\tau(\\hat{\\theta})\\).\n\n\nExample 3.6 Sea \\(X_1,\\ldots,X_n\\) una m.a.s de \\(X\\sim N(\\mu,\\sigma^2)\\). Podemos probar que el estimador de máxima verosimilitud para \\(\\mu\\), \\(\\hat{\\mu}=\\bar{X}\\). ¿Cuál es el estimador de máxima verosimilitud de \\(\\theta_1=3\\mu\\), \\(\\theta_2=\\mu^2\\) y \\(\\theta_3=1/\\mu\\)?\nPor el principio de invarianza tenemos que \\(\\hat{\\theta_1}=3\\bar{X}\\), \\(\\hat{\\theta_2}=\\bar{X}^2\\) y \\(\\hat{\\theta_3}=\\frac{1}{\\bar{X}}\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#referencias",
    "href": "chapter2.html#referencias",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.13 Referencias",
    "text": "3.13 Referencias\n\nGómez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisión. Departament d’Estadística i Investigació Operativa, Universitat Politècnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estadística matemática con aplicaciones (7ª ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.\nKalbfleisch, J. G. Probability and Statistical Inference. Springer-Verlag, 1985.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#error-cuadrático-medio",
    "href": "chapter2.html#error-cuadrático-medio",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.7 Error cuadrático medio",
    "text": "3.7 Error cuadrático medio\nUna vez se han presentado diferentes métodos de estimación surge la necesidad de desarrollar criterios para evaluarlos y compararlos de acuerdo a estos criterios. En este tema estudiaremos medidas de la calidad de un estimador. Lo haremos primero para muestras finitas para pasar después a proponer medidas asintóticas de calidad.\nSe define el error cuadrático medio (ECM) de un estimador \\(W\\) de un parámetro \\(\\theta\\) como \\[\n\\begin{align}\n    E_\\theta((W-\\theta)^2)\n\\end{align}\n\\] Ésta es una medida intuitiva del comportamiento de un estimador: cuanto menor sea el error cuadrático medio mejor será el estadístico \\(W\\). De hecho, para cualquier función \\(\\phi\\) creciente con \\(\\phi(0) = 0\\), \\(E_\\theta(\\phi(|W- \\theta|))\\) es una medida razonable de lo alejadas que estarán, en promedio, las estimaciones de \\(\\theta\\) que proporcione W.\nEn general, se prefiere el error cuadrático medio a otras medidas por ser más tratable analíticamente. Además el error cuadrático medio puede descomponerse \\[\\begin{align}\nE_\\theta((W-\\theta)^2)&=E_\\theta((W-E_\\theta(W))^2)+E_\\theta((E_\\theta(W)-\\theta)^2)\\nonumber\\\\\n&=Var_\\theta(W)+(B_\\theta(W))^2\n\\end{align}\\] El término \\(B_\\theta(W) = E_\\theta(W)-\\theta\\) se llama (en inglés bias) de \\(W\\) cuando se estima \\(\\theta\\) y es una medida de la desviación sistemática que se tiene cuando se estima \\(\\theta\\) por \\(W\\). Si un estimador tiene sesgo nulo para cualquier valor del parámetro se dice que es un estimador insesgado. En tal caso, \\(E_\\theta((W-\\theta)^2)=Var_\\theta(W)\\).\n\n3.7.1 Observaciones sobre el ECM\n\nAsí, el error cuadrático medio de un estimador es la suma de su varianza (una medida de su dispersión) más el cuadrado de su sesgo (medida de la desviación sistemática o de la exactitud del estimador).\nEs una medida conjunta de precisión y exactitud del estimador.\nPor lo tanto, parece sensato buscar estimadores que tengan error cuadrático medio pequeño, porque de esta manera controlaremos tanto la dispersión como la exactitud de las estimaciones.\n\n\n\nFigure 3.1: Comparación entre precisión y exactitud\n\n\n\n\n\n(a) Exactitud vs precisión\n\n\n\n\n\n\n\n\n\n\n\n# install.packages(\"ggplot2\")  # si hace falta\nlibrary(ggplot2)\n\ntheta    &lt;- 0      # valor \"verdadero\"\nthetahat &lt;- 1.2    # estimación\n\nx  &lt;- seq(theta - 3, thetahat + 3, length.out = 500)\ndf &lt;- data.frame(x = x,\n                 y = dnorm(x, mean = thetahat, sd = 0.9))\n\nggplot(df, aes(x, y)) +\n  geom_line(linewidth = 1.2) +\n  geom_hline(yintercept = 0, linewidth = 0.8) +\n  # marquitas en el eje para theta y theta-hat\n  geom_segment(aes(x = theta,    xend = theta,    y = 0, yend = max(y)*0.03),\n               inherit.aes = FALSE) +\n  geom_segment(aes(x = thetahat, xend = thetahat, y = 0, yend = max(y)*0.03),\n               inherit.aes = FALSE) +\n  annotate(\"text\", x = theta,    y = -max(df$y)*0.05, label = expression(theta)) +\n  annotate(\"text\", x = thetahat, y = -max(df$y)*0.05, label = expression(hat(theta))) +\n  labs(title = \"Distribución de estimaciones\", x = NULL, y = NULL) +\n  coord_cartesian(ylim = c(-max(df$y)*0.08, max(df$y)*1.05), clip = \"off\") +\n  theme_classic(base_size = 14) +\n  theme(\n    axis.text.y  = element_blank(),\n    axis.ticks.y = element_blank(),\n    plot.margin  = margin(10, 20, 25, 20) # deja espacio para las etiquetas bajo el eje\n  )\n\nWarning in geom_segment(aes(x = theta, xend = theta, y = 0, yend = max(y) * : All aesthetics have length 1, but the data has 500 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in geom_segment(aes(x = thetahat, xend = thetahat, y = 0, yend = max(y) * : All aesthetics have length 1, but the data has 500 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\n\n\n\n\n\n\nEstimador de \\(\\theta\\) estará indicado por \\(\\hat{\\theta}\\).\nQuisieramos que \\(E(\\hat{\\theta})=\\theta\\).\nLa distribución muestral para un estimador puntual sesgado positivamente, para el que \\(E(\\hat{\\theta})&gt;\\theta\\), se muestra en la siguiente figura\n\nlibrary(ggplot2)\n\n# --- Parámetros editables ---\ntheta       &lt;- 0\nE_thetahat  &lt;- 0.5      # sesgo: centro de la densidad\nthetahat    &lt;- 1.2\nsd0         &lt;- 0.7      # dispersión\n# ----------------------------\n\n# Curva de densidad (normal centrada en E(\\hat{theta}))\nx_min &lt;- theta - 1.2\nx_max &lt;- thetahat + 1.2\nx  &lt;- seq(x_min, x_max, length.out = 800)\ny  &lt;- dnorm(x, mean = E_thetahat, sd = sd0)\ndf &lt;- data.frame(x, y)\nymax &lt;- max(y)\n\n# Alturas EXACTAS de las barras (tocar la curva)\ny_theta     &lt;- dnorm(theta,      mean = E_thetahat, sd = sd0)  # altura en theta\ny_Ethetahat &lt;- dnorm(E_thetahat, mean = E_thetahat, sd = sd0)  # pico\n\nggplot(df, aes(x, y)) +\n  geom_line(linewidth = 1.1, lineend = \"round\") +\n  # ejes \"a mano\"\n  annotate(\"segment\", x = x_min, xend = x_max, y = 0, yend = 0, linewidth = 0.8) +\n  annotate(\"segment\", x = x_min, xend = x_min, y = 0, yend = 1.05*ymax, linewidth = 0.8) +\n  # barra corta en theta (hasta la curva)\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = y_theta), inherit.aes = FALSE) +\n  # barra larga en E(thetahat) (hasta el pico)\n  geom_segment(aes(x = E_thetahat, xend = E_thetahat, y = 0, yend = y_Ethetahat),\n               inherit.aes = FALSE) +\n  # etiquetas bajo el eje x\n  annotate(\"text\", x = theta,      y = -0.06*ymax, label = expression(theta)) +\n  annotate(\"text\", x = E_thetahat, y = -0.06*ymax, label = expression(E(hat(theta)))) +\n  annotate(\"text\", x = thetahat,   y = -0.06*ymax, label = expression(hat(theta))) +\n  # etiqueta del eje y\n  annotate(\"text\",\n           x = x_min - 0.03*(x_max - x_min), y = 0.9*ymax,\n           label = expression(f(hat(theta))), angle = 90) +\n  labs(x = NULL, y = NULL) +\n  coord_cartesian(xlim = c(x_min, x_max),\n                  ylim = c(-0.10*ymax, 1.08*ymax), clip = \"off\") +\n  theme_void(base_size = 14) +\n  theme(plot.margin = margin(10, 20, 35, 45))\n\nWarning in geom_segment(aes(x = theta, xend = theta, y = 0, yend = y_theta), : All aesthetics have length 1, but the data has 800 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in geom_segment(aes(x = E_thetahat, xend = E_thetahat, y = 0, yend = y_Ethetahat), : All aesthetics have length 1, but the data has 800 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# ===== Panel (a): arco =====\n# soporte con ~5% a la izquierda y 95% a la derecha\nxL &lt;- -0.10\nxR &lt;-  2.10\ntheta     &lt;- (xL + xR)/2    # centro del arco: ahí debe ir la barra\nthetahat1 &lt;- xR\n\n# definir el arco (semicircunferencia escalada)\nc_a  &lt;- (xL + xR)/2\nR_a  &lt;- (xR - xL)/2\nx_a  &lt;- seq(xL, xR, length.out = 700)\nhsca &lt;- 0.95\ny_a  &lt;- hsca * sqrt(pmax(0, R_a^2 - (x_a - c_a)^2))\ndfa  &lt;- data.frame(x = x_a, y = y_a)\nymax_a &lt;- max(dfa$y)\n\n# altura de la curva en theta\ny_theta &lt;- approx(x_a, y_a, xout = theta)$y\n\np_a &lt;-\n  ggplot(dfa, aes(x, y)) +\n  geom_line(linewidth = 1.2, lineend = \"round\") +\n  # ejes\n  annotate(\"segment\", x = xL-0.3, xend = xR+0.3, y = 0, yend = 0, linewidth = 0.8) +\n  annotate(\"segment\", x = 0, xend = 0, y = 0, yend = 1.05*ymax_a, linewidth = 0.8) +\n  # barra en el centro (theta)\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = y_theta), inherit.aes = FALSE) +\n  # etiquetas\n  annotate(\"text\", x = theta,     y = -0.08*ymax_a, label = expression(theta)) +\n  annotate(\"text\", x = thetahat1, y = -0.08*ymax_a, label = expression(hat(theta)[1])) +\n  annotate(\"text\", x = -0.15, y = 0.9*ymax_a,\n           label = expression(f(hat(theta)[1])), angle = 90) +\n  annotate(\"text\", x = (xL + xR)/2, y = -0.22*ymax_a, label = \"(a)\") +\n  coord_cartesian(xlim = c(xL-0.2, xR+0.2),\n                  ylim = c(-0.25*ymax_a, 1.1*ymax_a), clip = \"off\") +\n  theme_void(base_size = 14) +\n  theme(plot.margin = margin(10, 20, 40, 45))\n\n# ===== Panel (b): normal (sin cambios) =====\ntheta_b    &lt;- 1.00\nthetahat2  &lt;- 1.60\nsd_b       &lt;- 0.25\nx_b &lt;- seq(0, theta_b + 3.2*sd_b, length.out = 700)\ny_b &lt;- dnorm(x_b, mean = theta_b, sd = sd_b)\ndfb &lt;- data.frame(x = x_b, y = y_b)\nymax_b &lt;- max(dfb$y)\n\np_b &lt;-\n  ggplot(dfb, aes(x, y)) +\n  geom_line(linewidth = 1.2, lineend = \"round\") +\n  annotate(\"segment\", x = 0, xend = max(x_b)+0.3, y = 0, yend = 0, linewidth = 0.8) +\n  annotate(\"segment\", x = 0, xend = 0, y = 0, yend = 1.05*ymax_b, linewidth = 0.8) +\n  geom_segment(aes(x = theta_b, xend = theta_b, y = 0, yend = dnorm(theta_b, theta_b, sd_b)),\n               inherit.aes = FALSE) +\n  annotate(\"text\", x = theta_b,   y = -0.08*ymax_b, label = expression(theta)) +\n  annotate(\"text\", x = thetahat2, y = -0.08*ymax_b, label = expression(hat(theta)[2])) +\n  annotate(\"text\", x = -0.15, y = 0.9*ymax_b,\n           label = expression(f(hat(theta)[2])), angle = 90) +\n  annotate(\"text\", x = (min(x_b)+max(x_b))/2, y = -0.22*ymax_b, label = \"(b)\") +\n  coord_cartesian(xlim = c(0, max(x_b)+0.2),\n                  ylim = c(-0.25*ymax_b, 1.1*ymax_b), clip = \"off\") +\n  theme_void(base_size = 14) +\n  theme(plot.margin = margin(10, 20, 40, 45))\n\n# ===== Combinar =====\np_a | p_b\n\nWarning in geom_segment(aes(x = theta, xend = theta, y = 0, yend = y_theta), : All aesthetics have length 1, but the data has 700 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\nWarning in geom_segment(aes(x = theta_b, xend = theta_b, y = 0, yend = dnorm(theta_b, : All aesthetics have length 1, but the data has 700 rows.\nℹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\n\n\n\n\n\n\nLa figura (b) es la distribución deseada porque una varianza pequeña garantiza que, en un muestreo repetido, una fracción más alta de valores \\(\\hat{\\theta}_2\\) estará ``cerca’’ de \\(\\theta\\).\nPor consiguiente, además de preferir un estimador insesgado, necesitamos que la varianza de la distribución del estimador \\(V(\\hat{\\theta})\\) sea lo más pequeña posible. Dados dos estimadores insesgados de un parámetro \\(\\theta\\) seleccionamos el estimador con la menor varianza, mientras todos los demás parece igual.\n\nExample 3.7 Suponga que \\(Y_1,Y_2,Y_3\\) denotan una muestra aleatoria ind de una distribuci'on exponencial con funci'on de densidad \\[f(y)=\\left\\{\\begin{array}{ll}\\left(\\frac{1}{\\theta}\\right)e^{-y/\\theta},& y&gt;0,\\\\0,&\\mbox{ en cualquier otro punto}\\end{array}\\right.\\] Considere los siguientes estimadores de \\(\\theta\\): \\[\\hat{\\theta}_1=Y_1,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\hat{\\theta}_2=\\frac{Y_1+Y_2}{2},\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\hat{\\theta}_3=\\frac{Y_1+2Y_2}{3},\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\]\n\\[\\hat{\\theta}_4=\\min(Y_1,\\,Y_2,\\,Y_3),\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\hat{\\theta}_5=\\overline{Y}\\]\n\n¿Cuáles son insesgados?\n\nSol: Determinemos si \\(\\hat{\\theta}_4=\\min(Y_1,\\,Y_2,\\,Y_3)\\) es insesgado. Para esto, determinemos la distribución de \\(\\hat{\\theta}_4\\). Supongamos que \\(Y_i\\sim Exp(\\lambda_i)\\) con \\(i=1,2,3\\). \\[\n        \\begin{align}\n        P(\\hat{\\theta}_4&gt;a)&=P(\\min(Y_1,\\,Y_2,\\,Y_3)&gt;a)\\nonumber\\\\\n        &=P(Y_1&gt;a)P(Y_2&gt;a)P(Y_3&gt;a)\\nonumber\\\\\n        &=\\exp\\{-a\\lambda_1\\}\\exp\\{-a\\lambda_2\\}\\exp\\{-a\\lambda_3\\}\\nonumber\\\\\n        &\\exp\\left\\{-a\\left(\\sum_{i=1}^{3}\\lambda_i\\right)\\right\\}\n        \\end{align}\n\\] Así que \\[\n\\begin{align}\nF_{\\hat{\\theta}_4}(a)&=1-P(\\hat{\\theta}_4&gt;a)\\nonumber\\\\\n&=1-\\exp\\left\\{-a\\left(\\sum_{i=1}^{3}\\lambda_i\\right)\\right\\}\n\\end{align}\n\\] De ahí que \\(\\hat{\\theta}_4\\sim Exp\\left(\\sum_{i=1}^{3}\\lambda_i\\right)\\) entonces, \\(E(\\hat{\\theta}_4)=\\frac{1}{\\sum_{i=1}^{3}\\lambda_i}\\). Pero por hipótesis \\(\\lambda_i=\\frac{1}{\\theta}\\), para todo \\(i=1,2,3\\). Luego,\n\n\\[\n\\begin{align}\n    E(\\hat{\\theta}_4)&=\\frac{1}{\\sum_{i=1}^{3}\\lambda_i}\\nonumber\\\\\n    &=\\frac{1}{3\\lambda} \\mbox{ por ser las $Y_i$ son iid}\\nonumber\\\\\n    &=\\frac{1}{\\frac{3}{\\theta}}\\nonumber\\\\\n    &=\\frac{\\theta}{3}\n    \\end{align}\n\\] Luego \\(\\hat{\\theta}_4\\) no es insesgado, es sesgado.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#eficiencia-relativa",
    "href": "chapter2.html#eficiencia-relativa",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.8 Eficiencia relativa",
    "text": "3.8 Eficiencia relativa\n\nDefinition 3.1 Un estimador \\(W\\) de \\(\\theta\\) se denomina inadmisible si existe otro estimador \\(V\\) de \\(\\theta\\) tal que \\[\n\\begin{align}\nE_\\theta((V-\\theta)^2)\\leq E_\\theta((W-\\theta)^2) \\mbox{ para todo $\\theta \\in \\Theta$}\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#mejor-estimador-insesgado.",
    "href": "chapter2.html#mejor-estimador-insesgado.",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.9 Mejor estimador insesgado.",
    "text": "3.9 Mejor estimador insesgado.\n\nDefinition 3.2 Sean \\(\\hat{\\theta}_1\\) y \\(\\hat{\\theta}_2\\) dos estimadores insesgados de un parámetro \\(\\theta\\), con varianzas \\(V (\\hat{\\theta}_1)\\) y \\(V (\\hat{\\theta}_2)\\), respectivamente. Entonces la eficiencia de \\(\\hat{\\theta}_1\\) con respecto a \\(\\hat{\\theta}_2\\) denotada como \\(eff(\\hat{\\theta}_1,\\,\\hat{\\theta}_2)\\) se defiene por la expresión\n\\[eff (\\hat{\\theta}_1,\\, \\hat{\\theta}_2)=\\frac{V(\\hat{\\theta}_1)}{V(\\hat{\\theta}_2)}.\\]\n\n\nExample 3.8 Diremos que \\(\\hat{\\theta}_1\\) es más eficiente que \\(\\hat{\\theta}_2\\) si \\[eff(\\hat{\\theta}_1,\\,\\hat{\\theta}_2)&lt;1\\mbox{ si y sólo si }V(\\hat{\\theta}_2)&gt;V(\\hat{\\theta}_1)\\] luego \\(\\hat{\\theta}_1\\) es un mejor estimador insesgado que \\(\\hat{\\theta}_2\\).\n\n\nExample 3.9 Si \\(eff(\\hat{\\theta}_1,\\,\\hat{\\theta}_2)=1.8\\) entonces \\(V(\\hat{\\theta}_1)=1.8V(\\hat{\\theta}_2)\\) entonces \\(\\hat{\\theta}_2\\) se prefiere a \\(\\hat{\\theta}_1\\).\nSi \\(eff(\\hat{\\theta}_1,\\,\\hat{\\theta}_2)=0.73\\) entonces \\(V(\\hat{\\theta}_1)=0.73V(\\hat{\\theta}_2)\\) entonces \\(\\hat{\\theta}_1\\) se prefiere a \\(\\hat{\\theta}_2\\).\n\n\nTheorem 3.4 Teorema de Lehmann-Scheffé Si \\(\\hat{\\theta}\\) es un estimador insesgado para \\(\\theta\\) y si \\(U\\) es un estadístico suficiente para \\(\\theta\\), entonces hay una función de \\(U\\) que también es un estimador insesgado para \\(\\theta\\) y tiene una varianza no mayor que \\(\\hat{\\theta}\\).\nEn símbolos:\nSi \\(E(\\hat{\\theta})=\\theta\\) y \\(U\\) es suficiente para \\(\\theta\\) entonces existe una \\(f(U)\\) tal que \\[E(f(U))=\\theta\\] y \\[Var(\\hat{\\theta})\\geq Var(f(U))\\]\n\n\nExample 3.10 Contexto del teorema\nUn estimador insesgado de \\(\\theta\\) es una variable aleatoria \\(\\hat{\\theta}\\) que cumple:\n\\[\nE(\\hat{\\theta}) = \\theta.\n\\]\nUn estadístico suficiente \\(U\\) para \\(\\theta\\) contiene toda la información de la muestra acerca de \\(\\theta\\). Es decir, dados \\(U\\), la muestra completa no aporta nada más sobre \\(\\theta\\).\nEl Teorema de Lehmann–Scheffé dice que si combinas estos dos elementos:\n\nUn estimador insesgado cualquiera \\(\\hat{\\theta}\\).\nUn estadístico suficiente \\(U\\).\n\nEntonces puedes construir una función de \\(U\\), digamos \\(f(U)\\), que:\n\ntambién es insesgado,\ntiene varianza menor o igual a la de \\(\\hat{\\theta}\\).\n\nDe hecho, el resultado formal se apoya en el Teorema de Rao–Blackwell:\n\\[\nf(U) = E(\\hat{\\theta} \\mid U).\n\\]\nEsta transformación se llama Rao-Blackwellización.\nY el teorema de Lehmann–Scheffé añade que, si \\(U\\) además de suficiente es completo, entonces ese \\(f(U)\\) es el único estimador insesgado de varianza mínima (UMVUE: Uniformly Minimum Variance Unbiased Estimator).\n\n2. Intuición\n\nEmpiezas con cualquier estimador insesgado \\(\\hat{\\theta}\\).\nSi “condicionas” en la estadística suficiente \\(U\\), eliminas ruido innecesario que no aporta información sobre \\(\\theta\\).\nEso reduce (o al menos no aumenta) la varianza del estimador.\nEl resultado es un estimador más eficiente.\n\n\n3. Ejemplo clásico\nContexto Supongamos que:\n\\[\nX_1, X_2, \\dots, X_n \\overset{iid}{\\sim} \\text{Bernoulli}(p),\n\\]\ndonde el parámetro de interés es \\(p\\).\n\nPaso 1: un estimador insesgado cualquiera\nConsideremos el estimador basado sólo en el primer dato:\n\\[\n\\hat{p} = X_1.\n\\]\nClaramente:\n\\[\nE(\\hat{p}) = E(X_1) = p.\n\\]\nAsí que es insesgado, pero muy ineficiente (usa un solo dato).\n\nPaso 2: estadístico suficiente\nEl número total de éxitos:\n\\[\nU = \\sum_{i=1}^n X_i\n\\]\nes un estadístico suficiente para \\(p\\) (por factorización de la verosimilitud).\n\nPaso 3: aplicar Rao–Blackwell\nConstruimos:\n\\[\nf(U) = E(\\hat{p} \\mid U).\n\\]\nComo \\(\\hat{p} = X_1\\), necesitamos \\(E(X_1 \\mid U)\\).\nPor simetría, dado que hay \\(U\\) éxitos en total entre \\(n\\) ensayos, cada \\(X_i\\) tiene la misma probabilidad de ser 1. Entonces:\n\\[\nE(X_1 \\mid U) = \\frac{U}{n}.\n\\]\nAsí:\n\\[\nf(U) = \\frac{U}{n}.\n\\]\n\nPaso 4: verificar propiedades\n\nInsesgado:\n\n\\[\nE\\left(\\frac{U}{n}\\right) = \\frac{1}{n}E(U) = \\frac{1}{n}(np) = p.\n\\]\n\nVarianza:\n\n\\[\nVar(X_1) = p(1-p),\n\\]\n\\[\nVar\\left(\\frac{U}{n}\\right) = \\frac{1}{n^2} Var(U) = \\frac{1}{n^2}(np(1-p)) = \\frac{p(1-p)}{n}.\n\\]\nY efectivamente:\n\\[\n\\frac{p(1-p)}{n} \\leq p(1-p).\n\\]\n\n4. Conclusión\nEl estimador inicial \\(\\hat{p} = X_1\\) era insesgado pero ineficiente.\nRao–Blackwellizando con el suficiente \\(U\\), obtuvimos:\n\\[\nf(U) = \\frac{U}{n},\n\\]\nque es la media muestral.\nPor Lehmann–Scheffé, como \\(U\\) es suficiente y completo, \\(\\bar{X} = U/n\\) es el UMVUE de \\(p\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#teorema-de-cramér-rao.-información-de-fisher",
    "href": "chapter2.html#teorema-de-cramér-rao.-información-de-fisher",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.10 Teorema de Cramér-Rao. Información de Fisher",
    "text": "3.10 Teorema de Cramér-Rao. Información de Fisher\n\nDefinition 3.3 Diremos que un estimador \\(W^{*}\\) es el mejor estimador insesgado de \\(\\tau(\\theta)\\), o el UMVUE (Uniformly Minimum Variance Unbiased Estimator) (estimador insesgado de \\(\\tau(\\theta)\\) uniformemente de mínima varianza) , si \\(E_\\theta(W^{*}) = \\tau(\\theta)\\) para todo \\(\\theta\\in\\Theta\\) y si para cualquier otro estimador \\(W\\) , tal que \\(E_\\theta(W) = \\tau(\\theta)\\) para todo \\(\\theta\\in\\Theta\\), se tiene que \\(V_\\theta(W^{*}) \\leq V_\\theta(W)\\), para todo \\(\\theta\\in\\Theta\\).\n\nLa búsqueda del UMVUE no debe consistir en repasar todos los estimadores insesgados posibles. El siguiente resultado aborda el problema de un modo diferente: establece una cota inferior para la varianza de todos los estimadores insesgados de un parámetro. Así, si encontramos un estimador insesgado cuya varianza iguale esa cota podremos concluir que ese estimador es el UMVUE.\n\nTheorem 3.5 Sea \\(\\underset{\\sim}{X} =(X_1,\\ldots, X_n)\\) una variable aleatoria n-dimensional con función de densidad conjunta \\(f ( \\underset{\\sim}{x}|\\theta)\\), \\(\\theta\\in\\Theta\\subseteq\\mathbb{R}\\). Sea \\(W(\\underset{\\sim}{X} )\\) un estimador insesgado para \\(\\tau(\\theta)\\), es decir, \\(E_\\theta(W(\\underset{\\sim}{X})) = \\tau(\\theta)\\) para todo \\(\\theta\\), donde \\(\\tau\\) es una función de \\(\\theta\\) que cumple:\nH1: \\(\\tau(\\theta)\\) es diferenciable en \\(\\theta\\).\nH2: Se supone además que la verosimilitud conjunta \\(f(\\underset{\\sim}{x}|\\theta)\\) verifica que para cualquier función \\(h(\\underset{\\sim}{x})\\) tal que \\(E_\\theta|h(\\underset{\\sim}{X})| &lt; \\infty\\) se tiene que\n\\[\n\\begin{align}\n&\\frac{d}{d\\theta}\\int\\dotsc\\int h(\\underset{\\sim}{x})f (\\underset{\\sim}{x}|\\theta)dx_1\\ldots dx_n\\nonumber\\\\\n&=\\int\\dotsc\\int h(\\underset{\\sim}{x})\\left[\\frac{\\partial}{\\partial\\theta}f (\\underset{\\sim}{x}|\\theta)\\right]dx_1\\ldots dx_n\n\\end{align}\n\\]\nEntonces, \\[\\begin{align}\nV_\\theta(W(\\underset{\\sim}{X} ))\\geq\\frac{\\left(\\frac{d}{d\\theta}\\tau(\\theta)\\right)^2}{E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f(\\underset{\\sim}{X}|\\theta)\\right)^2\\right]}\n\\end{align}\\] A la cantidad del lado derecho de la desigualdad anterior se la denomina Cota de Cramér-Rao.\n\n\n\n\n\n\n\nNote 3.2\n\n\n\nNota: El teorema de Cramér-Rao es igualmente válido en el caso discreto. En este caso la hipótesis H2 afirma que pueden intercambiarse el sumatorio y la diferenciación.\n\n\n\nUn estimador insesgado para \\(\\tau(\\theta)\\) se denomina si su varianza es la mínima posible, es decir, si es igual a la cota de Cramér-Rao.\nLa eficiencia de un estimador insesgado se define como el cociente entre la cota de Cramér-Rao y su varianza.\nEs un valor menor o igual que 1 si se dan las hipótesis del teorema de Cramér-Rao.\n\nEn la demostración del teorema de Cramér-Rao se ha probado que\n\\[\n\\begin{align}\nE_\\theta(S(\\theta))&=E_\\theta(S(\\theta|\\underset{\\sim}{X}))\\nonumber\\\\\n&=E_\\theta\\left(\\frac{\\partial}{\\partial \\theta}\\log L(\\theta|\\underset{\\sim}{X})\\right)=0\n\\end{align}\n\\] Obsérvese que para obtener el estimador máximo verosímil de \\(\\theta\\) lo que se hace es resolver la ecuación \\[\\begin{align}\n    S(\\theta|\\underset{\\sim}{X})=0\n\\end{align}\\] lo que equivale a buscar el valor de \\(\\theta\\) para el cual el valor de \\(S(\\theta|\\underset{\\sim}{X})\\) coincide con su valor esperado.\nA la cantidad que aparece en el denominador de la cota de Cramér-Rao se le denomina cantidad de información de Fisher que sobre \\(\\theta\\) contiene el vector \\(\\underset{\\sim}{X}\\):\n\\[\n\\begin{align}\n\\mathscr{I}_{E}(\\theta)=\\mathscr{I}_{\\underset{\\sim}{X}}(\\theta)&=E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{X}|\\theta)\\right)^2\\right]\\\\\n&=V\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{X}|\\theta)\\right)\\\\\n&=V(S(\\theta|\\underset{\\sim}{X}))\n\\end{align}\n\\]\nSe denomina cantidad de información de Fisher que sobre \\(\\theta\\) contiene la variable \\(X_i\\) a \\[\n\\begin{align}\n    &=E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(X|\\theta)\\right)^2\\right]\\\\\n    &=V\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(X|\\theta)\\right)\\\\\n    &=V(S(\\theta|X_i))\n    \\end{align}\n\\]\nCuando \\(\\underset{\\sim}{X}=(X_1,\\ldots, X_n)\\) es una muestra aleatoria simple de \\(X\\) se verifica que la información de Fisher contenida en la muestra es la suma de las informaciones contenidas en cada una de las observaciones y, dado que éstas son idénticamente distribuidas, se tiene que\n\\[\n\\begin{align}\n\\mathscr{I}_{E}(\\theta)=\\mathscr{I}_{\\underset{\\sim}{X}}(\\theta)=n\\mathscr{I}_{X}(\\theta)\n\\end{align}\n\\] Este resultado es consecuencia del siguiente corolario del teorema de Cramér-Rao:\n\nCorollary 3.1 Bajo las hipótesis del teorema de Cramér-Rao, si \\(\\underset{\\sim}{X}=(X_1,\\ldots, X_n)\\) es una muestra aleatoria simple de \\(X\\) con distribución dada por \\(f(x|\\theta)\\) entonces \\[\n\\begin{align*}\n\\mathscr{I}_{E}(\\theta)=\\mathscr{I}_{\\underset{\\sim}{X}}(\\theta)&=E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{X}|\\theta)\\right)^2\\right]\\\\\n&=nE_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X}(X|\\theta)\\right)^2\\right]\\\\\n&=n\\mathscr{I}_{X}(\\theta)\n\\end{align*}\n\\]\n\n\nProof. Por independencia, la verosimilitud de \\(\\underset{\\sim}{X}\\) es el producto de verosimilitudes, luego \\[\\begin{align}\n    \\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)&=\\frac{\\partial}{\\partial \\theta}\\sum_{i=1}^{n}\\log f_{X}(x_i|\\theta)\\nonumber\\\\\n    &=\\sum_{i=1}^{n}\\frac{\\partial}{\\partial \\theta}\\log f_{X}(x_i|\\theta)\n    \\end{align}\\] Por lo tanto,\n\\[\n\\begin{align}\nE_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)\\right)^2\\right]&=E_\\theta\\left[\\left(\\sum_{i=1}^{n}\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\right)^2\\right]\\nonumber\\\\\n=&\\sum_{i=1}^{n}E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\right)^2\\right]\\nonumber\\\\\n+&\\sum_{i\\neq j}E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\frac{\\partial}{\\partial \\theta}\\log f_{X_j}(x_j|\\theta)\\right)\\right]\n\\end{align}\n\\tag{3.10}\\]\nLa segunga igualdad de Equation 3.10 se tiene por que \\(\\left(\\sum_{i=1}^{n}a_i\\right)^2=\\sum_{i=1}^{n}a_i^2+\\sum_{i\\neq j}a_ia_j\\). Pero la segunda sumatoria es igual a cero debido a la independencia entre \\(X_i\\) y \\(X_j\\) y dado que las funciones score tienen esperanza 0, según se vio en la demostración del teorema de Cramér-Rao. \\[\n\\begin{align}\nE_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)\\right)^2\\right]\n        =&\\sum_{i=1}^{n}E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\right)^2\\right]\\nonumber\\\\\n        +&\\sum_{i\\neq j}E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\right)\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_j}(x_j|\\theta)\\right)\\right]\\nonumber\\\\\n        =&\\sum_{i=1}^{n}E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\right)^2\\right]\\nonumber\\\\\n\\end{align}\n\\tag{3.11}\\]\n\n\nLemma 3.1 Si la función de verosimilitud satisface:\nH3: Se supone que la verosimilitud conjunta \\(f (\\underset{\\sim}{x}|\\theta)\\) verifica que para cualquier función \\(h(\\underset{\\sim}{x})\\) tal que \\(E_\\theta|h(\\underset{\\sim}{X})| &lt; \\infty\\) se tiene que \\[\n\\begin{align}\n&\\frac{\\partial^2}{\\partial\\theta^2}\\int\\dotsc\\int h(\\underset{\\sim}{x})f (\\underset{\\sim}{x}|\\theta)dx_1\\ldots dx_n\\nonumber\\\\\n&=\\int\\dotsc\\int h(\\underset{\\sim}{x})\\left[\\frac{\\partial^2}{\\partial\\theta^2}f (\\underset{\\sim}{x}|\\theta)\\right]dx_1\\ldots dx_n\n\\end{align}\n\\]\nEntonces \\[\n\\begin{align}\n\\mathscr{I}_{X}(\\theta)=E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X}(x|\\theta)\\right)^2\\right]=-E_\\theta\\left[\\frac{\\partial^2}{\\partial \\theta^2}\\log f_{X}(x|\\theta)\\right]\n\\end{align}\n\\]\n\n\nProof. \\[\n\\begin{align}\n        \\frac{\\partial^2}{\\partial \\theta^2}\\log f_{X}(x|\\theta)&=\\frac{\\partial}{\\partial \\theta}\\left[\\frac{1}{f_{X}(x|\\theta)}\\left(\\frac{\\partial}{\\partial \\theta}f_{X}(x|\\theta)\\right)\\right]\\nonumber\\\\\n        &=-\\frac{1}{f^2_{X}(x|\\theta)}\\left(\\frac{\\partial}{\\partial \\theta}f_{X}(x|\\theta)\\right)^2\\nonumber\\\\\n        &+\\frac{1}{f_{X}(x|\\theta)}\\frac{\\partial^2}{\\partial \\theta^2}f_{X}(x|\\theta)\n\\end{align}\n\\] Por otro lado, \\[\n\\begin{align}\n    E_\\theta\\left[\\frac{1}{f_{X}(x|\\theta)}\\frac{\\partial^2}{\\partial \\theta^2}f_{X}(x|\\theta)\\right]&=\\int\\frac{\\partial^2}{\\partial \\theta^2}f_{X}(x|\\theta)dx\\nonumber\\\\\n    &\\overset{\\text{H3}}{=}\\frac{d^2}{d \\theta^2}\\int f_{X}(x|\\theta)dx\\nonumber\\\\\n    &=\\frac{d^2}{d \\theta^2}1 =0\n\\end{align}\n\\] Así pues, \\[\n\\begin{align}\n        E_\\theta\\left[\\frac{\\partial^2}{\\partial \\theta^2}\\log f_{X}(x|\\theta)\\right]\n        &=-E_\\theta\\left[\\frac{1}{f^2_{X}(x|\\theta)}\\left(\\frac{\\partial}{\\partial \\theta}f_{X}(x|\\theta)\\right)^2\\right]\\nonumber\\\\\n        &=-E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X}(x|\\theta)\\right)^2\\right]\\nonumber\\\\\n        &=-\\mathscr{I}_{X}(\\theta)\n        \\end{align}\n\\]\n\n\nEn general, el teorema de Cramér-Rao no es aplicable si el soporte de \\(f(x|\\theta)\\) depende del parámetro \\(\\theta\\) debido a que la derivada y la integral no son intercambiables si los límites de integración dependen de \\(\\theta\\).\nAunque el teorema de Cramér-Rao pueda ser aplicado y la cota de Cramér-Rao sea efectiva, no hay garantías de que esta cota sea alcanzada por algún estimador insesgado del parámetro.\n\n\nCorollary 3.2 Sea \\(X_1 , \\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) con distribución dada por \\(f(x|\\theta)\\), \\(\\theta\\in\\mathbb{R}\\), donde \\(f\\) satisface las hipótesis del teorema de Cramér-Rao. Sea \\(L(\\theta|\\underset{\\sim}{x}) = \\prod_{i=1}^{n}f(x_i|\\theta)\\) la función de verosimilitud. Sea \\(W (\\underset{\\sim}{x}) = W(X_1 , \\ldots, X_n)\\) un estimador insesgado de \\(\\tau(\\theta)\\). Entonces \\(W(\\underset{\\sim}{x})\\) alcanza la cota de Cramér-Rao si y sólo si existe una función \\(a(\\theta)\\) tal que se tiene la igualdad \\[\n\\begin{align}\na(\\theta)(W(\\underset{\\sim}{x})-\\tau(\\theta))=\\frac{\\partial}{\\partial\\theta}\\log L(\\theta|\\underset{\\sim}{x}) \\mbox{ para todo $\\theta$}\n\\end{align}\n\\]\n\nAdemás, el enunciado del corolario Corollary 3.2 ocurre sí y sólo sí existen funciones \\(h(\\theta)\\), \\(k(\\theta)\\) y \\(u(\\underset{\\sim}{x})\\) tales que\n\\[\n\\begin{align}\nL(\\theta|\\underset{\\sim}{x})=u(\\underset{\\sim}{x})h(\\theta)\\exp\\{W(\\underset{\\sim}{x})k(\\theta)\\}\n\\end{align}\n\\] es decir, si y sólo si la distribución de partida pertenece a la familia exponencial.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#evaluación-de-estimadores",
    "href": "chapter2.html#evaluación-de-estimadores",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.11 Evaluación de estimadores",
    "text": "3.11 Evaluación de estimadores\n\n3.11.1 Mejor estimador insesgado.\nTeorema de Rao-Blackwell. Teorema de Lehmann-Scheffé\nSi buscamos estimadores insesgados con varianzas pequeñas, podemos restringir nuestra búsqueda a estimadores que sean funciones de estadísticos suficientes.\n\nTheorem 3.6 Si \\(Y_1\\) y \\(Y_2\\) son dos variables aleatorias, entonces\n\\(E(Y_1) = E[E(Y_1 \\mid Y_2)]\\),\ndonde en el lado derecho de la ecuación el valor esperado interior es con respecto a la distribución condicional de \\(Y_1\\) dada \\(Y_2\\), y el valor esperado exterior es con respecto a la distribución de \\(Y_2\\).\n\n\n\nTheorem 3.7 Si \\(Y_1\\) y \\(Y_2\\) representan variables aleatorias, entonces\n\\(V(Y_1) = E[V(Y_1 \\mid Y_2)] + V[E(Y_1 \\mid Y_2)]\\).\n\n\nTheorem 3.8 El Teorema de Rao-Blackwell Sea \\(\\hat{\\theta}\\) un estimador insesgado para \\(\\theta\\) tal que \\(V (\\hat{\\theta}) &lt;\\infty\\) . Si \\(U\\) es un estadístico suficiente para \\(\\theta\\), definamos \\(\\hat{\\theta}^* = E(\\hat{\\theta} |U)\\). Entonces, para toda \\(\\theta\\), \\[E(\\hat{\\theta}^*) =\\theta\\mbox{ y }V(\\hat{\\theta}^*) \\leq V(\\hat{\\theta})\\].\n\n\nProof. Como \\(U\\) es suficiente para \\(\\theta\\), la distribución condicional de cualquier estadístico (incluyendo \\(\\hat{\\theta}\\)), dada \\(U\\) no depende de \\(\\theta\\). Entonces, \\(\\hat{\\theta}^*=E(\\hat{\\theta}|U)\\) no es función de \\(\\theta\\) y es por tanto un estadístico.\nComo \\(\\hat{\\theta}\\) es un estimador insesgado para \\(\\theta\\) entonces de los Teoremas Theorem 3.6 y Theorem 3.7, tenemos \\[E(\\hat{\\theta}^*)=E[E(\\hat{\\theta}|U)]=E(\\hat{\\theta})=\\theta.\\] Entonces \\(\\hat{\\theta}^*\\) es un estimador insesgado para \\(\\theta\\). El Teorema Theorem 3.7 implica que \\[\\begin{eqnarray*}\nV(\\hat{\\theta})&=&V[E(\\hat{\\theta}|U)]+E[V(\\hat{\\theta}|U)]\\\\\n            &=&V(\\hat{\\theta}^*)+E[V(\\hat{\\theta}|U)].\n\\end{eqnarray*}\\] Como \\(V(\\hat{\\theta} |U = u) \\geq 0\\) para toda \\(u\\), se deduce que \\(E[V(\\hat{\\theta} |U)]\\geq 0\\) y por lo tanto que \\[\\begin{eqnarray*}\nV(\\hat{\\theta})&=&V(\\hat{\\theta}^*)+E[V(\\hat{\\theta}|U)]\\\\\n&\\geq&V(\\hat{\\theta}^*)+0\n\\end{eqnarray*}\\] luego \\(V (\\hat{\\theta}) \\geq V (\\hat{\\theta}^*)\\).\n\nEl Teorema de Rao-Blackwell implica que un estimador insesgado para \\(\\theta\\) con una varianza pequeña es, o puede llegar a ser, una función de un estadístico suficiente. Si \\(U\\) es un estadístico suficiente para \\(\\theta\\), \\(E(\\hat{\\theta}|U)=\\hat{\\theta}^*\\) entonces \\(E(\\hat{\\theta}^*)=\\theta\\) y \\(V(\\hat{\\theta}^*)\\leq V(\\hat{\\theta})\\). \\(\\theta^*\\) Estimador insesgado, \\(\\hat{\\theta}^*=h(U)\\) entonces \\(E(h(U)|U)=h(U)=\\hat{\\theta}^*\\).\nEn general, \\(E(h(U)|U)=h(U)\\), vemos que usando de nuevo el teorema de Rao-Blackwell nuestro nuevo estimador es simplemente \\(h(U)=\\hat{\\theta}^*\\). No ganamos nada después de la primera aplicación.\nDebido a que numerosos estadísticos son suficientes para un parámetro \\(\\theta\\) asociado con una distribución ¿qué estadístico suficiente debemos usar cuando aplicamos este teorema?\nEl criterio de factorización de manera típica identifica un estadístico \\(U\\) que mejor resume la información de los datos acerca del parámetro \\(\\theta\\). Tales estadísticos reciben el nombre de estadísticos suficinetes mínimos.\nSi aplicamos el Teoremo Theorem 3.8 usando \\(U\\), no sólo obtenemos un estimador con varianza más pequeña si no un estimador insesgado para \\(\\theta\\) con varianza mínima, este se le llama Estimador Insesgado de Varianza Mínima EIVM (MVUE).\n\n\n\n\n\n\nNote 3.3\n\n\n\nEl Teorema de Rao–Blackwell es uno de esos resultados hermosos que nos dicen: “Siempre puedes mejorar tus estimadores, si aprovechas la información disponible en un estadístico suficiente”.\nSupongamos que queremos estimar la media \\(\\theta = \\mu\\) de una distribución Bernoulli(\\(p\\)).\nEstimador inicial ingenuo:\nTomemos una muestra de tamaño \\(n\\) y digamos que solo miramos la primera observación \\(X_1\\).\nComo \\(E(X_1) = p\\), este es un estimador insesgado, pero claramente tiene varianza muy grande.\nEstadístico suficiente:\nLa suma \\(U = \\sum_{i=1}^n X_i\\) es suficiente para \\(p\\).\nEstimador Rao–Blackwellizado:\nCalculamos:\n\\[\\hat{p}^* = E(X_1 \\mid U) = \\frac{U}{n}.\\]\nEs decir, hemos pasado de un estimador ingenuo (\\(X_1\\)) a la media muestral, que sabemos es mucho más eficiente.\n\n\n\n## Teorema de Rao–Blackwell: ejemplo Bernoulli ----\n\nset.seed(123)\n\n# Parámetros verdaderos\np     &lt;- 0.6\nn     &lt;- 20         # tamaño de muestra\nNsim  &lt;- 10000      # número de simulaciones\n\n# Vectores para guardar los estimadores\nest_naive &lt;- numeric(Nsim)  # usa solo la primera observación X1\nest_RB    &lt;- numeric(Nsim)  # E[X1 | U] = U/n  (media muestral)\n\nfor (s in 1:Nsim) {\n  X &lt;- rbinom(n, size = 1, prob = p)\n  U &lt;- sum(X)\n\n  est_naive[s] &lt;- X[1]\n  est_RB[s]    &lt;- U / n\n}\n\n# Resumen empírico\nmean_naive &lt;- mean(est_naive)\nvar_naive  &lt;- var(est_naive)\n\nmean_RB &lt;- mean(est_RB)\nvar_RB  &lt;- var(est_RB)\n\n# Valores teóricos\nvar_naive_theo &lt;- p * (1 - p)            # Var(X1)\nvar_RB_theo    &lt;- p * (1 - p) / n        # Var(U/n)\n\ncat(\"==== Resultados (empíricos vs teóricos) ====\\n\")\n\n==== Resultados (empíricos vs teóricos) ====\n\ncat(sprintf(\"E[X1]            empírico = %.4f  (teórico = %.4f)\\n\", mean_naive, p))\n\nE[X1]            empírico = 0.6006  (teórico = 0.6000)\n\ncat(sprintf(\"Var(X1)          empírico = %.4f  (teórico = %.4f)\\n\\n\", var_naive, var_naive_theo))\n\nVar(X1)          empírico = 0.2399  (teórico = 0.2400)\n\ncat(sprintf(\"E[U/n]           empírico = %.4f  (teórico = %.4f)\\n\", mean_RB, p))\n\nE[U/n]           empírico = 0.6004  (teórico = 0.6000)\n\ncat(sprintf(\"Var(U/n)         empírico = %.4f  (teórico = %.4f)\\n\\n\", var_RB, var_RB_theo))\n\nVar(U/n)         empírico = 0.0119  (teórico = 0.0120)\n\ncat(sprintf(\"Reducción de varianza (empírica): Var(U/n) / Var(X1) = %.4f\\n\", var_RB / var_naive))\n\nReducción de varianza (empírica): Var(U/n) / Var(X1) = 0.0494\n\ncat(sprintf(\"Reducción de varianza (teórica) : Var(U/n) / Var(X1) = %.4f\\n\", var_RB_theo / var_naive_theo))\n\nReducción de varianza (teórica) : Var(U/n) / Var(X1) = 0.0500\n\n\nSi empezamos con un estimador insesgado para \\(\\theta\\) y el estadístico suficiente obtenido por medio del criterio de factorización, la aplicación del Teorema de Rao-Blackwell en general lleva a un MVUE para el parámetro.\nSea \\(\\hat{\\theta}\\) el parámetro insesgado para \\(\\theta\\). \\[E(\\hat{\\theta})=\\theta\\] \\(U\\) igual al obtenido por el método de factorización \\[\\hat{\\theta}^*=E(\\hat{\\theta}|U)\\] donde \\(\\hat{\\theta}^*\\) es el MVUE (Aplicar Blackwell).\nLa consecuencia fundamental de este teorema es que en la búsqueda del estimador UMVUE, basta con restringirnos a aquellos estimadores insesgados que son función de un estadístico suficiente: si trabajamos con un estadístico insesgado que no es función de uno suficiente, tomando esperanzas condicionadas podemos conseguir otro que sea al menos tan bueno como el anterior y sea función del estadístico suficiente. Este proceso se llama a veces Rao-Blackwellización.\n\n3.11.2 Otra versión del teorema de Rao-Blackwell\n\nTheorem 3.9 Otra versión del teorema de Rao-Blackwell Sea una m.a.s. de \\(X\\), con densidad (o masa de probabilidad) \\(f(x|\\theta)\\). Sea \\(T(\\underset{\\sim}{X})\\) un estadístico suficiente para \\(\\theta\\) y sea \\(W(\\underset{\\sim}{X})\\) un estimador insesgado de \\(\\tau(\\theta)\\). Definimos \\[\\begin{align}\nW_T=E_\\theta(W|T)\n\\end{align}\\] Entonces,\n\n\n\\(W_T\\) es función unicamente de \\(T(\\underset{\\sim}{X})\\) (Es decir, no depende de \\(\\theta\\) y no depende de la muestra \\(\\underset{\\sim}{X}\\) sólo a través del valor de \\(T(\\underset{\\sim}{X})\\))\n\n\\(E_\\theta(W_T)=\\tau(\\theta)\\).\n\n\\(V_\\theta(W_T)\\leq V_\\theta(W)\\) .\n\n\nLa consecuencia fundamental de este teorema es que en la búsqueda del estimador UMVUE, basta con restringirnos a aquellos estimadores insesgados que son función de un estadístico suficiente: si trabajamos con un estadístico insesgado que no es función de uno suficiente, tomando esperanzas condicionadas podemos conseguir otro que es al menos tan bueno como el anterior y es función del estadístico suficiente. Este proceso se llama a veces Rao-Blackwellización.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#comportamiento-asintótico",
    "href": "chapter2.html#comportamiento-asintótico",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.12 Comportamiento asintótico",
    "text": "3.12 Comportamiento asintótico\n\n3.12.1 Consistencia\n\nDefinition 3.4 Se dice que el estimador \\(\\hat{\\theta}_n\\) es un estimador consistente de \\(\\theta\\) si, para cualquier número positivo \\(\\varepsilon\\), \\[\\lim_{n\\rightarrow\\infty}P(|\\hat{\\theta}_n-\\theta|\\leq\\varepsilon)=1\\] o bien, de forma equivalente, \\[\\lim_{n\\rightarrow\\infty}P(|\\hat{\\theta}_n-\\theta|&gt;\\varepsilon)=0\\]\n\nLa consistencia es la misma convergencia en probabilidad!!\n\nTheorem 3.10 Un estimador insesgado \\(\\hat{\\theta}_n\\) para \\(\\theta\\) es un estimador consistente de \\(\\theta\\) si \\[\\lim_{n\\rightarrow\\infty}V(\\hat{\\theta}_n)=0.\\]\n\n\nProof. \\(E(\\hat{\\theta}_n)=\\theta\\). Sea \\(\\sigma_{\\hat{\\theta}_n}=\\sqrt{V(\\hat{\\theta}_n)}\\) aplicando el Teorema Tchebysheff para la v.a \\(\\hat{\\theta}_n\\), obtenemos \\[P(|\\hat{\\theta}_n-\\theta|&gt;k\\sigma_{\\hat{\\theta}_n}\n    )\\leq \\frac{1}{k^2}\\] Para cualquier número positivo \\(\\varepsilon\\), y \\(n\\) cualquier tamaño muestral \\[\\varepsilon=k\\sigma_{\\hat{\\theta}_n}\\Rightarrow k=\\frac{\\varepsilon}{\\sigma_{\\hat{\\theta}_n}}\\] luego \\(k&gt;0\\).\nLa aplicación del teorema de Chebyshev para esta \\(n\\) fija y esta selección de \\(k\\) muestra que \\[\\begin{eqnarray*}\n    P(|\\hat{\\theta}_n-\\theta|&gt;\\varepsilon)&=&P\\left(|\\hat{\\theta}_n-\\theta|&gt;\\left[\\frac{\\varepsilon}{\\sigma_{\\hat{\\theta}_n}}\\right]\\sigma_{\\hat{\\theta}_n}\\right)\\\\\n    &\\leq&\\frac{1}{(\\varepsilon/\\sigma_{\\hat{\\theta}_n})^2}\\\\\n    &=&\\frac{V(\\hat{\\theta}_n)}{\\varepsilon^2}\n\\end{eqnarray*}\\] Entonces, para cualquier \\(n\\) fija \\[0\\leq P(|\\hat{\\theta}_n-\\theta|&gt;\\varepsilon)\\leq \\frac{V(\\hat{\\theta}_n)}{\\varepsilon^2}\\] Si \\(\\lim_{n\\rightarrow\\infty}V(\\hat{\\theta}_n)=0\\) entonces \\[\\lim_{n\\rightarrow\\infty}0\\leq \\lim_{n\\rightarrow\\infty}P(|\\hat{\\theta}_n-\\theta|&gt;\\varepsilon)\\leq\\lim_{n\\rightarrow\\infty} \\frac{V(\\hat{\\theta}_n)}{\\varepsilon^2}=0\\] Luego \\[\\lim_{n\\rightarrow\\infty}P(|\\hat{\\theta}_n-\\theta|&gt;\\varepsilon)=0\\] luego \\(\\hat{\\theta}_n\\) es un estimador consistente para \\(\\theta\\).\n\n\nTheorem 3.11 \\(\\displaystyle{\\hat{\\theta}_n \\stackrel{P}{\\rightarrow} \\theta}\\) y \\(\\displaystyle{\\hat{\\theta}'_n \\stackrel{P}{\\rightarrow} \\theta'}\\) entonces\n\n\n\\(\\displaystyle{\\hat{\\theta}_n +\\hat{\\theta}'_n \\stackrel{P}{\\longrightarrow} \\theta+\\theta'}\\).\n\n\\(\\displaystyle{\\hat{\\theta}_n \\times\\hat{\\theta}'_n \\stackrel{P}{\\longrightarrow} \\theta\\times\\theta'}\\).\nSi \\(\\theta'\\neq 0\\), \\(\\displaystyle{\\frac{\\hat{\\theta}_n}{\\hat{\\theta}'_n}\\stackrel{P}{\\longrightarrow} \\frac{\\theta}{\\theta'}}\\).\nSi \\(g (\\cdot)\\) es una funci'on de valor real que es continua en \\(\\theta\\), entonces \\(g (\\hat{\\theta}_n )\\) converge en probabilidad en \\(g (\\theta)\\).\n\n\n\n\n\n\n\n\nTip 3.1\n\n\n\n\nEl teorema de Rao-Blackwell establece que basta con buscar el estimador UMVUE entre aquellos estimadores que son función de un estadístico suficiente.\nBajo ciertas condiciones (existencia de estadísticos suficientes y completos y de estimadores insesgados), esta combinación de los conceptos de estadístico completo y de estadístico suficiente garantiza la existencia de estimadores UMVUE de una función \\(\\tau(\\theta)\\) del parámetro y da un método para construirlos. El siguiente teorema establece este resultado. Podemos decir que este teorema resuelve teóricamente el problema de la estimación puntual, entendida ésta como la búsqueda del UMVUE.\n\n\n\n\n\nDefinition 3.6 (estadístico completo) Sea \\(f_T(t|\\theta)\\) la función de densidad (o de masa de probabilidad) de un estadístico \\(T\\) . Diremos que la familia de distribuciones \\({f_T(t|\\theta) : \\theta\\in \\Theta}\\) es completa si se da la implicación siguiente: \\[\\begin{align}\nE_\\theta(g(T))=0 \\mbox{para todo $\\theta$ entonces}  P_\\theta(g(T) = 0) = 1 \\mbox{para todo $\\theta$}.\n\\end{align}\\]\nEn ese caso diremos que \\(T\\) es un estadístico completo.\n\n## Completitud para T ~ Binomial(n, p)\nset.seed(1)\n\nn     &lt;- 10\ngridp &lt;- seq(0.1, 0.9, by = 0.1)\nN     &lt;- 100000  # simulaciones por p\n\n# Dos funciones no triviales de T (no dependen de p)\ng1 &lt;- function(T) T - n/2\ng2 &lt;- function(T) (T - n/2) * (T - n/3)\n\n# Función trivial (cero) para contraste\ng0 &lt;- function(T) 0 * T\n\nsim_mean_g &lt;- function(gfun) {\n  sapply(gridp, function(p) {\n    T &lt;- rbinom(N, size = n, prob = p)\n    mean(gfun(T))\n  })\n}\n\n# Medias empíricas\nm0 &lt;- sim_mean_g(g0)\nm1 &lt;- sim_mean_g(g1)\nm2 &lt;- sim_mean_g(g2)\n\n# Valores teóricos (para comparar)\n# E[T] = n p; Var[T] = n p (1-p); E[T^2] = Var[T] + (E[T])^2\ntheo_g1 &lt;- n * (gridp - 1/2)  # E[g1(T)] = n(p - 1/2)\n\nET   &lt;- n * gridp\nVarT &lt;- n * gridp * (1 - gridp)\nET2  &lt;- VarT + ET^2\ntheo_g2 &lt;- ET2 - (n/2 + n/3) * ET + (n^2)/(6)  # expandir (T - n/2)(T - n/3)\n\n# Mostrar resultados\ntab &lt;- data.frame(\n  p = gridp,\n  E_g0_emp = round(m0, 5),\n  E_g1_emp = round(m1, 5),\n  E_g1_teo = round(theo_g1, 5),\n  E_g2_emp = round(m2, 5),\n  E_g2_teo = round(theo_g2, 5)\n)\nprint(tab, row.names = FALSE)\n\n   p E_g0_emp E_g1_emp E_g1_teo E_g2_emp E_g2_teo\n 0.1        0 -4.00184       -4 10.24421 10.23333\n 0.2        0 -2.99891       -3  5.61325  5.60000\n 0.3        0 -2.00216       -2  2.77471  2.76667\n 0.4        0 -1.00631       -1  1.74363  1.73333\n 0.5        0 -0.00727        0  2.50485  2.50000\n 0.6        0  1.00466        1  5.09209  5.06667\n 0.7        0  1.99571        2  9.43229  9.43333\n 0.8        0  3.00090        3 15.55946 15.60000\n 0.9        0  3.99831        4 23.58862 23.56667\n\n\n\n\n\n\n\n\nTip 3.2: Qué observar\n\n\n\n\nPara \\(g_0(T)\\equiv 0\\), la media empírica es \\(\\approx 0\\) para todos los \\(p\\).\nPara \\(g_1(T) = T - \\tfrac{n}{2}\\), la esperanza teórica es \\(n(p - \\tfrac{1}{2})\\):\nsolo vale \\(0\\) cuando \\(p = \\tfrac{1}{2}\\); no es \\(0\\) para los demás \\(p\\).\nPara \\(g_2(T) = (T - \\tfrac{n}{2})(T - \\tfrac{n}{3})\\), la esperanza es un polinomio en \\(p\\) que no es idénticamente cero; de nuevo, no se anula para todos los \\(p\\).\n\n\nEsto ilustra la completitud: si alguna \\(g(T)\\) (que no depende de \\(p\\)) tuviera\\(E_p[g(T)] = 0\\) para todo \\(p \\in (0,1)\\), entonces esa \\(g\\) debe ser (casi seguro) la función cero.\n➡️ De ahí que, con suficiencia + completitud, el estimador insesgado derivado es el único UMVUE (Teorema de Lehmann–Scheffé).\n\n\nLa definición de completitud refuerza la de suficiencia en el sentido de que si un estadístico es suficiente y completo entonces, es suficiente minimal (el recíproco no es cierto)\n\nTheorem 3.12 (Teorema de Lehmann-Scheffé) Si \\(T(\\underset{\\sim}{X})\\) es un estadístico suficiente y completo para \\(\\theta\\) y \\(W(\\underset{\\sim}{X})\\) es un estimador insesgado cualquiera de \\(\\tau(\\theta)\\), entonces \\[\\begin{align}\nW_T(\\underset{\\sim}{X})=E_\\theta(W|T)\n\\end{align}\\] es el mejor estimador insesgado (UMVUE) de \\(\\tau(\\theta)\\). Si, además, \\(V(W_T) &lt; \\infty\\) para todo \\(\\theta\\), entonces \\(W_T\\) es único.\n\n\nLa demostración del teorema de Lehmann-Scheffé se basa en el hecho de que, si existen estimadores insesgados, esencialmente sólo existe uno que sea función del estadístico suficiente y completo, pues condicionando cualquiera de los insesgados al estadístico suficiente y completo se obtiene siempre el mismo resultado.\nEl teorema de Rao-Blackwell garantiza que al tomar esperanzas condicionadas se ha reducido la varianza, llegando así al UMVUE.\nLa principal conclusión del teorema de Lehmann-Scheffé es que si existe un estimador insesgado de \\(\\tau(\\theta)\\) que sea función de un estadístico suficiente y completo, entonces es el único UMVUE de \\(\\tau(\\theta)\\).\n\n\n\n\n\n\n\nTip 3.3: Recreando Lehmann–Scheffé en R\n\n\n\n¡Vamos a “recrear” Lehmann–Scheffé en R con un ejemplo clásico y totalmente replicable!\nUsaremos \\(X_1,\\dots,X_n \\sim \\text{i.i.d. Poisson}(\\lambda)\\).\nEntonces\n\\[\nT=\\sum_{i=1}^n X_i \\sim \\text{Poisson}(n\\lambda)\n\\]\nes suficiente y completo para \\(\\lambda\\).\nVeremos dos blancos \\(\\tau(\\theta)\\):\n\n\n\\(\\tau(\\lambda)=\\lambda\\)\n\n\\(\\tau(\\lambda)=e^{-\\lambda}\\)\n\nEn cada caso partimos de un estimador insesgado cualquiera \\(W(\\mathbf X)\\) y lo “Rao–Blackwellizamos” con \\(T\\):\n\\[\nW_T(\\mathbf X)=\\mathbb{E}_\\theta[W \\mid T].\n\\]\nPor Lehmann–Scheffé, \\(W_T\\) es el UMVUE.\nIdea teórica rápida\n\nPara \\(\\tau(\\lambda)=\\lambda\\):\nUn estimador insesgado simple es \\(W=X_1\\) (pues \\(\\mathbb{E}[X_1]=\\lambda\\)).\nCondicionando en \\(T\\):\n\n\\[\n  W_T = \\mathbb{E}[X_1 \\mid T] = \\tfrac{T}{n} \\quad \\Longrightarrow \\quad \\text{UMVUE}.\n\\]\n\nPara \\(\\tau(\\lambda)=e^{-\\lambda}\\):\nUn insesgado simple es \\(W=\\mathbf 1\\{X_1=0\\}\\) (pues \\(\\Pr(X_1=0)=e^{-\\lambda}\\)).\nDado \\(T=t\\),\n\n\\[\n  (X_1,\\dots,X_n)\\mid T=t \\sim \\text{Multinomial}\\Big(t;\\tfrac{1}{n},\\dots,\\tfrac{1}{n}\\Big),\n\\]\nasí que\n\\[\n  \\Pr(X_1=0 \\mid T=t)=\\Big(1-\\tfrac{1}{n}\\Big)^t.\n\\]\nPor ende,\n\\[\n  W_T = \\mathbb{E}[\\,\\mathbf 1\\{X_1=0\\}\\mid T]\n  = \\Big(1-\\tfrac{1}{n}\\Big)^T,\n\\]\nque es el UMVUE de \\(e^{-\\lambda}\\).\n\n\n\n## Lehmann–Scheffé con Poisson ----\n## X_i ~ Poisson(lambda).  T = sum X_i ~ Poisson(n*lambda) es suficiente y completo.\n\nset.seed(123)\n\n# Parámetros\nlambda &lt;- 2\nn      &lt;- 10\nNsim   &lt;- 20000\n\n# Contenedores\nW1_naive  &lt;- numeric(Nsim)  # para tau1(lambda)=lambda, W = X1\nW1_RB     &lt;- numeric(Nsim)  # W_T = E[X1|T] = T/n\n\nW2_naive  &lt;- numeric(Nsim)  # para tau2(lambda)=exp(-lambda), W = 1{X1=0}\nW2_RB     &lt;- numeric(Nsim)  # W_T = E[1{X1=0} | T] = ((n-1)/n)^T\n\nfor (s in 1:Nsim) {\n  X &lt;- rpois(n, lambda)\n  Tsum &lt;- sum(X)\n  \n  # Caso 1: tau(lambda) = lambda\n  W1_naive[s] &lt;- X[1]\n  W1_RB[s]    &lt;- Tsum / n\n  \n  # Caso 2: tau(lambda) = exp(-lambda)\n  W2_naive[s] &lt;- as.numeric(X[1] == 0)\n  W2_RB[s]    &lt;- (1 - 1/n)^Tsum\n}\n\n## Resúmenes empíricos\nres &lt;- data.frame(\n  Estimador = c(\"W = X1\", \"W_T = T/n\", \"W = 1{X1=0}\", \"W_T = ((n-1)/n)^T\"),\n  Objetivo  = c(\"lambda\", \"lambda\", \"exp(-lambda)\", \"exp(-lambda)\"),\n  Media     = c(mean(W1_naive), mean(W1_RB), mean(W2_naive), mean(W2_RB)),\n  Varianza  = c(var(W1_naive), var(W1_RB), var(W2_naive), var(W2_RB))\n)\n\nprint(res, row.names = FALSE)\n\n         Estimador     Objetivo    Media    Varianza\n            W = X1       lambda 2.015250 2.036219248\n         W_T = T/n       lambda 1.999100 0.197314056\n       W = 1{X1=0} exp(-lambda) 0.131500 0.114213461\n W_T = ((n-1)/n)^T exp(-lambda) 0.135274 0.003988959\n\n## Valores teóricos para comparación\n# Caso 1 (lambda):\nvar_W1_naive_theo &lt;- lambda            # Var(X1)\nvar_W1_RB_theo    &lt;- lambda / n        # Var(T/n)\n\n# Caso 2 (exp(-lambda)):\n# Var(1{X1=0}) = e^{-lambda}(1 - e^{-lambda})\nvar_W2_naive_theo &lt;- exp(-lambda) * (1 - exp(-lambda))\n\n# Var(((n-1)/n)^T) = E[a^{2T}] - (E[a^T])^2, con a = (n-1)/n y T~Poisson(n*lambda)\na &lt;- 1 - 1/n\nE_aT     &lt;- exp(n * lambda * (a - 1))        # = exp(n*lambda*(-1/n)) = exp(-lambda)\nE_a2T    &lt;- exp(n * lambda * (a^2 - 1))      # = exp(-2*lambda + lambda/n)\nvar_W2_RB_theo &lt;- E_a2T - E_aT^2             # = e^{-2lambda}(e^{lambda/n} - 1)\n\ncat(\"\\n--- Teórico ---\\n\")\n\n\n--- Teórico ---\n\ncat(sprintf(\"Var(W=X1)                 = %.5f\\n\", var_W1_naive_theo))\n\nVar(W=X1)                 = 2.00000\n\ncat(sprintf(\"Var(W_T=T/n)              = %.5f\\n\", var_W1_RB_theo))\n\nVar(W_T=T/n)              = 0.20000\n\ncat(sprintf(\"Var(W=1{X1=0})            = %.5f\\n\", var_W2_naive_theo))\n\nVar(W=1{X1=0})            = 0.11702\n\ncat(sprintf(\"Var(W_T=((n-1)/n)^T)      = %.5f\\n\\n\", var_W2_RB_theo))\n\nVar(W_T=((n-1)/n)^T)      = 0.00406\n\ncat(\"Relaciones esperadas (Rao–Blackwell):\\n\")\n\nRelaciones esperadas (Rao–Blackwell):\n\ncat(sprintf(\"Var(T/n)  &lt;= Var(X1):           %.5f &lt;= %.5f\\n\", var_W1_RB_theo, var_W1_naive_theo))\n\nVar(T/n)  &lt;= Var(X1):           0.20000 &lt;= 2.00000\n\ncat(sprintf(\"Var(((n-1)/n)^T) &lt;= Var(1{X1=0}): %.5f &lt;= %.5f\\n\", var_W2_RB_theo, var_W2_naive_theo))\n\nVar(((n-1)/n)^T) &lt;= Var(1{X1=0}): 0.00406 &lt;= 0.11702\n\n\nQué comprueba el script\n\nInsesgadez: las medias empíricas de \\(W\\) y \\(W_T\\) aproximan \\(\\tau(\\lambda)\\) (ya sea \\(\\lambda\\) o \\(e^{-\\lambda}\\)).\nMejor varianza:\\[\\mathrm{Var}(W_T) \\leq \\mathrm{Var}(W)\\]\nen ambos casos (se ve empíricamente y con fórmulas teóricas).\n\nForma cerrada del UMVUE:\n\nPara \\(\\tau(\\lambda)=\\lambda\\): \\(W_T = T/n\\).\n\nPara \\(\\tau(\\lambda)=e^{-\\lambda}\\): \\(W_T = \\Big(\\tfrac{n-1}{n}\\Big)^T\\).\n\n\n\nY, por Lehmann–Scheffé, como \\(T\\) es suficiente y completo y \\(\\mathrm{Var}(W_T)&lt;\\infty\\), este UMVUE es único.\n\n# --- Preparación ----\n# install.packages(\"ggplot2\") # si no lo tienes\nlibrary(ggplot2)\n\nexplore_LS &lt;- function(lambda = 2, n = 10, Nsim = 20000, seed = 123,\n                       show_plots = TRUE, save_plots = FALSE, prefix = \"LS\") {\n  set.seed(seed)\n\n  # ---- Simulación ----\n  # Generamos Nsim muestras, cada una de tamaño n (Poisson(lambda))\n  # Para eficiencia, simulamos Nsim*n y damos forma de matriz.\n  Xmat &lt;- matrix(rpois(Nsim * n, lambda), nrow = Nsim, ncol = n)\n  Tsum &lt;- rowSums(Xmat)\n\n  # Caso 1: tau(lambda) = lambda\n  W1  &lt;- Xmat[, 1]          # estimador ingenuo: X1\n  WT1 &lt;- Tsum / n           # Rao-Blackwell: E[X1 | T] = T/n  (UMVUE)\n\n  # Caso 2: tau(lambda) = exp(-lambda)\n  W2  &lt;- as.numeric(Xmat[, 1] == 0)        # ingenuo: 1{X1=0}\n  WT2 &lt;- (1 - 1/n)^Tsum                    # RB: ((n-1)/n)^T  (UMVUE)\n\n  # ---- Resúmenes empíricos ----\n  tab &lt;- data.frame(\n    Estimador = c(\"W = X1\", \"W_T = T/n\", \"W = 1{X1=0}\", \"W_T = ((n-1)/n)^T\"),\n    Objetivo  = c(\"lambda\", \"lambda\", \"exp(-lambda)\", \"exp(-lambda)\"),\n    Media     = c(mean(W1), mean(WT1), mean(W2), mean(WT2)),\n    Varianza  = c(var(W1),  var(WT1), var(W2), var(WT2))\n  )\n\n  # ---- Valores teóricos ----\n  # Caso 1:\n  var_W1_theo  &lt;- lambda           # Var(X1)\n  var_WT1_theo &lt;- lambda / n       # Var(T/n)\n\n  # Caso 2:\n  # Var(1{X1=0}) = e^{-lambda}(1 - e^{-lambda})\n  var_W2_theo  &lt;- exp(-lambda) * (1 - exp(-lambda))\n\n  # Var(((n-1)/n)^T) = E[a^{2T}] - (E[a^T])^2 con T ~ Poisson(n*lambda), a=(n-1)/n\n  a &lt;- 1 - 1/n\n  E_aT  &lt;- exp(n * lambda * (a - 1))           # = exp(-lambda)\n  E_a2T &lt;- exp(n * lambda * (a^2 - 1))         # = exp(-2*lambda + lambda/n)\n  var_WT2_theo &lt;- E_a2T - E_aT^2               # = e^{-2lambda}(e^{lambda/n} - 1)\n\n  tab_teo &lt;- data.frame(\n    Estimador = c(\"W = X1\", \"W_T = T/n\", \"W = 1{X1=0}\", \"W_T = ((n-1)/n)^T\"),\n    Var_teor  = c(var_W1_theo, var_WT1_theo, var_W2_theo, var_WT2_theo)\n  )\n\n  # ---- Data para gráficas ----\n  df1 &lt;- rbind(\n    data.frame(valor = W1,  tipo = \"W = X1\",        objetivo = \"lambda\"),\n    data.frame(valor = WT1, tipo = \"W_T = T/n\",     objetivo = \"lambda\")\n  )\n\n  df2 &lt;- rbind(\n    data.frame(valor = W2,  tipo = \"W = 1{X1=0}\",           objetivo = \"exp(-lambda)\"),\n    data.frame(valor = WT2, tipo = \"W_T = ((n-1)/n)^T\",     objetivo = \"exp(-lambda)\")\n  )\n\n  # ---- Gráficas ----\n  p_dens_1 &lt;- ggplot(df1, aes(x = valor, fill = tipo)) +\n    geom_density(alpha = 0.35, adjust = 1.1) +\n    geom_vline(xintercept = lambda, linetype = 2) +\n    labs(\n      title = bquote(\"Distribuciones de \" * W ~ \"vs\" ~ W[T] ~ \" para \" ~ tau(lambda) == lambda),\n      subtitle = bquote(lambda == .(lambda) ~ \", \" ~ n == .(n) ~ \", \" ~ N[sim] == .(Nsim)),\n      x = \"valor\", y = \"densidad\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"top\")\n\n  p_box_1 &lt;- ggplot(df1, aes(x = tipo, y = valor, fill = tipo)) +\n    geom_boxplot(alpha = 0.4, width = 0.6, outlier.alpha = 0.25) +\n    geom_hline(yintercept = lambda, linetype = 2) +\n    labs(\n      title   = \"Boxplots: W vs W_T (objetivo: lambda)\",\n      x = NULL, y = \"valor\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"none\")\n\n  # Para el caso indicador es discreto; usamos barras y boxplot (WT2 es continuo en [0,1])\n  p_bar_2 &lt;- ggplot(df2, aes(x = factor(round(valor, 3)), fill = tipo)) +\n    geom_bar(position = \"dodge\") +\n    labs(\n      title = bquote(\"Distribuciones de \" * W ~ \"vs\" ~ W[T] ~ \" para \" ~ tau(lambda) == e^{-lambda}),\n      subtitle = bquote(lambda == .(lambda) ~ \", \" ~ n == .(n) ~ \", \" ~ N[sim] == .(Nsim)),\n      x = \"valor (redondeado a 3 decimales)\", y = \"frecuencia\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"top\")\n\n  p_box_2 &lt;- ggplot(df2, aes(x = tipo, y = valor, fill = tipo)) +\n    geom_boxplot(alpha = 0.4, width = 0.6, outlier.alpha = 0.25) +\n    geom_hline(yintercept = exp(-lambda), linetype = 2) +\n    labs(\n      title = \"Boxplots: W vs W_T (objetivo: exp(-lambda))\",\n      x = NULL, y = \"valor\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"none\")\n\n  if (show_plots) {\n    print(p_dens_1); print(p_box_1)\n    print(p_bar_2);  print(p_box_2)\n  }\n\n  if (save_plots) {\n    ggsave(sprintf(\"%s_dens_lambda.png\", prefix), p_dens_1, width = 7, height = 4.5, dpi = 150)\n    ggsave(sprintf(\"%s_box_lambda.png\",  prefix), p_box_1,  width = 6, height = 4.5, dpi = 150)\n    ggsave(sprintf(\"%s_bar_expl.png\",    prefix), p_bar_2,  width = 7, height = 4.5, dpi = 150)\n    ggsave(sprintf(\"%s_box_expl.png\",    prefix), p_box_2,  width = 6, height = 4.5, dpi = 150)\n  }\n\n  # ---- Salida ----\n  list(\n    resumen_empirico = tab,\n    resumen_teorico  = tab_teo,\n    plots = list(dens_lambda = p_dens_1, box_lambda = p_box_1,\n                 bar_expl = p_bar_2, box_expl = p_box_2)\n  )\n}\n\n# ===== Ejemplo de uso =====\nout &lt;- explore_LS(lambda = 2, n = 10, Nsim = 20000, seed = 123, show_plots = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Mira los resúmenes:\nout$resumen_empirico\n\n          Estimador     Objetivo     Media    Varianza\n1            W = X1       lambda 1.9870500 1.961480372\n2         W_T = T/n       lambda 1.9991000 0.199480164\n3       W = 1{X1=0} exp(-lambda) 0.1354500 0.117109153\n4 W_T = ((n-1)/n)^T exp(-lambda) 0.1354626 0.004083226\n\nout$resumen_teorico\n\n          Estimador    Var_teor\n1            W = X1 2.000000000\n2         W_T = T/n 0.200000000\n3       W = 1{X1=0} 0.117019644\n4 W_T = ((n-1)/n)^T 0.004055133\n\n\nQué muestra\n\nDensidad y boxplot (objetivo \\(\\lambda\\)):\nCompara \\(W = X_1\\) vs \\(W_T = T/n\\).\nAmbos se centran en \\(\\lambda\\), pero verás menor varianza para \\(W_T\\).\nBarras/boxplot (objetivo \\(e^{-\\lambda}\\)):\nCompara \\(W = \\mathbf{1}\\{X_1=0\\}\\) vs \\(W_T = \\Big(\\tfrac{n-1}{n}\\Big)^T\\).\nAmbos centrados en \\(e^{-\\lambda}\\), con varianza menor para \\(W_T\\).\n\n\nSugerencia: juega con \\(\\lambda\\) y \\(n\\) en explore_LS(lambda, n, ...) para ver cómo cambia la varianza.\nPor Lehmann–Scheffé, \\(W_T\\) es el UMVUE y único (bajo varianza finita) cuando \\(T\\) es suficiente y completo.\n\n3.12.2 Normalidad asintótica\nEn muchas ocasiones sólo es posible realizar estudios del comportamiento asintótico (cuando n tiende a infinito) de los estimadores. Ya hemos estudiado una propiedad asintótica: la consistencia. Veremos ahora que es posible medir la velocidad de convergencia de estimadores consistentes y así seleccionar los que convergen al verdadero valor del parámetro más rápidamente.\n\nExample 3.11 Sea \\(X_1,\\ldots, X_n\\) una m.a.s. de \\(X\\sim Pois(\\lambda)\\), con \\(\\lambda&gt;0\\). En este modelo, el estimador de momentos de \\(\\lambda\\) coincide con el máximo verosimil: \\(\\hat{\\lambda}_n=\\bar{X}_n\\). Para determinar la distribución del estimador \\(\\hat{\\lambda}\\) resulta mucho más útil aproximarla por una distribución más sencilla a la que se acerca asintóticamente.\nLa versión del teorema central del límite para variables aleatorias independientes e idénticamente distribuidas puede aplicarse porque \\(V(X) = \\lambda &lt; \\infty\\).\n\\[\\begin{align}\n\\frac{\\sqrt{n}(\\hat{\\lambda}_n-\\lambda)}{\\sqrt{\\lambda}}\\longrightarrow N(0,1) \\mbox{ débilmente,}\n\\end{align}\\] es decir, para todo \\(\\lambda\\in \\Theta\\) y para todo \\(w\\in\\mathbb{R}\\), \\[\\begin{align}\nP_\\lambda(\\hat{\\lambda}\\leq w)\\approx \\phi\\left(\\frac{\\sqrt{n}(w-\\lambda)}{\\sqrt{\\lambda}}\\right)\n\\end{align}\\] donde \\(\\phi\\) es la función de distribución de la normal estándar. La aproximación es tanto mejor cuanto mayores son \\(n\\) o \\(\\lambda\\).\nObsérvese que \\(\\hat{\\lambda}_n\\) es consistente pues, por las leyes de los grandes números, \\[\\hat{\\lambda}_n = \\bar{X}_n \\stackrel{P}{\\longrightarrow} E(X) = \\lambda.\\] Así, \\(\\hat{\\lambda}_n -\\lambda \\stackrel{P}{\\longrightarrow} 0\\) y también en distribución. Esta convergencia a la distribución degenerada en 0 no nos informa de la velocidad a la que \\(\\hat{\\lambda}_n\\) se acerca a \\(\\lambda\\) ni de cómo lo hace.\nEl hecho de que \\(V(\\sqrt{n}(\\hat{\\lambda}_n -\\lambda)) = \\lambda\\) para todo n indica que la velocidad a la que \\(\\hat{\\lambda}_n\\) se acerca a \\(\\lambda\\) es la misma con la que \\(\\frac{1}{\\sqrt{n}}\\) se acerca a 0: multiplicar por \\(\\sqrt{n}\\) es la forma de estabilizar las diferencias \\((\\hat{\\lambda}_n-\\lambda)\\), es la estandarización adecuada.\nEl resultado derivado del teorema central del límite, la distribución asintótica de \\(\\sqrt{n}(\\hat{\\lambda}_n -\\lambda)\\) es \\(N(0,\\lambda)\\), responde a la pregunta de cómo es la aproximación \\(\\hat{\\lambda}_n\\) a \\(\\lambda\\) : los valores del estimador se distribuyen alrededor del verdadero valor del parámetro igual que los valores de una variable aleatoria \\(N(0,\\lambda)\\) se distribuyen alrededor de 0.\n\n\nDefinition 3.5 En la práctica la gran mayoría de los estimadores usuales, convenientemente centrados y normalizados, tienen distribución asintótica normal. Se dice que presentan y se denota \\[\\begin{align}\n        \\hat{\\theta}_n\\sim AN(\\theta,v_n)\n    \\end{align}\\] cuando \\[\\begin{align}\n    \\frac{1}{\\sqrt{v_n}}(\\hat{\\theta}_n-\\theta)\\stackrel{d}{\\longrightarrow}N(0,1)\n    \\end{align}\\]\n\nA la cantidad \\(v_n\\) se la llama varianza asintótica de \\(\\hat{\\theta}_n\\). El teorema central del límite es el responsable de la normalidad asintótica de muchos estimadores.\n\n3.12.3 Método delta\nEn muchos casos, sólo será de interés el comportamiento del estimador alrededor del verdadero valor del parámetro. Si además el estimador es una función suave de un estadístico cuyo comportamiento asintótico es conocido, esa función podrá linealizarse en un entorno del verdadero valor del parámetro, lo cuál facilitará enormemente el estudio asintótico del estimador.\n\nExample 3.12 Queremos estimar \\(\\theta=P(X=0) = \\exp\\{-\\lambda\\}\\). Por el principio de invariancia, el estimador máximo verosímil de \\(\\theta\\) es \\(\\hat{\\theta}_n = \\exp\\{-\\bar{X}_n\\}\\) , dado que \\(\\bar{X}_n\\) es el estimador máximo verosímil de \\(\\lambda\\). Por otro lado, \\(\\bar{X}_n\\) es consistente para \\(\\lambda\\) y \\(g(\\lambda) = \\exp\\{-\\lambda\\}\\) es una función continua, luego \\(\\hat{\\theta}_n\\) es consistente para \\(\\theta\\). Estamos interesados ahora en encontrar la distribución asintótica de \\[\\begin{align}\n    \\sqrt{n}(\\hat{\\theta}_n-\\theta)=\\sqrt{n}(\\exp\\{-\\bar{X}_n\\}-\\exp\\{-\\lambda\\})\n\\end{align}\\] La herramienta en la que nos basaremos para hallar esa distribución asintótica es el método delta.\n\n\nTheorem 3.13 (Método Delta) Sea \\(\\{a_n\\}_n\\) una sucesión de número reales tales que \\(a_n\\rightarrow\\infty\\) cuando \\(n\\rightarrow\\infty\\) y con \\(a_n\\neq0\\) para todo \\(n\\). Sea \\(\\hat{\\theta}_n\\) una sucesión de estimadores de \\(\\theta\\) tales que \\[\\begin{align}\na_n(\\hat{\\theta}_n-\\theta)\\stackrel{d}{\\longrightarrow}N(0,\\sigma_\\theta^2)\n\\end{align}\\] y sea \\(g(x)\\) una función con primera derivada continua en un intervalo que contiene a \\(\\theta\\). \\[\\begin{align}\na_n(g(\\hat{\\theta}_n)-g(\\theta))\\stackrel{d}{\\longrightarrow}N(0,(g^{'}(\\theta))^2\\sigma_\\theta^2)\n\\end{align}\\]\n\n\nExample 3.13 Estimamos \\(\\theta=P(X=0) = \\exp\\{-\\lambda\\}\\) mediante \\(\\hat{\\theta}_n = \\exp\\{-\\bar{X}_n\\}\\). Por otra parte, \\(\\sqrt{n}(\\hat{\\lambda}_n-\\lambda)\\stackrel{d}{\\longrightarrow}N(0,\\lambda)\\). Además \\(g(\\lambda)=\\exp\\{-\\lambda\\}\\) es derivable con derivada continua \\(g^{'}(\\lambda)=-\\exp\\{-\\lambda\\}\\)\nAplicando el método delta. \\[\\begin{align}\n        \\sqrt{n}(\\hat{\\theta}_n-\\theta)=\\sqrt{n}(\\exp\\{-\\bar{X}_n\\}-\\exp\\{-\\lambda\\})\\stackrel{d}{\\longrightarrow}N(0,\\lambda\\exp\\{-2\\lambda\\})\n        \\end{align}\\]\n\n\n3.12.4 Eficiencia relativa asintótica\nSea \\(T_n(\\underset{\\sim}{X}) = T_n(X_1 , \\ldots, X_n)\\) una sucesión de estimadores de una función \\(\\tau(\\theta)\\) que verifica lo siguiente: \\[\\begin{align}\n    \\sqrt{n}(T_n(\\underset{\\sim}{X})-\\tau(\\theta))\\stackrel{d}{\\longrightarrow}N(b(\\theta),\\sigma^2(\\theta))\n    \\end{align}\\] Si \\(b(\\theta) = 0\\) diremos que \\(T_n(\\underset{\\sim}{X})\\) es asintóticamente insesgado. En caso contrario, diremos que \\(T_n(\\underset{\\sim}{X})\\) es asintóticamente sesgado.\nSean dos sucesiones \\(T_n(X)\\) y \\(S_n(X)\\) de estimadores de \\(\\tau(\\theta)\\) asintóticamente normales:\n\\[\\begin{align}\n\\sqrt{n}(T_n(\\underset{\\sim}{X})-\\tau(\\theta))\\stackrel{d}{\\longrightarrow}N(0,\\sigma_T^2(\\theta))\n\\end{align}\\]\n\\[\\begin{align}\n\\sqrt{n}(S_n(\\underset{\\sim}{X})-\\tau(\\theta))\\stackrel{d}{\\longrightarrow}N(0,\\sigma_S^2(\\theta))\n\\end{align}\\] Se define la eficiencia relativa asintótica de \\(S_n(X)\\) respecto a \\(T_n(X)\\) como \\[\\begin{align}\nARE(\\theta, S_n , T_n)=\\frac{\\frac{1}{\\sigma_S^2(\\theta)}}{\\frac{1}{\\sigma_T^2(\\theta)}}=\\frac{\\sigma_T^2(\\theta)}{\\sigma_S^2(\\theta)}\n\\end{align}\\]\nEl valor de la eficiencia relativa asintótica puede interpretarse como el cociente de los tamaños de muestra necesarios para obtener la misma precisión asintótica (o la misma varianza asintótica) mediante los dos estimadores en la estimación de \\(\\tau(\\theta)\\). En efecto, si elegimos tamaño muestral m para \\(T\\) y n para \\(S\\), las varianzas asintóticas son, respectivamente, \\(\\frac{\\sigma_T^2(\\theta)}{m}\\) y \\(\\frac{\\sigma_S^2(\\theta)}{n}\\). Si forzamos aque ambas sean iguales, se tiene que \\[\\begin{align}\n\\frac{\\sigma_T^2(\\theta)}{m}=\\frac{\\sigma_S^2(\\theta)}{n}\\Longleftrightarrow\\frac{m}{n}=\\frac{\\sigma_T^2(\\theta)}{\\sigma_S^2(\\theta)}=ARE(\\theta, S_n , T_n)\n\\end{align}\\]\nEs decir, si \\(ARE(\\theta, S_n , T_m) = 0.5\\) entonces \\(S\\) es menos eficiente que \\(T\\) asintóticamente: para tener la misma precisión con el estimador \\(S\\) hace falta una muestra el doble de grande que si utilizásemos \\(T\\) (\\(ARE(\\theta, S_n , T_m)= 0.5=\\frac{m}{n}\\Longrightarrow n = 2m\\)).\n\n3.13 Referencias\n\nGómez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisión. Departament d’Estadística i Investigació Operativa, Universitat Politècnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estadística matemática con aplicaciones (7ª ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.\nKalbfleisch, J. G. Probability and Statistical Inference. Springer-Verlag, 1985.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter3.html",
    "href": "chapter3.html",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "",
    "text": "4.1 Definiciones básicas. Contraste de hipótesis simples\nUna hipótesis estadística es una conjetura o una afirmación sobre la distribución de una o más variables aleatorias. Un contraste de hipótesis (o un test de hipótesis o una prueba de hipótesis) es un procedimiento para decidir si se acepta o se rechaza una hipótesis.\nPodemos distinguir tres tipos de pruebas de hipótesis:\nA. Suponemos que \\(F\\) (y \\(f\\) ) pertenecen a una cierta familia paramétrica indexada por un parámetro \\(\\theta \\in\\Theta\\) y planteamos el contraste\n\\[\\left\\{ \\begin{array}{lcc}\n    H_0 &   :  & \\theta \\in\\Theta_0 \\\\\n    \\\\ H_1 &  : & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\] donde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\)\nB. Contrastes de bondad de ajuste (goodness-of-fit tests, en inglés): \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & f=f_0 \\\\\n\\\\ H_1 &  : & f\\neq f_0  \n\\end{array}\n\\right.\\]\nC. Para dos distribuciones \\(f_0\\) y \\(f_1\\) que no necesariamente pertenecen a la misma familia paramétrica, se plantea el contraste \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & f=f_0 \\\\\n\\\\ H_1 &  : & f= f_1  \n\\end{array}\n\\right.\\]\nUna hipótesis simple es aquella que especifica completamente la distribución de \\(X\\). En otro caso, se dice que la afirmación es una hipótesis compuesta. Por ejemplo, si \\(f \\in \\{f_\\theta : \\theta \\in \\Theta \\mathbb{R}\\}\\), la hipótesis \\(H : \\theta = \\theta_0\\) es una hipótesis simple. La hipótesis \\(H : \\theta &gt; \\theta_0\\) es compuesta.\nSupongamos que se contrasta \\(H_0\\) frente a \\(H_1\\) . Cuando se observa la muestra \\(\\underset{\\sim}{x} = (x_1 ,\\ldots, x_n )\\) se debe decidir si ésta presenta o no evidencia suficiente para rechazar \\(H_0\\) . El subconjunto \\(C\\) del espacio muestral \\(\\mathcal{X}^n\\) de muestras para las cuáles se decide rechazar la hipótesis nula en favor de la alternativa se llama región crítica o región de rechazo del contraste. El complementario de \\(C\\) se llama región de aceptación. Un contraste queda definido por su región crítica \\(C\\).",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#definiciones-básicas.-contraste-de-hipótesis-simples",
    "href": "chapter3.html#definiciones-básicas.-contraste-de-hipótesis-simples",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.2 1. Función de potencia",
    "text": "Usualmente se dispone de una muestra \\(X_1 ,\\ldots, X_n\\) de una variable aleatoria \\(X\\) con distribución \\(F\\) y función de densidad (o función de masa) \\(f\\) . Sobre la distribución de \\(X\\) se realizan dos afirmaciones entre las que se debe decidir.\nEn general esas dos afirmaciones serán excluyentes.\n\nuna se llama hipótesis nula y la otra hipótesis alternativa. Se denotan por \\(H_0\\) y \\(H_1\\), respectivamente. Se dice que en un test de hipótesis se contrasta \\(H_0\\) frente a \\(H_1\\) .\nLa hipótesis nula es más conservadora en el sentido de que no será rechazada a menos que la evidencia muestral en su contra sea muy clara.\nEsta hipótesis suele establecer un modelo sencillo para la distribución de \\(X\\) (por ejemplo, si \\(F\\) pertenece a una familia paramétrica, \\(H_0\\) fija el valor del parámetro) o bien propone como distribución de \\(X\\) aquella que es comúnmente aceptada como una buena descripción del fenómeno que modeliza \\(X\\).\nLa hipótesis alternativa especifica el tipo de alejamiento de la hipótesis nula que podría presentar la distribución de \\(X\\).\nSi un investigador considera que un fenómeno aleatorio no ha estado adecuadamente modelizado hasta ese momento y cree tener una explicación más satisfactoria, propondrá ésta como hipótesis alternativa y el modelo vigente como hipótesis nula.\nSólo si hay evidencia muestral suficiente para rechazar la hipótesis nula, será aceptada la hipótesis alternativa.\n\n\n\n\n\n\n\n\n\n4.1.1 Tipos de errores\nEl error de tipo I se considera más grave que el error de tipo II, dado que la hipótesis nula es siempre la más conservadora.\n\n\n\nDECISIÓN: Aceptar H₀\nDECISIÓN: Rechazar H₀\n\n\n\nREALIDAD: H₀ cierta\nDecisión correcta\nError de TIPO I\n\n\nREALIDAD: H₀ falsa\nError de TIPO II\nDecisión correcta\n\n\n\n\\[\\begin{eqnarray*}\n    \\alpha&=&P(\\mbox{error tipo I})\\\\\n    &=&P(\\mbox{Rechazar $H_0$ cuando $H_0$ es verdadera})\\\\\n    &=&P(\\underset{\\sim}{x}\\in C\\mid H_0\\mbox{ cierta})\n\\end{eqnarray*}\\]\n\\[\\begin{eqnarray*}\n    \\beta&=&P(\\mbox{error tipo II})\\\\\n    &=&P(\\mbox{No rechazar $H_0$ cuando $H_0$ es falsa})\\\\\n    &=&P(\\underset{\\sim}{x}\\notin C\\mid H_0\\mbox{ falsa})\n\\end{eqnarray*}\\]\n\nGráfico de hipótesis\n\n\nObsérvese que si se desea reducir la probabilidad del error de tipo I, \\(\\alpha = P_F(\\underset{\\sim}{x}\\in C\\mid H_0\\mbox{ cierta})\\), se habrán de reducir los puntos de la región crítica \\(C\\), pero ello implica que el conjunto \\(\\bar{C}\\), complementario de \\(C\\), aumenta y así la probabilidad de error de tipo II, \\(\\beta=P_F(\\underset{\\sim}{x}\\notin C\\mid H_0\\mbox{ falsa})\\), también crecerá en general.\n\nDado que el error de tipo I se ha considerado más grave que el error de tipo II, la práctica habitual en el contraste de hipótesis es considerar únicamente pruebas que garantizan que la probabilidad de cometer un error de tipo I será inferior a un valor dado \\(\\alpha\\) suficientemente pequeño (por ejemplo, \\(\\alpha = 0.01\\); \\(0.05\\); \\(0.1\\)) y\nbuscar entre todas ellas aquélla que hace mínima la probabilidad de cometer un error de tipo II.\nAl valor \\(\\alpha\\) se le llama nivel de significación del test.\n\n4.1.2 Algo de interpretación con R\nSensibilidad de \\(\\beta\\) respecto a α en una prueba de hipótesis\nCuando se hace una prueba unilateral para la media de una Normal con varianza conocida:\nHipótesis nula\n\\[\nH_0: \\mu = \\mu_0\n\\]\nHipótesis alternativa\n\\[\nH_1: \\mu &gt; \\mu_0\n\\]\n\nPunto crítico\nComo estamos en una prueba unilateral para la media de una Normal con varianza conocida:\n\nMuestra de tamaño \\(n\\):\\(\\bar{X} \\sim N\\!\\left(\\mu, \\tfrac{\\sigma^2}{n}\\right)\\).\nBajo \\(H_0: \\mu = \\mu_0\\), rechazamos si\n\n\\[\n\\bar{X} &gt; k, \\quad \\text{donde } k = \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\\] El error de tipo II ocurre cuando no rechazamos \\(H_0\\) a pesar de que \\(\\mu = \\mu_a &gt; \\mu_0\\).\n\\[\n\\beta(\\alpha) = \\Pr(\\bar{X} \\le k \\mid \\mu = \\mu_a).\n\\]\nBajo \\(\\mu = \\mu_a\\):\n\\[\n\\bar{X} \\sim N\\!\\left(\\mu_a, \\tfrac{\\sigma^2}{n}\\right).\n\\]\nEstandarizamos:\n\\[\nZ = \\frac{\\bar{X} - \\mu_a}{\\sigma/\\sqrt{n}} \\sim N(0,1).\n\\]\nEntonces:\n\\[\n\\Pr(\\bar{X} \\le k \\mid \\mu=\\mu_a)\n= \\Pr\\!\\left( \\frac{\\bar{X} - \\mu_a}{\\sigma/\\sqrt{n}} \\le \\frac{k - \\mu_a}{\\sigma/\\sqrt{n}} \\right).\n\\]\nRecordemos:\n\\[\nk = \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPor tanto:\n\\[\n\\frac{k - \\mu_a}{\\sigma/\\sqrt{n}}\n= \\frac{\\mu_0 - \\mu_a}{\\sigma/\\sqrt{n}} + z_{1-\\alpha}.\n\\]\nDefinimos:\n\\[\n\\delta = \\frac{\\mu_a - \\mu_0}{\\sigma/\\sqrt{n}}.\n\\]\nAsí:\n\\[\n\\frac{k - \\mu_a}{\\sigma/\\sqrt{n}} = z_{1-\\alpha} - \\delta.\n\\] Dado que \\(Z \\sim N(0,1)\\):\n\\[\n\\Pr(\\bar{X} \\le k \\mid \\mu = \\mu_a) = \\Pr\\!\\big(Z \\le z_{1-\\alpha} - \\delta\\big).\n\\]\nY esa probabilidad se escribe con la función de distribución acumulada de la Normal estándar (\\(\\Phi\\)):\n\\[\n\\beta(\\alpha) = \\Phi\\!\\left(z_{1-\\alpha} - \\delta\\right).\n\\]\n\nProbabilidad de error de tipo II\nSi en realidad \\(\\mu = \\mu_a &gt; \\mu_0\\), la probabilidad de cometer un error de tipo II es:\n\\[\n\\beta(\\alpha) = \\Pr(\\,\\bar{X} \\leq k \\mid \\mu = \\mu_a\\,)\n= \\Phi\\!\\left(z_{1-\\alpha} - \\delta\\right),\n\\]\ndonde:\n\\[\n\\delta = \\frac{\\mu_a - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\n\nInterpretación didáctica:\nAl disminuir \\(\\alpha\\) (ser más estricto para rechazar \\(H_0\\)), aumenta \\(\\beta\\) (es más difícil detectar \\(H_1\\)).\n\n# Parámetros del problema\nmu0  &lt;- 15\nmua  &lt;- 16              # media bajo H1\nsigma &lt;- 4              # desviación conocida\nn     &lt;- 25             # tamaño de muestra\n\n# Función beta(α) para prueba unilateral Z\nbeta_z &lt;- function(alpha, mu0, mua, sigma, n){\n  delta &lt;- (mua - mu0) / (sigma / sqrt(n))\n  pnorm(qnorm(1 - alpha) - delta)\n}\n\n# Curva beta(α) en una malla de α\nalphas &lt;- seq(0.001, 0.20, by = 0.001)\nbetas  &lt;- sapply(alphas, beta_z, mu0=mu0, mua=mua, sigma=sigma, n=n)\n\n# Tabla para valores típicos de α\nalpha_star &lt;- c(0.10, 0.05, 0.01)\nbeta_star  &lt;- sapply(alpha_star, beta_z, mu0=mu0, mua=mua, sigma=sigma, n=n)\ncbind(alpha=alpha_star, beta=round(beta_star, 4))\n\n     alpha   beta\n[1,]  0.10 0.5126\n[2,]  0.05 0.6535\n[3,]  0.01 0.8591\n\n# Gráfica en base R\nplot(alphas, betas, type=\"l\", lwd=2,\n     xlab=expression(alpha~\"(nivel de significancia)\"),\n     ylab=expression(beta~\"(error de tipo II)\"),\n     main=expression(paste(\"Sensibilidad de \", beta, \" respecto a \", alpha)))\ngrid()\n\n# Añadir referencias\nabline(v = alpha_star, lty = 3)\npoints(alpha_star, beta_star, pch = 19)\ntext(alpha_star, beta_star, labels=paste0(\"  β=\", round(beta_star,3)), pos=4)\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\n\ndiffs &lt;- c(0.5, 1.0, 1.5)       # diferencias mu_a - mu_0\ndf &lt;- do.call(rbind, lapply(diffs, function(dif){\n  mua_i &lt;- mu0 + dif\n  data.frame(\n    alpha = alphas,\n    beta  = sapply(alphas, beta_z, mu0=mu0, mua=mua_i, sigma=sigma, n=n),\n    dif   = paste0(\"Δ = \", dif)\n  )\n}))\n\nggplot(df, aes(alpha, beta, color=dif)) +\n  geom_line(size=1.1) +\n  labs(x=expression(alpha), y=expression(beta),\n       title=\"β vs α para distintos tamaños de efecto (Δ = μ_a - μ_0)\") +\n  theme_minimal(base_size = 12)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nCuando el efecto \\((\\Delta = \\mu_a - \\mu_0)\\) es mayor, la curva se desplaza hacia abajo:\npara el mismo \\(\\alpha\\), \\(\\beta\\) es menor \\(\\;\\Rightarrow\\;\\) la potencia \\((1-\\beta)\\) aumenta.\n\nset.seed(123)\nB &lt;- 1e5\nalpha_vec &lt;- c(0.10, 0.05, 0.01)\n\nsim_beta &lt;- function(alpha, mu0, mua, sigma, n, B=1e5){\n  k &lt;- mu0 + qnorm(1 - alpha) * sigma / sqrt(n)\n  xbar &lt;- replicate(B, mean(rnorm(n, mean=mua, sd=sigma)))\n  mean(xbar &lt;= k)  # proporción de NO-rechazos cuando H1 es verdadera = β\n}\n\nbeta_sim &lt;- sapply(alpha_vec, sim_beta, mu0=mu0, mua=mua, sigma=sigma, n=n, B=B)\nbeta_the &lt;- sapply(alpha_vec, beta_z, mu0=mu0, mua=mua, sigma=sigma, n=n)\n\ncbind(alpha=alpha_vec,\n      beta_teorico=round(beta_the,4),\n      beta_sim=round(beta_sim,4))\n\n     alpha beta_teorico beta_sim\n[1,]  0.10       0.5126   0.5133\n[2,]  0.05       0.6535   0.6534\n[3,]  0.01       0.8591   0.8606\n\n\n\n\n\n\n\n\n\nTip 4.1: Conclusiones\n\n\n\n\nReducir \\(\\alpha\\) implica aumentar \\(\\beta\\).\nUn mayor tamaño del efecto \\((\\mu_a - \\mu_0)\\) o un mayor tamaño de muestra \\(n\\) reducen \\(\\beta\\).\nLa práctica usual es fijar un \\(\\alpha\\) pequeño (0.01, 0.05, 0.1) y luego buscar el diseño que minimice \\(\\beta\\) o equivalga a maximizar la potencia del test.\n\n\n\nSi el menor valor obtenido \\(\\beta\\) para la probabilidad de error de tipo II es inaceptablemente grande, pueden tomarse dos medidas para reducirlo:\n\naumentar la probabilidad de error de tipo I \\(\\alpha\\) permitida, o\naumentar el tamaño de la muestra.\n\nSupongamos que la distribución de \\(X\\) pertenece a una familia paramétrica \\(\\{f_\\theta:\\theta \\in\\Theta\\}\\) y se contrasta\n\\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta \\in\\Theta_0 \\\\\n\\\\ H_1 &  : & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\] donde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\). ::: {#exm-4.1} Suponga que un candidato, Jones, dice que él ganará más de \\(50\\%\\) de los votos en una elección urbana y por tanto saldrá como ganador. Como buscamos apoyo para la hipótesis alternativa de que lo dicho por Jones es falso, nuestra hipótesis alternativa es que \\(p\\), la probabilidad de seleccionar un votante que esté a favor de Jones, es menor que \\(0.5\\). Si podemos demostrar que los datos apoyan el rechazo de la hipótesis nula \\(p = 0.5\\) (el valor mínimo necesario para conseguir una mayoría) en favor de la hipótesis alternativa \\(p &lt; 0.5\\), hemos alcanzado nuestro objetivo de investigación. Suponga que \\(n = 15\\) votantes se seleccionan aleatoriamente de una ciudad y se registra \\(Y\\), el número que está a favor de Jones. Calcule \\(\\alpha\\) si seleccionamos \\(C = \\{y \\leq 2\\}\\) como la región de rechazo.\nPara la encuesta política de Jones se muestrearon \\(n=15\\) votantes. \\[\\begin{eqnarray*}\n    H_0&:&p=0.5\\\\\n    H_a&:&p&lt;0.5\n\\end{eqnarray*}\\] Estadístico de prueba es \\(Y\\).\n\n\n\\(Y:\\#\\) de votantes a favor. \\(Y\\sim Binom(15,\\,p)\\)\n\nRegión de rechazo RR: \\[RR=\\{Y\\leq 2\\}\\]\nC'alculo de \\(\\alpha\\): \\[\\begin{eqnarray*}\n      \\alpha&=&P(\\mbox{error tipo I})\\\\\n      &=&P(\\mbox{Rechazar $H_0$ cuando $H_0$ es verdadera})\\\\\n      &=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\n  \\end{eqnarray*}\\]\n\n\n\\[\\begin{eqnarray*}\n        \\alpha&=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\\\\\n        &=&pbinom(2,\\,15,\\,0.5)\\\\\n        &=&0.003692627\n    \\end{eqnarray*}\\]\nAsumimos un riesgo muy pequeño (\\(\\alpha=0.004\\)), de concluir que Jones perderá si en realidad es el ganador.\n\\[\\begin{eqnarray*}\n    \\beta(p_1=0.3)&=&P(\\mbox{error tipo II})\\\\\n    &=&P(\\mbox{No rechazar $H_0$ cuando $H_a$ es verdadera})\\\\\n    &=&P(Y&gt; 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-P(Y\\leq 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-pbinom(2,\\,15,\\,0.3)\\\\\n    &=&0.8731723\n\\end{eqnarray*}\\] Esta prueba nos llevará a concluir que Jones es ganador, aún cuando \\(p=0.3\\). :::\n\nDefinition 4.1 Se define la función de potencia \\(\\eta(\\theta)\\) del contraste como \\[\\eta(\\theta)=P_\\theta(\\underset{\\sim}{x}\\in C)=\\left\\{ \\begin{array}{lcc}\n\\alpha &   si & \\theta \\in\\Theta_0 \\\\\n\\\\ 1-\\beta &  si & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\]\nPara \\(0\\leq\\alpha\\leq1\\), un contraste de hipótesis con función de potencia \\(\\eta(\\theta)\\) tiene tamaño \\(\\alpha\\) si \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)=\\alpha\\] Para \\(0\\leq\\alpha\\leq1\\), un contraste de hipótesis con función de potencia \\(\\eta(\\theta)\\) tiene Nivel de significancia \\(\\alpha\\) si \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)\\leq\\alpha\\]\n\nEl conjunto de contrastes con nivel de significación \\(\\alpha\\) contiene las pruebas de tamaño \\(\\alpha\\).\nUn contraste que minimiza \\(\\beta=P_\\theta(\\underset{\\sim}{x}\\in \\bar{C}\\mid H_1\\mbox{ cierta})\\) entre aquellos que tienen tamaño \\(\\alpha\\) se dice que es el contraste más potente de tamaño \\(\\alpha\\) o el mejor contraste de tamaño \\(\\alpha\\).\n\n\n\n\n\n\nTip 4.2: Función de potencia y contrastes más potentes\n\n\n\n\n4.2 1. Función de potencia\nLa función de potencia de una prueba mide, para cada valor posible del parámetro \\(\\theta\\), la probabilidad de rechazar la hipótesis nula:\n\\[\n\\eta(\\theta) = P_\\theta(\\tilde{x} \\in C),\n\\]\ndonde: - \\(\\tilde{x}\\) es la muestra, - \\(C\\) es la región crítica (el conjunto de valores de la muestra que llevan a rechazar \\(H_0\\)).\nEn palabras:La función de potencia nos dice qué tan probable es rechazar \\(H_0\\), dado que el parámetro vale \\(\\theta\\).\n\n4.3 2. Casos especiales de la función de potencia\n\n\nSi \\(\\theta \\in \\Theta_0\\) (es decir, si \\(H_0\\) es cierta):\n\\[\n\\eta(\\theta) = \\alpha\n\\]\nEsto refleja que, bajo \\(H_0\\), la probabilidad de rechazar \\(H_0\\) es justamente la probabilidad de cometer un error de tipo I.\n\n\nSi \\(\\theta \\in \\Theta_1\\) (es decir, si \\(H_1\\) es cierta):\n\\[\n\\eta(\\theta) = 1 - \\beta\n\\]\nEsto refleja que, bajo \\(H_1\\), la probabilidad de rechazar \\(H_0\\) es la potencia de la prueba.\n\n\n\n4.4 3. Tamaño y nivel de significación\n\n\nTamaño \\(\\alpha\\):\nUna prueba tiene tamaño \\(\\alpha\\) si el peor caso (la mayor probabilidad de rechazar \\(H_0\\) cuando es cierta) es exactamente \\(\\alpha\\):\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) = \\alpha\n\\]\n→ El tamaño es el “valor máximo real” de error tipo I que puede ocurrir bajo \\(H_0\\).\n\n\nNivel de significación \\(\\alpha\\):\nUna prueba tiene nivel de significación \\(\\alpha\\) si ese peor caso no excede \\(\\alpha\\):\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) \\leq \\alpha\n\\]\n→ El nivel de significación es un límite superior que ponemos a la probabilidad de error tipo I.\n\n\nNota: Todo contraste de tamaño \\(\\alpha\\) tiene también nivel de significación \\(\\alpha\\), pero no todo contraste con nivel de significación \\(\\alpha\\) necesariamente alcanza el tamaño exacto.\n\n4.5 4. Contraste más potente\nEntre todas las pruebas que tienen el mismo tamaño \\(\\alpha\\), buscamos la que minimiza \\(\\beta\\) (o equivalentemente, la que maximiza la potencia \\(1-\\beta\\)).\nEsa prueba se llama:\n\n\nEl contraste más potente de tamaño \\(\\alpha\\),\n\no el mejor contraste de tamaño \\(\\alpha\\).\n\nEs decir, para un mismo control de error tipo I, elegimos la prueba que detecta con mayor eficacia cuando \\(H_1\\) es verdadera.\n\nEn resumen:\n- La función de potencia es la herramienta que unifica \\(\\alpha\\) y \\(1-\\beta\\).\n- Tamaño = probabilidad máxima de error tipo I.\n- Nivel de significación = restricción para controlar ese error.\n- El mejor contraste de tamaño \\(\\alpha\\) es aquel que, manteniendo fijo el error tipo I, maximiza la probabilidad de rechazar \\(H_0\\) cuando realmente es falsa.\n\n\n\n\nExample 4.1 (Problema 1) Sea \\(X \\sim \\mathrm{Bin}(5,\\theta)\\). Considere el contraste \\[\n\\begin{cases}\nH_0:\\ \\theta \\le \\tfrac{1}{2},\\\\[2mm]\nH_1:\\ \\theta &gt; \\tfrac{1}{2}.\n\\end{cases}\n\\]\nEstablezca la función de potencia, gráfiquela e interprete comparativamente los resultados en las siguientes dos opciones:\n\nConsidere primero el contraste de rechazar \\(H_0\\) si y sólo si se observan todos los éxitos (es decir, \\(X=5\\)).\n\nOpción (a):\nRechazar \\(H_0\\) solo si se observan los 5 éxitos\nModelo. Sea \\(X \\sim \\mathrm{Bin}(5,\\theta)\\) con función de probabilidad\\(P_\\theta(X=x)=\\binom{5}{x}\\theta^x(1-\\theta)^{5-x}\\), \\(x=0,1,\\dots,5\\).\nRegión crítica La regla propuesta es rechazar \\(H_0\\) únicamente cuando \\(X=5\\). Por tanto, \\[\nC_a=\\{5\\},\\qquad \\bar C_a=\\{0,1,2,3,4\\}.\n\\]\nFunción de potencia \\(\\eta_a(\\theta)\\) Por definición, la potencia es la probabilidad de caer en la región crítica: \\[\n\\eta_a(\\theta)=P_\\theta(X\\in C_a)=P_\\theta(X=5)\n=\\binom{5}{5}\\theta^5(1-\\theta)^{0}\n=\\theta^5.\n\\] Es decir, para cualquier \\(0\\le \\theta\\le 1\\), \\[\n\\eta_a(\\theta)=\\theta^5.\n\\]\nTamaño (máximo error tipo I) El tamaño del contraste es \\[\n\\alpha_a=\\sup_{\\theta\\in\\Theta_0}\\eta_a(\\theta)\n=\\sup_{\\theta\\le 1/2}\\theta^5.\n\\] Como \\(\\theta^5\\) es estrictamente creciente en \\(\\theta\\) (derivada \\(5\\theta^4&gt;0\\)), el supremo en \\(\\Theta_0=\\{\\theta\\le 1/2\\}\\) se alcanza en el borde \\(\\theta=1/2\\): \\[\n\\alpha_a=\\left(\\tfrac12\\right)^5=\\frac{1}{32}\\approx 0.03125.\n\\]\nLectura e intuición - La regla \\(C_a=\\{5\\}\\) es muy conservadora: solo rechaza \\(H_0\\) en el caso más extremo. - Por eso, el tamaño es muy pequeño (\\(\\alpha_a\\approx 3.1\\%\\)). - La potencia \\(\\eta_a(\\theta)=\\theta^5\\) crece muy lentamente; el test casi nunca rechaza salvo que \\(\\theta\\) sea muy grande.\nEn términos del error tipo II \\(\\beta_a(\\theta)=1-\\eta_a(\\theta)=1-\\theta^5\\): - Si \\(\\theta=0.6\\), \\(\\beta_a=1-0.6^5\\approx 0.922\\) (muy alto). - Si \\(\\theta=0.9\\), \\(\\beta_a=1-0.9^5\\approx 0.410\\). - Recién cerca de \\(\\theta=0.99\\), \\(\\beta_a\\approx 0.049\\).\n\n\n\n\n\n\n\nConcepto\nExplicación\nEjemplos numéricos\n\n\n\n\nRegla \\(C_a = \\{5\\}\\)\n\nMuy conservadora: solo rechaza \\(H_0\\) en el caso más extremo.\n-\n\n\n\nTamaño \\(\\alpha_a\\)\n\nMuy pequeño (\\(\\alpha_a \\approx 3.1\\%\\)).\n-\n\n\n\nPotencia \\(\\eta_a(\\theta) = \\theta^5\\)\n\nCrece muy lentamente; el test casi nunca rechaza salvo que \\(\\theta\\) sea muy grande.\n-\n\n\n\nError tipo II \\(\\beta_a(\\theta) = 1 - \\eta_a(\\theta) = 1 - \\theta^5\\)\n\nSe mantiene alto para valores de \\(\\theta\\) moderados.\n- Para \\(\\theta=0.6\\): \\(\\beta_a = 1 - 0.6^5 \\approx 0.922\\) (muy alto).  - Para \\(\\theta=0.9\\): \\(\\beta_a = 1 - 0.9^5 \\approx 0.410\\).  - Para \\(\\theta=0.99\\): \\(\\beta_a \\approx 0.049\\).\n\n\n\nConclusión. Es un contraste con bajo error tipo I pero muy poca potencia, salvo cuando el efecto es extremadamente grande (valores de \\(\\theta\\) muy cercanos a 1).\n\nConsidere en segundo lugar el contraste de rechazar \\(H_0\\) si \\(X \\in \\{3,4,5\\}\\).\n\nOpción (b):\nRechazar \\(H_0\\) si \\(X\\in\\{3,4,5\\}\\) (equiv. \\(X\\ge 3\\))\nModelo. Sea \\(X\\sim \\mathrm{Bin}(5,\\theta)\\) con \\[\nP_\\theta(X=x)=\\binom{5}{x}\\,\\theta^x(1-\\theta)^{5-x},\\quad x=0,1,\\dots,5.\n\\]\nRegión crítica \\[\nC_b=\\{3,4,5\\},\\qquad \\bar C_b=\\{0,1,2\\}.\n\\]\nFunción de potencia \\(\\eta_b(\\theta)\\) Por definición, la potencia es la probabilidad de caer en la región crítica: \\[\n\\eta_b(\\theta)=P_\\theta(X\\in C_b)=P_\\theta(X\\ge 3)\n=\\sum_{k=3}^{5}\\binom{5}{k}\\theta^k(1-\\theta)^{5-k}.\n\\]\nSuma directa. \\[\n\\eta_b(\\theta)=10\\,\\theta^3(1-\\theta)^2+5\\,\\theta^4(1-\\theta)+\\theta^5.\n\\]\nVía complemento (útil para el tamaño). \\[\n\\eta_b(\\theta)=1-P_\\theta(X\\le 2)\n=1-\\Big[(1-\\theta)^5+5\\theta(1-\\theta)^4+10\\theta^2(1-\\theta)^3\\Big].\n\\]\nMonotonía. Para la familia binomial, \\(P_\\theta(X\\ge c)\\) es creciente en \\(\\theta\\) (propiedad MLR). Por tanto, \\(\\eta_b(\\theta)\\) aumenta con \\(\\theta\\).\nTamaño (máximo error tipo I) El tamaño es \\[\n\\alpha_b=\\sup_{\\theta\\le 1/2}\\eta_b(\\theta).\n\\] Como \\(\\eta_b(\\theta)\\) es creciente, el supremo se alcanza en el borde \\(\\theta=1/2\\): \\[\n\\alpha_b=\\eta_b(1/2)=P_{1/2}(X\\ge 3)=1-P_{1/2}(X\\le 2).\n\\] Con simetría binomial: \\[\nP_{1/2}(X\\le 2)=\\frac{\\binom50+\\binom51+\\binom52}{2^5}\n=\\frac{1+5+10}{32}=\\frac{16}{32},\n\\] luego \\[\n\\alpha_b=1-\\frac{16}{32}=\\frac{16}{32}=0.5.\n\\]\nLectura numérica (potencia y error tipo II) Valores aproximados:\n\\[\n\\begin{array}{c|ccccc}\n\\theta & 0.55 & 0.60 & 0.70 & 0.80 & 0.90\\\\ \\hline\n\\eta_b(\\theta)=P_\\theta(X\\ge 3) & 0.593 & 0.683 & 0.837 & 0.942 & 0.991\\\\\n\\beta_b(\\theta)=1-\\eta_b(\\theta) & 0.407 & 0.317 & 0.163 & 0.058 & 0.009\n\\end{array}\n\\]\n\nPara \\(\\theta&gt;1/2\\), la potencia crece rápido y el error tipo II cae pronto: ya con \\(\\theta\\approx 0.7\\) la potencia es alta.\nEl costo es un tamaño enorme: \\(\\alpha_b=0.5\\) (inaceptable en la práctica).\n\nObservación de diseño (cómo fijar \\(\\alpha\\) razonable)\nCon \\(n=5\\) y \\(H_0:\\theta\\le 1/2\\):\n\n\\(X\\ge 5\\) da \\(\\alpha=(1/2)^5=1/32\\approx 0.03125\\).\n\\(X\\ge 4\\) da \\(\\alpha=P_{1/2}(X\\ge 4)=(\\binom54+\\binom55)/32=(5+1)/32=6/32=0.1875\\).\nPara alcanzar, por ejemplo, \\(\\alpha=0.10\\), sería necesario aleatorizar en \\(X=4\\) (rechazar con cierta probabilidad cuando \\(X=4\\)) o aumentar el tamaño muestral.\n\n\n\n\ntheta &lt;- seq(0,1,by=0.001)\n\neta_a &lt;- theta^5\neta_b &lt;- 10*theta^3*(1-theta)^2 + 5*theta^4*(1-theta) + theta^5\n\nplot(theta, eta_a, type=\"l\", lwd=2,\n     xlab=expression(theta), ylab=expression(eta(theta)),\n     main=\"Funciones de potencia: regiones críticas {5} y {3,4,5}\")\nlines(theta, eta_b, lwd=2, lty=2)\nabline(v=0.5, lty=3); abline(h=c((0.5)^5, 0.5), lty=3)\nlegend(\"topleft\",\n       legend = c(expression(C[a]==5),\n                  expression(C[b] &gt;= 3)),\n       lwd = 2, lty = c(1,2), bty = \"n\")\n\n\n\n\n\n\n\n\n\nExample 4.2 (Problema 2) Apoyándose en el ejercicio anterior, responda claramente a las siguientes preguntas:\nI. A partir del contraste del inciso a, ¿es falsa o verdadera la afirmación: “La probabilidad del error tipo I es aceptablemente baja para todo \\(\\theta \\le \\tfrac{1}{2}\\)”? Explique su respuesta.\nSí, es verdadera.\nBajo \\(H_0:\\theta\\le \\tfrac12\\), el error tipo I del contraste (a) es \\[\nP_\\theta(\\text{rechazar }H_0)=\\eta_a(\\theta)=\\theta^5.\n\\] Como \\(\\theta^5\\) es creciente en \\(\\theta\\), su máximo sobre \\(\\Theta_0=\\{\\theta\\le \\tfrac12\\}\\) se alcanza en el borde: \\[\n\\alpha_a=\\sup_{\\theta\\le 1/2}\\eta_a(\\theta)=\\eta_a\\!\\left(\\tfrac12\\right)=\\left(\\tfrac12\\right)^5=\\frac{1}{32}\\approx 0.03125.\n\\] Por tanto, para todo \\(\\theta\\le \\tfrac12\\) se tiene \\(\\eta_a(\\theta)\\le 0.03125\\), es decir, un nivel de error tipo I muy bajo.\n\n¿Para qué valores de \\(\\theta\\) el error tipo II es menor que \\(\\tfrac{1}{2}\\) en el contraste del inciso a?\n\nEn (a), bajo \\(H_1\\) el error tipo II es \\[\n\\beta_a(\\theta)=1-\\eta_a(\\theta)=1-\\theta^5.\n\\] La condición \\(\\beta_a(\\theta)&lt;\\tfrac12\\) equivale a \\[\n1-\\theta^5&lt;\\tfrac12\\quad\\Longleftrightarrow\\quad \\theta^5&gt;\\tfrac12\n\\quad\\Longleftrightarrow\\quad \\theta&gt;(1/2)^{1/5}\\approx 0.87055.\n\\] Luego, para \\(\\theta&gt;0.87055\\) (y, por supuesto, \\(\\theta&gt;1/2\\)), el error tipo II es menor a \\(1/2\\).\n\nEn el contraste del inciso b, ¿para qué valores de \\(\\theta\\) el error tipo II alcanza valores pequeños?\n\nEn (b), \\[\n\\beta_b(\\theta)=1-\\eta_b(\\theta)=P_\\theta(X\\le 2)\n=(1-\\theta)^5+5\\theta(1-\\theta)^4+10\\theta^2(1-\\theta)^3,\n\\] función decreciente en \\(\\theta\\). Valores representativos: \\[\n\\begin{array}{c|ccccc}\n\\theta & 0.55 & 0.60 & 0.70 & 0.75 & 0.80\\\\ \\hline\n\\beta_b(\\theta) & 0.407 & 0.317 & 0.163 & 0.104 & 0.058\n\\end{array}\n\\] Se observa que \\(\\beta_b(\\theta)\\) ya es pequeña (por ejemplo \\(&lt;0.10\\)) a partir de \\(\\theta\\gtrsim 0.78\\) (pues en \\(0.75\\) es \\(\\approx 0.104\\) y en \\(0.80\\) es \\(\\approx 0.058\\)).\n\n¿Es falso o verdadero afirmar que: “La potencia del contraste del inciso b es mayor que la potencia del otro contraste para valores de \\(\\theta \\le \\tfrac{1}{2}\\). Entonces, la probabilidad del error tipo I del contraste del inciso b es mayor que la del otro contraste para valores de \\(\\theta \\le \\tfrac{1}{2}\\)”? Explique su respuesta.\n\n\nVerdadero.\nPara \\(\\theta\\le \\tfrac12\\) (región nula):\n\nLa “potencia” \\(\\eta(\\theta)\\) coincide con la probabilidad de error tipo I en ese punto.\nNuméricamente (y por la propiedad MLR de la binomial) se verifica que \\[\n\\eta_b(\\theta)=P_\\theta(X\\ge 3)\\;&gt;\\;\\eta_a(\\theta)=\\theta^5\n\\quad \\text{para todo }\\theta\\le \\tfrac12.\n\\] Ejemplos:\\(\\theta=0.5:\\ \\eta_b=0.5\\ \\text{vs}\\ \\eta_a=0.03125\\);\\(\\theta=0.4:\\ \\eta_b\\approx 0.31744\\ \\text{vs}\\ \\eta_a=0.01024\\).\nEn particular, el tamaño es mayor en (b):\\[\n\\alpha_b=\\eta_b(1/2)=0.5 \\quad\\gg\\quad \\alpha_a=\\eta_a(1/2)=1/32\\approx 0.03125.\n\\]\n\nConclusión: el contraste (b) rechaza con mucha más frecuencia bajo \\(H_0\\) (mayor error tipo I), lo que explica su mayor potencia bajo \\(H_1\\); el costo es un nivel \\(\\alpha\\) inaceptablemente alto en (b) comparado con (a).\n\nEl siguiente resultado determina cuál es el contraste más potente cuando se contrasta una hipótesis nula simple frente a una alternativa simple.\n\n4.5.1 Lema de Neyman-Pearson\nSea \\(X_1 ,\\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) con función de densidad (o función de masa de probabilidad) \\(f(x; \\theta)\\). Se desea contrastar \\(H_ 0 : \\theta = \\theta_0\\) frente a \\(H_1 : \\theta = \\theta_1\\) . Si \\(L(\\theta\\mid\\underset{\\sim}{x})\\) es la función de verosimilitud, el mejor contraste de tamaño \\(\\alpha\\) tiene región crítica de la forma \\[C=\\left\\{\\underset{\\sim}{x}\\in\\mathcal{X}^n:\\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\geq A\\right\\}\\] para algún \\(A\\geq 0\\).\nEl contraste que se propone en el Lema de Neyman-Pearson se denomina también test de la razón de verosimilitudes.\n\nExample 4.3 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu, \\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0 : \\mu= \\mu_0\\) frente a \\(H_1: \\mu = \\mu_1\\), con \\(\\mu_1 &gt; \\mu_0\\).\n\nNuestra intuición nos dice que se debe rechazar \\(H_0\\) si se observan valores grandes de \\(x\\). Veamos que la aplicación del Lema de Neyman-Pearson conduce a esta solución.\n\nExample 4.4 (Ejemplo anterior) Test Z unilateral por Neyman–Pearson (varianza conocida)\nSea \\(X_1,\\ldots,X_n\\) una muestra aleatoria simple de \\(X\\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocida.\nSe desea contrastar \\[\nH_0:\\ \\mu=\\mu_0\n\\qquad\\text{frente a}\\qquad\nH_1:\\ \\mu=\\mu_1,\\ \\ \\mu_1&gt;\\mu_0.\n\\]\nLa intuición sugiere rechazar \\(H_0\\) cuando la media muestral \\(\\bar X\\) tome valores grandes.\nVeremos que el Lema de Neyman–Pearson conduce exactamente a esta regla.\n\nVerosimilitud y cociente de verosimilitudes\nLa verosimilitud de una muestra \\(x=(x_1,\\dots,x_n)\\) es \\[\nL(\\mu\\mid x)=(2\\pi\\sigma^2)^{-n/2}\\exp\\!\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i-\\mu)^2\\right\\}.\n\\]\nEl cociente de verosimilitudes (likelihood ratio) es \\[\n\\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\n=\\exp\\!\\left\\{\\frac{1}{2\\sigma^2}\\sum_{i=1}^n\\Big[(x_i-\\mu_0)^2-(x_i-\\mu_1)^2\\Big]\\right\\}.\n\\]\nNotemos que \\[\n(x_i-\\mu_0)^2-(x_i-\\mu_1)^2\n=2x_i(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2),\n\\] de modo que, al sumar y usar \\(\\bar x=\\tfrac{1}{n}\\sum x_i\\), \\[\n\\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\n=\\exp\\!\\left\\{\\frac{n}{2\\sigma^2}\\Big(2\\bar x(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2)\\Big)\\right\\}.\n\\]\nPor el Lema de Neyman–Pearson, la región crítica óptima (para tamaño dado) es del tipo \\[\nC=\\Big\\{x:\\ \\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\\ge A\\Big\\}\n=\\left\\{x:\\ \\exp\\!\\left\\{\\frac{n}{2\\sigma^2}\\Big(2\\bar x(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2)\\Big)\\right\\}\\ge A\\right\\}.\n\\]\nComo \\(\\mu_1-\\mu_0&gt;0\\), el cociente es función creciente de \\(\\bar x\\). Por tanto, la región crítica puede escribirse como \\[\nC=\\{x:\\ \\bar x\\ge B\\}.\n\\]\nLas constantes \\(A\\) y \\(B\\) se relacionan por \\[\nB=\\frac{\\sigma^2\\log A}{n(\\mu_1-\\mu_0)}+\\frac{\\mu_1+\\mu_0}{2}.\n\\]\n\nFijar el tamaño \\(\\alpha\\) y obtener \\(B\\)\nNo es necesario hallar \\(B\\) a partir de \\(A\\). Basta imponer el tamaño deseado: \\[\nP(C\\mid H_0)=P(\\bar X\\ge B\\mid H_0)=\\alpha.\n\\] Bajo \\(H_0\\), \\(\\bar X\\sim N(\\mu_0,\\sigma^2/n)\\), así que \\[\nB=\\mu_0+z_\\alpha\\,\\frac{\\sigma}{\\sqrt{n}},\n\\] donde \\(z_\\alpha\\) satisface \\(P(Z\\ge z_\\alpha)=\\alpha\\) para \\(Z\\sim N(0,1)\\).\nLa regla de decisión equivalente es: \\[\n\\text{Rechazar }H_0\\ \\ \\Longleftrightarrow\\ \\ Z=\\frac{\\bar X-\\mu_0}{\\sigma/\\sqrt{n}}\\ge z_\\alpha.\n\\]\n\nEjemplo numérico\nSupongamos \\(\\mu_0=5\\), \\(\\mu_1=6\\), \\(\\sigma^2=1\\) (luego \\(\\sigma=1\\)), \\(\\alpha=0.05\\) y \\(n=4\\).\n\nUmbral crítico para \\(\\bar X\\): \\[\nB=\\mu_0+z_{0.05}\\frac{\\sigma}{\\sqrt{n}}\n=5+1.645\\cdot\\frac{1}{2}\n=5+0.8225\n=5.8225.\n\\]\nRegla equivalente con \\(Z\\): \\[\nZ=\\frac{\\bar X-5}{1/\\sqrt{4}}\n=\\frac{\\bar X-5}{0.5}\n\\ge 1.645.\n\\]\nDatos observados: \\(x=(5.1,\\,5.5,\\,4.9,\\,5.3)\\).\nMedia muestral: \\(\\bar x=\\tfrac{5.1+5.5+4.9+5.3}{4}=5.2\\).\nCálculo del estadístico: \\[\nz=\\frac{\\bar x-5}{1/\\sqrt{4}}=\\frac{5.2-5}{0.5}=0.4&lt;1.645.\n\\]\n\nDecisión: no se rechaza \\(H_0\\) al nivel \\(\\alpha=0.05\\).\n\nComentario final\nEste contraste se denomina test Z unilateral porque usa el estadístico \\[\nZ=\\sqrt{n}\\,\\frac{\\bar X-\\mu_0}{\\sigma}\\ \\sim\\ N(0,1)\\ \\ \\text{bajo }H_0.\n\\]\n\n\n\n\n\n\n\nTip 4.3: Conclusiones de un contraste: el p-valor.\n\n\n\n\nUna forma de informar de los resultados de un contraste de hipótesis es mediante el tamaño \\(\\alpha\\) del test usado y la decisión tomada sobre si se rechazó o no \\(H_0\\).\nSi \\(\\alpha\\) es pequeño la decisión de rechazar \\(H_0\\) es muy convincente, pero si \\(\\alpha\\) es grande la probabilidad de cometer un error de tipo I es grande, lo cuál resta fuerza al test si la decisión adoptada es la de rechazar \\(H_0\\).\nPor otro lado, para \\(\\alpha\\) muy pequeño, el hecho de no rechazar \\(H_0\\) no se interpretará como un apoyo indiscutible a esta hipótesis sino como que no fue posible encontrar evidencia suficiente en su contra como para superar la barrera tan restrictiva impuesta por ese valor de \\(\\alpha\\).\n\n\n\n\nDefinition 4.2 Una forma alternativa de presentar los resultados de un contraste de hipótesis es dar el p-valor o valor de probabilidad del test, definido éste como el supremo de los valores \\(\\alpha\\) para los cuáles se rechazaría la hipótesis nula si ésta se contrastase a nivel \\(\\alpha\\).\n\nEl p-valor depende de los datos muestrales. Puede interpretarse como la probabilidad de observar otra muestra que sea al menos tan poco favorable a la hipótesis nula como la que se ha observado.\nA partir del p-valor se puede tomar la decisión de rechazar (respectivamente, aceptar) \\(H_0\\) si el p-valor es pequeño (respectivamente, grande).\nPor ejemplo, el p-valor de un contraste dado por el Lema de Neyman-Pearson es: \\[p=P_{\\theta_0}\\left\\{\\frac{L(\\theta_1\\mid\\underset{\\sim}{X})}{L(\\theta_0\\mid\\underset{\\sim}{X})}\\geq \\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\right\\}\\] En general, cuando la región crítica de un contraste de tamaño \\(\\alpha\\) es tal que se rechaza \\(H_0\\) si y sólo si \\(W(\\underset{\\sim}{x})\\geq c_\\alpha\\), donde \\(W(\\underset{\\sim}{x})\\) es un estadístico y \\(c_\\alpha\\) se elige para que el test tenga tamaño \\(\\alpha\\), entonces el p-valor del contraste para una muestra observada \\(\\underset{\\sim}{x}\\) es \\[p(\\underset{\\sim}{x})=\\sup_{\\theta\\in\\Theta_0}P_{\\theta_0}\\{W(\\underset{\\sim}{X})\\geq W(\\underset{\\sim}{x})\\}\\]",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter4.html",
    "href": "chapter4.html",
    "title": "5  Estimación por intervalos",
    "section": "",
    "text": "5.1 Intervalos de confianza\nEn este capítulo se aborda el problema de la estimación por conjuntos, donde se estudian estimadores que proporcionan un conjunto como estimación de \\(\\theta\\). El resultado de una estimación por conjuntos es una afirmación del tipo \\(\\theta \\in C\\), donde \\(C = C(\\underset{\\sim}{x})\\) es un subconjunto del espacio paramétrico \\(\\theta\\) que depende de los datos observados \\(x\\). En el caso de que \\(\\Theta \\subseteq \\mathbb{R}\\) los conjuntos que se suelen usar para realizar inferencias sobre \\(\\theta\\) son intervalos.\nUn estimador por intervalos de un parámetro \\(\\theta\\in\\Theta \\subseteq \\mathbb{R}\\) es cualquier par de funciones reales \\(L(\\underset{\\sim}{x})\\) y \\(U (\\underset{\\sim}{x})\\) definidas en el espacio muestral \\(\\mathcal{X}\\) tales que \\(L(\\underset{\\sim}{x})\\leq U (\\underset{\\sim}{x})\\) para todo \\(\\underset{\\sim}{x} = (x_1 , \\ldots, x_n)\\in \\mathcal{X}\\) . Si se observa el valor \\(\\underset{\\sim}{x}= \\underset{\\sim}{x}\\) , mediante este estimador se hace la inferencia \\(L(\\underset{\\sim}{x})\\leq\\theta\\leq U (\\underset{\\sim}{x})\\). Al intervalo aleatorio \\([L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})]\\) se le llama estimador por intervalos de \\(\\theta\\)(o intervalo estimador de \\(\\theta\\)), mientras que al valor que ha tomado en la muestra observada \\([L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})]\\) se le llama estimación por intervalos de \\(\\theta\\) (o intervalo estimación de \\(\\theta\\)).\nSi se desea construir un intervalo para una transformación invertible \\(\\tau(\\theta)\\) del parámetro y \\([L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})]\\) es un intervalo de confianza \\((1-\\alpha)\\) para \\(\\theta\\), entonces el intervalo \\([\\tau(L(\\underset{\\sim}{x})),\\tau(U (\\underset{\\sim}{x}))]\\) es un intervalo de confianza \\((1- \\alpha)\\) para \\(\\tau(\\theta)\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación por intervalos</span>"
    ]
  },
  {
    "objectID": "chapter4.html#intervalos-de-confianza",
    "href": "chapter4.html#intervalos-de-confianza",
    "title": "5  Estimación por intervalos",
    "section": "",
    "text": "Example 5.1 Sea \\(X_1 , X_2 , X_3 , X_4\\) una muestra de tamaño 4 de \\(X \\sim N(\\mu, 1)\\). Un estimador por intervalos de \\(\\mu\\) es \\([\\bar{X}-1, \\bar{X} + 1]\\). Para cada muestra observada \\(x_1 , x_2 , x_3 , x_4\\), la estimación por intervalos de \\(\\mu\\) es \\([\\bar{x}-1, \\bar{x} + 1]\\).\n\n\nObsérvese que si se estima un parámetro \\(\\theta\\) mediante un intervalo, la inferencia es menos precisa que si se estima con un estimador puntual:\nahora nos limitamos a afirmar que el parámetro está en un cierto conjunto, mientras que antes dábamos un valor concreto como estimación suya.\nDado que se pierde en precisión, cabe preguntarse qué se gana al estimar un parámetro \\(\\theta\\) mediante un intervalo, respecto a hacerlo con un estimador puntual. La respuesta es que se gana en confianza:\nen general, la probabilidad de que un estimador sea exactamente igual al parámetro que desea estimar es 0, mientras que la probabilidad de que un estimador por intervalos cubra al parámetro será positiva.\n\n\nExample 5.2 Sea \\(X_1 , X_2 , X_3 , X_4\\) una muestra de tamaño 4 de \\(X \\sim N(\\mu, 1)\\). Un estimador por intervalos de \\(\\mu\\) es \\([\\bar{X}-1, \\bar{X} + 1]\\). Para cada muestra observada \\(x_1 , x_2 , x_3 , x_4\\), la estimación por intervalos de \\(\\mu\\) es \\([\\bar{x}-1, \\bar{x} + 1]\\).\nSea \\(X_1 , X_2 , X_3 , X_4\\) una muestra de tamaño 4 de \\(X \\sim N(\\mu, 1)\\).\nI. \\(P(\\bar{X}=\\mu)=0\\).\nII.\\(P[\\bar{X}-1, \\bar{X} + 1]=0.9544\\).\nA costa de algo de precisión, el paso de un estimador puntual a uno por intervalos ha permitido aumentar la confianza que tenemos en que sea correcta la afirmación hecha en la inferencia.\n\n\nDefinition 5.1 Se llama probabilidad de cobertura de un estimador por intervalos \\([L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})]\\) del parámetro \\(\\theta\\) a la probabilidad de que ese intervalo aleatorio cubra al verdadero valor del parámetro \\(\\theta\\): \\[P_\\theta(\\theta\\in[L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})] )\\] Obsérvese que esa probabilidad de cobertura puede variar con \\(\\theta\\). Se llama del intervalo \\([L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})]\\) como estimador del parámetro \\(\\theta\\) al ínfimo de las probabilidades de cobertura: \\[\\inf_{\\theta\\in\\Theta}P_\\theta(\\theta\\in[L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})] ).\\] Intervalo de confianza es el nombre que recibe usualmente un estimador por intervalos junto con su coeficiente de confianza.\nTambién se nombra así a veces a la estimación a que da lugar el estimador por intervalos aplicado a una muestra concreta.\nAdemás de \\(C(\\underset{\\sim}{x})\\), se usará también la notación \\(IC_{1-\\alpha}(\\theta)\\) se usará para referirse a un intervalo de confianza \\((1-\\alpha)\\) para \\(\\theta\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación por intervalos</span>"
    ]
  },
  {
    "objectID": "chapter4.html#métodos-para-construir-intervalos-de-confianza",
    "href": "chapter4.html#métodos-para-construir-intervalos-de-confianza",
    "title": "5  Estimación por intervalos",
    "section": "5.2 Métodos para construir intervalos de confianza",
    "text": "5.2 Métodos para construir intervalos de confianza\n\n5.2.1 Inversión de un contraste de hipótesis\nComo veremos a continuación, hay una estrecha relación entre la estimación por intervalos y los contrastes de hipótesis. En general, se puede decir que cada método de construcción de un intervalo de confianza corresponde a un método de contraste de un hipótesis, y viceversa.\n\nExample 5.3 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0:\\mu = \\mu_0\\) frente a \\(H_1 : \\mu\\neq\\mu_0\\).\nPara hacer el contraste a nivel \\(\\alpha\\) el test insesgado uniformemente de máxima potencia rechaza \\(H_0\\) si \\(\\mid \\bar{x}-\\mu_0\\mid &gt; z_{\\alpha/2}\\sigma/\\sqrt{n}\\), es decir, la región del espacio muestral \\(\\mathcal{X}\\) en donde se acepta \\(H_0\\) es el conjunto de \\(\\underset{\\sim}{x}\\) tales que \\[\\bar{x}-z_{\\alpha/2}\\sigma/\\sqrt{n}\\leq\\mu_0\\leq \\bar{x}+z_{\\alpha/2}\\sigma/\\sqrt{n}\\]\n\n\n\n5.2.2 Intervalos de confianza para la media\n\n\nIntervalo de confianza para \\(\\mu\\) cuando se conoce \\(\\sigma^2\\)\n\n\n\n \n\n\nIntervalo de predicción para una observación futura cuando se desconoce \\(\\sigma^2\\)\n\n\n\n\n\n5.2.3 Intervalos de confianza para la diferencia de medias\n\n\nIntervalo de confianza para \\(\\mu_1-\\mu_2\\) cuando se conocen \\(\\sigma_1^2\\) y \\(\\sigma_2^2\\)\n\n\n\n\n\nIntervalo de confianza para \\(\\mu_1-\\mu_2\\) cuando se conocen \\(\\sigma_1^2\\) y \\(\\sigma_2^2\\)\n\n\n\n\n\nIntervalo de confianza para \\(\\mu_1-\\mu_2\\) cuando se desconocen \\(\\sigma_1^2\\) y \\(\\sigma_2^2\\)\n\n\n\n\n\nEstimado agrupado de la varianza\n\n\n\n \n ### Intervalos de confianza para proporciones \\(p\\).\n\n\nIntervalos de confianza para \\(p\\) de una muestra grande\n\n\n\n\n\n5.2.4 Intervalos de confianza para diferencia de proporciones.\n\n\nIntervalos de confianza para \\(p_1-p_2\\) de una muestra grande\n\n\n\n\n\n5.2.5 Intervalos de confianza para \\(\\sigma^2\\)\n\n\nIntervalos de confianza para \\(\\sigma^2\\)\n\n\n\n\n\n5.2.6 Intervalos de confianza para comparación de varianzas.\n\n\nIntervalos de confianza para \\(\\sigma_1^2/\\sigma_2^2\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación por intervalos</span>"
    ]
  },
  {
    "objectID": "chapter4.html#test-de-la-razón-de-verosimilitudes",
    "href": "chapter4.html#test-de-la-razón-de-verosimilitudes",
    "title": "5  Estimación por intervalos",
    "section": "5.3 Test de la razón de verosimilitudes",
    "text": "5.3 Test de la razón de verosimilitudes\nSea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\), variable aleatoria con función de densidad (o de probabilidad) \\(f(x\\mid \\theta)\\) para algún \\(\\theta  \\in \\Theta\\). Se desea hacer el contraste\n\\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta \\in\\Theta_0 \\\\\n\\\\ H_1 &  : & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\] donde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset.\\) Se define el estadístico de la como\n\\[\\lambda=\\lambda(\\underset{\\sim}{x})=\\frac{\\max_{\\theta \\in \\Theta_0}L(\\theta \\mid \\underset{\\sim}{x})}{\\max_{\\theta \\in \\Theta}L(\\theta \\mid \\underset{\\sim}{x})}\\]\nEl test de la razón de verosimilitudes (también llamado test de la razón de verosimilitudes generalizado, para distinguirlo del test de Neyman- Pearson, o test de la razón de las máximas verosimilitudes) establece una región crítica de la forma \\[C=\\{\\underset{\\sim}{x}:\\lambda(\\underset{\\sim}{x})\\leq A\\}\\] para alguna constante \\(A\\) que se determinará para que el test tenga el tamaño \\(\\alpha\\) deseado.\nLa idea intuitiva que sustenta este método de contraste es simple. Observe que \\(0 \\leq \\lambda \\leq 1\\) y que cuanto más cercano a \\(1\\) sea el valor de \\(\\lambda\\), más verosímil es que \\(\\theta \\in \\Theta_0\\), mientras que cuanto más se aleje \\(\\lambda\\) de 1, más creíble será la hipótesis alternativa \\(\\theta \\in \\Theta_1\\).\n\nExample 5.4 Sea \\(\\underset{\\sim}{x}\\sim \\exp\\{\\frac{1}{\\lambda}\\}\\), \\(\\lambda=E(X)\\), se quiere encontrar la forma de la región crítica utilizando el principio de la razón de verosimilitudes del test \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\lambda=\\lambda_0 \\\\\n\\\\ H_1 &  : & \\lambda\\neq\\lambda_0\n\\end{array}\n\\right.\\]\n\n\nProof. Recordemos que la función de verosimilitud es \\[\\begin{align}\n            L(\\lambda\\mid\\underset{\\sim}{x})&=\\prod_{i=1}^{n}\\left(\\frac{1}{\\lambda}\\exp\\left\\{-\\frac{1}{\\lambda}x_i\\right\\}\\right)\\nonumber\\\\\n            &=\\left(\\frac{1}{\\lambda}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda}\\sum_{i=1}^{n}x_i\\right\\}\n        \\end{align}\\] Además, el estimador de máxima verosimilitud (emv) es \\(\\hat{\\lambda}=\\bar{x}\\) Luego, el estadístico por la razón de verosimilitudes\n\\[\\begin{align}\n        \\Lambda(\\underset{\\sim}{x})&=\\frac{\\max_{\\lambda \\in \\Theta_0}L(\\lambda \\mid \\underset{\\sim}{x})}{\\max_{\\lambda \\in \\Theta}L(\\lambda \\mid \\underset{\\sim}{x})}\\nonumber\\\\\n        &=\\frac{\\left(\\frac{1}{\\lambda_0}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}}{\\left(\\frac{1}{\\bar{x}_n}\\right)^n\\exp\\left\\{-\\frac{1}{\\bar{x}_n}\\sum_{i=1}^{n}x_i\\right\\}}\\nonumber\\\\\n        &=\\frac{\\left(\\frac{1}{\\lambda_0}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}}{\\left(\\frac{1}{\\frac{\\sum_{i=1}^{n}x_i}{n}}\\right)^n\\exp\\left\\{-\\frac{1}{\\frac{\\sum_{i=1}^{n}x_i}{n}}\\sum_{i=1}^{n}x_i\\right\\}}\\nonumber\\\\\n\\end{align}\\]\n\\[\\begin{align}\n\\Lambda(\\underset{\\sim}{x})&=\\frac{\\max_{\\lambda \\in \\Theta_0}L(\\lambda \\mid \\underset{\\sim}{x})}{\\max_{\\lambda \\in \\Theta}L(\\lambda \\mid \\underset{\\sim}{x})}\\nonumber\\\\\n&=\\left(\\frac{\\sum_{i=1}^{n}x_i}{n\\lambda_0}\\right)^n\\frac{\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}}{\\exp\\left\\{-n\\right\\}}\\nonumber\\\\\n&=\\left(\\frac{1}{n}\\right)^n\\left(\\frac{\\sum_{i=1}^{n}x_i}{\\lambda_0}\\right)^n\\frac{\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}}{\\exp\\left\\{-n\\right\\}}\\nonumber\\\\\n\\end{align}\\]\nSi \\(\\Lambda(\\underset{\\sim}{x})\\leq A\\) para alguna constante \\(A\\) que haga el test de tamaño \\(\\alpha\\), se tiene que\n\\[\\begin{align}\n\\left(\\frac{\\sum_{i=1}^{n}x_i}{\\lambda_0}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}\\leq A^*\n\\end{align}\\]\ndonde \\(A^*=An^n\\exp\\left\\{-n\\right\\}.\\)\nPara un valor fijo \\(\\lambda_0\\), la región de NO rechazo del test región de aceptaciónes\n\\[\\begin{align}\n        \\label{RA}\n        A(\\lambda_0)=\\left\\{\\underset{\\sim}{x}:\\left(\\frac{\\sum_{i=1}^{n}x_i}{\\lambda_0}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}\\geq k^*\\right\\}\n\\end{align} \\tag{5.1}\\]\ndonde la constante \\(k^*\\) se elige para que el test tenga tamaño \\(\\alpha\\), o lo que es lomismo, para que \\[P_{\\alpha}(\\underset{\\sim}{x}\\in A(\\lambda_0))=1-\\alpha\\]\n\n\n5.3.1 Cantidades pivotales.\nUno de los métodos más comunes de construcción de intervalos de confianza es el uso de cantidades pivotales.\nSea \\(\\underset{\\sim}{x} = (X_1 ,\\ldots , X_n)\\) una m.a.s. de \\(X\\sim F(x;\\theta)\\). Una función \\(Q(\\underset{\\sim}{x} , \\theta)\\) de la muestra y del parámetro es una si la distribución de probabilidad de \\(Q(\\underset{\\sim}{x} , \\theta)\\) no depende del parámetro \\(\\theta\\), es decir, \\(Q(\\underset{\\sim}{x} , \\theta)\\) tiene la misma distribución para cualquier valor de \\(\\theta\\).\nDada una cantidad pivotal \\(Q(\\underset{\\sim}{x} , \\theta)\\), para cualquier conjunto \\(A\\) del espacioimagen de \\(Q\\) se tiene que \\(P_\\theta (Q(\\underset{\\sim}{x} , \\theta) \\in A)\\) no depende de \\(\\theta\\). Por lo tanto si se elige un conjunto \\(A_\\alpha\\) tal que\n\\[P_\\theta (Q(\\underset{\\sim}{x} , \\theta) \\in A)=1-\\alpha,\\] para todo \\(\\theta\\), y se observa la muestra \\(\\underset{\\sim}{x} = \\underset{\\sim}{x}\\), entonces el conjunto \\[C(\\underset{\\sim}{x}) = \\{\\theta: Q(\\underset{\\sim}{x} , \\theta) \\in A\\}\\] es un conjunto de confianza \\(1-\\alpha\\) para \\(\\theta\\).\nEn la práctica, la forma en la que se construye un intervalo de confianza a partir de una cantidad pivotal es la siguiente. Supondremos que \\(Q(\\underset{\\sim}{x}, \\theta) \\in \\mathbb{R}\\) y \\(\\theta \\in \\mathbb{R}\\). Para un valor \\(\\alpha\\) dado, se buscan números a y b tales que \\[P_\\theta(a\\leq Q(\\underset{\\sim}{x}, \\theta)\\leq b)=1-\\alpha,\\] Observar que \\(a\\) y \\(b\\) no dependen de \\(\\theta\\) por ser Q cantidad pivotal, y que la elección de a y b no será única en general.\nPara cada \\(\\theta_0\\) , el conjunto \\[A(\\theta_0)=\\{\\underset{\\sim}{x}:a\\leq Q(\\underset{\\sim}{x}, \\theta)\\leq b\\}.\\] es la región de aceptación de un test de tamaño \\(\\alpha\\) para contrastar \\(H_0 : \\theta = \\theta_ 0\\) basado en el estadístico \\(T ( \\underset{\\sim}{x}) = Q(\\underset{\\sim}{x}, \\theta_0)\\). Invirtiendo este contraste obtenemos el conjunto de confianza \\(1-\\alpha\\) para \\(\\theta\\): \\[C(\\underset{\\sim}{x})=\\{\\theta:a\\leq Q(\\underset{\\sim}{x}, \\theta)\\leq b\\}.\\]\n\nExample 5.5 Obsérvese en Equation 5.1 que la expresión de la región de aceptación depende de la muestra y del parámetro sólo a través de \\(v =\\frac{\\sum_{i=1}^{n} x_i}{\\lambda_0}\\). Además, la distribución de \\(v =\\frac{\\sum_{i=1}^{n}X_i}{\\lambda_0}\\) no depende del parámetro \\(\\lambda_0\\) : \\(\\sum_{i=1}^{n}X_i\\sim \\gamma(n,\\lambda_0)\\) bajo \\(H_0\\) , luego \\(V\\sim \\gamma(n,\\lambda_0)\\). De esto se sigue que el valor \\(k^{*}\\) es el mismo para todo \\(\\lambda_0\\).\\\nInvirtiendo la región de aceptación se obtiene el conjunto de confianza \\(1-\\alpha\\): \\[C(\\underset{\\sim}{x})=\\left\\{\\lambda:\\left(\\frac{\\sum_{i=1}^{n}x_i}{\\lambda}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda}\\sum_{i=1}^{n}x_i\\right\\}\\geq k^*\\right\\}.\\]\n\nSea \\(g(v)=v^n\\exp\\{-v\\}\\)  a. \\(g\\) es positiva en todo \\(\\mathbb{R}^{+}\\). b. \\(g\\) vale cero en \\(v=0\\). c. \\(g\\) tiende a cero si \\(v\\) tiende a infinito. d. \\(g\\) tiene un único punto crítico en \\(v=n\\). e. \\(g\\) tiene un único máximo en \\(v=n\\). f. Los conjuntos de la forma \\(\\{v\\geq0: g(v)\\leq k^*\\}\\), \\(k^*\\leq g(n)=n^n\\exp\\left\\{-n\\right\\}\\), son intervalos de la forma \\([l,u]\\), donde \\(l\\leq n\\leq u\\) y \\(g(l)=g(u)=k^*\\).\nDe ello se deduce que \\(A(\\lambda_0)\\) es un intervalo para cualquier valor de \\(\\lambda_0\\), y que los conjuntos de confianza \\(C(\\underset{\\sim}{x})\\) también son intervalos para cualquier valor de \\(\\sum_{i=1}^{n}x_i\\). Así pues, el intervalo de confianza obtenido será de la forma\n\\[\\begin{align}\nC(\\underset{\\sim}{x})&=\\left\\{\\lambda:l\\leq v\\leq u\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:l\\leq \\frac{\\sum_{i=1}^{n}x_i}{\\lambda}\\leq u\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:\\frac{1}{u}\\leq \\frac{\\lambda}{\\sum_{i=1}^{n}x_i}\\leq \\frac{1}{l}\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:L\\left(\\sum_{i=1}^{n}x_i\\right)\\leq \\lambda\\leq U\\left(\\sum_{i=1}^{n}x_i\\right)\\right\\}\\nonumber\\\\\n\\end{align}\\]\ncon\n\n\n\n\n\n\n\nLímite inferior\nLímite superior\n\n\n\n\n\\[L\\!\\left(\\sum_{i=1}^{n}x_i\\right) = \\frac{\\sum_{i=1}^{n}x_i}{u}\\]\n\\[U\\!\\left(\\sum_{i=1}^{n}x_i\\right) = \\frac{\\sum_{i=1}^{n}x_i}{l}\\]\n\n\n\nLos valores \\(l\\) y \\(u\\) son las soluciones del sistema de ecuaciones no lineales\n\\[\\left\\{ \\begin{array}{lcc}\ng(l) =g(u)&     \\\\\n\\\\P(l\\leq V \\leq u)=1-\\alpha &   \n\\end{array}\n\\right.\\]\nSi \\(n = 2\\), \\(V\\sim \\gamma(2, 1)\\) y el sistema se transforma en éste: \\[\\left\\{ \\begin{array}{lcc}\n    l^2e^{-l} =u^2e^{-u} &     \\\\\n    \\\\e^{-l}(l+1)-e^{-u}(u+1)=1-\\alpha &   \n    \\end{array}\n    \\right.\\] Si hacemos \\(1-\\alpha = 0.9\\) y resolvemos el sistema, se obtiene \\(l = 0.4386\\) y \\(u =5.4945\\), luego el intervalo de confianza \\(0.90\\) para \\(\\lambda\\) es\n\\[\\left[0.182\\sum_{i=1}^{2} x_i;2.28\\sum_{i=1}^{2} x_i\\right]=\\left[0.364\\bar{X}_2;4.56\\bar{X}_2\\right]\\]  En el ejemplo anterior el intervalo de confianza construido se basó en\n\\[\\begin{align}\nV=\\frac{\\sum_{i=1}^{n}X_i}{\\lambda}\n\\end{align}\\]\ncuya distribución es \\(\\gamma(n, 1)\\) para cualquier valor de \\(\\lambda\\), así que \\(V\\) es una cantidad pivotal y el intervalo de confianza construido allí es un ejemplo de intervalo basado en una cantidad pivotal.\\ Si se define \\(T = 2V\\) , entonces \\(T\\sim \\gamma(n, 2)\\), es decir \\(T\\sim \\chi^2_{2n}\\) . Es más fácil encontrar tabulada la distribución \\(\\chi^2_{2n}\\) que la distribución gamma, por lo que \\(T\\) resultará más útil en la práctica.\n\nExample 5.6 En el ejemplo anteriormente mencionado \\[Q(\\underset{\\sim}{x},\\lambda)=\\frac{2\\sum_{i=1}^{n}X_i}{\\lambda}\\sim\\chi^2_{2n}\\] Así que podemos elegir\n\n\n\n(a)\n(b)\n\n\n\n\n\\[a = \\chi^2_{2n,\\,1-\\alpha/2}\\]\n\\[b = \\chi^2_{2n,\\,\\alpha/2}\\]\n\n\n\nEn este caso \\(g_{\\underset{\\sim}{x}}(\\lambda)=Q(\\underset{\\sim}{x},\\lambda)=\\frac{2\\sum_{i=1}^{n}X_i}{\\lambda}\\). Es decir, \\(g_{\\underset{\\sim}{x}}\\) es invertible y decreciente, luego el intervalo de confianza de \\(1-\\alpha\\) para \\(\\lambda\\) será\n\\[\\begin{align}\nC(\\underset{\\sim}{x})&=\\left\\{\\lambda:a\\leq g_{\\underset{\\sim}{x}}(\\lambda)\\leq b\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:a\\leq \\frac{2\\sum_{i=1}^{n}x_i}{\\lambda}\\leq b\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:\\frac{1}{b}\\leq \\frac{\\lambda}{2\\sum_{i=1}^{n}x_i}\\leq \\frac{1}{a}\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:g_{\\underset{\\sim}{x}}^{-1}\\left(b\\right)\\leq \\lambda\\leq g_{\\underset{\\sim}{x}}^{-1}\\left(a\\right)\\right\\}\\nonumber\\\\\n\\end{align}\\]\ncon\n\n\n\n\n\n\n\nExpresión con (b)\nExpresión con (a)\n\n\n\n\n\\[g_{\\underset{\\sim}{x}}^{-1}(b) = \\frac{2\\sum_{i=1}^{n} x_i}{\\chi^2_{2n,\\,\\alpha/2}}\\]\n\\[g_{\\underset{\\sim}{x}}^{-1}(a) = \\frac{2\\sum_{i=1}^{n} x_i}{\\chi^2_{2n,\\,1-\\alpha/2}}\\]\n\n\n\nEn el caso de \\(n = 2\\) y \\(\\alpha = 0.1\\), \\(\\chi^2_{4, 0.05} = 9,49\\) y \\(\\chi^2_{4, 0.95} = 0.71\\), luego el intervalo de confianza \\(0.90\\) es\n\\[\\left[\\frac{4\\bar{X}_2}{9.49};\\frac{4\\bar{X}_2}{0.71}\\right]=\\left[0.4215\\bar{X}_2;5.63\\bar{X}_2\\right]\\]\n\n\n\n5.3.2 Intervalos de verosimilitud.\nSupongamos que los datos (eventos observados) \\(E\\) de un experimento tiene probabilidad \\(P(E;\\theta)\\) la cual depende de un parámetros fijo pero desconocido \\(\\theta\\).\nEl estimador de máxima verosimilitud \\(\\hat{\\theta}\\) es el valor de \\(\\theta\\) el cual máximiza \\(P(E;\\theta)\\). Este valor es el más probable o más plausible de \\(\\theta\\) en el sentido de que esto máximiza la probabilidad de que ha sido observado.\nLas probabilidades relativas de otros valores de \\(\\theta\\) tal que \\(P(E;\\theta)\\) es tan cercano o casi tan grande como \\(P(E;\\hat{\\theta})\\) son justamente plausible en que ellos explican los datos casi tan bien como \\(\\hat{\\theta}\\) lo hace.\nValores de \\(\\theta\\) para los cuales \\(P(E;\\theta)\\) es mucho menos que \\(P(E;\\hat{\\theta})\\) son implausibles porque estos hacen que lo que se ha observado sea mucho menos probable que lo que hace \\(\\hat{\\theta}\\).\n\nDefinition 5.2 (Función de verosimilutud relativa de \\(\\theta\\)) La Función de verosimilutud relativa de \\(\\theta\\) (RLF), está definida como el ratio de la función de verosimilitud Función de verosimilutud relativa de \\(L(\\theta)\\) con el máximo \\(L(\\hat{\\theta})\\): \\[\\begin{align}\nR(\\theta)=\\frac{L(\\theta)}{L(\\hat{\\theta})}\n\\end{align}\\] Ya que \\(L(\\theta)=CP(E;\\theta)\\) donde \\(C\\) no depende de \\(\\theta\\), se sigue\n\\[\\begin{align}\nR(\\theta)=\\frac{CP(E;\\theta)}{CP(E;\\hat{\\theta})}=\\frac{P(E;\\theta)}{P(E;\\hat{\\theta})}\n\\end{align} \\tag{5.2}\\]\n\nLa constante multiplicativa \\(C\\) en la ecuación Equation 5.2 se cancela, así que \\(R(\\theta)\\) no se verá afectada por esta constante. Observe que \\(L(\\theta)\\leq L(\\hat{\\theta})\\) para todo \\(\\theta\\), así que se sigue \\(0\\leq R(\\theta)\\leq1\\).\n\nDefinition 5.3 (La función Logverosimilitud relativa) \\[\\begin{align}\nr(\\theta)&=\\log\\left(R(\\theta)\\right)\\nonumber\\\\\n&=log\\left(\\frac{P(E;\\theta)}{P(E;\\hat{\\theta})}\\right)\\nonumber\\\\\n&=log\\left(P(E;\\theta)\\right)-log\\left(P(E;\\hat{\\theta})\\right)\\nonumber\\\\\n&=log\\left(\\ell (\\theta)\\right)-log\\left( \\ell(\\hat{\\theta})\\right)\n\\end{align} \\tag{5.3}\\]\n\nDonde \\(\\ell(\\theta)\\) es la función logverosimilitud. Ya que \\(0\\leq R(\\theta)\\leq1\\), tenemos que \\(-\\infty\\leq r(\\theta)\\leq 0\\) para todos los valores parametrales posibles. Sea \\(\\theta_1\\) denota algún valor particular del parámetro, entonces\n\nSi \\(R(\\theta_1)=0.1\\), entonces \\(\\theta_1\\) es más bien un valor parametral inverosimil, porque los datos son \\(10\\) veces más probables cuando \\(\\theta=\\hat{\\theta}\\) que cuando \\(\\theta=\\theta_1\\).\nSi \\(R(\\theta_1)=0.5\\), entonces \\(\\theta_1\\) es más bien un valor parametral justamente plausible, porque los datos son \\(2\\) veces más probables cuando \\(\\theta=\\hat{\\theta}\\) que cuando \\(\\theta=\\theta_1\\).\n\n\nDefinition 5.4 (Regiones de verosimilitud e intervalos) El conjunto de los valores \\(\\theta\\) para el cual \\(R(\\theta)\\geq p\\) un \\(100\\% p\\) región de verosimilitud para \\(\\theta\\). Usualmente el \\(100\\% p\\) región verosimil consistirá de un intervalo de valores reales, y entonces este es llamado para \\(\\theta\\).\n\nUsualmente consideramos \\(50\\%\\), \\(10\\%\\) y \\(1\\%\\) intervalos verosímiles o regiones.\n\n\n\n\n\n\n\n\n\\[LI\\]\n\\[\\text{Dentro}\\]\n\\[\\text{Fuera}\\]\n\n\n\n\n\\(50\\%\\)\n\\[\\text{Evento muy probable}\\]\n\n\n\n\\(10\\%\\)\n\\[\\text{Evento posible}\\]\n\\[\\text{Evento imposible}\\]\n\n\n\\(1\\%\\)\n\n\\[\\text{Evento muy imposible}\\]\n\n\n\n\n\nFunción de verosimilitud del ejemplo\n\n\n\nEl \\(14.7\\%\\) y \\(3.6\\%\\) de los intervalos de verosimilitud son algunas veces calculado por su analogía al \\(95\\%\\) y el \\(99\\%\\) de intervalos de confianza. a. Como \\(log(0.5)=-0.69\\), tenemos que \\(r(\\theta_1) \\geq -0.69\\), \\(logR(\\theta_1)\\geq log(0.5)\\), luego es semejante \\(R(\\theta_1)\\geq 0.5\\), los datos son 2 veces más probables cuando \\(\\theta=\\hat{\\theta}\\), que cuando \\(\\theta=\\theta_1\\) (Más del \\(50\\%\\) de la probabilidad máxima posible bajo el modelo). b. Como \\(log(0.1)=-2.30\\), tenemos que \\(r(\\theta_1) \\geq -2.30\\), \\(logR(\\theta_1)\\geq log(0.1)\\), luego es semejante \\(R(\\theta_1)\\geq 0.1\\), los datos son 10 veces más probables cuando \\(\\theta=\\hat{\\theta}\\), que cuando \\(\\theta=\\theta_1\\) (Más del \\(10\\%\\) de la probabilidad máxima posible bajo el modelo). c. Como \\(log(0.01)=-4.61\\), tenemos que \\(r(\\theta_1) \\geq -4.61\\), \\(logR(\\theta_1)\\geq log(0.01)\\), luego es semejante \\(R(\\theta_1)\\geq 0.01\\), los datos son 100 veces más probables cuando \\(\\theta=\\hat{\\theta}\\), que cuando \\(\\theta=\\theta_1\\) (Más del \\(1\\%\\) de la probabilidad máxima posible bajo el modelo).\n\nExample 5.7 Supongamos que deseamos entimar \\(\\theta\\), la proporción de personas con tuberculosis en una gran población homogénea.Para esto nosotros seleccionamos aleatoriamente \\(n\\) individuos y encontramos \\(x\\) de ellos que tienen la enfermedad. Ya que la población es grande y homogénea, nosotros asumimos que los \\(n\\) individuos son examinados de manera independiente y que cada uno tiene probabilidad \\(\\theta\\) de tener tuberculosis. La probabilidad del evento observado \\(E\\) es entonces \\[\\begin{align}\nP(E;\\theta)&=P(\\mbox{$x$ de $n$ tienen tuberculosis}) \\nonumber\\\\\n&=\\binom{n}{x}\\theta^x(1-\\theta)^{n-x}\n\\end{align}\\]\ndonde \\(0\\leq \\theta \\leq 1\\). Ver \n\nDetermine el estimador de máxima verosimilitud e interprete en el contexto del problema.\nSuponga que de \\(100\\) personas son examinadas, tres son encontrados con tuberculosis. Sobre la base de estas observaciones, ¿cuales valores de \\(\\theta\\) son plausibles? Para responder, utilice el método gráfico de la función de verosimilitud relativa para hallar los intervalos de verosimilitud (IL) del \\(1\\%\\), \\(10\\%\\) y \\(50\\%\\).\nSuponga que de \\(200\\) personas son examinadas, seis son encontrados con tuberculosis. Sobre la base de estas observaciones, ¿cuales valores de \\(\\theta\\) son plausibles? Para responder, utilice el método gráfico de la función de verosimilitud relativa para hallar los intervalos de verosimilitud (IL) del \\(1\\%\\), \\(10\\%\\) y \\(50\\%\\).\nCompare b y c. con las dos gráficas en el mismo cuadro de inspección.\n\n\n\n\nContrastes de intervalos de verosimilitud",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación por intervalos</span>"
    ]
  },
  {
    "objectID": "chapter3.html#referencias",
    "href": "chapter3.html#referencias",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.7 Referencias",
    "text": "4.7 Referencias\n\nGómez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisión. Departament d’Estadística i Investigació Operativa, Universitat Politècnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estadística matemática con aplicaciones (7ª ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.\nKalbfleisch, J. G. Probability and Statistical Inference. Springer-Verlag, 1985.",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter4.html#referencias",
    "href": "chapter4.html#referencias",
    "title": "5  Estimación por intervalos",
    "section": "5.4 Referencias",
    "text": "5.4 Referencias\n\nGómez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisión. Departament d’Estadística i Investigació Operativa, Universitat Politècnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estadística matemática con aplicaciones (7ª ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.\nKalbfleisch, J. G. Probability and Statistical Inference. Springer-Verlag, 1985.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación por intervalos</span>"
    ]
  },
  {
    "objectID": "chapter3.html#punto-crítico",
    "href": "chapter3.html#punto-crítico",
    "title": "4  Contrastes de hipótesis",
    "section": "4.2 Punto crítico",
    "text": "4.2 Punto crítico\n\\[\nk = \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#probabilidad-de-error-de-tipo-ii",
    "href": "chapter3.html#probabilidad-de-error-de-tipo-ii",
    "title": "4  Contrastes de hipótesis",
    "section": "4.3 Probabilidad de error de tipo II",
    "text": "4.3 Probabilidad de error de tipo II\nSi en realidad (= _a &gt; _0), la probabilidad de cometer un error de tipo II es:\n\\[\n\\beta(\\alpha) = \\Pr(\\,\\bar{X} \\leq k \\mid \\mu = \\mu_a\\,)\n= \\Phi\\!\\left(z_{1-\\alpha} - \\delta\\right),\n\\]\ndonde:\n\\[\n\\delta = \\frac{\\mu_a - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\n\n👉 Interpretación didáctica:\nAl disminuir () (ser más estricto para rechazar (H_0)), aumenta () (es más difícil detectar (H_1)).\nSi el menor valor obtenido \\(\\beta\\) para la probabilidad de error de tipo II es inaceptablemente grande, pueden tomarse dos medidas para reducirlo:\n\naumentar la probabilidad de error de tipo I \\(\\alpha\\) permitida, o\naumentar el tamaño de la muestra.\n\nSupongamos que la distribución de \\(X\\) pertenece a una familia paramétrica \\(\\{f_\\theta:\\theta \\in\\Theta\\}\\) y se contrasta\n\\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta \\in\\Theta_0 \\\\\n\\\\ H_1 &  : & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\] donde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\).\\ Se define la función de potencia \\(\\eta(\\theta)\\) del contraste como \\[\\eta(\\theta)=P_\\theta(\\underset{\\sim}{x}\\in C)=\\left\\{ \\begin{array}{lcc}\n\\alpha &   si & \\theta \\in\\Theta_0 \\\\\n\\\\ 1-\\beta &  si & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\]\nPara \\(0\\leq\\alpha\\leq1\\), un contraste de hipótesis con función de potencia \\(\\eta(\\theta)\\) tiene tamaño \\(\\alpha\\) si [_{_0}()=] Para \\(0\\leq\\alpha\\leq1\\), un contraste de hipótesis con función de potencia \\(\\eta(\\theta)\\) tiene Nivel de significancia \\(\\alpha\\) si \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)\\leq\\alpha\\]\nEl conjunto de contrastes con nivel de significación \\(\\alpha\\) contiene las pruebas de tamaño \\(\\alpha\\).\nUn contraste que minimiza \\(\\beta=P_\\theta(\\underset{\\sim}{x}\\in \\bar{C}\\mid H_1\\mbox{ cierta})\\) entre aquellos que tienen tamaño \\(\\alpha\\) se dice que es el contraste más potente de tamaño \\(\\alpha\\) o el mejor contraste de tamaño \\(\\alpha\\).\n\nExample 4.1 Suponga que un candidato, Jones, dice que él ganará más de \\(50\\%\\) de los votos en una elección urbana y por tanto saldrá como ganador. Como buscamos apoyo para la hipótesis alternativa de que lo dicho por Jones es falso, nuestra hipótesis alternativa es que \\(p\\), la probabilidad de seleccionar un votante que esté a favor de Jones, es menor que \\(0.5\\). Si podemos demostrar que los datos apoyan el rechazo de la hipótesis nula \\(p = 0.5\\) (el valor mínimo necesario para conseguir una mayoría) en favor de la hipótesis alternativa \\(p &lt; 0.5\\), hemos alcanzado nuestro objetivo de investigación. Suponga que \\(n = 15\\) votantes se seleccionan aleatoriamente de una ciudad y se registra \\(Y\\), el número que está a favor de Jones. Calcule \\(\\alpha\\) si seleccionamos \\(C = \\{y \\leq 2\\}\\) como la región de rechazo.\n\nPara la encuesta política de Jones se muestrearon \\(n=15\\) votantes. \\[\\begin{eqnarray*}\n    H_0&:&p=0.5\\\\\n    H_a&:&p&lt;0.5\n\\end{eqnarray*}\\] Estadístico de prueba es \\(Y\\).\n\n\\(Y:\\#\\) de votantes a favor. \\(Y\\sim Binom(15,\\,p)\\)\nRegión de rechazo RR: \\[RR=\\{Y\\leq 2\\}\\]\nC'alculo de \\(\\alpha\\): \\[\\begin{eqnarray*}\n      \\alpha&=&P(\\mbox{error tipo I})\\\\\n      &=&P(\\mbox{Rechazar $H_0$ cuando $H_0$ es verdadera})\\\\\n      &=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\n  \\end{eqnarray*}\\]\n\n\\[\\begin{eqnarray*}\n        \\alpha&=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\\\\\n        &=&pbinom(2,\\,15,\\,0.5)\\\\\n        &=&0.003692627\n    \\end{eqnarray*}\\]\nAsumimos un riesgo muy pequeño (\\(\\alpha=0.004\\)), de concluir que Jones perderá si en realidad es el ganador.\n\\[\\begin{eqnarray*}\n    \\beta(p_1=0.3)&=&P(\\mbox{error tipo II})\\\\\n    &=&P(\\mbox{No rechazar $H_0$ cuando $H_a$ es verdadera})\\\\\n    &=&P(Y&gt; 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-P(Y\\leq 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-pbinom(2,\\,15,\\,0.3)\\\\\n    &=&0.8731723\n\\end{eqnarray*}\\] Esta prueba nos llevará a concluir que Jones es ganador, aún cuando \\(p=0.3\\).\nEl siguiente resultado determina cuál es el contraste más potente cuando se contrasta una hipótesis nula simple frente a una alternativa simple.\n\n4.3.1 Lema de Neyman-Pearson\nSea \\(X_1 ,\\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) con función de densidad (o función de masa de probabilidad) \\(f(x; \\theta)\\). Se desea contrastar \\(H_ 0 : \\theta = \\theta_0\\) frente a \\(H_1 : \\theta = \\theta_1\\) . Si \\(L(\\theta\\mid\\underset{\\sim}{x})\\) es la función de verosimilitud, el mejor contraste de tamaño \\(\\alpha\\) tiene región crítica de la forma \\[C=\\left\\{\\underset{\\sim}{x}\\in\\mathcal{X}^n:\\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\geq A\\right\\}\\] para algún \\(A\\geq 0\\).\\ El contraste que se propone en el Lema de Neyman-Pearson se denomina también test de la razón de verosimilitudes.\n\nExample 4.2 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu, \\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0 : \\mu= \\mu_0\\) frente a \\(H_1: \\mu = \\mu_1\\), con \\(\\mu_1 &gt; \\mu_0\\).\n\nNuestra intuición nos dice que se debe rechazar \\(H_0\\) si se observan valores grandes de \\(x\\). Veamos que la aplicación del Lema de Neyman-Pearson conduce a esta solución.\n\n\n4.3.2 Conclusiones de un contraste: el p-valor.\n\n\n\n\n\n\nTip 4.1\n\n\n\n\nUna forma de informar de los resultados de un contraste de hipótesis es mediante el tamaño \\(\\alpha\\) del test usado y la decisión tomada sobre si se rechazó o no \\(H_0\\).\nSi \\(\\alpha\\) es pequeño la decisión de rechazar \\(H_0\\) es muy convincente, pero si \\(\\alpha\\) es grande la probabilidad de cometer un error de tipo I es grande, lo cuál resta fuerza al test si la decisión adoptada es la de rechazar \\(H_0\\).\nPor otro lado, para \\(\\alpha\\) muy pequeño, el hecho de no rechazar \\(H_0\\) no se interpretará como un apoyo indiscutible a esta hipótesis sino como que no fue posible encontrar evidencia suficiente en su contra como para superar la barrera tan restrictiva impuesta por ese valor de \\(\\alpha\\).\n\n\n\n\nDefinition 4.1 Una forma alternativa de presentar los resultados de un contraste de hipótesis es dar el p-valor o valor de probabilidad del test, definido éste como el supremo de los valores \\(\\alpha\\) para los cuáles se rechazaría la hipótesis nula si ésta se contrastase a nivel \\(\\alpha\\).\n\nEl p-valor depende de los datos muestrales. Puede interpretarse como la probabilidad de observar otra muestra que sea al menos tan poco favorable a la hipótesis nula como la que se ha observado.\nA partir del p-valor se puede tomar la decisión de rechazar (respectivamente, aceptar) \\(H_0\\) si el p-valor es pequeño (respectivamente, grande).\nPor ejemplo, el p-valor de un contraste dado por el Lema de Neyman-Pearson es: \\[p=P_{\\theta_0}\\left\\{\\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\geq \\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\right\\}\\] En general, cuando la región crítica de un contraste de tamaño \\(\\alpha\\) es tal que se rechaza \\(H_0\\) si y sólo si \\(W(\\underset{\\sim}{x})\\geq c_\\alpha\\), donde \\(W(\\underset{\\sim}{x})\\) es un estadístico y \\(c_\\alpha\\) se elige para que el test tenga tamaño \\(\\alpha\\), entonces el p-valor del contraste para una muestra observada \\(\\underset{\\sim}{x}\\) es \\[p(\\underset{\\sim}{x})=\\sup_{\\theta\\in\\Theta_0}P_{\\theta_0}\\{W(\\underset{\\sim}{x})\\geq W(\\underset{\\sim}{x})\\}\\] ## Contrastes uniformemente más potentes\nNos ocuparemos ahora de los contrastes de hipótesis en los que la hipótesis alternativa es compuesta. Queremos contrastar.\n\\[\\left\\{ \\begin{array}{lcc}\n    H_0 &   :  & \\theta \\in\\Theta_0 \\\\\n    \\\\ H_1 &  : & \\theta \\in\\Theta_1  \n    \\end{array}\n    \\right.\\]\ndonde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\)\n\nExample 4.3 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta=\\theta_0 \\\\\n\\\\ H_1 &  : & \\theta&gt;\\theta_1  \n\\end{array}\n\\right.\\] diremos que se trata de un contraste unilateral.\n\n\nExample 4.4 Por ejemplo, si \\(\\Theta=\\mathbb{R}\\), podemos contrastar\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\leq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&gt;\\theta_0  \n        \\end{array}\n        \\right.\\]\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\geq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&lt;\\theta_0  \n        \\end{array}\n        \\right.\\]\ndiremos que se trata de un contraste unilateral.\n\n\nExample 4.5 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta=\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta\\neq\\theta_0  \n        \\end{array}\n        \\right.\\] diremos que se trata de un contraste bilateral.\n\n\nDefinition 4.2 Diremos que un contraste de hipótesis es Uniformemente más potente (UMP) para contrastar \\(H_0:\\theta\\in\\Theta_0\\) frente \\(H_1:\\theta\\in\\Theta_1\\) si su función de potencia \\(\\eta(\\theta)\\) verifica que \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)=\\alpha\\] y para cualquier otro contraste con función de potencia \\(\\eta^*\\) que sea también de tamaño \\(\\alpha\\), es decir, que cumpla \\[\\sup_{\\theta\\in\\Theta_0}\\eta^*(\\theta)=\\alpha\\] se tiene que \\[\\eta(\\theta)\\geq\\eta^*(\\theta),\\forall\\theta\\in\\Theta_1.\\]\n\n\n\n4.3.3 Razón de verosimilitud monótona. Teorema de Karlin-Rubin.\n\nEn esta sección veremos que bajo determinadas condiciones es posible encontrar tests UMP para contrastes unilaterales cuyas regiones críticas son fácilmente expresables en función de un estadístico suficiente.\nLas condiciones necesarias hacen referencia a la monotonía de la razón de verosimilitudes como función del estadístico suficiente.\nUna familia de funciones de densidad o de probabilidad \\(\\{g(t\\mid\\theta) : \\theta \\in \\Theta\\}\\) para una variable aleatoria \\(T\\) tiene razón de verosimilitudes monótona (RVM) si para cada \\(\\theta_2 &gt; \\theta_1\\) el cociente \\(g(t\\mid\\theta_2)/g(t\\mid\\theta_1)\\) es una función no decreciente de \\(t\\) para los valores t tales que \\(g(t\\mid\\theta_2) &gt; 0\\) o \\(g(t\\mid\\theta_1) &gt; 0\\).\n\n\nTheorem 4.1 Se desea contrastar \\(H_0: \\theta\\leq \\theta_0\\) frente a \\(H_1: \\theta &gt; \\theta_0\\) . Supongamos que \\(T\\) es un estadístico suficiente para \\(\\theta\\) y que la familia \\(\\{g(t\\mid\\theta): \\theta \\in \\Theta\\}\\) de funciones de densidad de \\(T\\) tiene RVM. Entonces para cada \\(t_0\\) el test que rechaza \\(H_0\\) si y sólo si \\(T&gt;t_0\\) es UMP de tamaño \\(\\alpha = P_{\\theta_0}(T&gt;t_0 )\\).\n\n\nExample 4.6 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0:\\mu = \\mu_0\\) frente a \\(H_1 : \\mu\\neq\\mu_0\\)\n\nPara contrastar \\(H_0\\) frente a \\(H_1\\) parece razonable rechazar \\(H_0\\) si se observan valores de la media muestral mucho mayores o mucho menores que \\(µ_0\\):\n\\[C=\\{\\underset{\\sim}{x}:\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\}\\] donde \\(A_1\\) y \\(A_2\\) se eligen para que el test tenga tamaño \\(\\alpha\\): \\[\\begin{align}\n\\alpha&=P(C\\mid H_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu0)\\\\\n\\end{align}\\] \\[\\begin{align}\n\\alpha&=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0) + P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\n\\end{align}\\] La forma de fijar \\(A_1\\) y \\(A_2\\) puede atender a distintos criterios. Una posibilidad es elegir \\(A_1\\) y \\(A_2\\) de forma que \\[P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0)= P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)=\\frac{\\alpha}{2}\\]\nes decir, \\(A_1=\\mu_0-\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\), \\(A_2=\\mu_0+\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\)\n\\[\\begin{eqnarray*}\n        \\beta&=&P(\\mbox{error tipo II})\\\\\n        &=&P(\\mbox{No rechazar $H_0$ cuando $H_0$ es falsa})\\\\\n        &=&P(\\underset{\\sim}{x}\\notin C\\mid H_0\\mbox{ falsa})\n    \\end{eqnarray*}\\]\n\n\nGráfico de la función potencia\n\n\n\nEste contraste no es UMP porque, por ejemplo, si rechazamos \\(H_0\\) cuando \\(\\bar{X}_n\\geq\\mu_0+\\frac{z_\\alpha´\\sigma}{\\sqrt{n}}\\) este contraste tiene potencia superior para \\(\\mu &gt; \\mu_0\\) , como puede verse en la figura anterior (curva de trazo discontinuo).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#contexto-de-la-prueba-unilateral",
    "href": "chapter3.html#contexto-de-la-prueba-unilateral",
    "title": "4  Contrastes de hipótesis",
    "section": "4.2 1. Contexto de la prueba unilateral",
    "text": "4.2 1. Contexto de la prueba unilateral\nEstamos en una prueba unilateral para la media de una Normal con varianza conocida:\n\nMuestra de tamaño \\(n\\):\n\\(\\bar{X} \\sim N\\!\\left(\\mu, \\tfrac{\\sigma^2}{n}\\right)\\).\nBajo \\(H_0: \\mu = \\mu_0\\), rechazamos si\n\n\\[\n\\bar{X} &gt; k, \\quad \\text{donde } k = \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#definición-de-error-de-tipo-ii",
    "href": "chapter3.html#definición-de-error-de-tipo-ii",
    "title": "4  Contrastes de hipótesis",
    "section": "4.3 2. Definición de error de tipo II",
    "text": "4.3 2. Definición de error de tipo II\nEl error de tipo II ocurre cuando no rechazamos \\(H_0\\) a pesar de que \\(\\mu = \\mu_a &gt; \\mu_0\\).\n\\[\n\\beta(\\alpha) = \\Pr(\\bar{X} \\le k \\mid \\mu = \\mu_a).\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#estandarización-de-barx",
    "href": "chapter3.html#estandarización-de-barx",
    "title": "4  Contrastes de hipótesis",
    "section": "4.4 3. Estandarización de \\(\\bar{X}\\)",
    "text": "4.4 3. Estandarización de \\(\\bar{X}\\)\nBajo \\(\\mu = \\mu_a\\):\n\\[\n\\bar{X} \\sim N\\!\\left(\\mu_a, \\tfrac{\\sigma^2}{n}\\right).\n\\]\nEstandarizamos:\n\\[\nZ = \\frac{\\bar{X} - \\mu_a}{\\sigma/\\sqrt{n}} \\sim N(0,1).\n\\]\nEntonces:\n\\[\n\\Pr(\\bar{X} \\le k \\mid \\mu=\\mu_a)\n= \\Pr\\!\\left( \\frac{\\bar{X} - \\mu_a}{\\sigma/\\sqrt{n}} \\le \\frac{k - \\mu_a}{\\sigma/\\sqrt{n}} \\right).\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#sustitución-del-punto-crítico-k",
    "href": "chapter3.html#sustitución-del-punto-crítico-k",
    "title": "4  Contrastes de hipótesis",
    "section": "4.5 4. Sustitución del punto crítico \\(k\\)",
    "text": "4.5 4. Sustitución del punto crítico \\(k\\)\nRecordemos:\n\\[\nk = \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPor tanto:\n\\[\n\\frac{k - \\mu_a}{\\sigma/\\sqrt{n}}\n= \\frac{\\mu_0 - \\mu_a}{\\sigma/\\sqrt{n}} + z_{1-\\alpha}.\n\\]\nDefinimos:\n\\[\n\\delta = \\frac{\\mu_a - \\mu_0}{\\sigma/\\sqrt{n}}.\n\\]\nAsí:\n\\[\n\\frac{k - \\mu_a}{\\sigma/\\sqrt{n}} = z_{1-\\alpha} - \\delta.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#expresión-final",
    "href": "chapter3.html#expresión-final",
    "title": "4  Contrastes de hipótesis",
    "section": "4.6 5. Expresión final",
    "text": "4.6 5. Expresión final\nDado que \\(Z \\sim N(0,1)\\):\n\\[\n\\Pr(\\bar{X} \\le k \\mid \\mu = \\mu_a) = \\Pr\\!\\big(Z \\le z_{1-\\alpha} - \\delta\\big).\n\\]\nY esa probabilidad se escribe con la función de distribución acumulada de la Normal estándar (\\(\\Phi\\)):\n\\[\n\\beta(\\alpha) = \\Phi\\!\\left(z_{1-\\alpha} - \\delta\\right).\n\\]\n\n✅ Esa es la justificación: estandarizamos \\(\\bar{X}\\) bajo \\(H_1\\), sustituimos el punto crítico y aparece directamente la forma compacta con \\(\\Phi\\).\n\nInterpretación didáctica:\nAl disminuir \\(\\alpha\\) (ser más estricto para rechazar \\(H_0\\)), aumenta \\(\\beta\\) (es más difícil detectar \\(H_1\\)).\n\nSi el menor valor obtenido \\(\\beta\\) para la probabilidad de error de tipo II es inaceptablemente grande, pueden tomarse dos medidas para reducirlo:\n\naumentar la probabilidad de error de tipo I \\(\\alpha\\) permitida, o\naumentar el tamaño de la muestra.\n\nSupongamos que la distribución de \\(X\\) pertenece a una familia paramétrica \\(\\{f_\\theta:\\theta \\in\\Theta\\}\\) y se contrasta\n\\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta \\in\\Theta_0 \\\\\n\\\\ H_1 &  : & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\] donde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\).\\ Se define la función de potencia \\(\\eta(\\theta)\\) del contraste como \\[\\eta(\\theta)=P_\\theta(\\underset{\\sim}{x}\\in C)=\\left\\{ \\begin{array}{lcc}\n\\alpha &   si & \\theta \\in\\Theta_0 \\\\\n\\\\ 1-\\beta &  si & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\]\nPara \\(0\\leq\\alpha\\leq1\\), un contraste de hipótesis con función de potencia \\(\\eta(\\theta)\\) tiene tamaño \\(\\alpha\\) si [_{_0}()=] Para \\(0\\leq\\alpha\\leq1\\), un contraste de hipótesis con función de potencia \\(\\eta(\\theta)\\) tiene Nivel de significancia \\(\\alpha\\) si \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)\\leq\\alpha\\]\nEl conjunto de contrastes con nivel de significación \\(\\alpha\\) contiene las pruebas de tamaño \\(\\alpha\\).\nUn contraste que minimiza \\(\\beta=P_\\theta(\\underset{\\sim}{x}\\in \\bar{C}\\mid H_1\\mbox{ cierta})\\) entre aquellos que tienen tamaño \\(\\alpha\\) se dice que es el contraste más potente de tamaño \\(\\alpha\\) o el mejor contraste de tamaño \\(\\alpha\\).\n\nExample 4.1 Suponga que un candidato, Jones, dice que él ganará más de \\(50\\%\\) de los votos en una elección urbana y por tanto saldrá como ganador. Como buscamos apoyo para la hipótesis alternativa de que lo dicho por Jones es falso, nuestra hipótesis alternativa es que \\(p\\), la probabilidad de seleccionar un votante que esté a favor de Jones, es menor que \\(0.5\\). Si podemos demostrar que los datos apoyan el rechazo de la hipótesis nula \\(p = 0.5\\) (el valor mínimo necesario para conseguir una mayoría) en favor de la hipótesis alternativa \\(p &lt; 0.5\\), hemos alcanzado nuestro objetivo de investigación. Suponga que \\(n = 15\\) votantes se seleccionan aleatoriamente de una ciudad y se registra \\(Y\\), el número que está a favor de Jones. Calcule \\(\\alpha\\) si seleccionamos \\(C = \\{y \\leq 2\\}\\) como la región de rechazo.\n\nPara la encuesta política de Jones se muestrearon \\(n=15\\) votantes. \\[\\begin{eqnarray*}\n    H_0&:&p=0.5\\\\\n    H_a&:&p&lt;0.5\n\\end{eqnarray*}\\] Estadístico de prueba es \\(Y\\).\n\n\\(Y:\\#\\) de votantes a favor. \\(Y\\sim Binom(15,\\,p)\\)\nRegión de rechazo RR: \\[RR=\\{Y\\leq 2\\}\\]\nC'alculo de \\(\\alpha\\): \\[\\begin{eqnarray*}\n      \\alpha&=&P(\\mbox{error tipo I})\\\\\n      &=&P(\\mbox{Rechazar $H_0$ cuando $H_0$ es verdadera})\\\\\n      &=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\n  \\end{eqnarray*}\\]\n\n\\[\\begin{eqnarray*}\n        \\alpha&=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\\\\\n        &=&pbinom(2,\\,15,\\,0.5)\\\\\n        &=&0.003692627\n    \\end{eqnarray*}\\]\nAsumimos un riesgo muy pequeño (\\(\\alpha=0.004\\)), de concluir que Jones perderá si en realidad es el ganador.\n\\[\\begin{eqnarray*}\n    \\beta(p_1=0.3)&=&P(\\mbox{error tipo II})\\\\\n    &=&P(\\mbox{No rechazar $H_0$ cuando $H_a$ es verdadera})\\\\\n    &=&P(Y&gt; 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-P(Y\\leq 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-pbinom(2,\\,15,\\,0.3)\\\\\n    &=&0.8731723\n\\end{eqnarray*}\\] Esta prueba nos llevará a concluir que Jones es ganador, aún cuando \\(p=0.3\\).\nEl siguiente resultado determina cuál es el contraste más potente cuando se contrasta una hipótesis nula simple frente a una alternativa simple.\n\n4.6.1 Lema de Neyman-Pearson\nSea \\(X_1 ,\\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) con función de densidad (o función de masa de probabilidad) \\(f(x; \\theta)\\). Se desea contrastar \\(H_ 0 : \\theta = \\theta_0\\) frente a \\(H_1 : \\theta = \\theta_1\\) . Si \\(L(\\theta\\mid\\underset{\\sim}{x})\\) es la función de verosimilitud, el mejor contraste de tamaño \\(\\alpha\\) tiene región crítica de la forma \\[C=\\left\\{\\underset{\\sim}{x}\\in\\mathcal{X}^n:\\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\geq A\\right\\}\\] para algún \\(A\\geq 0\\).\\ El contraste que se propone en el Lema de Neyman-Pearson se denomina también test de la razón de verosimilitudes.\n\nExample 4.2 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu, \\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0 : \\mu= \\mu_0\\) frente a \\(H_1: \\mu = \\mu_1\\), con \\(\\mu_1 &gt; \\mu_0\\).\n\nNuestra intuición nos dice que se debe rechazar \\(H_0\\) si se observan valores grandes de \\(x\\). Veamos que la aplicación del Lema de Neyman-Pearson conduce a esta solución.\n\n\n4.6.2 Conclusiones de un contraste: el p-valor.\n\n\n\n\n\n\nTip 4.1\n\n\n\n\nUna forma de informar de los resultados de un contraste de hipótesis es mediante el tamaño \\(\\alpha\\) del test usado y la decisión tomada sobre si se rechazó o no \\(H_0\\).\nSi \\(\\alpha\\) es pequeño la decisión de rechazar \\(H_0\\) es muy convincente, pero si \\(\\alpha\\) es grande la probabilidad de cometer un error de tipo I es grande, lo cuál resta fuerza al test si la decisión adoptada es la de rechazar \\(H_0\\).\nPor otro lado, para \\(\\alpha\\) muy pequeño, el hecho de no rechazar \\(H_0\\) no se interpretará como un apoyo indiscutible a esta hipótesis sino como que no fue posible encontrar evidencia suficiente en su contra como para superar la barrera tan restrictiva impuesta por ese valor de \\(\\alpha\\).\n\n\n\n\nDefinition 4.1 Una forma alternativa de presentar los resultados de un contraste de hipótesis es dar el p-valor o valor de probabilidad del test, definido éste como el supremo de los valores \\(\\alpha\\) para los cuáles se rechazaría la hipótesis nula si ésta se contrastase a nivel \\(\\alpha\\).\n\nEl p-valor depende de los datos muestrales. Puede interpretarse como la probabilidad de observar otra muestra que sea al menos tan poco favorable a la hipótesis nula como la que se ha observado.\nA partir del p-valor se puede tomar la decisión de rechazar (respectivamente, aceptar) \\(H_0\\) si el p-valor es pequeño (respectivamente, grande).\nPor ejemplo, el p-valor de un contraste dado por el Lema de Neyman-Pearson es: \\[p=P_{\\theta_0}\\left\\{\\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\geq \\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\right\\}\\] En general, cuando la región crítica de un contraste de tamaño \\(\\alpha\\) es tal que se rechaza \\(H_0\\) si y sólo si \\(W(\\underset{\\sim}{x})\\geq c_\\alpha\\), donde \\(W(\\underset{\\sim}{x})\\) es un estadístico y \\(c_\\alpha\\) se elige para que el test tenga tamaño \\(\\alpha\\), entonces el p-valor del contraste para una muestra observada \\(\\underset{\\sim}{x}\\) es \\[p(\\underset{\\sim}{x})=\\sup_{\\theta\\in\\Theta_0}P_{\\theta_0}\\{W(\\underset{\\sim}{x})\\geq W(\\underset{\\sim}{x})\\}\\] ## Contrastes uniformemente más potentes\nNos ocuparemos ahora de los contrastes de hipótesis en los que la hipótesis alternativa es compuesta. Queremos contrastar.\n\\[\\left\\{ \\begin{array}{lcc}\n    H_0 &   :  & \\theta \\in\\Theta_0 \\\\\n    \\\\ H_1 &  : & \\theta \\in\\Theta_1  \n    \\end{array}\n    \\right.\\]\ndonde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\)\n\nExample 4.3 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta=\\theta_0 \\\\\n\\\\ H_1 &  : & \\theta&gt;\\theta_1  \n\\end{array}\n\\right.\\] diremos que se trata de un contraste unilateral.\n\n\nExample 4.4 Por ejemplo, si \\(\\Theta=\\mathbb{R}\\), podemos contrastar\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\leq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&gt;\\theta_0  \n        \\end{array}\n        \\right.\\]\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\geq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&lt;\\theta_0  \n        \\end{array}\n        \\right.\\]\ndiremos que se trata de un contraste unilateral.\n\n\nExample 4.5 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta=\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta\\neq\\theta_0  \n        \\end{array}\n        \\right.\\] diremos que se trata de un contraste bilateral.\n\n\nDefinition 4.2 Diremos que un contraste de hipótesis es Uniformemente más potente (UMP) para contrastar \\(H_0:\\theta\\in\\Theta_0\\) frente \\(H_1:\\theta\\in\\Theta_1\\) si su función de potencia \\(\\eta(\\theta)\\) verifica que \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)=\\alpha\\] y para cualquier otro contraste con función de potencia \\(\\eta^*\\) que sea también de tamaño \\(\\alpha\\), es decir, que cumpla \\[\\sup_{\\theta\\in\\Theta_0}\\eta^*(\\theta)=\\alpha\\] se tiene que \\[\\eta(\\theta)\\geq\\eta^*(\\theta),\\forall\\theta\\in\\Theta_1.\\]\n\n\n\n4.6.3 Razón de verosimilitud monótona. Teorema de Karlin-Rubin.\n\nEn esta sección veremos que bajo determinadas condiciones es posible encontrar tests UMP para contrastes unilaterales cuyas regiones críticas son fácilmente expresables en función de un estadístico suficiente.\nLas condiciones necesarias hacen referencia a la monotonía de la razón de verosimilitudes como función del estadístico suficiente.\nUna familia de funciones de densidad o de probabilidad \\(\\{g(t\\mid\\theta) : \\theta \\in \\Theta\\}\\) para una variable aleatoria \\(T\\) tiene razón de verosimilitudes monótona (RVM) si para cada \\(\\theta_2 &gt; \\theta_1\\) el cociente \\(g(t\\mid\\theta_2)/g(t\\mid\\theta_1)\\) es una función no decreciente de \\(t\\) para los valores t tales que \\(g(t\\mid\\theta_2) &gt; 0\\) o \\(g(t\\mid\\theta_1) &gt; 0\\).\n\n\nTheorem 4.1 Se desea contrastar \\(H_0: \\theta\\leq \\theta_0\\) frente a \\(H_1: \\theta &gt; \\theta_0\\) . Supongamos que \\(T\\) es un estadístico suficiente para \\(\\theta\\) y que la familia \\(\\{g(t\\mid\\theta): \\theta \\in \\Theta\\}\\) de funciones de densidad de \\(T\\) tiene RVM. Entonces para cada \\(t_0\\) el test que rechaza \\(H_0\\) si y sólo si \\(T&gt;t_0\\) es UMP de tamaño \\(\\alpha = P_{\\theta_0}(T&gt;t_0 )\\).\n\n\nExample 4.6 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0:\\mu = \\mu_0\\) frente a \\(H_1 : \\mu\\neq\\mu_0\\)\n\nPara contrastar \\(H_0\\) frente a \\(H_1\\) parece razonable rechazar \\(H_0\\) si se observan valores de la media muestral mucho mayores o mucho menores que \\(µ_0\\):\n\\[C=\\{\\underset{\\sim}{x}:\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\}\\] donde \\(A_1\\) y \\(A_2\\) se eligen para que el test tenga tamaño \\(\\alpha\\): \\[\\begin{align}\n\\alpha&=P(C\\mid H_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu0)\\\\\n\\end{align}\\] \\[\\begin{align}\n\\alpha&=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0) + P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\n\\end{align}\\] La forma de fijar \\(A_1\\) y \\(A_2\\) puede atender a distintos criterios. Una posibilidad es elegir \\(A_1\\) y \\(A_2\\) de forma que \\[P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0)= P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)=\\frac{\\alpha}{2}\\]\nes decir, \\(A_1=\\mu_0-\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\), \\(A_2=\\mu_0+\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\)\n\\[\\begin{eqnarray*}\n        \\beta&=&P(\\mbox{error tipo II})\\\\\n        &=&P(\\mbox{No rechazar $H_0$ cuando $H_0$ es falsa})\\\\\n        &=&P(\\underset{\\sim}{x}\\notin C\\mid H_0\\mbox{ falsa})\n    \\end{eqnarray*}\\]\n\n\nGráfico de la función potencia\n\n\n\nEste contraste no es UMP porque, por ejemplo, si rechazamos \\(H_0\\) cuando \\(\\bar{X}_n\\geq\\mu_0+\\frac{z_\\alpha´\\sigma}{\\sqrt{n}}\\) este contraste tiene potencia superior para \\(\\mu &gt; \\mu_0\\) , como puede verse en la figura anterior (curva de trazo discontinuo).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#conclusiones",
    "href": "chapter3.html#conclusiones",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.2 Conclusiones",
    "text": "4.2 Conclusiones\n\nReducir \\(\\alpha\\) implica aumentar \\(\\beta\\).\nUn mayor tamaño del efecto \\((\\mu_a - \\mu_0)\\) o un mayor tamaño de muestra \\(n\\) reducen \\(\\beta\\).\nLa práctica usual es fijar un \\(\\alpha\\) pequeño (0.01, 0.05, 0.1) y luego buscar el diseño que minimice \\(\\beta\\) o equivalga a maximizar la potencia del test.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#función-de-potencia",
    "href": "chapter3.html#función-de-potencia",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "",
    "text": "La función de potencia de una prueba mide, para cada valor posible del parámetro \\(\\theta\\), la probabilidad de rechazar la hipótesis nula:\n\\[\n\\eta(\\theta) = P_\\theta(\\tilde{x} \\in C),\n\\]\ndonde: - \\(\\tilde{x}\\) es la muestra, - \\(C\\) es la región crítica (el conjunto de valores de la muestra que llevan a rechazar \\(H_0\\)).\nEn palabras:La función de potencia nos dice qué tan probable es rechazar \\(H_0\\), dado que el parámetro vale \\(\\theta\\).",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#casos-especiales-de-la-función-de-potencia",
    "href": "chapter3.html#casos-especiales-de-la-función-de-potencia",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.3 2. Casos especiales de la función de potencia",
    "text": "4.3 2. Casos especiales de la función de potencia\n\n\nSi \\(\\theta \\in \\Theta_0\\) (es decir, si \\(H_0\\) es cierta):\n\\[\n\\eta(\\theta) = \\alpha\n\\]\nEsto refleja que, bajo \\(H_0\\), la probabilidad de rechazar \\(H_0\\) es justamente la probabilidad de cometer un error de tipo I.\n\n\nSi \\(\\theta \\in \\Theta_1\\) (es decir, si \\(H_1\\) es cierta):\n\\[\n\\eta(\\theta) = 1 - \\beta\n\\]\nEsto refleja que, bajo \\(H_1\\), la probabilidad de rechazar \\(H_0\\) es la potencia de la prueba.",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#tamaño-y-nivel-de-significación",
    "href": "chapter3.html#tamaño-y-nivel-de-significación",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.4 3. Tamaño y nivel de significación",
    "text": "4.4 3. Tamaño y nivel de significación\n\n\nTamaño \\(\\alpha\\):\nUna prueba tiene tamaño \\(\\alpha\\) si el peor caso (la mayor probabilidad de rechazar \\(H_0\\) cuando es cierta) es exactamente \\(\\alpha\\):\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) = \\alpha\n\\]\n→ El tamaño es el “valor máximo real” de error tipo I que puede ocurrir bajo \\(H_0\\).\n\n\nNivel de significación \\(\\alpha\\):\nUna prueba tiene nivel de significación \\(\\alpha\\) si ese peor caso no excede \\(\\alpha\\):\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) \\leq \\alpha\n\\]\n→ El nivel de significación es un límite superior que ponemos a la probabilidad de error tipo I.\n\n\nNota: Todo contraste de tamaño \\(\\alpha\\) tiene también nivel de significación \\(\\alpha\\), pero no todo contraste con nivel de significación \\(\\alpha\\) necesariamente alcanza el tamaño exacto.",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#contraste-más-potente",
    "href": "chapter3.html#contraste-más-potente",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.5 4. Contraste más potente",
    "text": "4.5 4. Contraste más potente\nEntre todas las pruebas que tienen el mismo tamaño \\(\\alpha\\), buscamos la que minimiza \\(\\beta\\) (o equivalentemente, la que maximiza la potencia \\(1-\\beta\\)).\nEsa prueba se llama:\n\n\nEl contraste más potente de tamaño \\(\\alpha\\),\n\no el mejor contraste de tamaño \\(\\alpha\\).\n\nEs decir, para un mismo control de error tipo I, elegimos la prueba que detecta con mayor eficacia cuando \\(H_1\\) es verdadera.\n\nEn resumen:\n- La función de potencia es la herramienta que unifica \\(\\alpha\\) y \\(1-\\beta\\).\n- Tamaño = probabilidad máxima de error tipo I.\n- Nivel de significación = restricción para controlar ese error.\n- El mejor contraste de tamaño \\(\\alpha\\) es aquel que, manteniendo fijo el error tipo I, maximiza la probabilidad de rechazar \\(H_0\\) cuando realmente es falsa.",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#problema-2",
    "href": "chapter3.html#problema-2",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.6 Problema 2",
    "text": "4.6 Problema 2\nApoyándose en el ejercicio anterior, responda claramente a las siguientes preguntas:\nI. A partir del contraste del inciso a, ¿es falsa o verdadera la afirmación: “La probabilidad del error tipo I es aceptablemente baja para todo \\(\\theta \\le \\tfrac{1}{2}\\)”? Explique su respuesta.\nSí, es verdadera.\nBajo \\(H_0:\\theta\\le \\tfrac12\\), el error tipo I del contraste (a) es \\[\nP_\\theta(\\text{rechazar }H_0)=\\eta_a(\\theta)=\\theta^5.\n\\] Como \\(\\theta^5\\) es creciente en \\(\\theta\\), su máximo sobre \\(\\Theta_0=\\{\\theta\\le \\tfrac12\\}\\) se alcanza en el borde: \\[\n\\alpha_a=\\sup_{\\theta\\le 1/2}\\eta_a(\\theta)=\\eta_a\\!\\left(\\tfrac12\\right)=\\left(\\tfrac12\\right)^5=\\frac{1}{32}\\approx 0.03125.\n\\] Por tanto, para todo \\(\\theta\\le \\tfrac12\\) se tiene \\(\\eta_a(\\theta)\\le 0.03125\\), es decir, un nivel de error tipo I muy bajo.\n\n¿Para qué valores de \\(\\theta\\) el error tipo II es menor que \\(\\tfrac{1}{2}\\) en el contraste del inciso a?\n\nEn (a), bajo \\(H_1\\) el error tipo II es \\[\n\\beta_a(\\theta)=1-\\eta_a(\\theta)=1-\\theta^5.\n\\] La condición \\(\\beta_a(\\theta)&lt;\\tfrac12\\) equivale a \\[\n1-\\theta^5&lt;\\tfrac12\\quad\\Longleftrightarrow\\quad \\theta^5&gt;\\tfrac12\n\\quad\\Longleftrightarrow\\quad \\theta&gt;(1/2)^{1/5}\\approx 0.87055.\n\\] Luego, para \\(\\theta&gt;0.87055\\) (y, por supuesto, \\(\\theta&gt;1/2\\)), el error tipo II es menor a \\(1/2\\).\n\nEn el contraste del inciso b, ¿para qué valores de \\(\\theta\\) el error tipo II alcanza valores pequeños?\n\nEn (b), \\[\n\\beta_b(\\theta)=1-\\eta_b(\\theta)=P_\\theta(X\\le 2)\n=(1-\\theta)^5+5\\theta(1-\\theta)^4+10\\theta^2(1-\\theta)^3,\n\\] función decreciente en \\(\\theta\\). Valores representativos: \\[\n\\begin{array}{c|ccccc}\n\\theta & 0.55 & 0.60 & 0.70 & 0.75 & 0.80\\\\ \\hline\n\\beta_b(\\theta) & 0.407 & 0.317 & 0.163 & 0.104 & 0.058\n\\end{array}\n\\] Se observa que \\(\\beta_b(\\theta)\\) ya es pequeña (por ejemplo \\(&lt;0.10\\)) a partir de \\(\\theta\\gtrsim 0.78\\) (pues en \\(0.75\\) es \\(\\approx 0.104\\) y en \\(0.80\\) es \\(\\approx 0.058\\)).\n\n¿Es falso o verdadero afirmar que: “La potencia del contraste del inciso b es mayor que la potencia del otro contraste para valores de \\(\\theta \\le \\tfrac{1}{2}\\). Entonces, la probabilidad del error tipo I del contraste del inciso b es mayor que la del otro contraste para valores de \\(\\theta \\le \\tfrac{1}{2}\\)”? Explique su respuesta.\n\n\nVerdadero.\nPara \\(\\theta\\le \\tfrac12\\) (región nula):\n\nLa “potencia” \\(\\eta(\\theta)\\) coincide con la probabilidad de error tipo I en ese punto.\nNuméricamente (y por la propiedad MLR de la binomial) se verifica que \\[\n\\eta_b(\\theta)=P_\\theta(X\\ge 3)\\;&gt;\\;\\eta_a(\\theta)=\\theta^5\n\\quad \\text{para todo }\\theta\\le \\tfrac12.\n\\] Ejemplos:\\(\\theta=0.5:\\ \\eta_b=0.5\\ \\text{vs}\\ \\eta_a=0.03125\\);\\(\\theta=0.4:\\ \\eta_b\\approx 0.31744\\ \\text{vs}\\ \\eta_a=0.01024\\).\nEn particular, el tamaño es mayor en (b):\\[\n\\alpha_b=\\eta_b(1/2)=0.5 \\quad\\gg\\quad \\alpha_a=\\eta_a(1/2)=1/32\\approx 0.03125.\n\\]\n\nConclusión: el contraste (b) rechaza con mucha más frecuencia bajo \\(H_0\\) (mayor error tipo I), lo que explica su mayor potencia bajo \\(H_1\\); el costo es un nivel \\(\\alpha\\) inaceptablemente alto en (b) comparado con (a).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#opción-a-rechazar-h_0-solo-si-se-observan-los-5-éxitos",
    "href": "chapter3.html#opción-a-rechazar-h_0-solo-si-se-observan-los-5-éxitos",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.6 Opción (a): Rechazar (H_0) solo si se observan los 5 éxitos",
    "text": "4.6 Opción (a): Rechazar (H_0) solo si se observan los 5 éxitos\nModelo. Sea (X (5,)) con función de probabilidad\n(P_(X=x)=x(1-){5-x}), (x=0,1,,5).\n\n4.6.1 Región crítica\nLa regla propuesta es rechazar (H_0) únicamente cuando (X=5). Por tanto, \\[\nC_a=\\{5\\},\\qquad \\bar C_a=\\{0,1,2,3,4\\}.\n\\]\n\n4.6.2 Función de potencia (_a())\nPor definición, la potencia es la probabilidad de caer en la región crítica: \\[\n\\eta_a(\\theta)=P_\\theta(X\\in C_a)=P_\\theta(X=5)\n=\\binom{5}{5}\\theta^5(1-\\theta)^{0}\n=\\theta^5.\n\\] Es decir, para cualquier (0), \\[\n\\eta_a(\\theta)=\\theta^5.\n\\]\n\n4.6.3 Tamaño (máximo error tipo I)\nEl tamaño del contraste es \\[\n\\alpha_a=\\sup_{\\theta\\in\\Theta_0}\\eta_a(\\theta)\n=\\sup_{\\theta\\le 1/2}\\theta^5.\n\\] Como (^5) es estrictamente creciente en () (derivada (5^4&gt;0)), el supremo en (_0={/2}) se alcanza en el borde (/2): \\[\n\\alpha_a=\\left(\\tfrac12\\right)^5=\\frac{1}{32}\\approx 0.03125.\n\\]\n\n4.6.4 Lectura e intuición\n\nLa regla (C_a={5}) es muy conservadora: solo rechaza (H_0) en el caso más extremo.\nPor eso, el tamaño es muy pequeño ((_a%)).\nLa potencia (_a()=^5) crece muy lentamente; el test casi nunca rechaza salvo que () sea muy grande.\nEn términos del error tipo II (_a()=1-_a()=1-^5):\n\nSi (), (_a=1-0.6^5) (muy alto).\nSi (), (_a=1-0.9^5).\nRecién cerca de (), (_a).\n\n\n\nConclusión. Es un contraste con bajo error tipo I pero muy poca potencia, salvo cuando el efecto es extremadamente grande (valores de () muy cercanos a 1).\n\nConsidere en segundo lugar el contraste de rechazar \\(H_0\\) si \\(X \\in \\{3,4,5\\}\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#opción-b-rechazar-h_0-si-xin345-equiv.-xge-3",
    "href": "chapter3.html#opción-b-rechazar-h_0-si-xin345-equiv.-xge-3",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.6 Opción (b): Rechazar \\(H_0\\) si \\(X\\in\\{3,4,5\\}\\) (equiv. \\(X\\ge 3\\))",
    "text": "4.6 Opción (b): Rechazar \\(H_0\\) si \\(X\\in\\{3,4,5\\}\\) (equiv. \\(X\\ge 3\\))\nModelo. Sea \\(X\\sim \\mathrm{Bin}(5,\\theta)\\) con \\[\nP_\\theta(X=x)=\\binom{5}{x}\\,\\theta^x(1-\\theta)^{5-x},\\quad x=0,1,\\dots,5.\n\\]\n\n4.6.1 Región crítica\n\\[\nC_b=\\{3,4,5\\},\\qquad \\bar C_b=\\{0,1,2\\}.\n\\]\n\n4.6.2 Función de potencia \\(\\eta_b(\\theta)\\)\n\nPor definición, la potencia es la probabilidad de caer en la región crítica: \\[\n\\eta_b(\\theta)=P_\\theta(X\\in C_b)=P_\\theta(X\\ge 3)\n=\\sum_{k=3}^{5}\\binom{5}{k}\\theta^k(1-\\theta)^{5-k}.\n\\]\nSuma directa. \\[\n\\eta_b(\\theta)=10\\,\\theta^3(1-\\theta)^2+5\\,\\theta^4(1-\\theta)+\\theta^5.\n\\]\nVía complemento (útil para el tamaño). \\[\n\\eta_b(\\theta)=1-P_\\theta(X\\le 2)\n=1-\\Big[(1-\\theta)^5+5\\theta(1-\\theta)^4+10\\theta^2(1-\\theta)^3\\Big].\n\\]\nMonotonía. Para la familia binomial, \\(P_\\theta(X\\ge c)\\) es creciente en \\(\\theta\\) (propiedad MLR). Por tanto, \\(\\eta_b(\\theta)\\) aumenta con \\(\\theta\\).\n\n4.6.3 Tamaño (máximo error tipo I)\nEl tamaño es \\[\n\\alpha_b=\\sup_{\\theta\\le 1/2}\\eta_b(\\theta).\n\\] Como \\(\\eta_b(\\theta)\\) es creciente, el supremo se alcanza en el borde \\(\\theta=1/2\\): \\[\n\\alpha_b=\\eta_b(1/2)=P_{1/2}(X\\ge 3)=1-P_{1/2}(X\\le 2).\n\\] Con simetría binomial: \\[\nP_{1/2}(X\\le 2)=\\frac{\\binom50+\\binom51+\\binom52}{2^5}\n=\\frac{1+5+10}{32}=\\frac{16}{32},\n\\] luego \\[\n\\alpha_b=1-\\frac{16}{32}=\\frac{16}{32}=0.5.\n\\]\n\n4.6.4 Lectura numérica (potencia y error tipo II)\nValores aproximados: \\[\n\\begin{array}{c|ccccc}\n\\theta & 0.55 & 0.60 & 0.70 & 0.80 & 0.90\\\\ \\hline\n\\eta_b(\\theta)=P_\\theta(X\\ge 3) & 0.593 & 0.683 & 0.837 & 0.942 & 0.991\\\\\n\\beta_b(\\theta)=1-\\eta_b(\\theta) & 0.407 & 0.317 & 0.163 & 0.058 & 0.009\n\\end{array}\n\\]\n\nPara \\(\\theta&gt;1/2\\), la potencia crece rápido y el error tipo II cae pronto: ya con \\(\\theta\\approx 0.7\\) la potencia es alta.\nEl costo es un tamaño enorme: \\(\\alpha_b=0.5\\) (inaceptable en la práctica).\n\n4.6.5 Observación de diseño (cómo fijar \\(\\alpha\\) razonable)\nCon \\(n=5\\) y \\(H_0:\\theta\\le 1/2\\): - \\(X\\ge 5\\) da \\(\\alpha=(1/2)^5=1/32\\approx 0.03125\\). - \\(X\\ge 4\\) da \\(\\alpha=P_{1/2}(X\\ge 4)=(\\binom54+\\binom55)/32=(5+1)/32=6/32=0.1875\\). - Para alcanzar, por ejemplo, \\(\\alpha=0.10\\), sería necesario aleatorizar en \\(X=4\\) (rechazar con cierta probabilidad cuando \\(X=4\\)) o aumentar el tamaño muestral.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#contrastes-uniformemente-más-potentes",
    "href": "chapter3.html#contrastes-uniformemente-más-potentes",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.6 Contrastes uniformemente más potentes",
    "text": "4.6 Contrastes uniformemente más potentes\nNos ocuparemos ahora de los contrastes de hipótesis en los que la hipótesis alternativa es compuesta. Queremos contrastar.\n\\[\\left\\{ \\begin{array}{lcc}\n    H_0 &   :  & \\theta \\in\\Theta_0 \\\\\n    \\\\ H_1 &  : & \\theta \\in\\Theta_1  \n    \\end{array}\n    \\right.\\]\ndonde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\)\n\nExample 4.5 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta=\\theta_0 \\\\\n\\\\ H_1 &  : & \\theta&gt;\\theta_1  \n\\end{array}\n\\right.\\] diremos que se trata de un contraste unilateral.\n\n\nExample 4.6 Por ejemplo, si \\(\\Theta=\\mathbb{R}\\), podemos contrastar\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\leq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&gt;\\theta_0  \n        \\end{array}\n        \\right.\\]\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\geq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&lt;\\theta_0  \n        \\end{array}\n        \\right.\\]\ndiremos que se trata de un contraste unilateral.\n\n\nExample 4.7 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta=\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta\\neq\\theta_0  \n        \\end{array}\n        \\right.\\] diremos que se trata de un contraste bilateral.\n\n\nDefinition 4.3 Diremos que un contraste de hipótesis es Uniformemente más potente (UMP) para contrastar \\(H_0:\\theta\\in\\Theta_0\\) frente \\(H_1:\\theta\\in\\Theta_1\\) si su función de potencia \\(\\eta(\\theta)\\) verifica que \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)=\\alpha\\] y para cualquier otro contraste con función de potencia \\(\\eta^*\\) que sea también de tamaño \\(\\alpha\\), es decir, que cumpla \\[\\sup_{\\theta\\in\\Theta_0}\\eta^*(\\theta)=\\alpha\\] se tiene que \\[\\eta(\\theta)\\geq\\eta^*(\\theta),\\forall\\theta\\in\\Theta_1.\\]\n\n\n\n\n\n\n\nTip 4.4: Test Uniformemente Más Potente (UMP)\n\n\n\nDefinición - La función de potencia de un test con región crítica \\(C\\) es:\n\\[\n  \\eta(\\theta) = P_\\theta(X \\in C)\n  \\]\n\n\nUn test es UMP de tamaño \\(\\alpha\\) para \\(H_0:\\theta \\in \\Theta_0\\) vs \\(H_1:\\theta \\in \\Theta_1\\) si:\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) = \\alpha\n\\]\ny, para cualquier otro test del mismo tamaño con función de potencia \\(\\eta^*(\\theta)\\),\n\\[\n\\eta(\\theta) \\geq \\eta^*(\\theta), \\quad \\forall \\theta \\in \\Theta_1\n\\]\n\n\nLectura intuitiva - Mismo control de falsos positivos: todos los tests comparados tienen el mismo tamaño \\(\\alpha\\).\n- Mejor detección bajo la alternativa: en todo \\(\\Theta_1\\), la probabilidad de rechazar \\(H_0\\) es al menos tan grande como la de cualquier otro test del mismo tamaño.\nObservaciones - A veces no existe un UMP (por ejemplo, en muchas alternativas bilaterales).\n- Sí existe UMP en varios problemas unilaterales cuando la familia tiene razón de verosimilitudes monótona (teorema de Karlin–Rubin).\nMini-ejemplo (binomial unilateral) - Modelo: \\(X \\sim \\text{Bin}(n,p)\\).\n- Contraste: \\(H_0: p \\le p_0\\) vs \\(H_1: p &gt; p_0\\).\n- Región crítica de tamaño \\(\\alpha\\): \\(C = \\{x : x \\ge c_\\alpha\\}\\) donde\n\\[\n  \\alpha = P_{p_0}(X \\ge c_\\alpha)\n  \\]\n\n\nPotencia para cualquier \\(p\\):\n\\[\n\\eta(p) = P_p(X \\ge c_\\alpha) = \\sum_{k=c_\\alpha}^n \\binom{n}{k} p^k (1-p)^{n-k}\n\\]\n\n\nEste test es UMP de tamaño \\(\\alpha\\) para \\(H_1: p &gt; p_0\\).\nComparación: Test cualquiera vs. Test UMP\n\n\n\n\n\n\n\nCaracterística\nTest cualquiera\nTest UMP\n\n\n\n\nTamaño (error Tipo I)\nControlado a nivel \\(\\alpha\\)\n\nControlado a nivel \\(\\alpha\\)\n\n\n\nPotencia en algunos \\(\\theta \\in \\Theta_1\\)\nPuede ser alta o baja, dependiendo del valor de \\(\\theta\\)\n\nSiempre es mayor o igual que la de cualquier otro test del mismo tamaño\n\n\nComportamiento global\nPuede ser mejor en unos valores de \\(\\theta\\) y peor en otros\nEs el mejor en todos los valores de \\(\\theta \\in \\Theta_1\\)\n\n\n\nAnalogía\nUn detector que funciona bien en ciertos ángulos pero falla en otros\nUn detector que funciona igual o mejor en todos los ángulos\n\n\n\nExistencia\nSiempre existe un test de tamaño \\(\\alpha\\), pero no siempre es el mejor\nNo siempre existe un UMP; cuando existe, es la opción óptima\n\n\n\n\n\n\n# --- Curvas de potencia (Binomial) UMP vs. otros tests del mismo tamaño ---\n\n# Parámetros del problema\nn &lt;- 25\np0 &lt;- 0.30\nalpha_target &lt;- 0.05\n\n# Función: cola superior P(X &gt;= c) para Binomial(n, p)\nbinom_tail_ge &lt;- function(n, c, p) 1 - pbinom(c - 1, size = n, prob = p)\n\n# 1) UMP: región crítica de cola superior {k &gt;= c_alpha} con tamaño ≈ alpha_target\ncandidates &lt;- 0:n\ntails &lt;- sapply(candidates, function(c) binom_tail_ge(n, c, p0))\n\n# Elegimos el menor c tal que P_{p0}(X &gt;= c) &lt;= alpha_target\nc_alpha &lt;- which(tails &lt;= alpha_target)[1]\nif (is.na(c_alpha)) c_alpha &lt;- n  # por si la discretud no permite bajar de alpha\n\nR_UMP &lt;- c_alpha:n\nsize_UMP &lt;- sum(dbinom(R_UMP, n, p0))\n\n# 2) Test A: empezamos más conservador (c_alpha+1) y agregamos un punto interior\nR_A &lt;- (c_alpha + 1):n\nsize_A &lt;- sum(dbinom(R_A, n, p0))\n\n# Apuntamos a un punto interior cerca de la moda ~ n*p0\nmode_approx &lt;- round(n * p0)\nk_star_candidates &lt;- seq(max(0, mode_approx - 4), min(n, mode_approx + 4))\nbest_k &lt;- NA\nbest_diff &lt;- Inf\nfor (k in k_star_candidates) {\n  if (!(k %in% R_A)) {\n    trial &lt;- size_A + dbinom(k, n, p0)\n    diff &lt;- abs(alpha_target - trial)\n    if (diff &lt; best_diff) {\n      best_diff &lt;- diff\n      best_k &lt;- k\n    }\n  }\n}\nif (!is.na(best_k)) {\n  R_A &lt;- sort(unique(c(R_A, best_k)))\n  size_A &lt;- sum(dbinom(R_A, n, p0))\n}\n\n# 3) Test B: aún más conservador (c_alpha+2) y agregamos dos puntos interiores\nR_B &lt;- (c_alpha + 2):n\nsize_B &lt;- sum(dbinom(R_B, n, p0))\nk_cand_B &lt;- c(mode_approx - 3, mode_approx + 3,\n              mode_approx - 4, mode_approx + 4,\n              mode_approx - 2, mode_approx + 2)\n\nfor (k in k_cand_B) {\n  if (k &gt;= 0 && k &lt;= n && !(k %in% R_B)) {\n    trial &lt;- size_B + dbinom(k, n, p0)\n    # Permitimos leve sobrepaso por discretud\n    if (trial &lt;= alpha_target || (trial - alpha_target) &lt; 0.005) {\n      R_B &lt;- sort(unique(c(R_B, k)))\n      size_B &lt;- trial\n    }\n  }\n  if (size_B &gt;= alpha_target - 1e-6) break\n}\n# Si quedó muy por debajo, añadimos el k que mejor aproxime alpha\nif (size_B &lt; alpha_target - 0.01) {\n  diffs &lt;- sapply(setdiff(0:n, R_B), function(k) abs(alpha_target - (size_B + dbinom(k, n, p0))))\n  add_k &lt;- setdiff(0:n, R_B)[which.min(diffs)]\n  R_B &lt;- sort(unique(c(R_B, add_k)))\n  size_B &lt;- sum(dbinom(R_B, n, p0))\n}\n\n# --- Curvas de potencia ---\nps &lt;- seq(p0, 1, length.out = 200)\npower_UMP &lt;- sapply(ps, function(p) sum(dbinom(R_UMP, n, p)))\npower_A   &lt;- sapply(ps, function(p) sum(dbinom(R_A,   n, p)))\npower_B   &lt;- sapply(ps, function(p) sum(dbinom(R_B,   n, p)))\n\n# Data frame para graficar\ndf &lt;- data.frame(\n  p = rep(ps, 3),\n  potencia = c(power_UMP, power_A, power_B),\n  test = factor(rep(c(\n    sprintf(\"UMP (k ≥ %d), tamaño≈%.3f\", c_alpha, size_UMP),\n    sprintf(\"Test A (tamaño≈%.3f)\", size_A),\n    sprintf(\"Test B (tamaño≈%.3f)\", size_B)\n  ), each = length(ps)))\n)\n\n# --- Gráfico con ggplot2 ---\nif (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\ng &lt;- ggplot(df, aes(x = p, y = potencia, linetype = test)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dotted\") +\n  labs(\n    title = sprintf(\"Curvas de potencia (Binomial n=%d, H0: p ≤ p0, p0=%.2f)\", n, p0),\n    x = \"p\",\n    y = \"Potencia  η(p) = P_p(rechazar H0)\",\n    linetype = NULL\n  ) +\n  theme_minimal(base_size = 12)\n\nprint(g)\n\n\n\n\n\n\n# Guardar PNG\nggplot2::ggsave(\"power_curves_UMP_vs_others.png\", g, width = 8, height = 5, dpi = 150)\ncat(\"Archivo guardado: power_curves_UMP_vs_others.png\\n\")\n\nArchivo guardado: power_curves_UMP_vs_others.png\n\n# --- Opcional: mostrar las regiones críticas resultantes ---\ncat(\"Región crítica UMP: {\", paste(R_UMP, collapse = \", \"), \"}\\n\", sep = \"\")\n\nRegión crítica UMP: {13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}\n\ncat(\"Región crítica Test A: {\", paste(R_A, collapse = \", \"), \"}\\n\", sep = \"\")\n\nRegión crítica Test A: {11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}\n\ncat(\"Región crítica Test B: {\", paste(R_B, collapse = \", \"), \"}\\n\", sep = \"\")\n\nRegión crítica Test B: {3, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}\n\n\n\n4.6.1 Razón de verosimilitud monótona. Teorema de Karlin-Rubin.\n\nEn esta sección veremos que bajo determinadas condiciones es posible encontrar tests UMP para contrastes unilaterales cuyas regiones críticas son fácilmente expresables en función de un estadístico suficiente.\nLas condiciones necesarias hacen referencia a la monotonía de la razón de verosimilitudes como función del estadístico suficiente.\nUna familia de funciones de densidad o de probabilidad \\(\\{g(t\\mid\\theta) : \\theta \\in \\Theta\\}\\) para una variable aleatoria \\(T\\) tiene razón de verosimilitudes monótona (RVM) si para cada \\(\\theta_2 &gt; \\theta_1\\) el cociente \\(g(t\\mid\\theta_2)/g(t\\mid\\theta_1)\\) es una función no decreciente de \\(t\\) para los valores t tales que \\(g(t\\mid\\theta_2) &gt; 0\\) o \\(g(t\\mid\\theta_1) &gt; 0\\).\n\n\nTheorem 4.1 Se desea contrastar \\(H_0: \\theta\\leq \\theta_0\\) frente a \\(H_1: \\theta &gt; \\theta_0\\) . Supongamos que \\(T\\) es un estadístico suficiente para \\(\\theta\\) y que la familia \\(\\{g(t\\mid\\theta): \\theta \\in \\Theta\\}\\) de funciones de densidad de \\(T\\) tiene RVM. Entonces para cada \\(t_0\\) el test que rechaza \\(H_0\\) si y sólo si \\(T&gt;t_0\\) es UMP de tamaño \\(\\alpha = P_{\\theta_0}(T&gt;t_0 )\\).\n\n\nExample 4.8 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0:\\mu = \\mu_0\\) frente a \\(H_1 : \\mu\\neq\\mu_0\\)\n\nPara contrastar \\(H_0\\) frente a \\(H_1\\) parece razonable rechazar \\(H_0\\) si se observan valores de la media muestral mucho mayores o mucho menores que \\(µ_0\\):\n\\[C=\\{\\underset{\\sim}{x}:\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\}\\] donde \\(A_1\\) y \\(A_2\\) se eligen para que el test tenga tamaño \\(\\alpha\\): \\[\\begin{align}\n\\alpha&=P(C\\mid H_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu0)\\\\\n\\end{align}\\] \\[\\begin{align}\n\\alpha&=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0) + P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\n\\end{align}\\] La forma de fijar \\(A_1\\) y \\(A_2\\) puede atender a distintos criterios. Una posibilidad es elegir \\(A_1\\) y \\(A_2\\) de forma que \\[P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0)= P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)=\\frac{\\alpha}{2}\\]\nes decir, \\(A_1=\\mu_0-\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\), \\(A_2=\\mu_0+\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\)\nEntonces se rechazará \\(H_0\\) si\n\\[\n\\left| \\overline{X}_n - \\mu_0 \\right| \\geq z_{\\alpha/2} \\, \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nLa función de potencia es tal como se refleja en la figura siguiente (curva de trazo continuo).\n\nGráfico de la función potencia\n\n\nEste contraste no es UMP porque, por ejemplo, si rechazamos \\(H_0\\) cuando \\(\\bar{X}_n\\geq\\mu_0+\\frac{z_\\alpha´\\sigma}{\\sqrt{n}}\\) este contraste tiene potencia superior para \\(\\mu &gt; \\mu_0\\) , como puede verse en la figura anterior (curva de trazo discontinuo).\n\n\n\n\n\n\nTip 4.5: Teorema de Karlin–Rubin aplicado al caso normal\n\n\n\nPlanteamiento - Muestra i.i.d. \\(X_1,\\dots,X_n \\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocida.\n- Estadístico: \\(\\overline{X}_n\\).\n- Queremos contrastar, por ejemplo:\n\\[\n  H_0:\\ \\mu \\le \\mu_0 \\quad \\text{vs} \\quad H_1:\\ \\mu &gt; \\mu_0\n  \\]\nVerificación de las hipótesis del teorema 1. Suficiencia: para varianza conocida, \\(\\overline{X}_n\\) es suficiente para \\(\\mu\\).\n2. Razón de verosimilitudes monótona (RVM): la familia \\(\\{N(\\mu,\\sigma^2/n): \\mu \\in \\mathbb{R}\\}\\) posee RVM en \\(\\overline{X}_n\\), porque para \\(\\mu_1&gt;\\mu_0\\) la razón\n\\[\n   \\frac{f_{\\mu_1}(\\overline{x})}{f_{\\mu_0}(\\overline{x})}\n   \\]\nes creciente en \\(\\overline{x}\\).\nPor el teorema, existe un test UMP de tamaño \\(\\alpha\\) cuya región crítica es de cola superior.\nTest UMP (unilateral a la derecha) - Bajo \\(\\mu=\\mu_0\\):\n\\[\n  Z=\\frac{\\overline{X}_n-\\mu_0}{\\sigma/\\sqrt{n}} \\sim N(0,1)\n  \\]\n\n\nEl test UMP de tamaño \\(\\alpha\\) rechaza \\(H_0\\) si:\n\\[\n\\overline{X}_n &gt; \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\quad \\Longleftrightarrow \\quad\nZ &gt; z_{1-\\alpha}\n\\]\n\nFunción de potencia: Como \\(\\overline{X}_n \\sim N(\\mu,\\ \\sigma^2/n)\\), podemos escribir:\n\n\\[\n\\overline{X}_n = \\mu + \\frac{\\sigma}{\\sqrt{n}}\\,W,\n\\]\ndonde \\(W \\sim N(0,1)\\).\nSustituyendo en la definición de \\(Z\\):\n\\[\nZ = \\frac{\\mu + \\tfrac{\\sigma}{\\sqrt{n}}W - \\mu_0}{\\sigma/\\sqrt{n}}\n= \\frac{\\mu-\\mu_0}{\\sigma/\\sqrt{n}} + W.\n\\]\nPor lo tanto:\n\\[\nZ \\sim N\\!\\left(\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0),\\,1\\right).\n\\]\nEs decir: - Media: \\(\\delta = \\tfrac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\)\n- Varianza: \\(1\\)\nEl estadístico de prueba es:\n\\[\nZ = \\frac{\\overline{X}_n - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\ny bajo el verdadero valor de \\(\\mu\\) se distribuye como:\n\\[\nZ \\sim N\\!\\left(\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0),\\,1\\right).\n\\]\nEs decir, una normal con media desplazada: - Media: \\(\\delta = \\tfrac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\)\n- Varianza: \\(1\\)\n\\[\n\\eta(\\mu) = P_\\mu(\\text{rechazar } H_0)\n= P_\\mu(Z &gt; z_{1-\\alpha}).\n\\]\n\\[\n\\eta(\\mu) = P\\!\\left(Z &gt; z_{1-\\alpha}\\right).\n\\]\nEstandarizando:\n\\[\n\\eta(\\mu) = P\\!\\left(\n\\frac{Z - \\tfrac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)}{1} &gt;\nz_{1-\\alpha} - \\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\n\\right).\n\\] \\[\n  \\eta(\\mu)=1-\\Phi\\!\\left(z_{1-\\alpha}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\right)\n  \\]\nVersión unilateral a la izquierda Para \\(H_0:\\mu\\ge\\mu_0\\) vs \\(H_1:\\mu&lt;\\mu_0\\), el test UMP es:\n\\[\n\\text{Rechazar }H_0 \\text{ si } \\overline{X}_n &lt; \\mu_0 - z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\]\ncon potencia\n\\[\n\\eta(\\mu)=\\Phi\\!\\left(-z_{1-\\alpha}+\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\right)\n\\]\nCaso bilateral El ejemplo plantea \\(H_0:\\mu=\\mu_0\\) vs \\(H_1:\\mu\\neq\\mu_0\\).\n\nNo existe UMP en general para alternativas bilaterales.\n\nSe usa el test más potente imparcial (MPI):\n\\[\n\\text{Rechazar }H_0 \\text{ si } \\left|\\overline{X}_n-\\mu_0\\right|\n\\ge z_{1-\\alpha/2}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\]\n\n\nSu potencia es:\n\\[\n\\eta(\\mu)=1-\\Big[\\Phi\\!\\Big(z_{1-\\alpha/2}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\Big)\n        -\\Phi\\!\\Big(-z_{1-\\alpha/2}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\Big)\\Big]\n\\]\n\n\nIntuición clave - Con RVM, “valores grandes de \\(\\overline{X}_n\\) favorecen \\(\\mu\\) grandes”, por eso la región crítica es de cola y el test es UMP en el caso unilateral.\n- En bilateral no hay un único sentido de “grande”, por eso no existe UMP; el test adecuado es MPI.",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#verosimilitud-y-cociente-de-verosimilitudes",
    "href": "chapter3.html#verosimilitud-y-cociente-de-verosimilitudes",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n5.1 Verosimilitud y cociente de verosimilitudes",
    "text": "5.1 Verosimilitud y cociente de verosimilitudes\nLa verosimilitud de una muestra \\(x=(x_1,\\dots,x_n)\\) es \\[\nL(\\mu\\mid x)=(2\\pi\\sigma^2)^{-n/2}\\exp\\!\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i-\\mu)^2\\right\\}.\n\\]\nEl cociente de verosimilitudes (likelihood ratio) es \\[\n\\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\n=\\exp\\!\\left\\{\\frac{1}{2\\sigma^2}\\sum_{i=1}^n\\Big[(x_i-\\mu_0)^2-(x_i-\\mu_1)^2\\Big]\\right\\}.\n\\]\nNotemos que \\[\n(x_i-\\mu_0)^2-(x_i-\\mu_1)^2\n=2x_i(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2),\n\\] de modo que, al sumar y usar \\(\\bar x=\\tfrac{1}{n}\\sum x_i\\), \\[\n\\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\n=\\exp\\!\\left\\{\\frac{n}{2\\sigma^2}\\Big(2\\bar x(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2)\\Big)\\right\\}.\n\\]\nPor el Lema de Neyman–Pearson, la región crítica óptima (para tamaño dado) es del tipo \\[\nC=\\Big\\{x:\\ \\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\\ge A\\Big\\}\n=\\left\\{x:\\ \\exp\\!\\left\\{\\frac{n}{2\\sigma^2}\\Big(2\\bar x(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2)\\Big)\\right\\}\\ge A\\right\\}.\n\\]\nComo \\(\\mu_1-\\mu_0&gt;0\\), el cociente es función creciente de \\(\\bar x\\). Por tanto, la región crítica puede escribirse como \\[\nC=\\{x:\\ \\bar x\\ge B\\}.\n\\]\nLas constantes \\(A\\) y \\(B\\) se relacionan por \\[\nB=\\frac{\\sigma^2\\log A}{n(\\mu_1-\\mu_0)}+\\frac{\\mu_1+\\mu_0}{2}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#fijar-el-tamaño-alpha-y-obtener-b",
    "href": "chapter3.html#fijar-el-tamaño-alpha-y-obtener-b",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n5.2 Fijar el tamaño \\(\\alpha\\) y obtener \\(B\\)\n",
    "text": "5.2 Fijar el tamaño \\(\\alpha\\) y obtener \\(B\\)\n\nNo es necesario hallar \\(B\\) a partir de \\(A\\). Basta imponer el tamaño deseado: \\[\nP(C\\mid H_0)=P(\\bar X\\ge B\\mid H_0)=\\alpha.\n\\] Bajo \\(H_0\\), \\(\\bar X\\sim N(\\mu_0,\\sigma^2/n)\\), así que \\[\nB=\\mu_0+z_\\alpha\\,\\frac{\\sigma}{\\sqrt{n}},\n\\] donde \\(z_\\alpha\\) satisface \\(P(Z\\ge z_\\alpha)=\\alpha\\) para \\(Z\\sim N(0,1)\\).\nLa regla de decisión equivalente es: \\[\n\\text{Rechazar }H_0\\ \\ \\Longleftrightarrow\\ \\ Z=\\frac{\\bar X-\\mu_0}{\\sigma/\\sqrt{n}}\\ge z_\\alpha.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#ejemplo-numérico",
    "href": "chapter3.html#ejemplo-numérico",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n5.3 Ejemplo numérico",
    "text": "5.3 Ejemplo numérico\nSupongamos \\(\\mu_0=5\\), \\(\\mu_1=6\\), \\(\\sigma^2=1\\) (luego \\(\\sigma=1\\)), \\(\\alpha=0.05\\) y \\(n=4\\).\n\nUmbral crítico para \\(\\bar X\\): \\[\nB=\\mu_0+z_{0.05}\\frac{\\sigma}{\\sqrt{n}}\n=5+1.645\\cdot\\frac{1}{2}\n=5+0.8225\n=5.8225.\n\\]\nRegla equivalente con \\(Z\\): \\[\nZ=\\frac{\\bar X-5}{1/\\sqrt{4}}\n=\\frac{\\bar X-5}{0.5}\n\\ge 1.645.\n\\]\nDatos observados: \\(x=(5.1,\\,5.5,\\,4.9,\\,5.3)\\).\nMedia muestral: \\(\\bar x=\\tfrac{5.1+5.5+4.9+5.3}{4}=5.2\\).\nCálculo del estadístico: \\[\nz=\\frac{\\bar x-5}{1/\\sqrt{4}}=\\frac{5.2-5}{0.5}=0.4&lt;1.645.\n\\]\n\nDecisión: no se rechaza \\(H_0\\) al nivel \\(\\alpha=0.05\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#comentario-final",
    "href": "chapter3.html#comentario-final",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n5.4 Comentario final",
    "text": "5.4 Comentario final\nEste contraste se denomina test Z unilateral porque usa el estadístico \\[\nZ=\\sqrt{n}\\,\\frac{\\bar X-\\mu_0}{\\sigma}\\ \\sim\\ N(0,1)\\ \\ \\text{bajo }H_0.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#definición",
    "href": "chapter3.html#definición",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.7 Definición",
    "text": "4.7 Definición\n\n\nLa función de potencia de un test con región crítica \\(C\\) es:\n\\[\n\\eta(\\theta) = P_\\theta(X \\in C)\n\\]\n\n\nUn test es UMP de tamaño \\(\\alpha\\) para \\(H_0:\\theta \\in \\Theta_0\\) vs \\(H_1:\\theta \\in \\Theta_1\\) si:\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) = \\alpha\n\\]\ny, para cualquier otro test del mismo tamaño con función de potencia \\(\\eta^\\*(\\theta)\\),\n\\[\n\\eta(\\theta) \\geq \\eta^\\*(\\theta), \\quad \\forall \\theta \\in \\Theta_1\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#lectura-intuitiva",
    "href": "chapter3.html#lectura-intuitiva",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.8 Lectura intuitiva",
    "text": "4.8 Lectura intuitiva\n\n\nMismo control de falsos positivos: todos los tests comparados tienen el mismo tamaño \\(\\alpha\\).\n\n\nMejor detección bajo la alternativa: en todo \\(\\Theta_1\\), la probabilidad de rechazar \\(H_0\\) es al menos tan grande como la de cualquier otro test del mismo tamaño.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#observaciones",
    "href": "chapter3.html#observaciones",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.9 Observaciones",
    "text": "4.9 Observaciones\n\nA veces no existe un UMP (por ejemplo, en muchas alternativas bilaterales).\n\nSí existe UMP en varios problemas unilaterales cuando la familia tiene razón de verosimilitudes monótona (teorema de Karlin–Rubin).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#mini-ejemplo-binomial-unilateral",
    "href": "chapter3.html#mini-ejemplo-binomial-unilateral",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.10 Mini-ejemplo (binomial unilateral)",
    "text": "4.10 Mini-ejemplo (binomial unilateral)\n\nModelo: \\(X \\sim \\text{Bin}(n,p)\\).\nContraste: \\(H_0: p \\le p_0\\) vs \\(H_1: p &gt; p_0\\).\n\nRegión crítica de tamaño \\(\\alpha\\): \\(C = \\{x : x \\ge c_\\alpha\\}\\) donde\n\\[\n\\alpha = P_{p_0}(X \\ge c_\\alpha)\n\\]\n\n\nPotencia para cualquier \\(p\\):\n\\[\n\\eta(p) = P_p(X \\ge c_\\alpha) = \\sum_{k=c_\\alpha}^n \\binom{n}{k} p^k (1-p)^{n-k}\n\\]\n\n\nEste test es UMP de tamaño \\(\\alpha\\) para \\(H_1: p &gt; p_0\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#planteamiento",
    "href": "chapter3.html#planteamiento",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.7 Planteamiento",
    "text": "4.7 Planteamiento\n\nMuestra i.i.d. \\(X_1,\\dots,X_n \\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocida.\nEstadístico: \\(\\overline{X}_n\\).\n\nQueremos contrastar, por ejemplo:\n\\[\nH_0:\\ \\mu \\le \\mu_0 \\quad \\text{vs} \\quad H_1:\\ \\mu &gt; \\mu_0\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#verificación-de-las-hipótesis-del-teorema",
    "href": "chapter3.html#verificación-de-las-hipótesis-del-teorema",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.8 Verificación de las hipótesis del teorema",
    "text": "4.8 Verificación de las hipótesis del teorema\n\nSuficiencia: para varianza conocida, \\(\\overline{X}_n\\) es suficiente para \\(\\mu\\).\n\nRazón de verosimilitudes monótona (RVM): la familia \\(\\{N(\\mu,\\sigma^2/n): \\mu \\in \\mathbb{R}\\}\\) posee RVM en \\(\\overline{X}_n\\), porque para \\(\\mu_1&gt;\\mu_0\\) la razón\n\\[\n\\frac{f_{\\mu_1}(\\overline{x})}{f_{\\mu_0}(\\overline{x})}\n\\]\nes creciente en \\(\\overline{x}\\).\n\n\nPor el teorema, existe un test UMP de tamaño \\(\\alpha\\) cuya región crítica es de cola superior.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#test-ump-unilateral-a-la-derecha",
    "href": "chapter3.html#test-ump-unilateral-a-la-derecha",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.9 Test UMP (unilateral a la derecha)",
    "text": "4.9 Test UMP (unilateral a la derecha)\n\n\nBajo \\(\\mu=\\mu_0\\):\n\\[\nZ=\\frac{\\overline{X}_n-\\mu_0}{\\sigma/\\sqrt{n}} \\sim N(0,1)\n\\]\n\n\nEl test UMP de tamaño \\(\\alpha\\) rechaza \\(H_0\\) si:\n\\[\n\\overline{X}_n &gt; \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\quad \\Longleftrightarrow \\quad\nZ &gt; z_{1-\\alpha}\n\\]\n\n\nFunción de potencia:\n\\[\n\\eta(\\mu)=1-\\Phi\\!\\left(z_{1-\\alpha}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\right)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#versión-unilateral-a-la-izquierda",
    "href": "chapter3.html#versión-unilateral-a-la-izquierda",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.10 Versión unilateral a la izquierda",
    "text": "4.10 Versión unilateral a la izquierda\nPara \\(H_0:\\mu\\ge\\mu_0\\) vs \\(H_1:\\mu&lt;\\mu_0\\), el test UMP es:\n\\[\n\\text{Rechazar }H_0 \\text{ si } \\overline{X}_n &lt; \\mu_0 - z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\]\ncon potencia\n\\[\n\\eta(\\mu)=\\Phi\\!\\left(-z_{1-\\alpha}+\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\right)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#caso-bilateral",
    "href": "chapter3.html#caso-bilateral",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.11 Caso bilateral",
    "text": "4.11 Caso bilateral\nEl ejemplo plantea \\(H_0:\\mu=\\mu_0\\) vs \\(H_1:\\mu\\neq\\mu_0\\).\n\nNo existe UMP en general para alternativas bilaterales.\n\nSe usa el test más potente imparcial (MPI):\n\\[\n\\text{Rechazar }H_0 \\text{ si } \\left|\\overline{X}_n-\\mu_0\\right|\n\\ge z_{1-\\alpha/2}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\]\n\n\nSu potencia es:\n\\[\n\\eta(\\mu)=1-\\Big[\\Phi\\!\\Big(z_{1-\\alpha/2}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\Big)\n        -\\Phi\\!\\Big(-z_{1-\\alpha/2}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\Big)\\Big]\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#intuición-clave",
    "href": "chapter3.html#intuición-clave",
    "title": "\n4  Contrastes de hipótesis\n",
    "section": "\n4.12 Intuición clave",
    "text": "4.12 Intuición clave\n\nCon RVM, “valores grandes de \\(\\overline{X}_n\\) favorecen \\(\\mu\\) grandes”, por eso la región crítica es de cola y el test es UMP en el caso unilateral.\n\nEn bilateral no hay un único sentido de “grande”, por eso no existe UMP; el test adecuado es MPI.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Contrastes de hipótesis</span>"
    ]
  }
]