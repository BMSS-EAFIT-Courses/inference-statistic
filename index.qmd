---
# Si quieres un encabezado local, puedes dejarlo as√≠:
# O simplemente eliminar este bloque completamente
---

# INTRODUCCI√ìN
Este libro ha sido concebido como un recurso integral para el estudio riguroso y aplicado de la inferencia estad√≠stica. Est√° dirigido a estudiantes de programas de estad√≠stica, matem√°ticas aplicadas y disciplinas afines, y busca fortalecer la comprensi√≥n conceptual y t√©cnica de los fundamentos que sustentan el an√°lisis estad√≠stico moderno.

A lo largo de sus cap√≠tulos, el lector encontrar√° un desarrollo progresivo de los siguientes temas:

- Fundamentos de la probabilidad y los modelos estad√≠sticos.
- Propiedades de las variables aleatorias y familias param√©tricas comunes.
- Principios clave para la reducci√≥n de datos: suficiencia, completitud y verosimilitud.
- Construcci√≥n y evaluaci√≥n de estimadores puntuales.
- Estimaci√≥n por intervalos y su interpretaci√≥n inferencial.
- Contrastes de hip√≥tesis y principios de optimalidad en pruebas estad√≠sticas.
- Introducci√≥n a la teor√≠a de la decisi√≥n y sus aplicaciones en inferencia.

El material combina el rigor formal con ejemplos y aplicaciones que ilustran c√≥mo los m√©todos estad√≠sticos permiten extraer conclusiones v√°lidas a partir de datos.

> Este libro se encuentra en construcci√≥n. Los cap√≠tulos se ir√°n publicando progresivamente y pueden estar sujetos a revisiones o mejoras. Por ahora, son s√≥lo trozos de contenido de otros libros o notas de clase de una selecci√≥n personal y que se ir√°n referenciando en cada cap√≠tulo.

---

## ¬øC√≥mo navegar este libro?

- Usa el **√≠ndice lateral izquierdo** para acceder a cada cap√≠tulo y subcap√≠tulo.
- Haz uso del **buscador** para encontrar conceptos o t√©rminos clave.
- Revisa los apartados de ‚ÄúLista de problemas‚Äù incluidos al final de cada secci√≥n para practicar.

---

## ¬°Bienvenida/o!

Te invito a recorrer este texto con atenci√≥n, curiosidad y sentido cr√≠tico.  
Espero que este libro te acompa√±e, rete y apoye en tu formaci√≥n como profesional en ciencias de datos o √°reas relacionadas.

<!-- 1. [Datos y modelos](Datos%20y%20modelos.qmd)   -->
<!-- 2. [Variable aleatoria](Variable%20aleatoria.qmd)   -->




# DATOS Y MODELOS

En esta secci√≥n establecemos la base conceptual para el an√°lisis estad√≠stico, diferenciando claramente entre el fen√≥meno aleatorio observado y la medida de probabilidad que lo describe.  

## Fen√≥meno aleatorio y variable observada

> ‚ÄúSe observa una realizaci√≥n de un fen√≥meno aleatorio, digamos X. Este puede ser un elemento aleatorio de varios tipos: n√∫mero (variable aleatoria), un vector de dimensi√≥n finita (vector aleatorio), una funci√≥n, etc.  
> La premisa principal es que el car√°cter aleatorio de X se concibe como una realizaci√≥n de un fen√≥meno aleatorio que tiene una distribuci√≥n de probabilidad P, donde la distribuci√≥n P es desconocida ya sea en su totalidad o en alg√∫n detalle espec√≠fico (por ejemplo, su soporte, su media, etc.). Es de inter√©s conocer P. Si la medida de probabilidad P fuese conocida, entonces no hay problema estad√≠stico propiamente, pues el problema estad√≠stico tiene que ver con _inferir_ la propiedad desconocida de P con base en X.‚Äù [Ver referencia 1]

- **Definici√≥n de X**  
  - **X** puede ser un valor real $X \in \mathbb{R}$, un vector en $\mathbb{R}^n$, o incluso una funci√≥n $\;X: [0,1]\to\mathbb{R}$.  
- **Medida de probabilidad P**  
  - Desconocida: soporte, media, varianza, etc.  
  - Objetivo estad√≠stico: _inferir_ caracter√≠sticas de \(P\) a partir de la muestra (la realizaci√≥n de X).

## Incertidumbre inductiva vs. estoc√°stica

> ‚ÄúLa observaci√≥n **X** est√° dada, por lo que no hay incertidumbre tal como la hay en la teor√≠a de probabilidad desarrollada anteriormente en el curso. Antes, fue concebida una estructura $(\Omega, \mathcal{F}, P)$ para enfrentar el que haya incertidumbre acerca del valor de **X**. En el problema estad√≠stico, el valor de **X** ha sido observado, y la incertidumbre radica en otro punto: radica en que existe duda acerca de cu√°l **P** es la que produjo el valor **X**. En algunas ocasiones se utilizan los t√©rminos _incertidumbre estoc√°stica_ e _incertidumbre inductiva_ para distinguir estos dos tipos. Es com√∫n que estos se confundan entre s√≠, porque en estad√≠stica matem√°tica la teor√≠a de probabilidad constituye tambi√©n una de las maneras naturales de afrontar la cuantificaci√≥n de incertidumbre inductiva. En cualquier caso, el concebir a **P** como medida de probabilidad es la base para formular soluciones a la incertidumbre inductiva. Con este lenguaje, probabilidad y estad√≠stica son problemas diferentes y de cierta manera inversos. Teor√≠a de probabilidad tiene que ver con cuantificar incertidumbre acerca de **X** y teor√≠a estad√≠stica con cuantificar incertidumbre acerca de **P** a la luz de haber ya observado **X**.‚Äù[Ver referencia 1]

- **Incertidumbre estoc√°stica**: duda previa sobre el valor de X, modelada por $(\Omega,\mathcal{F},P)$.  
- **Incertidumbre inductiva**: tras observar X, la incertidumbre se desplaza a la ley generadora P.

---

#### Ejemplos en Matem√°tica Aplicada e Ingenier√≠a de Sistemas

1. **Modelado de tiempos de respuesta en redes**  
   - $X$: tiempo de llegada de paquetes (variable continua).  
   - $P$: distribuci√≥n de retardo desconocida; objetivo: estimar par√°metros de una ley de colas M/M/1.  

2. **Estimaci√≥n de par√°metros en ecuaciones diferenciales estoc√°sticas**  
   - $X(t)$: trayectoria observada de un proceso de It√¥.  
   - $P$: ley del proceso (por ejemplo, coeficientes de difusi√≥n y deriva), inferidos a partir de trayectorias discretas.  

3. **Calibraci√≥n de sensores en sistemas de control**  
   - $X$: lecturas del sensor (vector aleatorio).  
   - $P$: distribuci√≥n conjunta desconocida de ruido; se estima para dise√±ar filtros de Kalman √≥ptimos.  

---

Con esta distinci√≥n clara entre dato observado y modelo probabil√≠stico, estamos listos para construir estimadores y desarrollar la inferencia estad√≠stica en las secciones siguientes. 




# VARIABLE ALEATORIA


## Variables y vectores aleatorios
Consideramos un experimento aleatorio cuyos resultados pertenecen al espacio muestral Œ©. Modelamos este proceso suponiendo que existe una terna $(\Omega, \mathcal{A}, P),$ donde:

- $\Omega$ es el espacio muestra,  
- $\mathcal{P}(\Omega)$ es el conjunto de partes de Œ©,  
- $\mathcal{A}\in\mathcal{P}(\Omega)$ es una œÉ-√°lgebra,  
- $P\colon \mathcal{A} \to [0,1]$ es una medida de probabilidad que refleja las caracter√≠sticas aleatorias del experimento realizado.  

A esta terna se le llama **espacio de probabilidad**.

Los resultados de un experimento aleatorio no son analizados ‚Äúen bruto‚Äù, sino que se les da una representaci√≥n num√©rica que facilita su tratamiento. Esto se logra introduciendo variables aleatorias, que asocian cada resultado $\omega\in \Omega$ con un valor num√©rico o vectorial, y sobre las cuales luego aplicamos t√©cnicas de inferencia estad√≠stica.

En todo estudio estad√≠stico partimos de un **experimento aleatorio** cuyo conjunto de resultados posibles se denomina **espacio muestral** Œ©. Para cuantificar dichos resultados definimos las siguientes estructuras:

**Definici√≥n: Variables Aleatorias**

Sea $(\Omega,\mathcal{A},P)$ un espacio de probabilidad. Una **variable aleatoria** es una funci√≥n $X\colon (\Omega,\mathcal{A})\;\longrightarrow\; (\mathbb{R},\mathcal{B}),$ tal que para todo $B\in\mathcal{B}$ (la $\sigma$-√°lgebra de Borel en ‚Ñù),  $X^{-1}(B)\;=\;\{\omega\in\Omega : X(\omega)\in B\}\;\in\;\mathcal{A}.$

- Si el espacio muestral Œ© es **finito o numerable**, diremos que es un espacio **discreto** y las variables aleatorias asociadas al experimento normalmente estar√°n definidas como $X\colon \Omega \;\longrightarrow\; \mathbb{Z}.$

- Si $\Omega$ es **no numerable**, entonces diremos que es un espacio **continuo** y $X\colon \Omega \;\longrightarrow\; \mathbb{R}.$
---

**Definici√≥n: Vector aleatorio**

Un **vector aleatorio** de dimensi√≥n $n$ es $\mathbf{X} = (X_1,\dots,X_n)\colon(\Omega,\mathcal{A})\longrightarrow(\mathbb{R}^n,\mathcal{B}^n),$ donde cada componente $X_i$ es variable aleatoria y $\mathcal{B}^n$ la $\sigma$-√°lgebra de Borel en ‚Ñù‚Åø.

---

**Ejemplos**
  **Lanzamiento de dos monedas**

Sea $\Omega =\{\,CC,\;C-,\;-C,\;--\},$ donde $C$ = ‚Äúcara‚Äù y $-$ = ‚Äúcruz‚Äù. Podemos definir:  
$X_1(\omega) = \text{n√∫mero de caras en }\omega.$
$X_2(\omega) = 2 - X_1(\omega)\;=\; \text{n√∫mero de cruces}.$
$X_3(\omega) = \bigl(X_1(\omega)\bigr)^2.$

Entonces $(X_1,X_2,X_3)$ es un vector aleatorio de dimensi√≥n 3.

 **Tiempos de servicio en un servidor**

Sean $T_i$ los tiempos de servicio (en segundos) de las peticiones $i=1,2,3$. Definimos  
$\mathbf{T}=(T_1,T_2,T_3),\quad S = T_1 + T_2 + T_3,\quad M = \max\{T_1,T_2,T_3\}.$

  **Lecturas de sensores en red distribuida**

En tres nodos $i=1,2,3$ medimos temperatura $X_{i,1}$, presi√≥n $X_{i,2}$ y humedad $X_{i,3}$. El vector global es $\mathbf{X} = (X_{1,1},X_{1,2},X_{1,3},\,X_{2,1},\dots,X_{3,3}) \in \mathbb{R}^9.$

---

Con estas definiciones rigurosas disponemos ya de los objetos b√°sicos para, en las siguientes secciones, construir estimadores, estudiar su comportamiento asint√≥tico y contrastar hip√≥tesis sobre la distribuci√≥n subyacente $P$.


## Distribuci√≥n de una variable aleatoria. Funciones de distribuci√≥n, de probabilidad y de densidad
  
  **Distribuci√≥n de una Variable Aleatoria**

La realizaci√≥n de un experimento aleatorio da lugar a un resultado $\omega\in\Omega$ que es aleatorio. Por lo tanto, $X(\omega)$ es un valor de $\mathbb{R}$ tambi√©n aleatorio. Es decir, la variable aleatoria $X$ induce una medida de probabilidad en $\mathbb{R}$. A esa medida de probabilidad se le llama **distribuci√≥n de $X$** o **ley de $X$**. Una de las formas de caracterizar la distribuci√≥n de una variable aleatoria es dar su funci√≥n de distribuci√≥n $F_X$, que est√° definida as√≠:

$F_X(x) \;=\; P(X \le x)\;=\; P\bigl(\{\omega \in \Omega : X(\omega) \le x\}\bigr)\;=\; P\bigl(X^{-1}((-\infty, x])\bigr).$$

En el caso de que $X$ sea una **variable aleatoria discreta**, es decir, en el caso de que $X$ solo tome una cantidad finita o numerable de valores de $\mathbb{R}$, su distribuci√≥n tambi√©n puede caracterizarse por su **funci√≥n de probabilidad** (o **funci√≥n de masa de probabilidad**) $f_X$, definida como

$$f_X : \mathbb{R} \longrightarrow [0,1],\qquad f_X(x) = P(X = x).$$

Esa funci√≥n solo es no nula en un conjunto finito o numerable. Supondremos en adelante, sin p√©rdida de generalidad, que ese conjunto est√° contenido en $\mathbb{Z}$.
A partir de la funci√≥n de masa de probabilidad se puede calcular la probabilidad 
de que la variable aleatoria $X$ tome valores en cualquier elemento $A \subseteq \mathbb{B}$:

$P(X \in A) = \sum_{x \in A} f_X(x).$
me


La funci√≥n de distribuci√≥n y la funci√≥n de masa de probabilidad se relacionan 
de la siguiente forma:

$F_X(x) = \sum_{u \leq x} f_X(u), \quad f_X(x) = F_X(x) - F_X(x^-),$ donde $F_X(x^-) = \lim_{h \to 0^+} F_X(x - h)$.

Una clase relevante de variables aleatorias no discretas son las que poseen **funci√≥n de densidad**, es decir, aquellas cuya distribuci√≥n de probabilidad puede caracterizarse por una funci√≥n $f_X(x) \geq 0$ que cumple que:

$P(X \in A) = \int_{x \in A} f_X(x) \, dx, \quad \text{para todo } A \subseteq \mathbb{B}.$

La relaci√≥n entre $F_X$ y $f_X$ es la siguiente:

$F_X(x) = \int_{-\infty}^{x} f_X(u) \, du, \quad f_X(x) = \frac{d}{dx} F_X(x),$

salvo quiz√°s en un n√∫mero finito de puntos $x \in \mathbb{R}$. Las variables aleatorias que poseen funci√≥n de densidad se llaman **variables aleatorias absolutamente continuas**. Abusando del lenguaje, aqu√≠ nos referiremos a ellas como variables aleatorias continuas.



## Esperanza y varianza
Si se desea describir totalmente la distribuci√≥n de probabilidad de una variable aleatoria $X$ acabamos de ver que podemos dar su funci√≥n de distribuci√≥n o su funci√≥n de masa o de densidad, seg√∫n el caso. Una descripci√≥n parcial puede efectuarse calculando algunas caracter√≠sticas de la variable aleatoria $X$, como por ejemplo medidas de posici√≥n o de dispersi√≥n. Estudiaremos algunas de ellas.

Se define la **esperanza** de una variable aleatoria $X$ como la integral de Lebesgue de $X$:

$E(X) = \int_{\Omega} X(w) dP(w).$

En el caso de variables aleatorias discretas la esperanza puede calcularse como:

$E(X) = \sum_{w \in \Omega} X(w) P(w) = \sum_{k \in \mathbb{Z}} k P(X = k) = \sum_{k \in \mathbb{Z}} k f_X(k).$

Por otro lado, la esperanza de una variable aleatoria continua se puede calcular as√≠:

$E(X) = \int_{\mathbb{R}} x f_X(x) dx.$

La esperanza de una variable aleatoria $X$ es una medida de posici√≥n de $X$: es el centro de gravedad de la distribuci√≥n de probabilidad de $X$.

Si $h$ es una funci√≥n medible $h : \mathbb{R} \rightarrow \mathbb{R}$, entonces $Y = h(X)$ es tambi√©n variable aleatoria y su esperanza se puede calcular a partir de la distribuci√≥n de $X$:

$E(h(X)) = \int_{\Omega} h(X(w)) dP(w)$ que en el caso de que $X$ sea discreta puede reescribirse como

$E(h(X)) = \sum_{k \in \mathbb{Z}} h(k) f_X(k).$

Si $X$ es una variable aleatoria continua entonces

$E(h(X)) = \int_{\mathbb{R}} h(x) f_X(x) dx.$

Si existe $\mu = E(X)$ y es finita puede definirse una medida de dispersi√≥n de la variable aleatoria $X$ a partir de una transformaci√≥n $h$ de $X$. Es lo que se denomina **varianza** de $X$ y se define as√≠:

$V(X) = E((X - \mu)^2) = E(X^2) - \mu^2 = E(X^2) - (E(X))^2.$

## Funci√≥n generadora de momentos 
Dada una variable aleatoria $X$, o su funci√≥n de distribuci√≥n $F$, vamos a definir otra funci√≥n generadora, como

$M_X(t) = \mathbb{E}(e^{tX}),$ siempre que este valor esperado exista.

Notemos que cuando $X$ toma valores en los enteros no-negativos, $M_X(t) = \phi_X(e^t)$, donde $\phi_X(s)=E[s^X]=\sum_{k=0}^{\infty}p_ks^k$ para $s\in[0,1]$ es la funci√≥n generadora de probabilidad (f.g.p.) de la variable $X$, con $p_k=P(X=k)$. Si $X$ est√° acotada, $M_X$ est√° bien definida para todo $t$ real; en cambio, si $X$ no est√° acotada, es posible que el dominio de $M_X$ no sea el conjunto de todos los reales. En todo caso, $\phi$ siempre est√° definida en cero, y $M(0) = 1$.

Es posible demostrar que si la f.g.m. de la v.a. $X$ existe en un entorno de 0, entonces para todo $k > 0$,

$\mathbb{E}[|X|^k] < \infty.$

M√°s a√∫n, la serie

$M_X(t) = 
\mathbb{E}(e^{tX}) 
= \mathbb{E}\left(1 + \sum_{k=1}^{\infty} \frac{t^k X^k}{k!}\right) 
= 1 + \sum_{n=1}^{\infty} \frac{t^k}{k!} \mathbb{E}(X^k)
\tag{5.1}$

es convergente y se puede derivar t√©rmino a t√©rmino. Obtenemos

$M'_X(0) = \mathbb{E}(X); \quad M''_X(0) = \mathbb{E}(X^2)$

y en general

$M_X^{(k)}(0) = \mathbb{E}(X^k).$

Es por esta √∫ltima propiedad que esta funci√≥n se conoce como **funci√≥n generadora de momentos** (f.g.m.).

üé≤ Ejemplo: f.g.m. de la distribuci√≥n Binomial

Sea $X \sim \text{Binomial}(n, p)$, es decir, la suma de $n$ ensayos de Bernoulli con probabilidad de √©xito $p$. La funci√≥n generadora de momentos es: [Ejemplo fgm binomial](https://github.com/BMSS-EAFIT-Courses/inference-statistic/blob/main/mgf_binomial.r)

$M_X(t) = \mathbb{E}[e^{tX}] = (1 - p + p e^t)^n$

<pre> ```r #
mgf_binomial <- function(t, n = 10, p = 0.3) {
  (1 - p + p * exp(t))^n
}

t_vals <- seq(-3, 3, length.out = 300)
mgf_vals <- sapply(t_vals, mgf_binomial)

plot(t_vals, mgf_vals, type = "l", lwd = 2,
     main = expression("F.G.M. para X ~ Binomial(10, 0.3)"),
     xlab = "t", ylab = expression(M[X](t)))
grid()
``` </pre>
üìà Ejemplo: f.g.m. de la distribuci√≥n Normal Est√°ndar

Sea $X \sim \mathcal{N}(0, 1)$. Su funci√≥n generadora de momentos es:

$M_X(t) = \mathbb{E}[e^{tX}] = e^{\frac{t^2}{2}}$

Esta expresi√≥n se obtiene usando la forma cerrada del momento de una normal est√°ndar.
<pre> ```r #
mgf_normal <- function(t) {
  exp(t^2 / 2)
}

t_vals <- seq(-3, 3, length.out = 300)
mgf_vals <- sapply(t_vals, mgf_normal)

plot(t_vals, mgf_vals, type = "l", lwd = 2,
     main = expression("F.G.M. para X ~ N(0, 1)"),
     xlab = "t", ylab = expression(M[X](t)))
grid()
``` </pre>

 **‚ùì Preguntas gu√≠a sobre la gr√°fica de la funci√≥n generadora de momentos**

  **üìå ¬øQu√© representa la gr√°fica de la f.g.m. $M_X(t)$?**

La gr√°fica muestra c√≥mo evoluciona el valor esperado de $e^{tX}$ cuando $t$ var√≠a. Esta funci√≥n codifica **todos los momentos de la variable aleatoria** $X$, y por tanto, contiene informaci√≥n completa sobre su distribuci√≥n (si existe un entorno donde la f.g.m. es finita).

---

  **üß≠ ¬øQu√© se observa en la f.g.m. de una distribuci√≥n Binomial?**
<img width="480" height="480" alt="mgf_binomial" src="https://github.com/user-attachments/assets/8524edee-0b5c-4938-a9e8-8af0e8c5840c" />

![Gr√°fica MGF Binomial]

  #Preguntas y respuestas

- **¬øC√≥mo es el comportamiento de la f.g.m. cerca de $t = 0$?**

  En $t = 0$, siempre se cumple que $M_X(0) = 1$, ya que:

  $M_X(0) = \mathbb{E}[e^{0 \cdot X}] = \mathbb{E}[1] = 1$

- **¬øQu√© indica la curvatura de la gr√°fica?**

   La curvatura refleja el crecimiento exponencial de los momentos. Si la curva crece r√°pidamente hacia la derecha, significa que los momentos (media, varianza, etc.) tambi√©n crecen con rapidez.

- **¬øPor qu√© la gr√°fica es convexa?**

  Todas las funciones generadoras de momentos son **estrictamente convexas** en el intervalo donde est√°n definidas. Esto es una consecuencia de que derivadas sucesivas representan momentos positivos.

- **¬øQu√© pasa si cambio los par√°metros $n$ y $p$?**

  Aumentar $ n $ o $p$ tiende a **elevar** la f.g.m. en el lado derecho, reflejando una mayor media y varianza.

---

  **üìà ¬øC√≥mo se comporta la f.g.m. para la Normal Est√°ndar?**
<img width="480" height="480" alt="mgf_normal" src="https://github.com/user-attachments/assets/e877129d-4235-42d9-baff-7f29d3afc4a7" />

![Gr√°fica MGF Normal]

  **Preguntas y respuestas**

- **¬øPor qu√© es sim√©trica respecto al eje $ t = 0 $?**

  Porque la normal est√°ndar es sim√©trica alrededor de su media $ \mu = 0 $, y su f.g.m. tiene la forma:

 $M_X(t) = e^{t^2 / 2}$

  lo cual es una funci√≥n par: $M_X(-t)= M_X(t)$.

- **¬øQu√© tan r√°pido crece la funci√≥n?**

  Muy r√°pido. El crecimiento es exponencial cuadr√°tico. Esto implica que los momentos de la normal crecen r√°pidamente en magnitud.

- **¬øC√≥mo se relaciona esta gr√°fica con los momentos de la normal?**

  Derivando sucesivamente la f.g.m. en $ t = 0 $, se obtiene:

  $\mathbb{E}[X^k] = M_X^{(k)}(0)$

  Por tanto, la gr√°fica "encierra" toda la informaci√≥n sobre los momentos.

---

  **üß† Conclusi√≥n**

Estas gr√°ficas te permiten **visualizar la informaci√≥n estad√≠stica codificada en una variable aleatoria**. La f.g.m. no es solo una herramienta algebraica para obtener momentos, sino una forma poderosa de describir el comportamiento global de la variable.

> **¬øQu√© pasa si dos variables tienen la misma f.g.m.?**  
> ¬°Tienen la misma distribuci√≥n! (si la f.g.m. est√° definida en un entorno de 0).

  **Ejemplo: Distribuci√≥n uniforme $U(a,b)$**

Si 
$$X \sim U(a,b),$$  
su densidad es  
$$f(x) = \frac{1}{b - a}\quad\text{para }a < x < b,$$  
y su funci√≥n generadora de momentos viene dada por 

<a id="eq:5.2"></a> 
<table align="center">
  <tr>
    <td align="center">
$$M(t)= \int_a^b \frac{e^{t x}}{b - a}\,dx= \frac{e^{b t} - e^{a t}}{t\,(b - a)}.$$  
    </td>
    <td valign="bottom">
      (5.2)
    </td>
  </tr>
</table>

En el caso particular de la distribuci√≥n uniforme en $(0,1)$ se obtiene  
$$M(t) = \frac{e^t - 1}{t}.$$

---

Para derivar la f√≥rmula [#(5.2)](#eq:5.2) y obtener los momentos, podemos usar el desarrollo en serie de la funci√≥n exponencial:

$$M(t)= \frac{1}{t\,(b - a)}\bigl(e^{b t} - e^{a t}\bigr) \\
= \frac{1}{t\,(b - a)}\Bigl[\bigl(1 + \sum_{n=1}^\infty \tfrac{(b t)^n}{n!}\bigr)
                    -\bigl(1 + \sum_{n=1}^\infty \tfrac{(a t)^n}{n!}\bigr)\Bigr] \\
= \frac{1}{b - a}\sum_{n=1}^\infty \frac{b^n - a^n}{n!}\,t^{n-1}.
$$

Este es el desarrollo de Maclaurin de $M(t)$ en $t=0$; por tanto, sus derivadas en cero satisfacen

<table align="center">
  <tr>
    <td align="center">
$$M^{(k)}(0)= \frac{b^{k+1} - a^{k+1}}{(k+1)\,(b - a)}.$$
    </td>
    <td valign="bottom">
      (5.3)
    </td>
  </tr>
</table>
En particular:

-  $$M'(0)= \frac{b^2 - a^2}{2\,(b - a)}= \frac{a + b}{2},$$
  que coincide con $\mathbb{E}(X)$.

-  $$M''(0)= \frac{b^3 - a^3}{3\,(b - a)}= \frac{a^2 + a b + b^2}{3},$$

y un c√°lculo directo muestra que la varianza es

$$\mathrm{Var}(X)= \mathbb{E}(X^2) - \bigl(\mathbb{E}(X)\bigr)^2= \frac{(a + b)^2}{12}.$$

  **Observaci√≥n importante** 
Sea $X$ una v.a. con f.g.m. $M_X$ y sea $Y=aX+b$ una transformaci√≥n lineal de $X$, entonces

$$M_Y(t)=E(e^{tY})=E(e^{t(aX+b)})=E(e^{taX}e^{tb})=e^{tb}E(e^{taX})=e^{tb}M_X(at)$$



  **Teorema (fgm de suma de v.a.s)**

Si $X$ tiene funci√≥n generadora de momentos $M(t)$ que est√° definida en un entorno $(-a,a)$ de 0, entonces $M(t)$ caracteriza a la distribuci√≥n de $X$; es decir, si otra variable $Y$ tiene la misma funci√≥n generadora de momentos, las distribuciones de $X$ e $Y$ coinciden.

---

Si $X,Y$ son variables aleatorias con funciones generadoras de momentos respectivas $M_X$ y $M_Y$ que existen en un dominio com√∫n $|t| < d$, entonces la f.g.m. de la suma $X+Y$ est√° dada por
<a id="eq:5.5"></a> 
<table align="center">
  <tr>
    <td align="center">
$$M_{X+Y}(t)= \mathbb{E}\bigl[e^{t(X+Y)}\bigr]= \mathbb{E}\bigl[e^{tX}\,e^{tY}\bigr]=\mathbb{E}\bigl[e^{tX}\bigr]\;\mathbb{E}\bigl[e^{tY}\bigr]= M_X(t)\,M_Y(t).
\tag{5.5}
$$
  </td>
    <td valign="bottom">
      (5.5)
    </td>
  </tr>
</table>

Este resultado se extiende a la suma de $n$ variables aleatorias independientes. Si

$$S_n = X_1 + \cdots + X_n,$$

entonces

$$M_{S_n}(t)= \mathbb{E}\bigl[e^{tS_n}\bigr]= \mathbb{E}\Bigl[e^{t\sum_{i=1}^n X_i}\Bigr]= \prod_{i=1}^n\mathbb{E}\bigl[e^{tX_i}\bigr]= \prod_{i=1}^n M_{X_i}(t).$$

La funci√≥n generadora de momentos resulta particularmente √∫til cuando consideramos sucesiones de variables aleatorias, como lo muestra el siguiente teorema que enunciamos sin demostraci√≥n:

---

  **Teorema (de Continuidad)**

Sea $F_n(x)$, $n\ge1$, una sucesi√≥n de funciones de distribuci√≥n con funciones generadoras de momentos respectivas $M_n(t)$, definidas en $|t|<b$. Supongamos que cuando $n\to\infty$,

$$
M_n(t)\,\longrightarrow\,M(t)
\quad\text{para }|t|\le a,
$$

donde $M(t)$ es la funci√≥n generadora de momentos de la distribuci√≥n l√≠mite $F(x)$. Entonces

$$
F_n(x)\,\longrightarrow\,F(x)
\quad\text{cuando }n\to\infty
$$

para todo punto $x$ en el cual $F$ es continua.

  **Teorema de Laplace‚ÄìMoivre**

Sea $X_1, X_2, \ldots, X_n$ una sucesi√≥n de variables aleatorias **i.i.d.** con distribuci√≥n \( \text{Bernoulli}(p) \), donde \( 0 < p < 1 \). Sea:

$$
S_n = X_1 + X_2 + \cdots + X_n \sim \text{Binomial}(n, p)
$$

y consideremos la variable tipificada:

$$
Z_n = \frac{S_n - np}{\sqrt{np(1 - p)}}
$$

Entonces, cuando \( n \to \infty \), se tiene convergencia en distribuci√≥n a una normal est√°ndar:

$$
Z_n \xrightarrow{d} \mathcal{N}(0, 1)
$$

es decir,

$$
\lim_{n \to \infty} \mathbb{P}(Z_n \leq z) = \Phi(z), \quad \text{para todo } z \in \mathbb{R}
$$

donde \( \Phi(z) \) es la funci√≥n de distribuci√≥n acumulada de la normal est√°ndar.

---

  **Demostraci√≥n usando funciones generadoras de momentos**

La funci√≥n generadora de momentos (mgf) de $S_n \sim \text{Binomial}(n, p)$ es:

$$
M_{S_n}(t) = \left(1 - p + p e^t\right)^n
$$

Queremos obtener la mgf de la variable tipificada \( Z_n \). Usamos la propiedad de cambio de variable de la mgf:

$$
M_{Z_n}(t) = \mathbb{E}\left[ e^{t Z_n} \right]
= \mathbb{E}\left[ e^{t \cdot \frac{S_n - np}{\sqrt{np(1 - p)}}} \right]
= e^{-t \cdot \frac{np}{\sqrt{np(1 - p)}}} \cdot M_{S_n}\left( \frac{t}{\sqrt{np(1 - p)}} \right)
$$

Sustituimos la mgf de \( S_n \):

$$
M_{Z_n}(t) = \exp\left( -t \cdot \frac{np}{\sqrt{np(1 - p)}} \right)
\cdot \left( 1 - p + p e^{t / \sqrt{np(1 - p)}} \right)^n
$$

---

  **Aproximaci√≥n por series de Taylor**

Expandimos  $e^{t / \sqrt{np(1 - p)}}$ para $n$ grande:

$$
e^{t / \sqrt{np(1 - p)}} = 1 + \frac{t}{\sqrt{np(1 - p)}} + \frac{t^2}{2np(1 - p)} + \cdots
$$

Entonces:

$$
1 - p + p e^{t / \sqrt{np(1 - p)}} \approx 1 + \frac{pt}{\sqrt{np(1 - p)}} + \frac{pt^2}{2np(1 - p)} + \cdots
$$

Usamos que $\log(1 + x) \approx x - \frac{x^2}{2} + \cdots$ para $x \approx 0$:

$$\log M_{Z_n}(t) \approx -t \cdot \frac{np}{\sqrt{np(1 - p)}}+ n \left( \frac{pt}{\sqrt{np(1 - p)}} + \frac{pt^2}{2np(1 - p)} \right)$$

Simplificamos:

- El t√©rmino lineal se cancela:

$$
-t \cdot \frac{np}{\sqrt{np(1 - p)}} + n \cdot \frac{pt}{\sqrt{np(1 - p)}} = 0
$$

- Queda:

$$
\log M_{Z_n}(t) \to \frac{t^2}{2}, \quad \text{cuando } n \to \infty
$$

Por tanto:

$$
M_{Z_n}(t) \to e^{t^2 / 2}
$$

---

  **Conclusi√≥n**

Como $e^{t^2/2}$ es la mgf de $\mathcal{N}(0, 1)$, y por el teorema de unicidad de la funci√≥n generadora de momentos:

$$
Z_n \xrightarrow{d} \mathcal{N}(0, 1)
$$

Esto concluye la demostraci√≥n del **Teorema de Laplace‚ÄìMoivre** utilizando funciones generadoras de momentos.


## Muestra aleatoria simple

Sea $\underset{\sim}{X} =(X_1 ,..., X_n)$ un vector aleatorio. Se dice que sus componentes $X_1 ,..., X_n$ son \textcolor{red}{independientes} si $P(X_1\leq x_1 ,..., X_n\leq x_n)=P(X_1\leq x_1)...P(X_n\leq x_n)$ para cualesquiera valores $x_1,..., x_n$ .
	
Si adem√°s la distribuci√≥n de las $n$ variables aleatorias $X_i$ es la misma, se dice que $X_1 ,...,X_n$ son variables aleatorias **independientes e id√©nticamente distribuidas**, o bien que son v.a.i.i.d o simplemente i.i.d.
	
Si $\underset{\sim}{X} =(X_1 ,..., X_n)$ y $X_1 ,..., X_n$ son i.i.d. con funci√≥n de densidad (en su caso, de masa) $f_X$ , la distribuci√≥n conjunta de $\underset{\sim}{X}$ viene dada por la funci√≥n de densidad (en su caso, de masa) conjunta
$$
\begin{align*}
f_{\underset{\sim}{X}}(\underset{\sim}{x})&=f_{(X_1 ,..., X_n)}(x_1 ,..., x_n)\\
&=f_{(X_1)}(x_1)...f_{(X_n)}(x_n)\\
&=\prod_{i=1}^{n}f_{(X_i)}(x_i)
\end{align*}
$$

A un vector $\underset{\sim}{X} =(X_1 ,..., X_n)$ de v.a.i.i.d. con distribuci√≥n igual a la de la variable aleatoria $X$ se le denomina tambi√©n **muestra aleatoria simple** de $X$ (m.a.s de $X$).

Esto responde al hecho siguiente. Supongamos que se desea estudiar la caracter√≠stica $X$ de los individuos de una poblaci√≥n de tama√±o infinito. Definimos el experimento consistente en elegir aleatoriamente un individuo de la poblaci√≥n y llamamos $X$ al valor de la caracter√≠stica de inter√©s en ese individuo. X es una variable aleatoria.


Si definimos un nuevo experimento consistente en elegir una muestra aleatoria de n individuos y se anota $X_i$, el valor de la caracter√≠stica en el individuo i-√©simo, entonces **X** $=(X_1 ,..., X_n)$ es una colecci√≥n de n v.a.i.i.d. con distribuci√≥n igual a la de la variable aleatoria $X$, es decir, $X_1 ,..., X_n$ es una m.a.s. de X.

## Modelo param√©trico
Usualmente la ley de probabilidad de una variable aleatoria se supone perteneciente a un modelo matem√°tico que depende s√≥lo de un n√∫mero finito de par√°metros:
	$f_X \in\{f(x|\theta):\theta \in \Theta \subseteq \mathbb{R}^k\}$.
	Escribiremos alternativamente $f(x;\theta)$, $f(x|\theta)$ o $f_\theta(x)$.

**Definici√≥n**
		El conjunto de distribuciones dadas por $f_\theta(x)$, $\theta \in \Theta$ se llama familia param√©trica de distribuciones. $\Theta$ es el conjunto de par√°metros.
	

**Definici√≥n**
	La correspondiente distribuci√≥n conjunta de una muestra aleatoria simple de $X$ viene dada por la funci√≥n de densidad (o funci√≥n de masa de probabilidad, seg√∫n el caso)

$$
f_{\underset{\sim}{X}}(\underset{\sim}{x} \mid \theta) = \prod_{i=1}^{n} f_{\theta}(x_i)
$$

A esta funci√≥n la llamaremos **funci√≥n de verosimilitud** de la muestra $X_{\sim}$. Utilizaremos este t√©rmino para referirnos indistintamente a la funci√≥n de densidad conjunta (si las variables aleatorias son continuas) o a la funci√≥n de masa conjunta (si son discretas).
	

## Sumas de variables aleatorias
Cuando se obtiene una muestra aleatoria simple $X_{1},X_{2},\ldots,X_{n}$ normalmente se calculan a partir de ellas cantidades que resumen los valores observados. Cualquiera de estos res√∫menes se puede expresar como una funci√≥n $T(x_1,\ldots,x_n)$ definida en el espacio $\mathcal{X}^n\subseteq\mathbb{R}^n$ donde est√°n las im√°genes del vector $(X_{1},X_{2},\ldots,X_{n})$.

Esta funci√≥n $T$ puede devolver valores de $\mathbb{R}$, $\mathbb{R}^2$ o, en general, $\mathbb{R}^k$.

$$T(X_1 , \ldots, X_n)=\sum_{i=1}^{n}X_i,\bar{X},\bar{X}+3, \min{X_1 , \ldots, X_n},$$ 
$$T(X_1 , \ldots, X_n)=\left(\sum_{i=1}^{n}X_i,\sum_{i=1}^{n}(X_i-\bar{X})^2\right),$$
$$T(X_1 , \ldots, X_n)=\left(\min\{X_1 , \ldots, X_n\},\sum_{i=1}^{n}X_i,\sum_{i=1}^{n}(X_i-\bar{X})^2\right),$$
$$T(X_1 , \ldots, X_n)= (X_1 , \ldots, X_n)$$


**Definici√≥n de estad√≠sticos:** Las funciones $T$ que dependen de una muestra aleatoria simple $X_1 , \ldots, X_n$ se llaman **estad√≠sticos**. Dependen de los valores observados, pero no de los
	par√°metros desconocidos que determinan la distribuci√≥n de $X_i$ . 	

Cuando un estad√≠stico $T$ es utilizado con el prop√≥sito de estimar un par√°metro $\theta$ diremos que $T$ es un estimador de $\theta$.	

**Ejemplo de estad√≠stico**

$T(X_1 , \ldots, X_n)=\bar{X}$ es un estimador de $E(X)=\mu$.

En inferencia estad√≠stica interesa saber qu√© estad√≠sticos son suficientes para recoger toda la informaci√≥n que la muestra aporta sobre la distribuci√≥n de la variable aleatoria X muestreada. La respuesta depende de la distribuci√≥n de X.

**Definici√≥n distribuci√≥n en el muestreo:** Dado que $\underset{\sim}{X} =(X_1 ,..., X_n)$ es una variable aleatoria, se tiene que $Y=T(\underset{\sim}{X})=T(X_1 ,..., X_n)$ ser√° tambi√©n una variable aleatoria. La ley de probabilidad de $Y$ se denomina **distribuci√≥n en el muestreo de $Y$** (o distribuci√≥n muestral). Los siguientes resultados dan informaci√≥n sobre algunas caracter√≠sticas de estad√≠sticos definidos a partir de sumas de variables aleatorias.

## Estad√≠sticos definidos a partir de sumas de variables aleatorias

**Teorema** Sean $X_1,\ldots, X_n$,n n√∫meros reales, sea $\bar{x} = \frac{1}{n} \sum_{i=1}^{n}x_i$ su media aritm√©tica y sea $S_n^2=\frac{\sum_{i=1}^{n}(x_i-\bar{x})^2}{n-1}$ su varianza muestral.

- $\min_a\sum_{i=1}^{n}(x_i-a)^2=\sum_{i=1}^{n}(x_i-\bar{x})^2$
- $(n-1)S_n^2=\sum_{i=1}^{n}(x_i-\bar{x})^2=\sum_{i=1}^{n}x_i^2-n\bar{x}^2$

**Lema** Sea $X_1,\ldots, X_n$ una muestra aleatoria simple de $X$ y sea $g(x)$ una funci√≥n tal que $E(g(X))$ y $Var(g(X))$ existen. Entonces,

- $E(\sum_{i=1}^{n}g(X_i))=nE(g(X))$,
- $Var(\sum_{i=1}^{n}g(X_i))=nVar(g(X))$.

Para la demostraci√≥n ver G√≥mez et al. (2006)

**Teorema** Sea $X 1,\ldots, X_n$ una muestra aleatoria simple de una poblaci√≥n $X$ con esperanza $\mu$ y varianza $\sigma^2 < \infty$. Sean
$$
		\begin{align*}
		&\bar{X}=\frac{1}{n}\sum_{i=1}^{n}X_i,\ \
		S^2=\frac{\sum_{i=1}^{n}(X_i-\bar{X})^2}{n-1},
		\end{align*}	
$$
la media y la varianza muestrales, respectivamente. Entonces,

a. $E(\bar{X}) = \mu,$
b. $Var(\bar{X}) = \frac{\sigma^2}{n},$
c. $E(S^2) = \sigma^2$.


**Teorema** Sea $X 1,\ldots, X_n$ una muestra aleatoria simple de una poblaci√≥n $X$ con funci√≥n generadora de momentos $M_X(t)$. La funci√≥n generatriz de momentos de $X$ es
$$\begin{align*}
		&M_{\bar{X}}(t)=\left(M_X\left(\frac{t}{n}\right)\right)^n
		\end{align*}
$$
::: {.theorem #teo6-3}
**Teorema (Combinaci√≥n lineal de normales es normal)**  (Wackerly et al. (2008))
Sean $Y_1,\,Y_2,\cdots,\,Y_n$  variables aleatorias independientes normalmente distribuidas $E(Y_i)=\mu_i$ y $V(Y_i)=\sigma_i^2$ara $i=1,\cdots,\,n$ y sean $a_1,\,a_2,\cdots,\,a_n$ constantes. Si $$U=\sum_{i=1}^na_iY_i$$

entonces $U$ es una variable aleatoria normalmente distribuida con
	$$E(U)=\sum_{i=1}^na_i\mu_i$$
	y 
	$$V(U)=\sum_{i=1}^na_i^2\sigma^2_i$$
:::

**Ejemplo** $X 1,\ldots, X_n$ m.a.s. de $X \sim N(\mu,\sigma^2)$. Entonces, $M_{X}(t)=\exp\left\{\mu t+ \frac{\sigma^2t^2}{2}\right\}$. De ah√≠ que 

$$
	\begin{align*}
	M_{\bar{X}}(t)
	&=\left(\exp\left\{\mu \frac{t}{n}+ \frac{\sigma^2\left(\frac{t}{n}\right)^2}{2}\right\}\right)^n
	\end{align*}
$$


$X 1,\ldots, X_n$ m.a.s. de $X \sim N(\mu,\sigma^2)$. Entonces, $M_{X}(t)=\exp\left\{\mu t+ \frac{\sigma^2t^2}{2}\right\}$. De ah√≠ que 
$$
		\begin{align*}
		M_{\bar{X}}(t)&=\exp\left\{\mu t+ \frac{\sigma^2t^2}{2n}\right\}
		\end{align*}
$$
De ah√≠ que $\bar{X}\sim N(\mu,\frac{\sigma^2}{n})$.

## Muestreo de una distribuci√≥n normal

### Definici√≥n de distribuci√≥n Chi cuadrada

::: {.theorem #def-4.10}
**Definici√≥n** (Wackerly et al. (2008)) 
Sea $\nu$ un entero positivo. Se dice que una v.a $Y$ tiene distribuci\'on **chi cuadrada con $\nu$ grados de libertad** si y s√≥lo si $Y$ es una vriable aleatoria con distribuci√≥n gamma y par√°metros $\alpha=\nu/2$ y $\beta=2$.
:::

::: {.theorem #teo-Fisher}
**Teorema de Fisher** En el resto del tema supondremos que $X 1,\ldots, X_n$ m.a.s. de una $N(\mu, \sigma^2)$.

a. $\bar{X}$ y $S_n^2$ son variables aleatorias independientes.
b. $\bar{X}\sim N(\mu, \frac{\sigma^2}{n})$
c. $\frac{(n-1)S_n^2}{\sigma^2}\sim \mathcal{X}^2_{n-1}.$
:::

### Distribuciones asociadas a la normal

::: {.theorem #teo6-4}
**Teorema** (Wackerly et al. (2008)) Sean $Y_1,\,Y_2,\cdots,\,Y_n$ definidas como en el Teorema 6.3 de \cite{Wackerly} y definimos $Z_i$ por 
	$$Z_i=\frac{Y_i-\mu_i}{\sigma_i}$$
	con $i=1,\,2,\cdots,\,n$. Entonces $\sum_{i=1}^nZ_i^2$ tiene distribuici\'on $\chi^2$ con $n$ grados de libertad. 
:::

::: {.theorem #teo7-2}
**Teorema ** (Wackerly et al. (2008)) Si $Y_1,\,Y_2,\cdots,\,Y_n$ es una muestra aleatoria de una distribuci\'on normal con media $\mu$ y varianza $\sigma^2$, $Y_i$, $i=1,\,2,\cdots,n$ son v.a's independientes distribu\'idas normalmente, con $E(Y_i)=\mu$ y $V(Y_i)=\sigma^2$.

Entonces $$Z_i=\frac{Y_i-\mu}{\sigma}$$
		son v.a's independientes, $i=1,\,2,\cdots,n$  y 
		$$\sum_{i=1}^nZ_i^2=\sum_{i=1}^n\left(\frac{Y_i-\mu}{\sigma}\right)^2$$tienen una distribuci\'on $\chi^2$ con $n$ grados de libertad (gl).
:::

::: {.theorem #teo7-3}
**Teorema** (Wackerly et al. (2008)) Sea $Y_1,\,Y_2,\cdots,\,Y_n$ una muestra aleatoria con media $\mu$ y varianza $\sigma^2$. Entonces
		$$\frac{(n-1)S^2}{\sigma^2}=\frac{1}{\sigma^2}\sum_{i=1}^n(Y_i-\overline{Y})^2$$
		tiene una distribuci\'on $\chi^2$ con $(n-1)$ gl. $\overline{Y}$ y $S^2$ son v.a independientes.
:::

::: {.theorem #def7-2}
**Definici√≥n** (Wackerly et al. (2008))
Sea $Z$ una v.a normal est\'andar y sea $W$ una v.a con distribuci\'on $\chi^2_\nu$. Entonces, si $W$ y $Z$ son ind
		$$T=\frac{Z}{\sqrt{W/\nu}}$$
		se dice que tiene una distribuci\'on $t$ con $\nu$ grados de libertad.
:::



**Observaci√≥n** Si $Y_1,\,Y_2,\cdots,\,Y_n\sim N(\mu,\sigma^2)$ del Teorema \@ref(teo7-1)
$$Z=\frac{\sqrt{n}(\overline{Y}-\mu)}{\sigma}\sim N(0,1)$$
El teorema \@ref(teo7-3) nos dice que
$$W=\frac{(n-1)S^2}{\sigma^2}\sim\chi^2_{n-1}$$
y que $Z$ y $W$ son ind.





\begin{frame}{1.2.1. Distribuciones asociadas a la normal}
\begin{remark}
Por tanto, de la definici\'on 7.2
\begin{eqnarray*}
	T&=&\frac{Z}{\sqrt{W/\nu}}\\
	&=&\frac{\sqrt{n}(\overline{Y}-\mu)/\sigma}{\sqrt{\left[\frac{(n-1)S^2}{\sigma^2}\right]/(n-1)}}\\
	&=&\sqrt{n}\left(\frac{\overline{Y}-\mu}{S}\right)
\end{eqnarray*}
tiene distribuci\'on $t$ con $(n-1)$ grados de libertad.
\end{remark}
\end{frame}
\begin{frame}{1.2.1. Distribuciones asociadas a la normal}
\begin{defi}[Definici\'on 7.3]{\em Sean $W_1$ y $W_2$ v.a's independientes con distribuci\'on $\chi^2$, con $\nu_1$ y $\nu_2$  grados de libertad respectivamente. Entonces se dice que:
		$$F=\frac{W_1/\nu_1}{W_2/\nu_2}$$
		tiene una distribuc\'on $F$ con $\nu_1$ grados de libertad en el numerador y $\nu_2$ grados de libertad en el denominador.}
	\end{defi} 
\end{frame}

\begin{frame}{1.2.1. Distribuciones asociadas a la normal}
	\begin{remark}
	Considerando dos muestras aleatorias independientes tomadas de distribuiciones normales
	$$W_1=\frac{(n_1-1)S_1^2}{\sigma_1^2}\sim\chi^2_{n_1-1}$$
	$$W_1=\frac{(n_2-1)S_2^2}{\sigma_2^2}\sim\chi^2_{n_2-1}$$
	$W_1\bot W_2$.
	\end{remark}
\end{frame}

\begin{frame}{1.2.1. Distribuciones asociadas a la normal}
	\begin{remark}
		\begin{eqnarray*}
			F&=&\frac{W_1/\nu_1}{W_2/\nu_2}\\
			&=&\frac{[(n_1-1)S_1^2/\sigma_1^2]/(n_1-1)}{[(n_2-1)S_2^2/\sigma_2^2]/(n_2-1)}\\
			&=&\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2}
		\end{eqnarray*}
		tiene distribuci\'on $F$ con $(n_1-1)$ gl en el numerador y $(n_2-1)$ gl en el denominador
	\end{remark}
\end{frame}

\begin{frame}
	\begin{center}
		\includegraphics[width=0.8\textwidth]{fig74}
	\end{center}
\end{frame}

\begin{frame}
	\begin{center}
		\includegraphics[width=0.8\textwidth]{T7}
	\end{center}
\end{frame}

\begin{frame}
	\begin{ejemplo}[Ejemplo 7.7]{\em $$Y_1^1,\,Y_2^1\,\cdots,\,Y_{n_1}^1\sim N(\mu_1,\,\sigma^2)$$
			$$Y_1^2,\,Y_2^2\,\cdots,\,Y_{n_2}^2\sim N(\mu_2,\,\sigma^2)$$
			$P\left(\frac{S_1^2}{S_2^2}\leq b\right)=0.95$ con $n_1=6$ y $n_2=10$, ?`$b$?}
	\end{ejemplo}
	Como $n_1=6$ y $n_2=10$ y las varianzas poblacionales son iguales, entonces 
	$\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2}=\frac{S_1^2}{S_2^2}\sim F_{5,9}$
	$$P\left(\frac{S_1^2}{S_2^2}\leq b\right)= F_{5,9}(b)=0.95$$
	entonces $qf(0.95,\,5,\,9)=b$, $b=3.48$.
\end{frame}

\begin{frame}
\begin{ejemplo}Experimento en R, generar n\'umeros aleatorios exponenciales (1/10). Por ser los datos distribu√≠dos exponecialmente, su media ser√° $\mu=10$ y la {\tiny$\sigma^2=100$.
		$$\begin{array}{ccccc}\mbox{Tama\~no muestral}&\mbox{Promedio muestreo repetido}&\mbox{Media te√≥rica} \mu&\mbox{Varianza muestreo repetido}&\mbox{Varianza te√≥rica}\frac{\sigma^2}{n}\\n=5&10.07389&10&19.01144&20\\n=25&10.04106&10&3.6275184&4\end{array}$$}
\end{ejemplo}
\end{frame}

\begin{frame}
Resultado previo a la prueba del Teorema 7.4 sin prueba
\begin{teo}[Teorema 7.5]Sean $Y_1,\,Y_2,\cdots,\,Y_n$  v.a's  con funciones generadoras de momentos $m(t)$  y $m_1(t),\,m_2(t),\cdots,$ respectivamente. Si 
	$$\lim_{n\rightarrow\infty}m_n(t)=m(t)\mbox{ para toda $t$ real,}$$
	entonces la funci\'on de distribuci\'on de $Y_n$ converge hacia la funci\'on de distribuci\'on de $Y$ cuando $n\rightarrow\infty$
\end{teo}
\end{frame}

\section{1.3. Leyes de los Grandes N√∫meros y Teorema Central del L√≠mite }

\subsection{1.3.1. Leyes de los grandes n√∫meros}
\begin{defi}
Una sucesi√≥n de variables aleatorias converge en media a $X$, y se denota por $X_{n}\xrightarrow{cm}X$ , si para cualquier $\epsilon>0$ se tiene que:  
\[\lim _{n\to \infty }E(\left|X_{n}-X\right|)=0,\]
siempre que dicha esperanza exista.\\

De forma an√°loga se define convergencia en media de orden r si:
\[\lim _{n\to \infty }E(\left|X_{n}-X\right|^r)=0,\]

Cuando $r=2$ se dice que se tiene convergencia en media cuadr√°tica

\[\lim _{n\to \infty }E(\left|X_{n}-X\right|^2)=0,\]

\end{defi}

\begin{frame}{Relaciones entre tipos de convergencias}
	\begin{center}
		\includegraphics[width=0.7\textwidth]{esquema}
	\end{center}
\end{frame}

\begin{frame}{Ley d√©bil de los grandes n√∫meros}
\begin{teo}
Sea $X 1,\ldots, X_n$ una sucesi√≥n de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante $C$, independiente de $n$. Sea $S_n = \sum_{i=1  }^{n}X_i$. Entonces

\begin{align}
E\left(\left|\frac{S_n-E(S_n)}{n}\right|^2\right)\leq \frac{C}{n}
\end{align}
\end{teo}
\end{frame}


\begin{frame}{Ley d√©bil de los grandes n√∫meros}

		
		y, como consecuencia
		
		\[\lim _{n\to \infty }\frac{S_n-E(S_n)}{n}=0,\]
		
		en el sentido de la convergencia en \textcolor{red}{media cuadr√°tica}.

\end{frame}

\begin{frame}
Los resultados que garantizan la convergencia casi segura de la media muestral se conocen como leyes fuertes de los grandes n√∫meros. Se enuncia a continuaci√≥n una \textcolor{red}{ley fuerte} para variables con segundos momentos finitos e
incorreladas.
\end{frame}

\begin{frame}{Ley fuerte de los grandes n√∫meros}
	\begin{teo}
		Sea $X 1,\ldots, X_n$ una sucesi√≥n de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante $C$, independiente de $n$. Sea $S_n = \sum_{i=1  }^{n}X_i$. Entonces
		
		\begin{align}
		E\left(\left|\frac{S_n-E(S_n)}{n}\right|^2\right)\leq \frac{C}{n}
		\end{align}
	\end{teo}
\end{frame}


\begin{frame}{Ley fuerte de los grandes n√∫meros}
	
	
	y, como consecuencia
	
	\[\lim _{n\to \infty }\frac{S_n-E(S_n)}{n}=0,\]
	
	en el sentido de la \textcolor{red}{casi segura}.
	
\end{frame}



\subsection{1.3.2. Teorema central del l√≠mite}
\begin{frame}{1.3.2. Teorema central del l√≠mite}
\begin{teo}[Teorema 7.4, Teorema del l\'imite central \cite{Wackerly}] Sean $Y_1,\,Y_2,\cdots,\,Y_n$  v.a's iid ( no se precisa de que distribuci\'on se generan) con $E[Y_i]=\mu$ y $V[Y_i]=\sigma^2<\infty$. Definamos 
	$$U_n=\frac{\sum_{i=1}^nY_i-n\mu}{\sigma\sqrt{n}}=\frac{\overline{Y}-\mu}{\sigma/\sqrt{n}}\mbox{ donde} \overline{Y}=\frac{1}{n}\sum_{i=1}^nY_i$$
	\end{teo}
\end{frame}

\begin{frame}{1.3.2. Teorema central del l√≠mite}
	
		Entonces la funci\'on de distribuci\'on de $U_n$ converge hacia la funci\'on de distribuci\'on normal est\'andar cuando n tiende a infinito . Esto es,
		$$\lim_{n\rightarrow\infty}P(U_n\leq u)=\int_{-\infty}^u\frac{1}{\sqrt{2\pi}}e^{-t^2/2}dt\,\forall u$$
\end{frame}

---
## Referencias

- **G√≥mez, Guadalupe**, & **Delicado, Pedro** (2006). *Curso de Inferencia y Decisi√≥n*. Departament d‚ÄôEstad√≠stica i Investigaci√≥ Operativa, Universitat Polit√®cnica de Catalunya.

- **Wackerly, D. D., Mendenhall, W.**, & **Scheaffer, R. L.** (2008). **Estad√≠stica matem√°tica con aplicaciones** (7¬™ ed.). Cengage Learning.

- **Roussas, G. G.** (1997). **A Course in Mathematical Statistics** (2nd ed.). Academic Press.
