---
# Si quieres un encabezado local, puedes dejarlo as√≠:
# O simplemente eliminar este bloque completamente
---

# INTRODUCCI√ìN
Este libro ha sido concebido como un recurso integral para el estudio riguroso y aplicado de la inferencia estad√≠stica. Est√° dirigido a estudiantes de programas de estad√≠stica, matem√°ticas aplicadas y disciplinas afines, y busca fortalecer la comprensi√≥n conceptual y t√©cnica de los fundamentos que sustentan el an√°lisis estad√≠stico moderno.

A lo largo de sus cap√≠tulos, el lector encontrar√° un desarrollo progresivo de los siguientes temas:

- Fundamentos de la probabilidad y los modelos estad√≠sticos.
- Propiedades de las variables aleatorias y familias param√©tricas comunes.
- Principios clave para la reducci√≥n de datos: suficiencia, completitud y verosimilitud.
- Construcci√≥n y evaluaci√≥n de estimadores puntuales.
- Estimaci√≥n por intervalos y su interpretaci√≥n inferencial.
- Contrastes de hip√≥tesis y principios de optimalidad en pruebas estad√≠sticas.
- Introducci√≥n a la teor√≠a de la decisi√≥n y sus aplicaciones en inferencia.

El material combina el rigor formal con ejemplos y aplicaciones que ilustran c√≥mo los m√©todos estad√≠sticos permiten extraer conclusiones v√°lidas a partir de datos.

> Este libro se encuentra en construcci√≥n. Los cap√≠tulos se ir√°n publicando progresivamente y pueden estar sujetos a revisiones o mejoras. Por ahora, son s√≥lo trozos de contenido de otros libros o notas de clase de una selecci√≥n personal y que se ir√°n referenciando en cada cap√≠tulo.

---

## ¬øC√≥mo navegar este libro?

- Usa el **√≠ndice lateral izquierdo** para acceder a cada cap√≠tulo y subcap√≠tulo.
- Haz uso del **buscador** para encontrar conceptos o t√©rminos clave.
- Revisa los apartados de ‚ÄúLista de problemas‚Äù incluidos al final de cada secci√≥n para practicar.

---

## ¬°Bienvenida/o!

Te invito a recorrer este texto con atenci√≥n, curiosidad y sentido cr√≠tico.  
Espero que este libro te acompa√±e, rete y apoye en tu formaci√≥n como profesional en ciencias de datos o √°reas relacionadas.

<!-- 1. [Datos y modelos](Datos%20y%20modelos.qmd)   -->
<!-- 2. [Variable aleatoria](Variable%20aleatoria.qmd)   -->




## DATOS Y MODELOS

En esta secci√≥n establecemos la base conceptual para el an√°lisis estad√≠stico, diferenciando claramente entre el fen√≥meno aleatorio observado y la medida de probabilidad que lo describe.  

### Fen√≥meno aleatorio y variable observada

‚ÄúSe observa una realizaci√≥n de un fen√≥meno aleatorio, digamos X. Este puede ser un elemento aleatorio de varios tipos: n√∫mero (variable aleatoria), un vector de dimensi√≥n finita (vector aleatorio), una funci√≥n, etc.

La premisa principal es que el car√°cter aleatorio de X se concibe como una realizaci√≥n de un fen√≥meno aleatorio que tiene una distribuci√≥n de probabilidad P, donde la distribuci√≥n P es desconocida ya sea en su totalidad o en alg√∫n detalle espec√≠fico (por ejemplo, su soporte, su media, etc.). Es de inter√©s conocer P. Si la medida de probabilidad P fuese conocida, entonces no hay problema estad√≠stico propiamente, pues el problema estad√≠stico tiene que ver con _inferir_ la propiedad desconocida de P con base en X.‚Äù [Ver referencia 1]

- **Definici√≥n de X**  
  - **X** puede ser un valor real $X \in \mathbb{R}$, un vector en $\mathbb{R}^n$, o incluso una funci√≥n $\;X: [0,1]\to\mathbb{R}$.  
- **Medida de probabilidad P**  
  - Desconocida: soporte, media, varianza, etc.  
  - Objetivo estad√≠stico: _inferir_ caracter√≠sticas de \(P\) a partir de la muestra (la realizaci√≥n de X).

### Incertidumbre inductiva vs. estoc√°stica

‚ÄúLa observaci√≥n **X** est√° dada, por lo que no hay incertidumbre tal como la hay en la teor√≠a de probabilidad desarrollada anteriormente en el curso. Antes, fue concebida una estructura $(\Omega, \mathcal{F}, P)$ para enfrentar el que haya incertidumbre acerca del valor de **X**. En el problema estad√≠stico, el valor de **X** ha sido observado, y la incertidumbre radica en otro punto: radica en que existe duda acerca de cu√°l **P** es la que produjo el valor **X**. En algunas ocasiones se utilizan los t√©rminos _incertidumbre estoc√°stica_ e _incertidumbre inductiva_ para distinguir estos dos tipos. Es com√∫n que estos se confundan entre s√≠, porque en estad√≠stica matem√°tica la teor√≠a de probabilidad constituye tambi√©n una de las maneras naturales de afrontar la cuantificaci√≥n de incertidumbre inductiva. En cualquier caso, el concebir a **P** como medida de probabilidad es la base para formular soluciones a la incertidumbre inductiva. Con este lenguaje, probabilidad y estad√≠stica son problemas diferentes y de cierta manera inversos. Teor√≠a de probabilidad tiene que ver con cuantificar incertidumbre acerca de **X** y teor√≠a estad√≠stica con cuantificar incertidumbre acerca de **P** a la luz de haber ya observado **X**.‚Äù[Ver referencia 1]

- **Incertidumbre estoc√°stica**: duda previa sobre el valor de X, modelada por $(\Omega,\mathcal{F},P)$.  
- **Incertidumbre inductiva**: tras observar X, la incertidumbre se desplaza a la ley generadora P.

---

#### Ejemplos en Matem√°tica Aplicada e Ingenier√≠a de Sistemas

1. **Modelado de tiempos de respuesta en redes**  
   - $X$: tiempo de llegada de paquetes (variable continua).  
   - $P$: distribuci√≥n de retardo desconocida; objetivo: estimar par√°metros de una ley de colas M/M/1.  

2. **Estimaci√≥n de par√°metros en ecuaciones diferenciales estoc√°sticas**  
   - $X(t)$: trayectoria observada de un proceso de It√¥.  
   - $P$: ley del proceso (por ejemplo, coeficientes de difusi√≥n y deriva), inferidos a partir de trayectorias discretas.  

3. **Calibraci√≥n de sensores en sistemas de control**  
   - $X$: lecturas del sensor (vector aleatorio).  
   - $P$: distribuci√≥n conjunta desconocida de ruido; se estima para dise√±ar filtros de Kalman √≥ptimos.  

---

Con esta distinci√≥n clara entre dato observado y modelo probabil√≠stico, estamos listos para construir estimadores y desarrollar la inferencia estad√≠stica en las secciones siguientes. 




## VARIABLE ALEATORIA


### Variables y vectores aleatorios
Consideramos un experimento aleatorio cuyos resultados pertenecen al espacio muestral Œ©. Modelamos este proceso suponiendo que existe una terna $(\Omega, \mathcal{A}, P),$ donde:

- $\Omega$ es el espacio muestra,  
- $\mathcal{P}(\Omega)$ es el conjunto de partes de Œ©,  
- $\mathcal{A}\in\mathcal{P}(\Omega)$ es una œÉ-√°lgebra,  
- $P\colon \mathcal{A} \to [0,1]$ es una medida de probabilidad que refleja las caracter√≠sticas aleatorias del experimento realizado.  

A esta terna se le llama **espacio de probabilidad**.

Los resultados de un experimento aleatorio no son analizados ‚Äúen bruto‚Äù, sino que se les da una representaci√≥n num√©rica que facilita su tratamiento. Esto se logra introduciendo variables aleatorias, que asocian cada resultado $\omega\in \Omega$ con un valor num√©rico o vectorial, y sobre las cuales luego aplicamos t√©cnicas de inferencia estad√≠stica.

En todo estudio estad√≠stico partimos de un **experimento aleatorio** cuyo conjunto de resultados posibles se denomina **espacio muestral** Œ©. Para cuantificar dichos resultados definimos las siguientes estructuras:

::: {.definition #def-1.1}
**(Variables Aleatorias)** Sea $(\Omega,\mathcal{A},P)$ un espacio de probabilidad. Una **variable aleatoria** es una funci√≥n $X\colon (\Omega,\mathcal{A})\;\longrightarrow\; (\mathbb{R},\mathcal{B}),$ tal que para todo $B\in\mathcal{B}$ (la $\sigma$-√°lgebra de Borel en ‚Ñù),  $X^{-1}(B)\;=\;\{\omega\in\Omega : X(\omega)\in B\}\;\in\;\mathcal{A}.$
:::

Si el espacio muestral $\Omega$ es **finito o numerable**, diremos que es un espacio **discreto** y las variables aleatorias asociadas al experimento normalmente estar√°n definidas como $X\colon \Omega \;\longrightarrow\; \mathbb{Z}.$

Si $\Omega$ es **no numerable**, entonces diremos que es un espacio **continuo** y $X\colon \Omega \;\longrightarrow\; \mathbb{R}.$


---

::: {.definition #def-1.2}
Un **vector aleatorio** de dimensi√≥n $n$ es $\mathbf{X} = (X_1,\dots,X_n)\colon(\Omega,\mathcal{A})\longrightarrow(\mathbb{R}^n,\mathcal{B}^n),$ donde cada componente $X_i$ es variable aleatoria y $\mathcal{B}^n$ la $\sigma$-√°lgebra de Borel en ‚Ñù‚Åø.
:::



---

**Ejemplos**
  **Lanzamiento de dos monedas**

Sea $\Omega =\{\,CC,\;C-,\;-C,\;--\},$ donde $C$ = ‚Äúcara‚Äù y $-$ = ‚Äúcruz‚Äù. Podemos definir:  
$X_1(\omega) = \text{n√∫mero de caras en }\omega.$
$X_2(\omega) = 2 - X_1(\omega)\;=\; \text{n√∫mero de cruces}.$
$X_3(\omega) = \bigl(X_1(\omega)\bigr)^2.$

Entonces $(X_1,X_2,X_3)$ es un vector aleatorio de dimensi√≥n 3.

 **Tiempos de servicio en un servidor**

Sean $T_i$ los tiempos de servicio (en segundos) de las peticiones $i=1,2,3$. Definimos  
$\mathbf{T}=(T_1,T_2,T_3),\quad S = T_1 + T_2 + T_3,\quad M = \max\{T_1,T_2,T_3\}.$

  **Lecturas de sensores en red distribuida**

En tres nodos $i=1,2,3$ medimos temperatura $X_{i,1}$, presi√≥n $X_{i,2}$ y humedad $X_{i,3}$. El vector global es $\mathbf{X} = (X_{1,1},X_{1,2},X_{1,3},\,X_{2,1},\dots,X_{3,3}) \in \mathbb{R}^9.$

---

Con estas definiciones rigurosas disponemos ya de los objetos b√°sicos para, en las siguientes secciones, construir estimadores, estudiar su comportamiento asint√≥tico y contrastar hip√≥tesis sobre la distribuci√≥n subyacente $P$.


## Distribuci√≥n de una variable aleatoria. Funciones de distribuci√≥n, de probabilidad y de densidad
  
  **Distribuci√≥n de una Variable Aleatoria**

La realizaci√≥n de un experimento aleatorio da lugar a un resultado $\omega\in\Omega$ que es aleatorio. Por lo tanto, $X(\omega)$ es un valor de $\mathbb{R}$ tambi√©n aleatorio. Es decir, la variable aleatoria $X$ induce una medida de probabilidad en $\mathbb{R}$. A esa medida de probabilidad se le llama **distribuci√≥n de $X$** o **ley de $X$**. Una de las formas de caracterizar la distribuci√≥n de una variable aleatoria es dar su funci√≥n de distribuci√≥n $F_X$, que est√° definida as√≠:

$F_X(x) \;=\; P(X \le x)\;=\; P\bigl(\{\omega \in \Omega : X(\omega) \le x\}\bigr)\;=\; P\bigl(X^{-1}((-\infty, x])\bigr).$$

En el caso de que $X$ sea una **variable aleatoria discreta**, es decir, en el caso de que $X$ solo tome una cantidad finita o numerable de valores de $\mathbb{R}$, su distribuci√≥n tambi√©n puede caracterizarse por su **funci√≥n de probabilidad** (o **funci√≥n de masa de probabilidad**) $f_X$, definida como

$$f_X : \mathbb{R} \longrightarrow [0,1],\qquad f_X(x) = P(X = x).$$

Esa funci√≥n solo es no nula en un conjunto finito o numerable. Supondremos en adelante, sin p√©rdida de generalidad, que ese conjunto est√° contenido en $\mathbb{Z}$.
A partir de la funci√≥n de masa de probabilidad se puede calcular la probabilidad 
de que la variable aleatoria $X$ tome valores en cualquier elemento $A \subseteq \mathbb{B}$:

$P(X \in A) = \sum_{x \in A} f_X(x).$
me


La funci√≥n de distribuci√≥n y la funci√≥n de masa de probabilidad se relacionan 
de la siguiente forma:

$F_X(x) = \sum_{u \leq x} f_X(u), \quad f_X(x) = F_X(x) - F_X(x^-),$ donde $F_X(x^-) = \lim_{h \to 0^+} F_X(x - h)$.

Una clase relevante de variables aleatorias no discretas son las que poseen **funci√≥n de densidad**, es decir, aquellas cuya distribuci√≥n de probabilidad puede caracterizarse por una funci√≥n $f_X(x) \geq 0$ que cumple que:

$P(X \in A) = \int_{x \in A} f_X(x) \, dx, \quad \text{para todo } A \subseteq \mathbb{B}.$

La relaci√≥n entre $F_X$ y $f_X$ es la siguiente:

$F_X(x) = \int_{-\infty}^{x} f_X(u) \, du, \quad f_X(x) = \frac{d}{dx} F_X(x),$

salvo quiz√°s en un n√∫mero finito de puntos $x \in \mathbb{R}$. Las variables aleatorias que poseen funci√≥n de densidad se llaman **variables aleatorias absolutamente continuas**. Abusando del lenguaje, aqu√≠ nos referiremos a ellas como variables aleatorias continuas.



## Esperanza y varianza
Si se desea describir totalmente la distribuci√≥n de probabilidad de una variable aleatoria $X$ acabamos de ver que podemos dar su funci√≥n de distribuci√≥n o su funci√≥n de masa o de densidad, seg√∫n el caso. Una descripci√≥n parcial puede efectuarse calculando algunas caracter√≠sticas de la variable aleatoria $X$, como por ejemplo medidas de posici√≥n o de dispersi√≥n. Estudiaremos algunas de ellas.

Se define la **esperanza** de una variable aleatoria $X$ como la integral de Lebesgue de $X$:

$E(X) = \int_{\Omega} X(w) dP(w).$

En el caso de variables aleatorias discretas la esperanza puede calcularse como:

$E(X) = \sum_{w \in \Omega} X(w) P(w) = \sum_{k \in \mathbb{Z}} k P(X = k) = \sum_{k \in \mathbb{Z}} k f_X(k).$

Por otro lado, la esperanza de una variable aleatoria continua se puede calcular as√≠:

$E(X) = \int_{\mathbb{R}} x f_X(x) dx.$

La esperanza de una variable aleatoria $X$ es una medida de posici√≥n de $X$: es el centro de gravedad de la distribuci√≥n de probabilidad de $X$.

Si $h$ es una funci√≥n medible $h : \mathbb{R} \rightarrow \mathbb{R}$, entonces $Y = h(X)$ es tambi√©n variable aleatoria y su esperanza se puede calcular a partir de la distribuci√≥n de $X$:

$E(h(X)) = \int_{\Omega} h(X(w)) dP(w)$ que en el caso de que $X$ sea discreta puede reescribirse como

$E(h(X)) = \sum_{k \in \mathbb{Z}} h(k) f_X(k).$

Si $X$ es una variable aleatoria continua entonces

$E(h(X)) = \int_{\mathbb{R}} h(x) f_X(x) dx.$

Si existe $\mu = E(X)$ y es finita puede definirse una medida de dispersi√≥n de la variable aleatoria $X$ a partir de una transformaci√≥n $h$ de $X$. Es lo que se denomina **varianza** de $X$ y se define as√≠:

$V(X) = E((X - \mu)^2) = E(X^2) - \mu^2 = E(X^2) - (E(X))^2.$

## Funci√≥n generadora de momentos 
Dada una variable aleatoria $X$, o su funci√≥n de distribuci√≥n $F$, vamos a definir otra funci√≥n generadora, como

$M_X(t) = \mathbb{E}(e^{tX}),$ siempre que este valor esperado exista.

Notemos que cuando $X$ toma valores en los enteros no-negativos, $M_X(t) = \phi_X(e^t)$, donde $\phi_X(s)=E[s^X]=\sum_{k=0}^{\infty}p_ks^k$ para $s\in[0,1]$ es la funci√≥n generadora de probabilidad (f.g.p.) de la variable $X$, con $p_k=P(X=k)$. Si $X$ est√° acotada, $M_X$ est√° bien definida para todo $t$ real; en cambio, si $X$ no est√° acotada, es posible que el dominio de $M_X$ no sea el conjunto de todos los reales. En todo caso, $\phi$ siempre est√° definida en cero, y $M(0) = 1$.

Es posible demostrar que si la f.g.m. de la v.a. $X$ existe en un entorno de 0, entonces para todo $k > 0$,

$\mathbb{E}[|X|^k] < \infty.$

M√°s a√∫n, la serie

$M_X(t) = 
\mathbb{E}(e^{tX}) 
= \mathbb{E}\left(1 + \sum_{k=1}^{\infty} \frac{t^k X^k}{k!}\right) 
= 1 + \sum_{n=1}^{\infty} \frac{t^k}{k!} \mathbb{E}(X^k)
\tag{5.1}$

es convergente y se puede derivar t√©rmino a t√©rmino. Obtenemos

$M'_X(0) = \mathbb{E}(X); \quad M''_X(0) = \mathbb{E}(X^2)$

y en general

$M_X^{(k)}(0) = \mathbb{E}(X^k).$

Es por esta √∫ltima propiedad que esta funci√≥n se conoce como **funci√≥n generadora de momentos** (f.g.m.).

üé≤ Ejemplo: f.g.m. de la distribuci√≥n Binomial

Sea $X \sim \text{Binomial}(n, p)$, es decir, la suma de $n$ ensayos de Bernoulli con probabilidad de √©xito $p$. La funci√≥n generadora de momentos es: [Ejemplo fgm binomial](https://github.com/BMSS-EAFIT-Courses/inference-statistic/blob/main/mgf_binomial.r)

$M_X(t) = \mathbb{E}[e^{tX}] = (1 - p + p e^t)^n$

<pre> ```r #
mgf_binomial <- function(t, n = 10, p = 0.3) {
  (1 - p + p * exp(t))^n
}

t_vals <- seq(-3, 3, length.out = 300)
mgf_vals <- sapply(t_vals, mgf_binomial)

plot(t_vals, mgf_vals, type = "l", lwd = 2,
     main = expression("F.G.M. para X ~ Binomial(10, 0.3)"),
     xlab = "t", ylab = expression(M[X](t)))
grid()
``` </pre>
üìà Ejemplo: f.g.m. de la distribuci√≥n Normal Est√°ndar

Sea $X \sim \mathcal{N}(0, 1)$. Su funci√≥n generadora de momentos es:

$M_X(t) = \mathbb{E}[e^{tX}] = e^{\frac{t^2}{2}}$

Esta expresi√≥n se obtiene usando la forma cerrada del momento de una normal est√°ndar.
<pre> ```r #
mgf_normal <- function(t) {
  exp(t^2 / 2)
}

t_vals <- seq(-3, 3, length.out = 300)
mgf_vals <- sapply(t_vals, mgf_normal)

plot(t_vals, mgf_vals, type = "l", lwd = 2,
     main = expression("F.G.M. para X ~ N(0, 1)"),
     xlab = "t", ylab = expression(M[X](t)))
grid()
``` </pre>

 **‚ùì Preguntas gu√≠a sobre la gr√°fica de la funci√≥n generadora de momentos**

  **üìå ¬øQu√© representa la gr√°fica de la f.g.m. $M_X(t)$?**

La gr√°fica muestra c√≥mo evoluciona el valor esperado de $e^{tX}$ cuando $t$ var√≠a. Esta funci√≥n codifica **todos los momentos de la variable aleatoria** $X$, y por tanto, contiene informaci√≥n completa sobre su distribuci√≥n (si existe un entorno donde la f.g.m. es finita).

---

  **üß≠ ¬øQu√© se observa en la f.g.m. de una distribuci√≥n Binomial?**
<img width="480" height="480" alt="mgf_binomial" src="https://github.com/user-attachments/assets/8524edee-0b5c-4938-a9e8-8af0e8c5840c" />

![Gr√°fica MGF Binomial]

  #Preguntas y respuestas

- **¬øC√≥mo es el comportamiento de la f.g.m. cerca de $t = 0$?**

  En $t = 0$, siempre se cumple que $M_X(0) = 1$, ya que:

  $M_X(0) = \mathbb{E}[e^{0 \cdot X}] = \mathbb{E}[1] = 1$

- **¬øQu√© indica la curvatura de la gr√°fica?**

   La curvatura refleja el crecimiento exponencial de los momentos. Si la curva crece r√°pidamente hacia la derecha, significa que los momentos (media, varianza, etc.) tambi√©n crecen con rapidez.

- **¬øPor qu√© la gr√°fica es convexa?**

  Todas las funciones generadoras de momentos son **estrictamente convexas** en el intervalo donde est√°n definidas. Esto es una consecuencia de que derivadas sucesivas representan momentos positivos.

- **¬øQu√© pasa si cambio los par√°metros $n$ y $p$?**

  Aumentar $ n $ o $p$ tiende a **elevar** la f.g.m. en el lado derecho, reflejando una mayor media y varianza.

---

  **üìà ¬øC√≥mo se comporta la f.g.m. para la Normal Est√°ndar?**
<img width="480" height="480" alt="mgf_normal" src="https://github.com/user-attachments/assets/e877129d-4235-42d9-baff-7f29d3afc4a7" />

![Gr√°fica MGF Normal]

  **Preguntas y respuestas**

- **¬øPor qu√© es sim√©trica respecto al eje $ t = 0 $?**

  Porque la normal est√°ndar es sim√©trica alrededor de su media $ \mu = 0 $, y su f.g.m. tiene la forma:

 $M_X(t) = e^{t^2 / 2}$

  lo cual es una funci√≥n par: $M_X(-t)= M_X(t)$.

- **¬øQu√© tan r√°pido crece la funci√≥n?**

  Muy r√°pido. El crecimiento es exponencial cuadr√°tico. Esto implica que los momentos de la normal crecen r√°pidamente en magnitud.

- **¬øC√≥mo se relaciona esta gr√°fica con los momentos de la normal?**

  Derivando sucesivamente la f.g.m. en $ t = 0 $, se obtiene:

  $\mathbb{E}[X^k] = M_X^{(k)}(0)$

  Por tanto, la gr√°fica "encierra" toda la informaci√≥n sobre los momentos.

---

  **üß† Conclusi√≥n**

Estas gr√°ficas te permiten **visualizar la informaci√≥n estad√≠stica codificada en una variable aleatoria**. La f.g.m. no es solo una herramienta algebraica para obtener momentos, sino una forma poderosa de describir el comportamiento global de la variable.

> **¬øQu√© pasa si dos variables tienen la misma f.g.m.?**  
> ¬°Tienen la misma distribuci√≥n! (si la f.g.m. est√° definida en un entorno de 0).

  **Ejemplo: Distribuci√≥n uniforme $U(a,b)$**

Si 
$$X \sim U(a,b),$$  
su densidad es  
$$f(x) = \frac{1}{b - a}\quad\text{para }a < x < b,$$  
y su funci√≥n generadora de momentos viene dada por 

<a id="eq:5.2"></a> 
<table align="center">
  <tr>
    <td align="center">
$$M(t)= \int_a^b \frac{e^{t x}}{b - a}\,dx= \frac{e^{b t} - e^{a t}}{t\,(b - a)}.$$  
    </td>
    <td valign="bottom">
      (5.2)
    </td>
  </tr>
</table>

En el caso particular de la distribuci√≥n uniforme en $(0,1)$ se obtiene  
$$M(t) = \frac{e^t - 1}{t}.$$

---

Para derivar la f√≥rmula [#(5.2)](#eq:5.2) y obtener los momentos, podemos usar el desarrollo en serie de la funci√≥n exponencial:

$$
\begin{align}
M(t)&= \frac{1}{t\,(b - a)}\bigl(e^{b t} - e^{a t}\bigr) \\
&= \frac{1}{t\,(b - a)}\Bigl[\bigl(1 + \sum_{n=1}^\infty \tfrac{(b t)^n}{n!}\bigr)
                    -\bigl(1 + \sum_{n=1}^\infty \tfrac{(a t)^n}{n!}\bigr)\Bigr] \\
&= \frac{1}{b - a}\sum_{n=1}^\infty \frac{b^n - a^n}{n!}\,t^{n-1}.
\end{align}
$$

Este es el desarrollo de Maclaurin de $M(t)$ en $t=0$; por tanto, sus derivadas en cero satisfacen

<table align="center">
  <tr>
    <td align="center">
$$M^{(k)}(0)= \frac{b^{k+1} - a^{k+1}}{(k+1)\,(b - a)}.$$
    </td>
    <td valign="bottom">
      (5.3)
    </td>
  </tr>
</table>
En particular:

-  $$M'(0)= \frac{b^2 - a^2}{2\,(b - a)}= \frac{a + b}{2},$$
  que coincide con $\mathbb{E}(X)$.

-  $$M''(0)= \frac{b^3 - a^3}{3\,(b - a)}= \frac{a^2 + a b + b^2}{3},$$

y un c√°lculo directo muestra que la varianza es

$$\mathrm{Var}(X)= \mathbb{E}(X^2) - \bigl(\mathbb{E}(X)\bigr)^2= \frac{(a + b)^2}{12}.$$

  **Observaci√≥n importante** 
Sea $X$ una v.a. con f.g.m. $M_X$ y sea $Y=aX+b$ una transformaci√≥n lineal de $X$, entonces

$$M_Y(t)=E(e^{tY})=E(e^{t(aX+b)})=E(e^{taX}e^{tb})=e^{tb}E(e^{taX})=e^{tb}M_X(at)$$

::: {#thm-1}
**(fgm de suma de v.a.s)**
Si $X$ tiene funci√≥n generadora de momentos $M(t)$ que est√° definida en un entorno $(-a,a)$ de 0, entonces $M(t)$ caracteriza a la distribuci√≥n de $X$; es decir, si otra variable $Y$ tiene la misma funci√≥n generadora de momentos, las distribuciones de $X$ e $Y$ coinciden.
:::

  
---

Si $X,Y$ son variables aleatorias con funciones generadoras de momentos respectivas $M_X$ y $M_Y$ que existen en un dominio com√∫n $|t| < d$, entonces la f.g.m. de la suma $X+Y$ est√° dada por
<!-- <a id="eq:5.5"></a>  -->
<!-- <table align="center"> -->
<!--   <tr> -->
<!--     <td align="center"> -->
$$
\begin{align}
M_{X+Y}(t)&= \mathbb{E}\bigl[e^{t(X+Y)}\bigr]\\
&= \mathbb{E}\bigl[e^{tX}\,e^{tY}\bigr]\\
&=\mathbb{E}\bigl[e^{tX}\bigr]\mathbb{E}\bigl[e^{tY}\bigr]\\
&= M_X(t)\,M_Y(t).
\end{align}
\tag{1}
$$
<!--   </td> -->
<!--     <td valign="bottom"> -->
<!--       (5.5) -->
<!--     </td> -->
<!--   </tr> -->
<!-- </table> -->

Este resultado se extiende a la suma de $n$ variables aleatorias independientes. Si

$$S_n = X_1 + \cdots + X_n,$$

entonces

$$M_{S_n}(t)= \mathbb{E}\bigl[e^{tS_n}\bigr]= \mathbb{E}\Bigl[e^{t\sum_{i=1}^n X_i}\Bigr]= \prod_{i=1}^n\mathbb{E}\bigl[e^{tX_i}\bigr]= \prod_{i=1}^n M_{X_i}(t).$$

La funci√≥n generadora de momentos resulta particularmente √∫til cuando consideramos sucesiones de variables aleatorias, como lo muestra el siguiente teorema que enunciamos sin demostraci√≥n:

---

::: {#thm-2}
**(de Continuidad)** Sea $F_n(x)$, $n\ge1$, una sucesi√≥n de funciones de distribuci√≥n con funciones generadoras de momentos respectivas $M_n(t)$, definidas en $|t|<b$. Supongamos que cuando $n\to\infty$,

$$
M_n(t)\,\longrightarrow\,M(t)
\quad\text{para }|t|\le a,
$$

donde $M(t)$ es la funci√≥n generadora de momentos de la distribuci√≥n l√≠mite $F(x)$. Entonces

$$
F_n(x)\,\longrightarrow\,F(x)
\quad\text{cuando }n\to\infty
$$

para todo punto $x$ en el cual $F$ es continua.
:::

::: {#thm-3}
**Laplace‚ÄìMoivre** Sea $X_1, X_2, \ldots, X_n$ una sucesi√≥n de variables aleatorias **i.i.d.** con distribuci√≥n \( \text{Bernoulli}(p) \), donde \( 0 < p < 1 \). Sea:

$$
S_n = X_1 + X_2 + \cdots + X_n \sim \text{Binomial}(n, p)
$$

y consideremos la variable tipificada:

$$
Z_n = \frac{S_n - np}{\sqrt{np(1 - p)}}
$$

Entonces, cuando \( n \to \infty \), se tiene convergencia en distribuci√≥n a una normal est√°ndar:

$$
Z_n \xrightarrow{d} \mathcal{N}(0, 1)
$$

es decir,

$$
\lim_{n \to \infty} \mathbb{P}(Z_n \leq z) = \Phi(z), \quad \text{para todo } z \in \mathbb{R}
$$

donde \( \Phi(z) \) es la funci√≥n de distribuci√≥n acumulada de la normal est√°ndar.

:::

::: {.proof}
**Demostraci√≥n usando funciones generadoras de momentos**

La funci√≥n generadora de momentos (mgf) de $S_n \sim \text{Binomial}(n, p)$ es:

$$
M_{S_n}(t) = \left(1 - p + p e^t\right)^n
$$

Queremos obtener la mgf de la variable tipificada \( Z_n \). Usamos la propiedad de cambio de variable de la mgf:

$$
M_{Z_n}(t) = \mathbb{E}\left[ e^{t Z_n} \right]
= \mathbb{E}\left[ e^{t \cdot \frac{S_n - np}{\sqrt{np(1 - p)}}} \right]
= e^{-t \cdot \frac{np}{\sqrt{np(1 - p)}}} \cdot M_{S_n}\left( \frac{t}{\sqrt{np(1 - p)}} \right)
$$

Sustituimos la mgf de \( S_n \):

$$
M_{Z_n}(t) = \exp\left( -t \cdot \frac{np}{\sqrt{np(1 - p)}} \right)
\cdot \left( 1 - p + p e^{t / \sqrt{np(1 - p)}} \right)^n
$$


**Aproximaci√≥n por series de Taylor**

Expandimos  $e^{t / \sqrt{np(1 - p)}}$ para $n$ grande:

$$
e^{t / \sqrt{np(1 - p)}} = 1 + \frac{t}{\sqrt{np(1 - p)}} + \frac{t^2}{2np(1 - p)} + \cdots
$$

Entonces:

$$
1 - p + p e^{t / \sqrt{np(1 - p)}} \approx 1 + \frac{pt}{\sqrt{np(1 - p)}} + \frac{pt^2}{2np(1 - p)} + \cdots
$$

Usamos que $\log(1 + x) \approx x - \frac{x^2}{2} + \cdots$ para $x \approx 0$:

$$\log M_{Z_n}(t) \approx -t \cdot \frac{np}{\sqrt{np(1 - p)}}+ n \left( \frac{pt}{\sqrt{np(1 - p)}} + \frac{pt^2}{2np(1 - p)} \right)$$

Simplificamos:

- El t√©rmino lineal se cancela:

$$
-t \cdot \frac{np}{\sqrt{np(1 - p)}} + n \cdot \frac{pt}{\sqrt{np(1 - p)}} = 0
$$

- Queda:

$$
\log M_{Z_n}(t) \to \frac{t^2}{2}, \quad \text{cuando } n \to \infty
$$

Por tanto:

$$
M_{Z_n}(t) \to e^{t^2 / 2}
$$
  **Conclusi√≥n**

Como $e^{t^2/2}$ es la mgf de $\mathcal{N}(0, 1)$, y por el teorema de unicidad de la funci√≥n generadora de momentos:

$$
Z_n \xrightarrow{d} \mathcal{N}(0, 1)
$$


Esto concluye la demostraci√≥n del **Teorema de Laplace‚ÄìMoivre** utilizando funciones generadoras de momentos.
:::

## Muestra aleatoria simple

Sea $\underset{\sim}{X} =(X_1 ,..., X_n)$ un vector aleatorio. Se dice que sus componentes $X_1 ,..., X_n$ son \textcolor{red}{independientes} si $P(X_1\leq x_1 ,..., X_n\leq x_n)=P(X_1\leq x_1)...P(X_n\leq x_n)$ para cualesquiera valores $x_1,..., x_n$ .
	
Si adem√°s la distribuci√≥n de las $n$ variables aleatorias $X_i$ es la misma, se dice que $X_1 ,...,X_n$ son variables aleatorias **independientes e id√©nticamente distribuidas**, o bien que son v.a.i.i.d o simplemente i.i.d.
	
Si $\underset{\sim}{X} =(X_1 ,..., X_n)$ y $X_1 ,..., X_n$ son i.i.d. con funci√≥n de densidad (en su caso, de masa) $f_X$ , la distribuci√≥n conjunta de $\underset{\sim}{X}$ viene dada por la funci√≥n de densidad (en su caso, de masa) conjunta
$$
\begin{align*}
f_{\underset{\sim}{X}}(\underset{\sim}{x})&=f_{(X_1 ,..., X_n)}(x_1 ,..., x_n)\\
&=f_{(X_1)}(x_1)...f_{(X_n)}(x_n)\\
&=\prod_{i=1}^{n}f_{(X_i)}(x_i)
\end{align*}
$$

A un vector $\underset{\sim}{X} =(X_1 ,..., X_n)$ de v.a.i.i.d. con distribuci√≥n igual a la de la variable aleatoria $X$ se le denomina tambi√©n **muestra aleatoria simple** de $X$ (m.a.s de $X$).

Esto responde al hecho siguiente. Supongamos que se desea estudiar la caracter√≠stica $X$ de los individuos de una poblaci√≥n de tama√±o infinito. Definimos el experimento consistente en elegir aleatoriamente un individuo de la poblaci√≥n y llamamos $X$ al valor de la caracter√≠stica de inter√©s en ese individuo. X es una variable aleatoria.


Si definimos un nuevo experimento consistente en elegir una muestra aleatoria de n individuos y se anota $X_i$, el valor de la caracter√≠stica en el individuo i-√©simo, entonces **X** $=(X_1 ,..., X_n)$ es una colecci√≥n de n v.a.i.i.d. con distribuci√≥n igual a la de la variable aleatoria $X$, es decir, $X_1 ,..., X_n$ es una m.a.s. de X.

## Modelo param√©trico
Usualmente la ley de probabilidad de una variable aleatoria se supone perteneciente a un modelo matem√°tico que depende s√≥lo de un n√∫mero finito de par√°metros:
	$f_X \in\{f(x|\theta):\theta \in \Theta \subseteq \mathbb{R}^k\}$.
	Escribiremos alternativamente $f(x;\theta)$, $f(x|\theta)$ o $f_\theta(x)$.

::: {.definition #def-1.3}
El conjunto de distribuciones dadas por $f_\theta(x)$, $\theta \in \Theta$ se llama familia param√©trica de distribuciones. $\Theta$ es el conjunto de par√°metros.
:::

::: {.definition #def-1.4}
La correspondiente distribuci√≥n conjunta de una muestra aleatoria simple de $X$ viene dada por la funci√≥n de densidad (o funci√≥n de masa de probabilidad, seg√∫n el caso)

$$
f_{\underset{\sim}{X}}(\underset{\sim}{x} \mid \theta) = \prod_{i=1}^{n} f_{\theta}(x_i)
$$

A esta funci√≥n la llamaremos **funci√≥n de verosimilitud** de la muestra $X_{\sim}$. Utilizaremos este t√©rmino para referirnos indistintamente a la funci√≥n de densidad conjunta (si las variables aleatorias son continuas) o a la funci√≥n de masa conjunta (si son discretas).
:::
	

	

## Sumas de variables aleatorias
Cuando se obtiene una muestra aleatoria simple $X_{1},X_{2},\ldots,X_{n}$ normalmente se calculan a partir de ellas cantidades que resumen los valores observados. Cualquiera de estos res√∫menes se puede expresar como una funci√≥n $T(x_1,\ldots,x_n)$ definida en el espacio $\mathcal{X}^n\subseteq\mathbb{R}^n$ donde est√°n las im√°genes del vector $(X_{1},X_{2},\ldots,X_{n})$.

Esta funci√≥n $T$ puede devolver valores de $\mathbb{R}$, $\mathbb{R}^2$ o, en general, $\mathbb{R}^k$.

$$T(X_1 , \ldots, X_n)=\sum_{i=1}^{n}X_i,\bar{X},\bar{X}+3, \min{X_1 , \ldots, X_n},$$ 
$$T(X_1 , \ldots, X_n)=\left(\sum_{i=1}^{n}X_i,\sum_{i=1}^{n}(X_i-\bar{X})^2\right),$$
$$T(X_1 , \ldots, X_n)=\left(\min\{X_1 , \ldots, X_n\},\sum_{i=1}^{n}X_i,\sum_{i=1}^{n}(X_i-\bar{X})^2\right),$$
$$T(X_1 , \ldots, X_n)= (X_1 , \ldots, X_n)$$

::: {.definition #def-1.5}
**(Definici√≥n de estad√≠sticos)** Las funciones $T$ que dependen de una muestra aleatoria simple $X_1 , \ldots, X_n$ se llaman **estad√≠sticos**. Dependen de los valores observados, pero no de los
	par√°metros desconocidos que determinan la distribuci√≥n de $X_i$ . 	
:::

Cuando un estad√≠stico $T$ es utilizado con el prop√≥sito de estimar un par√°metro $\theta$ diremos que $T$ es un estimador de $\theta$.	

**Ejemplo de estad√≠stico**

$T(X_1 , \ldots, X_n)=\bar{X}$ es un estimador de $E(X)=\mu$.

En inferencia estad√≠stica interesa saber qu√© estad√≠sticos son suficientes para recoger toda la informaci√≥n que la muestra aporta sobre la distribuci√≥n de la variable aleatoria X muestreada. La respuesta depende de la distribuci√≥n de X.

::: {.definition #def-1.6}
**(Definici√≥n distribuci√≥n en el muestreo)** Dado que $\underset{\sim}{X} =(X_1 ,..., X_n)$ es una variable aleatoria, se tiene que $Y=T(\underset{\sim}{X})=T(X_1 ,..., X_n)$ ser√° tambi√©n una variable aleatoria. La ley de probabilidad de $Y$ se denomina **distribuci√≥n en el muestreo de $Y$** (o distribuci√≥n muestral). Los siguientes resultados dan informaci√≥n sobre algunas caracter√≠sticas de estad√≠sticos definidos a partir de sumas de variables aleatorias.
:::

## Estad√≠sticos definidos a partir de sumas de variables aleatorias

::: {#thm-4}
Sean $X_1,\ldots, X_n$,n n√∫meros reales, sea $\bar{x} = \frac{1}{n} \sum_{i=1}^{n}x_i$ su media aritm√©tica y sea $S_n^2=\frac{\sum_{i=1}^{n}(x_i-\bar{x})^2}{n-1}$ su varianza muestral.

1. $\min_a\sum_{i=1}^{n}(x_i-a)^2=\sum_{i=1}^{n}(x_i-\bar{x})^2$
2. $(n-1)S_n^2=\sum_{i=1}^{n}(x_i-\bar{x})^2=\sum_{i=1}^{n}x_i^2-n\bar{x}^2$
:::

::: {#lem-1}
Sea $X_1,\ldots, X_n$ una muestra aleatoria simple de $X$ y sea $g(x)$ una funci√≥n tal que $E(g(X))$ y $Var(g(X))$ existen. Entonces,

1. $E(\sum_{i=1}^{n}g(X_i))=nE(g(X))$,
2. $Var(\sum_{i=1}^{n}g(X_i))=nVar(g(X))$.
::: 

::: {.proof}
Para la demostraci√≥n ver G√≥mez et al. (2006)
:::

::: {#thm-5}
Sea $X 1,\ldots, X_n$ una muestra aleatoria simple de una poblaci√≥n $X$ con esperanza $\mu$ y varianza $\sigma^2 < \infty$. Sean
$$
		\begin{align*}
		&\bar{X}=\frac{1}{n}\sum_{i=1}^{n}X_i,\ \
		S^2=\frac{\sum_{i=1}^{n}(X_i-\bar{X})^2}{n-1},
		\end{align*}	
$$
la media y la varianza muestrales, respectivamente. Entonces,

a. $E(\bar{X}) = \mu,$
b. $Var(\bar{X}) = \frac{\sigma^2}{n},$
c. $E(S^2) = \sigma^2$.
:::

::: {#thm-6}
Sea $X 1,\ldots, X_n$ una muestra aleatoria simple de una poblaci√≥n $X$ con funci√≥n generadora de momentos $M_X(t)$. La funci√≥n generatriz de momentos de $X$ es
$$\begin{align*}
		&M_{\bar{X}}(t)=\left(M_X\left(\frac{t}{n}\right)\right)^n
		\end{align*}
$$
:::

::: {#thm-7}
**(Combinaci√≥n lineal de normales es normal)**  (Wackerly et al. (2008))
Sean $Y_1,\,Y_2,\cdots,\,Y_n$  variables aleatorias independientes normalmente distribuidas $E(Y_i)=\mu_i$ y $V(Y_i)=\sigma_i^2$ara $i=1,\cdots,\,n$ y sean $a_1,\,a_2,\cdots,\,a_n$ constantes. Si $$U=\sum_{i=1}^na_iY_i$$

entonces $U$ es una variable aleatoria normalmente distribuida con
	$$E(U)=\sum_{i=1}^na_i\mu_i$$
	y 
	$$V(U)=\sum_{i=1}^na_i^2\sigma^2_i$$
:::


**Ejemplo** $X 1,\ldots, X_n$ m.a.s. de $X \sim N(\mu,\sigma^2)$. Entonces, $M_{X}(t)=\exp\left\{\mu t+ \frac{\sigma^2t^2}{2}\right\}$. De ah√≠ que 

$$
	\begin{align*}
	M_{\bar{X}}(t)
	&=\left(\exp\left\{\mu \frac{t}{n}+ \frac{\sigma^2\left(\frac{t}{n}\right)^2}{2}\right\}\right)^n
	\end{align*}
$$


$X 1,\ldots, X_n$ m.a.s. de $X \sim N(\mu,\sigma^2)$. Entonces, $M_{X}(t)=\exp\left\{\mu t+ \frac{\sigma^2t^2}{2}\right\}$. De ah√≠ que 
$$
		\begin{align*}
		M_{\bar{X}}(t)&=\exp\left\{\mu t+ \frac{\sigma^2t^2}{2n}\right\}
		\end{align*}
$$
De ah√≠ que $\bar{X}\sim N(\mu,\frac{\sigma^2}{n})$.

## Muestreo de una distribuci√≥n normal

### Definici√≥n de distribuci√≥n Chi cuadrada

::: {.definition #def-1.7}
(Wackerly et al. (2008)) 
Sea $\nu$ un entero positivo. Se dice que una v.a $Y$ tiene distribuci√≥n **chi cuadrada con $\nu$ grados de libertad** si y s√≥lo si $Y$ es una vriable aleatoria con distribuci√≥n gamma y par√°metros $\alpha=\nu/2$ y $\beta=2$.
:::



::: {#thm-8}
**(Teorema de Fisher)** En el resto del tema supondremos que $X 1,\ldots, X_n$ m.a.s. de una $N(\mu, \sigma^2)$.

a. $\bar{X}$ y $S_n^2$ son variables aleatorias independientes.
b. $\bar{X}\sim N(\mu, \frac{\sigma^2}{n})$
c. $\frac{(n-1)S_n^2}{\sigma^2}\sim \mathcal{X}^2_{n-1}.$
:::


### Distribuciones asociadas a la normal

::: {#thm-9}
(Wackerly et al. (2008)) Sean $Y_1,\,Y_2,\cdots,\,Y_n$ definidas como en el Teorema @thm-7 de Wackerly et al. (2008) y definimos $Z_i$ por 
	$$Z_i=\frac{Y_i-\mu_i}{\sigma_i}$$
	con $i=1,\,2,\cdots,\,n$. Entonces $\sum_{i=1}^nZ_i^2$ tiene distribuici√≥n $\chi^2$ con $n$ grados de libertad. 
:::

::: {#thm-10}
(Wackerly et al. (2008)) Si $Y_1,\,Y_2,\cdots,\,Y_n$ es una muestra aleatoria de una distribuci√≥n normal con media $\mu$ y varianza $\sigma^2$, $Y_i$, $i=1,\,2,\cdots,n$ son v.a's independientes distribu√≠das normalmente, con $E(Y_i)=\mu$ y $V(Y_i)=\sigma^2$.

Entonces $$Z_i=\frac{Y_i-\mu}{\sigma}$$
		son v.a's independientes, $i=1,\,2,\cdots,n$  y 
		$$\sum_{i=1}^nZ_i^2=\sum_{i=1}^n\left(\frac{Y_i-\mu}{\sigma}\right)^2$$tienen una distribuci√≥n $\chi^2$ con $n$ grados de libertad (gl).
:::

::: {#thm-11}
(Wackerly et al. (2008)) Sea $Y_1,\,Y_2,\cdots,\,Y_n$ una muestra aleatoria con media $\mu$ y varianza $\sigma^2$. Entonces
		$$\frac{(n-1)S^2}{\sigma^2}=\frac{1}{\sigma^2}\sum_{i=1}^n(Y_i-\overline{Y})^2$$
		tiene una distribuci√≥n $\chi^2$ con $(n-1)$ gl. $\overline{Y}$ y $S^2$ son v.a independientes.
:::


::: {.definition #def-1.8}
(Wackerly et al. (2008))
Sea $Z$ una v.a normal est√°ndar y sea $W$ una v.a con distribuci√≥n $\chi^2_\nu$. Entonces, si $W$ y $Z$ son ind
		$$T=\frac{Z}{\sqrt{W/\nu}}$$
		se dice que tiene una distribuci√≥n $t$ con $\nu$ grados de libertad.
:::


::: {.callout-note appearance="default" icon="false" title="Observaci√≥n 1" #obs-1}
Si $Y_1,\,Y_2,\cdots,\,Y_n\sim N(\mu,\sigma^2)$ del [Teorema (Combinaci√≥n lineal de normales es normal)](@teo6-3)
$$Z=\frac{\sqrt{n}(\overline{Y}-\mu)}{\sigma}\sim N(0,1)$$
El teorema  [Observaci√≥n 1](#teo7-3) nos dice que
$$W=\frac{(n-1)S^2}{\sigma^2}\sim\chi^2_{n-1}$$
y que $Z$ y $W$ son ind.
:::

::: {.callout-note appearance="default" icon="false" title="Observaci√≥n 2" #obs-2}
Por tanto, de la definici√≥n 7.2 se tiene la siguiente expresi√≥n:
$$
\begin{aligned}
T &= \frac{Z}{\sqrt{W/\nu}} \\
  &= \frac{\sqrt{n}(\overline{Y}-\mu)/\sigma}{\sqrt{\left[\frac{(n-1)S^2}{\sigma^2}\right]/(n-1)}} \\
  &= \sqrt{n}\left(\frac{\overline{Y}-\mu}{S}\right)
\end{aligned}
$$

Tiene distribuci√≥n $t$ con $(n-1)$ grados de libertad.
:::




Como se indica en la [Observaci√≥n 7.1](#obs-normal), esta propiedad...


::: {.definition #def-1.9}
Sean $W_1$ y $W_2$ v.a's independientes con distribuci√≥n $\chi^2$, con $\nu_1$ y $\nu_2$  grados de libertad respectivamente. Entonces se dice que:
		$$F=\frac{W_1/\nu_1}{W_2/\nu_2}$$
		tiene una distribuci√≥n $F$ con $\nu_1$ grados de libertad en el numerador y $\nu_2$ grados de libertad en el denominador.
:::



::: {#rem-3}
Considerando dos muestras aleatorias independientes tomadas de distribuiciones normales
	$$W_1=\frac{(n_1-1)S_1^2}{\sigma_1^2}\sim\chi^2_{n_1-1}$$
	$$W_1=\frac{(n_2-1)S_2^2}{\sigma_2^2}\sim\chi^2_{n_2-1}$$
	$W_1\bot W_2$.    
::: 
::: {#rem-4}
$$
\begin{eqnarray*}
			F&=&\frac{W_1/\nu_1}{W_2/\nu_2}\\
			&=&\frac{[(n_1-1)S_1^2/\sigma_1^2]/(n_1-1)}{[(n_2-1)S_2^2/\sigma_2^2]/(n_2-1)}\\
			&=&\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2}
		\end{eqnarray*}
$$
		tiene distribuci√≥n $F$ con $(n_1-1)$ gl en el numerador y $(n_2-1)$ gl en el denominador    
::: 


```{r}
library(ggplot2)

figura_densidad_asimetrica <- function(alpha = 0.05) {
  shape <- 2
  rate <- 1
  
  # Cuantil de inter√©s
  F_alpha <- qgamma(1 - alpha, shape = shape, rate = rate)
  
  # Datos para la densidad
  x_vals <- seq(0, 10, length.out = 1000)
  df <- data.frame(
    x = x_vals,
    y = dgamma(x_vals, shape = shape, rate = rate)
  )
  
  # Datos para el sombreado
  df_shaded <- subset(df, x >= F_alpha)
  
  # Altura de la flecha
  y_arrow <- dgamma(F_alpha, shape, rate)
  
  ggplot(df, aes(x, y)) +
    geom_line(linewidth = 1.2) +
    geom_area(data = df_shaded, aes(x, y), fill = "black", alpha = 0.3) +
    
    # Flecha vertical
    annotate("segment", x = F_alpha, xend = F_alpha, y = 0, yend = y_arrow,
             arrow = arrow(length = unit(0.15, "cm")), color = "black") +
    
    # Etiqueta F_Œ±
    annotate("text", x = F_alpha, y = 0, label = expression(F[alpha]),
             vjust = 1.5, hjust = 1.1, size = 5) +
    
    # Etiqueta Œ±
    annotate("text", x = F_alpha, y = y_arrow, label = expression(alpha),
             vjust = -1, size = 5) +
    
    labs(x = "u", y = expression(f(u))) +
    theme_minimal(base_size = 14)
}
figura_densidad_asimetrica()
```

**Ejercicios con la distribuci√≥n F en R**

A continuaci√≥n se presentan dos ejercicios t√≠picos en los que anteriormente se utilizaban tablas de valores cr√≠ticos de la distribuci√≥n F. Ahora, gracias a funciones como `qf()` y `var.test()` en R, estos an√°lisis pueden hacerse de manera precisa y autom√°tica.

---

**Ejercicio 1: Contrastar dos varianzas**

**Enunciado:**  
Se tienen dos muestras independientes con:
- Tama√±os: $n_1 = 6$, $n_2 = 10$
- Varianzas muestrales: $s_1^2 = 25$, $s_2^2 = 10$

¬øExiste evidencia para afirmar que las varianzas poblacionales son diferentes al nivel de significancia del 5%?

**Soluci√≥n en R:**

```{r}
# Datos
s1_sq <- 25
s2_sq <- 10
n1 <- 6
n2 <- 10

# Estad√≠stico F observado (mayor varianza sobre menor)
F_obs <- s1_sq / s2_sq
gl1 <- n1 - 1
gl2 <- n2 - 1

# Cuantiles cr√≠ticos para prueba bilateral al 5%
alpha <- 0.05
F_inf <- qf(alpha / 2, df1 = gl1, df2 = gl2)
F_sup <- qf(1 - alpha / 2, df1 = gl1, df2 = gl2)

# Decisi√≥n
cat("F observado:", round(F_obs, 3), "\n")
cat("Intervalo de aceptaci√≥n: [", round(F_inf, 3), ",", round(F_sup, 3), "]\n")

if (F_obs < F_inf || F_obs > F_sup) {
  cat("Se rechaza H0: las varianzas son significativamente diferentes.\n")
} else {
  cat("No se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.\n")
}
``` 
**Ejercicio 2: Obtener un valor cr√≠tico F directamente**

**Enunciado:**  
Calcular el valor cr√≠tico $F_{0.05,\,5,\,9}$ para una prueba unilateral con nivel de significancia del 5%.

Este valor se usa, por ejemplo, cuando se contrasta si una varianza es significativamente mayor que otra, con:
- $\alpha = 0.05$
- $\text{gl}_1 = 5$ (grados de libertad del numerador)
- $\text{gl}_2 = 9$ (grados de libertad del denominador)

**C√°lculo en R:**

```{r}
# Valor cr√≠tico F para prueba unilateral con alpha = 0.05
qf(0.95, df1 = 5, df2 = 9)
```
El valor cr√≠tico es $F_{0.05,\,5,\,9}=3.478$. Si el estad√≠stico F observado es mayor que este valor, se rechaza la hip√≥tesis nula de igualdad de varianzas a favor de que la varianza del numerador es mayor.

::: {#exm-1}
$$Y_1^1,\,Y_2^1\,\cdots,\,Y_{n_1}^1\sim N(\mu_1,\,\sigma^2)$$
			$$Y_1^2,\,Y_2^2\,\cdots,\,Y_{n_2}^2\sim N(\mu_2,\,\sigma^2)$$
			$P\left(\frac{S_1^2}{S_2^2}\leq b\right)=0.95$ con $n_1=6$ y $n_2=10$, ?`$b$?  
			
Como $n_1=6$ y $n_2=10$ y las varianzas poblacionales son iguales, entonces 
	$\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2}=\frac{S_1^2}{S_2^2}\sim F_{5,9}$
	$$P\left(\frac{S_1^2}{S_2^2}\leq b\right)= F_{5,9}(b)=0.95$$
	entonces $qf(0.95,\,5,\,9)=b$, $b=3.48$.
::: 

**Simulaci√≥n del comportamiento del promedio muestral**

Simulamos 1000 repeticiones del promedio muestral a partir de una distribuci√≥n exponencial con media \( \mu = 10 \), para distintos tama√±os de muestra \( n \).
```{r}
simular_promedios <- function(n, repeticiones = 1000, media = 10) {
  promedios <- replicate(repeticiones, mean(rexp(n, rate = 1 / media)))
  data.frame(
    `n` = n,
    `Promedio repetido` = mean(promedios),
    `Media te√≥rica` = media,
    `Varianza repetida` = var(promedios),
    `Varianza te√≥rica` = media^2 / n
  )
}

# Evaluar para varios tama√±os
tama√±os <- c(5, 10, 25, 50, 100)
resultados <- do.call(rbind, lapply(tama√±os, simular_promedios))
knitr::kable(resultados, digits = 5)
```

::: {#thm-12}
Sean $Y_1,\,Y_2,\cdots,\,Y_n$  v.a's  con funciones generadoras de momentos $m(t)$  y $m_1(t),\,m_2(t),\cdots,$ respectivamente. Si 
	$$\lim_{n\rightarrow\infty}m_n(t)=m(t)\mbox{ para toda $t$ real,}$$
	entonces la funci√≥n de distribuci√≥n de $Y_n$ converge hacia la funci√≥n de distribuci√≥n de $Y$ cuando $n\rightarrow\infty$
:::


## Leyes de los Grandes N√∫meros y Teorema Central del L√≠mite

### Leyes de los grandes n√∫meros
::: {.definition #def-1.10}
Una sucesi√≥n de variables aleatorias converge en media a $X$, y se denota por $X_{n}\xrightarrow{cm}X$ , si para cualquier $\epsilon>0$ se tiene que:  
\[\lim _{n\to \infty }E(\left|X_{n}-X\right|)=0,\]
siempre que dicha esperanza exista.\\

De forma an√°loga se define convergencia en media de orden r si:
$$\lim _{n\to \infty }E(\left|X_{n}-X\right|^r)=0,$$

Cuando $r=2$ se dice que se tiene convergencia en media cuadr√°tica

$$\lim _{n\to \infty }E(\left|X_{n}-X\right|^2)=0,$$
:::


### Relaciones entre tipos de convergencias

## Diagrama de convergencias

### Diagrama de relaciones entre tipos de convergencia

![Diagrama de convergencias](images/esquema.png)

### Ley d√©bil de los grandes n√∫meros
::: {#thm-13}
Sea $X 1,\ldots, X_n$ una sucesi√≥n de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante $C$, independiente de $n$. Sea $S_n = \sum_{i=1  }^{n}X_i$. Entonces
$$
\begin{align}
E\left(\left|\frac{S_n-E(S_n)}{n}\right|^2\right)\leq \frac{C}{n}
\end{align}
$$
y, como consecuencia $$\lim _{n\to \infty }\frac{S_n-E(S_n)}{n}=0$$ en el sentido de la convergencia en **media cuadr√°tica**.
:::

Los resultados que garantizan la convergencia casi segura de la media muestral se conocen como leyes fuertes de los grandes n√∫meros. Se enuncia a continuaci√≥n una **ley fuerte** para variables con segundos momentos finitos e
incorreladas.


### Ley fuerte de los grandes n√∫meros

::: {#thm-line}
Sea $X 1,\ldots, X_n$ una sucesi√≥n de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante $C$, independiente de $n$. Sea $S_n = \sum_{i=1  }^{n}X_i$. Entonces
		$$
		\begin{align}
		E\left(\left|\frac{S_n-E(S_n)}{n}\right|^2\right)\leq \frac{C}{n}
		\end{align}
		$$
y, como consecuencia $$\lim _{n\to \infty }\frac{S_n-E(S_n)}{n}=0$$ en el sentido de la **casi segura**.
:::
	

## Teorema central del l√≠mite
::: {#thm-line}
**Central de L√≠mite** Sean $Y_1,\,Y_2,\cdots,\,Y_n$  v.a's iid ( no se precisa de que distribuci√≥n se generan) con $E[Y_i]=\mu$ y $V[Y_i]=\sigma^2<\infty$. Definamos 
	$$U_n=\frac{\sum_{i=1}^nY_i-n\mu}{\sigma\sqrt{n}}=\frac{\overline{Y}-\mu}{\sigma/\sqrt{n}}\mbox{ donde} \overline{Y}=\frac{1}{n}\sum_{i=1}^nY_i$$
Entonces la funci√≥n de distribuci√≥n de $U_n$ converge hacia la funci√≥n de distribuci√≥n normal est√°ndar cuando n tiende a infinito . Esto es,
$$\lim_{n\rightarrow\infty}P(U_n\leq u)=\int_{-\infty}^u\frac{1}{\sqrt{2\pi}}e^{-t^2/2}dt, \forall u$$ 

:::




<!-- ## Ejemplo -->

<!-- ::: {#thm-line} -->

<!-- The equation of any straight line, called a linear equation, can be written as: -->

<!-- $$ -->
<!-- y = mx + b -->
<!-- $$ -->
<!-- ::: -->

<!-- See @thm-line. -->
## Ejercicio 

::: {#exr-1.1}
Para $i=1,...,n$ sea $\{X_{i}\}$ variables aleatorias independientes. Tal que 
\begin{align*}
	P(X_n=1)&=p_n,\\
	P(X_n=0)&=1-p_n.
\end{align*}

¬øBajo qu√© condiciones de $p_n$, $X_{n}\xrightarrow{P}0$ cuando $n\to \infty$?
:::

::: {#exr-1.2}
Sea $\{X_{i}\}$ v.a.i.i.d, tal que $E(X_{i})=\mu$ y $Var(X_{i})=\sigma^2$ para todo $i=1,...,n$. Muestre que $E(\hat{X}_{n}-\mu)^2\xrightarrow{}0$ cuando $n\to \infty$.
::: 

::: {#exr-1.3}
Para $i=1,...,n$ sea $\{X_{i}\}$ variables aleatorias reales. Supongase que $\sqrt{n}(X_n-\mu)\xrightarrow{d}N(0,\sigma^2)$. Demostrar que $X_n\xrightarrow{P}\mu$, cuando $n\to \infty$.
::: 


::: {#exr-1.4}
Sea $S={1,2,3,4}$ y sobre los subconjuntos de $S$ se definen las siguientes variables aleatorias con funci√≥n de distribuci√≥n uniforme  discreta de la siguiente manera:
\begin{align*}
&X_{n}(1)=X_{n}(2)=1,\ \
X_n(3) = X_n(4) = 0, n=1,2,...\\ 
&X(1)=X(2)=0,\ \
X(3) = X(4) = 1.
\end{align*}
Muestre que $X_n\xrightarrow{d}X$, pero no converge en probabilidad cuando $n\to \infty$
:::


::: {#exr-1.5}

Demuestre la Desigualdad de Chebychev que establece los siguiente. Si $X$ es una variable aleatoria tal que $\exists E(X^2)$, se tiene
	\begin{align*}
	P(|X-E(X)|\geq k)\leq \frac{Var[X]}{k^2}, \forall k > 0
	\end{align*}
:::


::: {#exr-1.6}
Sea $g(Y)=Y-\mu$, donde $Y$ es una v.a normalmente distribuida con media $\mu$ y varianza $\sigma^2$. Encuentre la funci√≥n generadora de momento para $g(Y)$.
:::


::: {#exr-1.7}
%Denotemos con $m_X(t)$ y $m_Y(t)$ las funciones generadoras de momentos de las v.a's $X$ y $Y$, respectivamente. 
Demuestre que si existen funciones generadoras de momento y $M_X(t)=M_Y(t)$ para toda $t$, entonces $X$, y $Y$ tienen la misma distribuci√≥n de probabilidad.
::: 

::: {#exr-1.8}
Sea $Y$ una variable aleatoria normalmente distribuida con media $\mu$ y varianza $\sigma^2$. Demuestre que 
$$Z=\frac{Y-\mu}{\sigma}$$
tiene una distribuci√≥n normal est√°ndar, una distribuci√≥n con media 0 y varianza 1.
:::

::: {#exr-1.9}
Demostrar el siguiente teorema. 
::: 

::: {#thm-1.16}

Sea $X 1,\ldots, X_n$ una muestra aleatoria simple de una poblaci√≥n $X$ con funci√≥n generadora de momentos $M_X(t)$. La funci√≥n generatriz de momentos de $X$ es 
\begin{align*}
	&M_{\bar{X}}(t)=\left(M_X\left(\frac{t}{n}\right)\right)^n
\end{align*}	 .
::: 

::: {#exr-1.10}

Una m√°quina embotelladora puede ser regulada para que descargue un promedio de $\mu$ onzas por botella. Se ha observado que la cantidad de l√≠quido dosificado por la m\'aquina est√° distribuida normalmente con $\sigma=1$ onza. Una muestra de $n=9$ botellas se selecciona aleatoriamente de la producci√≥n de la m√°quina en un d√≠a determinado (todas embotelladas  con el mismo ajuste de la m√°quina) y las onzas de contenido l√≠quido se miden para cada una. Determine la probabilidad de que la media muestral se encuentre a no m√°s de .3 onza de la verdadera media $\mu$ para el ajuste seleccionado de la m√°quina
::: 

::: {#exr-1.11}
Bajo el mismo contexto del Ejemplo 7.1. Determinar ?`Cu√°ntas observaciones deben de estar inclu√≠das en la muestra si deseamos que $\overline{Y}$ se encuentre a no m√°s de 0.3 onzas de $\mu$ con probabilidad 0.95?
::: 


::: {#exr-1.12}
La resistencia  a la tensi√≥n para un tipo de alambre se distribuye $N(\mu,\,\sigma^2)$. $Y_i$: La resistencia a la tensi√≥n para el trozo $i$, se mide para $i=1,\cdots,\,6$.

La media $\mu$ y la varianza $\sigma^2$ pueden ser estimadas por $\overline{X}$ y $S^2$, respectivamente $\sigma_{\overline{Y}}^2=\frac{\sigma^2}{n}$ puede ser estimada por $\frac{S^2}{n}$. Encuentre la probabilidad aproximada de que $\overline{Y}$ est√© dentro de $\frac{2S}{n}$ de la verdadera media poblacional $\mu$.
:::


::: {#exr-1.13}
Sean $Y_1,\,Y_2,\cdots,\,Y_n$  v.a's  con funciones generadoras de momentos $m(t)$  y $m_1(t),\,m_2(t),\cdots,$ respectivamente. Si 
$$\lim_{n\rightarrow\infty}m_n(t)=m(t)\mbox{ para toda $t$ real,}$$
entonces la funci√≥n de distribuci√≥n de $Y_n$ converge hacia la funci√≥n de distribuci√≥n de $Y$ cuando $n\rightarrow\infty$
:::



---
## Referencias

- **G√≥mez, Guadalupe**, & **Delicado, Pedro** (2006). *Curso de Inferencia y Decisi√≥n*. Departament d‚ÄôEstad√≠stica i Investigaci√≥ Operativa, Universitat Polit√®cnica de Catalunya.

- **Wackerly, D. D., Mendenhall, W.**, & **Scheaffer, R. L.** (2008). **Estad√≠stica matem√°tica con aplicaciones** (7¬™ ed.). Cengage Learning.

- **Roussas, G. G.** (1997). **A Course in Mathematical Statistics** (2nd ed.). Academic Press.
