<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Biviana M. Suárez Sierra">
<title>Inferencia Estadística</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-241b0f728d524ab724cf38981e173e36.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./index.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">INTRODUCCIÓN</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Inferencia Estadística</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">INTRODUCCIÓN</span></span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#introducci%C3%B3n" id="toc-introducción" class="nav-link active" data-scroll-target="#introducci%C3%B3n"><span class="header-section-number">1</span> INTRODUCCIÓN</a>
  <ul class="collapse">
<li><a href="#c%C3%B3mo-navegar-este-libro" id="toc-cómo-navegar-este-libro" class="nav-link" data-scroll-target="#c%C3%B3mo-navegar-este-libro"><span class="header-section-number">1.1</span> ¿Cómo navegar este libro?</a></li>
  <li><a href="#bienvenidao" id="toc-bienvenidao" class="nav-link" data-scroll-target="#bienvenidao"><span class="header-section-number">1.2</span> ¡Bienvenida/o!</a></li>
  </ul>
</li>
  <li>
<a href="#datos-y-modelos" id="toc-datos-y-modelos" class="nav-link" data-scroll-target="#datos-y-modelos"><span class="header-section-number">2</span> DATOS Y MODELOS</a>
  <ul class="collapse">
<li><a href="#fen%C3%B3meno-aleatorio-y-variable-observada" id="toc-fenómeno-aleatorio-y-variable-observada" class="nav-link" data-scroll-target="#fen%C3%B3meno-aleatorio-y-variable-observada"><span class="header-section-number">2.1</span> Fenómeno aleatorio y variable observada</a></li>
  <li><a href="#incertidumbre-inductiva-vs.-estoc%C3%A1stica" id="toc-incertidumbre-inductiva-vs.-estocástica" class="nav-link" data-scroll-target="#incertidumbre-inductiva-vs.-estoc%C3%A1stica"><span class="header-section-number">2.2</span> Incertidumbre inductiva vs.&nbsp;estocástica</a></li>
  </ul>
</li>
  <li>
<a href="#variable-aleatoria" id="toc-variable-aleatoria" class="nav-link" data-scroll-target="#variable-aleatoria"><span class="header-section-number">3</span> VARIABLE ALEATORIA</a>
  <ul class="collapse">
<li><a href="#variables-y-vectores-aleatorios" id="toc-variables-y-vectores-aleatorios" class="nav-link" data-scroll-target="#variables-y-vectores-aleatorios"><span class="header-section-number">3.1</span> Variables y vectores aleatorios</a></li>
  <li><a href="#distribuci%C3%B3n-de-una-variable-aleatoria.-funciones-de-distribuci%C3%B3n-de-probabilidad-y-de-densidad" id="toc-distribución-de-una-variable-aleatoria.-funciones-de-distribución-de-probabilidad-y-de-densidad" class="nav-link" data-scroll-target="#distribuci%C3%B3n-de-una-variable-aleatoria.-funciones-de-distribuci%C3%B3n-de-probabilidad-y-de-densidad"><span class="header-section-number">3.2</span> Distribución de una variable aleatoria. Funciones de distribución, de probabilidad y de densidad</a></li>
  <li><a href="#esperanza-y-varianza" id="toc-esperanza-y-varianza" class="nav-link" data-scroll-target="#esperanza-y-varianza"><span class="header-section-number">3.3</span> Esperanza y varianza</a></li>
  <li><a href="#funci%C3%B3n-generadora-de-momentos" id="toc-función-generadora-de-momentos" class="nav-link" data-scroll-target="#funci%C3%B3n-generadora-de-momentos"><span class="header-section-number">3.4</span> Función generadora de momentos</a></li>
  <li><a href="#muestra-aleatoria-simple" id="toc-muestra-aleatoria-simple" class="nav-link" data-scroll-target="#muestra-aleatoria-simple"><span class="header-section-number">3.5</span> Muestra aleatoria simple</a></li>
  <li><a href="#modelo-param%C3%A9trico" id="toc-modelo-paramétrico" class="nav-link" data-scroll-target="#modelo-param%C3%A9trico"><span class="header-section-number">3.6</span> Modelo paramétrico</a></li>
  <li><a href="#sumas-de-variables-aleatorias" id="toc-sumas-de-variables-aleatorias" class="nav-link" data-scroll-target="#sumas-de-variables-aleatorias"><span class="header-section-number">3.7</span> Sumas de variables aleatorias</a></li>
  <li><a href="#estad%C3%ADsticos-definidos-a-partir-de-sumas-de-variables-aleatorias" id="toc-estadísticos-definidos-a-partir-de-sumas-de-variables-aleatorias" class="nav-link" data-scroll-target="#estad%C3%ADsticos-definidos-a-partir-de-sumas-de-variables-aleatorias"><span class="header-section-number">3.8</span> Estadísticos definidos a partir de sumas de variables aleatorias</a></li>
  <li>
<a href="#muestreo-de-una-distribuci%C3%B3n-normal" id="toc-muestreo-de-una-distribución-normal" class="nav-link" data-scroll-target="#muestreo-de-una-distribuci%C3%B3n-normal"><span class="header-section-number">3.9</span> Muestreo de una distribución normal</a>
  <ul class="collapse">
<li><a href="#definici%C3%B3n-de-distribuci%C3%B3n-chi-cuadrada" id="toc-definición-de-distribución-chi-cuadrada" class="nav-link" data-scroll-target="#definici%C3%B3n-de-distribuci%C3%B3n-chi-cuadrada"><span class="header-section-number">3.9.1</span> Definición de distribución Chi cuadrada</a></li>
  <li><a href="#distribuciones-asociadas-a-la-normal" id="toc-distribuciones-asociadas-a-la-normal" class="nav-link" data-scroll-target="#distribuciones-asociadas-a-la-normal"><span class="header-section-number">3.9.2</span> Distribuciones asociadas a la normal</a></li>
  </ul>
</li>
  <li>
<a href="#leyes-de-los-grandes-n%C3%BAmeros-y-teorema-central-del-l%C3%ADmite" id="toc-leyes-de-los-grandes-números-y-teorema-central-del-límite" class="nav-link" data-scroll-target="#leyes-de-los-grandes-n%C3%BAmeros-y-teorema-central-del-l%C3%ADmite"><span class="header-section-number">3.10</span> Leyes de los Grandes Números y Teorema Central del Límite</a>
  <ul class="collapse">
<li><a href="#leyes-de-los-grandes-n%C3%BAmeros" id="toc-leyes-de-los-grandes-números" class="nav-link" data-scroll-target="#leyes-de-los-grandes-n%C3%BAmeros"><span class="header-section-number">3.10.1</span> Leyes de los grandes números</a></li>
  <li><a href="#relaciones-entre-tipos-de-convergencias" id="toc-relaciones-entre-tipos-de-convergencias" class="nav-link" data-scroll-target="#relaciones-entre-tipos-de-convergencias"><span class="header-section-number">3.10.2</span> Relaciones entre tipos de convergencias</a></li>
  </ul>
</li>
  <li>
<a href="#diagrama-de-convergencias" id="toc-diagrama-de-convergencias" class="nav-link" data-scroll-target="#diagrama-de-convergencias"><span class="header-section-number">3.11</span> Diagrama de convergencias</a>
  <ul class="collapse">
<li><a href="#diagrama-de-relaciones-entre-tipos-de-convergencia" id="toc-diagrama-de-relaciones-entre-tipos-de-convergencia" class="nav-link" data-scroll-target="#diagrama-de-relaciones-entre-tipos-de-convergencia"><span class="header-section-number">3.11.1</span> Diagrama de relaciones entre tipos de convergencia</a></li>
  <li><a href="#ley-d%C3%A9bil-de-los-grandes-n%C3%BAmeros" id="toc-ley-débil-de-los-grandes-números" class="nav-link" data-scroll-target="#ley-d%C3%A9bil-de-los-grandes-n%C3%BAmeros"><span class="header-section-number">3.11.2</span> Ley débil de los grandes números</a></li>
  <li><a href="#ley-fuerte-de-los-grandes-n%C3%BAmeros" id="toc-ley-fuerte-de-los-grandes-números" class="nav-link" data-scroll-target="#ley-fuerte-de-los-grandes-n%C3%BAmeros"><span class="header-section-number">3.11.3</span> Ley fuerte de los grandes números</a></li>
  </ul>
</li>
  <li><a href="#teorema-central-del-l%C3%ADmite" id="toc-teorema-central-del-límite" class="nav-link" data-scroll-target="#teorema-central-del-l%C3%ADmite"><span class="header-section-number">3.12</span> Teorema central del límite</a></li>
  <li><a href="#referencias" id="toc-referencias" class="nav-link" data-scroll-target="#referencias"><span class="header-section-number">3.13</span> Referencias</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">Inferencia Estadística</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Biviana M. Suárez Sierra </p>
          </div>
  </div>
    
  
    
  </div>
  


</header><section id="introducción" class="level1" data-number="1"><h1 data-number="1">
<span class="header-section-number">1</span> INTRODUCCIÓN</h1>
<p>Este libro ha sido concebido como un recurso integral para el estudio riguroso y aplicado de la inferencia estadística. Está dirigido a estudiantes de programas de estadística, matemáticas aplicadas y disciplinas afines, y busca fortalecer la comprensión conceptual y técnica de los fundamentos que sustentan el análisis estadístico moderno.</p>
<p>A lo largo de sus capítulos, el lector encontrará un desarrollo progresivo de los siguientes temas:</p>
<ul>
<li>Fundamentos de la probabilidad y los modelos estadísticos.</li>
<li>Propiedades de las variables aleatorias y familias paramétricas comunes.</li>
<li>Principios clave para la reducción de datos: suficiencia, completitud y verosimilitud.</li>
<li>Construcción y evaluación de estimadores puntuales.</li>
<li>Estimación por intervalos y su interpretación inferencial.</li>
<li>Contrastes de hipótesis y principios de optimalidad en pruebas estadísticas.</li>
<li>Introducción a la teoría de la decisión y sus aplicaciones en inferencia.</li>
</ul>
<p>El material combina el rigor formal con ejemplos y aplicaciones que ilustran cómo los métodos estadísticos permiten extraer conclusiones válidas a partir de datos.</p>
<blockquote class="blockquote">
<p>Este libro se encuentra en construcción. Los capítulos se irán publicando progresivamente y pueden estar sujetos a revisiones o mejoras. Por ahora, son sólo trozos de contenido de otros libros o notas de clase de una selección personal y que se irán referenciando en cada capítulo.</p>
</blockquote>
<hr>
<section id="cómo-navegar-este-libro" class="level2" data-number="1.1"><h2 data-number="1.1" class="anchored" data-anchor-id="cómo-navegar-este-libro">
<span class="header-section-number">1.1</span> ¿Cómo navegar este libro?</h2>
<ul>
<li>Usa el <strong>índice lateral izquierdo</strong> para acceder a cada capítulo y subcapítulo.</li>
<li>Haz uso del <strong>buscador</strong> para encontrar conceptos o términos clave.</li>
<li>Revisa los apartados de “Lista de problemas” incluidos al final de cada sección para practicar.</li>
</ul>
<hr></section><section id="bienvenidao" class="level2" data-number="1.2"><h2 data-number="1.2" class="anchored" data-anchor-id="bienvenidao">
<span class="header-section-number">1.2</span> ¡Bienvenida/o!</h2>
<p>Te invito a recorrer este texto con atención, curiosidad y sentido crítico.<br>
Espero que este libro te acompañe, rete y apoye en tu formación como profesional en ciencias de datos o áreas relacionadas.</p>
<!-- 1. [Datos y modelos](Datos%20y%20modelos.qmd)   -->
<!-- 2. [Variable aleatoria](Variable%20aleatoria.qmd)   -->
</section></section><section id="datos-y-modelos" class="level1" data-number="2"><h1 data-number="2">
<span class="header-section-number">2</span> DATOS Y MODELOS</h1>
<p>En esta sección establecemos la base conceptual para el análisis estadístico, diferenciando claramente entre el fenómeno aleatorio observado y la medida de probabilidad que lo describe.</p>
<section id="fenómeno-aleatorio-y-variable-observada" class="level2" data-number="2.1"><h2 data-number="2.1" class="anchored" data-anchor-id="fenómeno-aleatorio-y-variable-observada">
<span class="header-section-number">2.1</span> Fenómeno aleatorio y variable observada</h2>
<p>“Se observa una realización de un fenómeno aleatorio, digamos X. Este puede ser un elemento aleatorio de varios tipos: número (variable aleatoria), un vector de dimensión finita (vector aleatorio), una función, etc.</p>
<p>La premisa principal es que el carácter aleatorio de X se concibe como una realización de un fenómeno aleatorio que tiene una distribución de probabilidad P, donde la distribución P es desconocida ya sea en su totalidad o en algún detalle específico (por ejemplo, su soporte, su media, etc.). Es de interés conocer P. Si la medida de probabilidad P fuese conocida, entonces no hay problema estadístico propiamente, pues el problema estadístico tiene que ver con <em>inferir</em> la propiedad desconocida de P con base en X.” [Ver referencia 1]</p>
<ul>
<li>
<strong>Definición de X</strong>
<ul>
<li>
<strong>X</strong> puede ser un valor real <span class="math inline">\(X \in \mathbb{R}\)</span>, un vector en <span class="math inline">\(\mathbb{R}^n\)</span>, o incluso una función <span class="math inline">\(\;X: [0,1]\to\mathbb{R}\)</span>.<br>
</li>
</ul>
</li>
<li>
<strong>Medida de probabilidad P</strong>
<ul>
<li>Desconocida: soporte, media, varianza, etc.<br>
</li>
<li>Objetivo estadístico: <em>inferir</em> características de (P) a partir de la muestra (la realización de X).</li>
</ul>
</li>
</ul></section><section id="incertidumbre-inductiva-vs.-estocástica" class="level2" data-number="2.2"><h2 data-number="2.2" class="anchored" data-anchor-id="incertidumbre-inductiva-vs.-estocástica">
<span class="header-section-number">2.2</span> Incertidumbre inductiva vs.&nbsp;estocástica</h2>
<p>“La observación <strong>X</strong> está dada, por lo que no hay incertidumbre tal como la hay en la teoría de probabilidad desarrollada anteriormente en el curso. Antes, fue concebida una estructura <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span> para enfrentar el que haya incertidumbre acerca del valor de <strong>X</strong>. En el problema estadístico, el valor de <strong>X</strong> ha sido observado, y la incertidumbre radica en otro punto: radica en que existe duda acerca de cuál <strong>P</strong> es la que produjo el valor <strong>X</strong>. En algunas ocasiones se utilizan los términos <em>incertidumbre estocástica</em> e <em>incertidumbre inductiva</em> para distinguir estos dos tipos. Es común que estos se confundan entre sí, porque en estadística matemática la teoría de probabilidad constituye también una de las maneras naturales de afrontar la cuantificación de incertidumbre inductiva. En cualquier caso, el concebir a <strong>P</strong> como medida de probabilidad es la base para formular soluciones a la incertidumbre inductiva. Con este lenguaje, probabilidad y estadística son problemas diferentes y de cierta manera inversos. Teoría de probabilidad tiene que ver con cuantificar incertidumbre acerca de <strong>X</strong> y teoría estadística con cuantificar incertidumbre acerca de <strong>P</strong> a la luz de haber ya observado <strong>X</strong>.”[Ver referencia 1]</p>
<ul>
<li>
<strong>Incertidumbre estocástica</strong>: duda previa sobre el valor de X, modelada por <span class="math inline">\((\Omega,\mathcal{F},P)\)</span>.<br>
</li>
<li>
<strong>Incertidumbre inductiva</strong>: tras observar X, la incertidumbre se desplaza a la ley generadora P.</li>
</ul>
<hr>
<section id="ejemplos-en-matemática-aplicada-e-ingeniería-de-sistemas" class="level4" data-number="2.2.0.1"><h4 data-number="2.2.0.1" class="anchored" data-anchor-id="ejemplos-en-matemática-aplicada-e-ingeniería-de-sistemas">
<span class="header-section-number">2.2.0.1</span> Ejemplos en Matemática Aplicada e Ingeniería de Sistemas</h4>
<ol type="1">
<li>
<strong>Modelado de tiempos de respuesta en redes</strong>
<ul>
<li>
<span class="math inline">\(X\)</span>: tiempo de llegada de paquetes (variable continua).<br>
</li>
<li>
<span class="math inline">\(P\)</span>: distribución de retardo desconocida; objetivo: estimar parámetros de una ley de colas M/M/1.</li>
</ul>
</li>
<li>
<strong>Estimación de parámetros en ecuaciones diferenciales estocásticas</strong>
<ul>
<li>
<span class="math inline">\(X(t)\)</span>: trayectoria observada de un proceso de Itô.<br>
</li>
<li>
<span class="math inline">\(P\)</span>: ley del proceso (por ejemplo, coeficientes de difusión y deriva), inferidos a partir de trayectorias discretas.</li>
</ul>
</li>
<li>
<strong>Calibración de sensores en sistemas de control</strong>
<ul>
<li>
<span class="math inline">\(X\)</span>: lecturas del sensor (vector aleatorio).<br>
</li>
<li>
<span class="math inline">\(P\)</span>: distribución conjunta desconocida de ruido; se estima para diseñar filtros de Kalman óptimos.</li>
</ul>
</li>
</ol>
<hr>
<p>Con esta distinción clara entre dato observado y modelo probabilístico, estamos listos para construir estimadores y desarrollar la inferencia estadística en las secciones siguientes.</p>
</section></section></section><section id="variable-aleatoria" class="level1" data-number="3"><h1 data-number="3">
<span class="header-section-number">3</span> VARIABLE ALEATORIA</h1>
<section id="variables-y-vectores-aleatorios" class="level2" data-number="3.1"><h2 data-number="3.1" class="anchored" data-anchor-id="variables-y-vectores-aleatorios">
<span class="header-section-number">3.1</span> Variables y vectores aleatorios</h2>
<p>Consideramos un experimento aleatorio cuyos resultados pertenecen al espacio muestral Ω. Modelamos este proceso suponiendo que existe una terna <span class="math inline">\((\Omega, \mathcal{A}, P),\)</span> donde:</p>
<ul>
<li>
<span class="math inline">\(\Omega\)</span> es el espacio muestra,<br>
</li>
<li>
<span class="math inline">\(\mathcal{P}(\Omega)\)</span> es el conjunto de partes de Ω,<br>
</li>
<li>
<span class="math inline">\(\mathcal{A}\in\mathcal{P}(\Omega)\)</span> es una σ-álgebra,<br>
</li>
<li>
<span class="math inline">\(P\colon \mathcal{A} \to [0,1]\)</span> es una medida de probabilidad que refleja las características aleatorias del experimento realizado.</li>
</ul>
<p>A esta terna se le llama <strong>espacio de probabilidad</strong>.</p>
<p>Los resultados de un experimento aleatorio no son analizados “en bruto”, sino que se les da una representación numérica que facilita su tratamiento. Esto se logra introduciendo variables aleatorias, que asocian cada resultado <span class="math inline">\(\omega\in \Omega\)</span> con un valor numérico o vectorial, y sobre las cuales luego aplicamos técnicas de inferencia estadística.</p>
<p>En todo estudio estadístico partimos de un <strong>experimento aleatorio</strong> cuyo conjunto de resultados posibles se denomina <strong>espacio muestral</strong> Ω. Para cuantificar dichos resultados definimos las siguientes estructuras:</p>
<div id="def-1.1" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.1</strong></span> <strong>(Variables Aleatorias)</strong> Sea <span class="math inline">\((\Omega,\mathcal{A},P)\)</span> un espacio de probabilidad. Una <strong>variable aleatoria</strong> es una función <span class="math inline">\(X\colon (\Omega,\mathcal{A})\;\longrightarrow\; (\mathbb{R},\mathcal{B}),\)</span> tal que para todo <span class="math inline">\(B\in\mathcal{B}\)</span> (la <span class="math inline">\(\sigma\)</span>-álgebra de Borel en ℝ), <span class="math inline">\(X^{-1}(B)\;=\;\{\omega\in\Omega : X(\omega)\in B\}\;\in\;\mathcal{A}.\)</span></p>
</div>
<p>Si el espacio muestral <span class="math inline">\(\Omega\)</span> es <strong>finito o numerable</strong>, diremos que es un espacio <strong>discreto</strong> y las variables aleatorias asociadas al experimento normalmente estarán definidas como <span class="math inline">\(X\colon \Omega \;\longrightarrow\; \mathbb{Z}.\)</span></p>
<p>Si <span class="math inline">\(\Omega\)</span> es <strong>no numerable</strong>, entonces diremos que es un espacio <strong>continuo</strong> y <span class="math inline">\(X\colon \Omega \;\longrightarrow\; \mathbb{R}.\)</span></p>
<hr>
<div id="def-1.2" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.2</strong></span> Un <strong>vector aleatorio</strong> de dimensión <span class="math inline">\(n\)</span> es <span class="math inline">\(\mathbf{X} = (X_1,\dots,X_n)\colon(\Omega,\mathcal{A})\longrightarrow(\mathbb{R}^n,\mathcal{B}^n),\)</span> donde cada componente <span class="math inline">\(X_i\)</span> es variable aleatoria y <span class="math inline">\(\mathcal{B}^n\)</span> la <span class="math inline">\(\sigma\)</span>-álgebra de Borel en ℝⁿ.</p>
</div>
<hr>
<p><strong>Ejemplos</strong> <strong>Lanzamiento de dos monedas</strong></p>
<p>Sea <span class="math inline">\(\Omega =\{\,CC,\;C-,\;-C,\;--\},\)</span> donde <span class="math inline">\(C\)</span> = “cara” y <span class="math inline">\(-\)</span> = “cruz”. Podemos definir:<br><span class="math inline">\(X_1(\omega) = \text{número de caras en }\omega.\)</span> <span class="math inline">\(X_2(\omega) = 2 - X_1(\omega)\;=\; \text{número de cruces}.\)</span> <span class="math inline">\(X_3(\omega) = \bigl(X_1(\omega)\bigr)^2.\)</span></p>
<p>Entonces <span class="math inline">\((X_1,X_2,X_3)\)</span> es un vector aleatorio de dimensión 3.</p>
<p><strong>Tiempos de servicio en un servidor</strong></p>
<p>Sean <span class="math inline">\(T_i\)</span> los tiempos de servicio (en segundos) de las peticiones <span class="math inline">\(i=1,2,3\)</span>. Definimos<br><span class="math inline">\(\mathbf{T}=(T_1,T_2,T_3),\quad S = T_1 + T_2 + T_3,\quad M = \max\{T_1,T_2,T_3\}.\)</span></p>
<p><strong>Lecturas de sensores en red distribuida</strong></p>
<p>En tres nodos <span class="math inline">\(i=1,2,3\)</span> medimos temperatura <span class="math inline">\(X_{i,1}\)</span>, presión <span class="math inline">\(X_{i,2}\)</span> y humedad <span class="math inline">\(X_{i,3}\)</span>. El vector global es <span class="math inline">\(\mathbf{X} = (X_{1,1},X_{1,2},X_{1,3},\,X_{2,1},\dots,X_{3,3}) \in \mathbb{R}^9.\)</span></p>
<hr>
<p>Con estas definiciones rigurosas disponemos ya de los objetos básicos para, en las siguientes secciones, construir estimadores, estudiar su comportamiento asintótico y contrastar hipótesis sobre la distribución subyacente <span class="math inline">\(P\)</span>.</p>
</section><section id="distribución-de-una-variable-aleatoria.-funciones-de-distribución-de-probabilidad-y-de-densidad" class="level2" data-number="3.2"><h2 data-number="3.2" class="anchored" data-anchor-id="distribución-de-una-variable-aleatoria.-funciones-de-distribución-de-probabilidad-y-de-densidad">
<span class="header-section-number">3.2</span> Distribución de una variable aleatoria. Funciones de distribución, de probabilidad y de densidad</h2>
<p><strong>Distribución de una Variable Aleatoria</strong></p>
<p>La realización de un experimento aleatorio da lugar a un resultado <span class="math inline">\(\omega\in\Omega\)</span> que es aleatorio. Por lo tanto, <span class="math inline">\(X(\omega)\)</span> es un valor de <span class="math inline">\(\mathbb{R}\)</span> también aleatorio. Es decir, la variable aleatoria <span class="math inline">\(X\)</span> induce una medida de probabilidad en <span class="math inline">\(\mathbb{R}\)</span>. A esa medida de probabilidad se le llama <strong>distribución de <span class="math inline">\(X\)</span></strong> o <strong>ley de <span class="math inline">\(X\)</span></strong>. Una de las formas de caracterizar la distribución de una variable aleatoria es dar su función de distribución <span class="math inline">\(F_X\)</span>, que está definida así:</p>
<p><span class="math inline">\(F_X(x) \;=\; P(X \le x)\;=\; P\bigl(\{\omega \in \Omega : X(\omega) \le x\}\bigr)\;=\; P\bigl(X^{-1}((-\infty, x])\bigr).\)</span>$</p>
<p>En el caso de que <span class="math inline">\(X\)</span> sea una <strong>variable aleatoria discreta</strong>, es decir, en el caso de que <span class="math inline">\(X\)</span> solo tome una cantidad finita o numerable de valores de <span class="math inline">\(\mathbb{R}\)</span>, su distribución también puede caracterizarse por su <strong>función de probabilidad</strong> (o <strong>función de masa de probabilidad</strong>) <span class="math inline">\(f_X\)</span>, definida como</p>
<p><span class="math display">\[f_X : \mathbb{R} \longrightarrow [0,1],\qquad f_X(x) = P(X = x).\]</span></p>
<p>Esa función solo es no nula en un conjunto finito o numerable. Supondremos en adelante, sin pérdida de generalidad, que ese conjunto está contenido en <span class="math inline">\(\mathbb{Z}\)</span>. A partir de la función de masa de probabilidad se puede calcular la probabilidad de que la variable aleatoria <span class="math inline">\(X\)</span> tome valores en cualquier elemento <span class="math inline">\(A \subseteq \mathbb{B}\)</span>:</p>
<p><span class="math inline">\(P(X \in A) = \sum_{x \in A} f_X(x).\)</span> me</p>
<p>La función de distribución y la función de masa de probabilidad se relacionan de la siguiente forma:</p>
<p><span class="math inline">\(F_X(x) = \sum_{u \leq x} f_X(u), \quad f_X(x) = F_X(x) - F_X(x^-),\)</span> donde <span class="math inline">\(F_X(x^-) = \lim_{h \to 0^+} F_X(x - h)\)</span>.</p>
<p>Una clase relevante de variables aleatorias no discretas son las que poseen <strong>función de densidad</strong>, es decir, aquellas cuya distribución de probabilidad puede caracterizarse por una función <span class="math inline">\(f_X(x) \geq 0\)</span> que cumple que:</p>
<p><span class="math inline">\(P(X \in A) = \int_{x \in A} f_X(x) \, dx, \quad \text{para todo } A \subseteq \mathbb{B}.\)</span></p>
<p>La relación entre <span class="math inline">\(F_X\)</span> y <span class="math inline">\(f_X\)</span> es la siguiente:</p>
<p><span class="math inline">\(F_X(x) = \int_{-\infty}^{x} f_X(u) \, du, \quad f_X(x) = \frac{d}{dx} F_X(x),\)</span></p>
<p>salvo quizás en un número finito de puntos <span class="math inline">\(x \in \mathbb{R}\)</span>. Las variables aleatorias que poseen función de densidad se llaman <strong>variables aleatorias absolutamente continuas</strong>. Abusando del lenguaje, aquí nos referiremos a ellas como variables aleatorias continuas.</p>
</section><section id="esperanza-y-varianza" class="level2" data-number="3.3"><h2 data-number="3.3" class="anchored" data-anchor-id="esperanza-y-varianza">
<span class="header-section-number">3.3</span> Esperanza y varianza</h2>
<p>Si se desea describir totalmente la distribución de probabilidad de una variable aleatoria <span class="math inline">\(X\)</span> acabamos de ver que podemos dar su función de distribución o su función de masa o de densidad, según el caso. Una descripción parcial puede efectuarse calculando algunas características de la variable aleatoria <span class="math inline">\(X\)</span>, como por ejemplo medidas de posición o de dispersión. Estudiaremos algunas de ellas.</p>
<p>Se define la <strong>esperanza</strong> de una variable aleatoria <span class="math inline">\(X\)</span> como la integral de Lebesgue de <span class="math inline">\(X\)</span>:</p>
<p><span class="math inline">\(E(X) = \int_{\Omega} X(w) dP(w).\)</span></p>
<p>En el caso de variables aleatorias discretas la esperanza puede calcularse como:</p>
<p><span class="math inline">\(E(X) = \sum_{w \in \Omega} X(w) P(w) = \sum_{k \in \mathbb{Z}} k P(X = k) = \sum_{k \in \mathbb{Z}} k f_X(k).\)</span></p>
<p>Por otro lado, la esperanza de una variable aleatoria continua se puede calcular así:</p>
<p><span class="math inline">\(E(X) = \int_{\mathbb{R}} x f_X(x) dx.\)</span></p>
<p>La esperanza de una variable aleatoria <span class="math inline">\(X\)</span> es una medida de posición de <span class="math inline">\(X\)</span>: es el centro de gravedad de la distribución de probabilidad de <span class="math inline">\(X\)</span>.</p>
<p>Si <span class="math inline">\(h\)</span> es una función medible <span class="math inline">\(h : \mathbb{R} \rightarrow \mathbb{R}\)</span>, entonces <span class="math inline">\(Y = h(X)\)</span> es también variable aleatoria y su esperanza se puede calcular a partir de la distribución de <span class="math inline">\(X\)</span>:</p>
<p><span class="math inline">\(E(h(X)) = \int_{\Omega} h(X(w)) dP(w)\)</span> que en el caso de que <span class="math inline">\(X\)</span> sea discreta puede reescribirse como</p>
<p><span class="math inline">\(E(h(X)) = \sum_{k \in \mathbb{Z}} h(k) f_X(k).\)</span></p>
<p>Si <span class="math inline">\(X\)</span> es una variable aleatoria continua entonces</p>
<p><span class="math inline">\(E(h(X)) = \int_{\mathbb{R}} h(x) f_X(x) dx.\)</span></p>
<p>Si existe <span class="math inline">\(\mu = E(X)\)</span> y es finita puede definirse una medida de dispersión de la variable aleatoria <span class="math inline">\(X\)</span> a partir de una transformación <span class="math inline">\(h\)</span> de <span class="math inline">\(X\)</span>. Es lo que se denomina <strong>varianza</strong> de <span class="math inline">\(X\)</span> y se define así:</p>
<p><span class="math inline">\(V(X) = E((X - \mu)^2) = E(X^2) - \mu^2 = E(X^2) - (E(X))^2.\)</span></p>
</section><section id="función-generadora-de-momentos" class="level2" data-number="3.4"><h2 data-number="3.4" class="anchored" data-anchor-id="función-generadora-de-momentos">
<span class="header-section-number">3.4</span> Función generadora de momentos</h2>
<p>Dada una variable aleatoria <span class="math inline">\(X\)</span>, o su función de distribución <span class="math inline">\(F\)</span>, vamos a definir otra función generadora, como</p>
<p><span class="math inline">\(M_X(t) = \mathbb{E}(e^{tX}),\)</span> siempre que este valor esperado exista.</p>
<p>Notemos que cuando <span class="math inline">\(X\)</span> toma valores en los enteros no-negativos, <span class="math inline">\(M_X(t) = \phi_X(e^t)\)</span>, donde <span class="math inline">\(\phi_X(s)=E[s^X]=\sum_{k=0}^{\infty}p_ks^k\)</span> para <span class="math inline">\(s\in[0,1]\)</span> es la función generadora de probabilidad (f.g.p.) de la variable <span class="math inline">\(X\)</span>, con <span class="math inline">\(p_k=P(X=k)\)</span>. Si <span class="math inline">\(X\)</span> está acotada, <span class="math inline">\(M_X\)</span> está bien definida para todo <span class="math inline">\(t\)</span> real; en cambio, si <span class="math inline">\(X\)</span> no está acotada, es posible que el dominio de <span class="math inline">\(M_X\)</span> no sea el conjunto de todos los reales. En todo caso, <span class="math inline">\(\phi\)</span> siempre está definida en cero, y <span class="math inline">\(M(0) = 1\)</span>.</p>
<p>Es posible demostrar que si la f.g.m. de la v.a. <span class="math inline">\(X\)</span> existe en un entorno de 0, entonces para todo <span class="math inline">\(k &gt; 0\)</span>,</p>
<p><span class="math inline">\(\mathbb{E}[|X|^k] &lt; \infty.\)</span></p>
<p>Más aún, la serie</p>
<p><span class="math inline">\(M_X(t) =
\mathbb{E}(e^{tX})
= \mathbb{E}\left(1 + \sum_{k=1}^{\infty} \frac{t^k X^k}{k!}\right)
= 1 + \sum_{n=1}^{\infty} \frac{t^k}{k!} \mathbb{E}(X^k)
\tag{5.1}\)</span></p>
<p>es convergente y se puede derivar término a término. Obtenemos</p>
<p><span class="math inline">\(M'_X(0) = \mathbb{E}(X); \quad M''_X(0) = \mathbb{E}(X^2)\)</span></p>
<p>y en general</p>
<p><span class="math inline">\(M_X^{(k)}(0) = \mathbb{E}(X^k).\)</span></p>
<p>Es por esta última propiedad que esta función se conoce como <strong>función generadora de momentos</strong> (f.g.m.).</p>
<p>🎲 Ejemplo: f.g.m. de la distribución Binomial</p>
<p>Sea <span class="math inline">\(X \sim \text{Binomial}(n, p)\)</span>, es decir, la suma de <span class="math inline">\(n\)</span> ensayos de Bernoulli con probabilidad de éxito <span class="math inline">\(p\)</span>. La función generadora de momentos es: <a href="https://github.com/BMSS-EAFIT-Courses/inference-statistic/blob/main/mgf_binomial.r">Ejemplo fgm binomial</a></p>
<p><span class="math inline">\(M_X(t) = \mathbb{E}[e^{tX}] = (1 - p + p e^t)^n\)</span></p>
<pre> ```` </pre>
<p>📈 Ejemplo: f.g.m. de la distribución Normal Estándar</p>
<p>Sea <span class="math inline">\(X \sim \mathcal{N}(0, 1)\)</span>. Su función generadora de momentos es:</p>
<p><span class="math inline">\(M_X(t) = \mathbb{E}[e^{tX}] = e^{\frac{t^2}{2}}\)</span></p>
Esta expresión se obtiene usando la forma cerrada del momento de una normal estándar.
<pre> ```` </pre>
<p><strong>❓ Preguntas guía sobre la gráfica de la función generadora de momentos</strong></p>
<p><strong>📌 ¿Qué representa la gráfica de la f.g.m. <span class="math inline">\(M_X(t)\)</span>?</strong></p>
<p>La gráfica muestra cómo evoluciona el valor esperado de <span class="math inline">\(e^{tX}\)</span> cuando <span class="math inline">\(t\)</span> varía. Esta función codifica <strong>todos los momentos de la variable aleatoria</strong> <span class="math inline">\(X\)</span>, y por tanto, contiene información completa sobre su distribución (si existe un entorno donde la f.g.m. es finita).</p>
<hr>
<p><strong>🧭 ¿Qué se observa en la f.g.m. de una distribución Binomial?</strong> <img width="480" height="480" alt="mgf_binomial" src="https://github.com/user-attachments/assets/8524edee-0b5c-4938-a9e8-8af0e8c5840c"></p>
<p>![Gráfica MGF Binomial]</p>
<p>#Preguntas y respuestas</p>
<ul>
<li>
<p><strong>¿Cómo es el comportamiento de la f.g.m. cerca de <span class="math inline">\(t = 0\)</span>?</strong></p>
<p>En <span class="math inline">\(t = 0\)</span>, siempre se cumple que <span class="math inline">\(M_X(0) = 1\)</span>, ya que:</p>
<p><span class="math inline">\(M_X(0) = \mathbb{E}[e^{0 \cdot X}] = \mathbb{E}[1] = 1\)</span></p>
</li>
<li>
<p><strong>¿Qué indica la curvatura de la gráfica?</strong></p>
<p>La curvatura refleja el crecimiento exponencial de los momentos. Si la curva crece rápidamente hacia la derecha, significa que los momentos (media, varianza, etc.) también crecen con rapidez.</p>
</li>
<li>
<p><strong>¿Por qué la gráfica es convexa?</strong></p>
<p>Todas las funciones generadoras de momentos son <strong>estrictamente convexas</strong> en el intervalo donde están definidas. Esto es una consecuencia de que derivadas sucesivas representan momentos positivos.</p>
</li>
<li>
<p><strong>¿Qué pasa si cambio los parámetros <span class="math inline">\(n\)</span> y <span class="math inline">\(p\)</span>?</strong></p>
<p>Aumentar $ n $ o <span class="math inline">\(p\)</span> tiende a <strong>elevar</strong> la f.g.m. en el lado derecho, reflejando una mayor media y varianza.</p>
</li>
</ul>
<hr>
<p><strong>📈 ¿Cómo se comporta la f.g.m. para la Normal Estándar?</strong> <img width="480" height="480" alt="mgf_normal" src="https://github.com/user-attachments/assets/e877129d-4235-42d9-baff-7f29d3afc4a7"></p>
<p>![Gráfica MGF Normal]</p>
<p><strong>Preguntas y respuestas</strong></p>
<ul>
<li>
<p><strong>¿Por qué es simétrica respecto al eje $ t = 0 $?</strong></p>
<p>Porque la normal estándar es simétrica alrededor de su media $ = 0 $, y su f.g.m. tiene la forma:</p>
</li>
</ul>
<p><span class="math inline">\(M_X(t) = e^{t^2 / 2}\)</span></p>
<p>lo cual es una función par: <span class="math inline">\(M_X(-t)= M_X(t)\)</span>.</p>
<ul>
<li>
<p><strong>¿Qué tan rápido crece la función?</strong></p>
<p>Muy rápido. El crecimiento es exponencial cuadrático. Esto implica que los momentos de la normal crecen rápidamente en magnitud.</p>
</li>
<li>
<p><strong>¿Cómo se relaciona esta gráfica con los momentos de la normal?</strong></p>
<p>Derivando sucesivamente la f.g.m. en $ t = 0 $, se obtiene:</p>
<p><span class="math inline">\(\mathbb{E}[X^k] = M_X^{(k)}(0)\)</span></p>
<p>Por tanto, la gráfica “encierra” toda la información sobre los momentos.</p>
</li>
</ul>
<hr>
<p><strong>🧠 Conclusión</strong></p>
<p>Estas gráficas te permiten <strong>visualizar la información estadística codificada en una variable aleatoria</strong>. La f.g.m. no es solo una herramienta algebraica para obtener momentos, sino una forma poderosa de describir el comportamiento global de la variable.</p>
<blockquote class="blockquote">
<p><strong>¿Qué pasa si dos variables tienen la misma f.g.m.?</strong><br>
¡Tienen la misma distribución! (si la f.g.m. está definida en un entorno de 0).</p>
</blockquote>
<p><strong>Ejemplo: Distribución uniforme <span class="math inline">\(U(a,b)\)</span></strong></p>
<p>Si <span class="math display">\[X \sim U(a,b),\]</span><br>
su densidad es<br><span class="math display">\[f(x) = \frac{1}{b - a}\quad\text{para }a &lt; x &lt; b,\]</span><br>
y su función generadora de momentos viene dada por</p>
<a id="eq:5.2"></a>
<table align="center"><tbody><tr>
<td align="center">
<span class="math display">\[M(t)= \int_a^b \frac{e^{t x}}{b - a}\,dx= \frac{e^{b t} - e^{a t}}{t\,(b - a)}.\]</span><br>
</td>
<td valign="bottom">
(5.2)
</td>
</tr></tbody></table>
<p>En el caso particular de la distribución uniforme en <span class="math inline">\((0,1)\)</span> se obtiene<br><span class="math display">\[M(t) = \frac{e^t - 1}{t}.\]</span></p>
<hr>
<p>Para derivar la fórmula <a href="#eq:5.2">#(5.2)</a> y obtener los momentos, podemos usar el desarrollo en serie de la función exponencial:</p>
<p><span class="math display">\[M(t)= \frac{1}{t\,(b - a)}\bigl(e^{b t} - e^{a t}\bigr) \\
= \frac{1}{t\,(b - a)}\Bigl[\bigl(1 + \sum_{n=1}^\infty \tfrac{(b t)^n}{n!}\bigr)
                    -\bigl(1 + \sum_{n=1}^\infty \tfrac{(a t)^n}{n!}\bigr)\Bigr] \\
= \frac{1}{b - a}\sum_{n=1}^\infty \frac{b^n - a^n}{n!}\,t^{n-1}.
\]</span></p>
<p>Este es el desarrollo de Maclaurin de <span class="math inline">\(M(t)\)</span> en <span class="math inline">\(t=0\)</span>; por tanto, sus derivadas en cero satisfacen</p>
<table align="center"><tbody><tr>
<td align="center">
<span class="math display">\[M^{(k)}(0)= \frac{b^{k+1} - a^{k+1}}{(k+1)\,(b - a)}.\]</span>
</td>
<td valign="bottom">
(5.3)
</td>
</tr></tbody></table>
<p>En particular:</p>
<ul>
<li><p><span class="math display">\[M'(0)= \frac{b^2 - a^2}{2\,(b - a)}= \frac{a + b}{2},\]</span> que coincide con <span class="math inline">\(\mathbb{E}(X)\)</span>.</p></li>
<li><p><span class="math display">\[M''(0)= \frac{b^3 - a^3}{3\,(b - a)}= \frac{a^2 + a b + b^2}{3},\]</span></p></li>
</ul>
<p>y un cálculo directo muestra que la varianza es</p>
<p><span class="math display">\[\mathrm{Var}(X)= \mathbb{E}(X^2) - \bigl(\mathbb{E}(X)\bigr)^2= \frac{(a + b)^2}{12}.\]</span></p>
<p><strong>Observación importante</strong> Sea <span class="math inline">\(X\)</span> una v.a. con f.g.m. <span class="math inline">\(M_X\)</span> y sea <span class="math inline">\(Y=aX+b\)</span> una transformación lineal de <span class="math inline">\(X\)</span>, entonces</p>
<p><span class="math display">\[M_Y(t)=E(e^{tY})=E(e^{t(aX+b)})=E(e^{taX}e^{tb})=e^{tb}E(e^{taX})=e^{tb}M_X(at)\]</span></p>
<div id="thm-1" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.1</strong></span> <strong>(fgm de suma de v.a.s)</strong> Si <span class="math inline">\(X\)</span> tiene función generadora de momentos <span class="math inline">\(M(t)\)</span> que está definida en un entorno <span class="math inline">\((-a,a)\)</span> de 0, entonces <span class="math inline">\(M(t)\)</span> caracteriza a la distribución de <span class="math inline">\(X\)</span>; es decir, si otra variable <span class="math inline">\(Y\)</span> tiene la misma función generadora de momentos, las distribuciones de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> coinciden.</p>
</div>
<hr>
<p>Si <span class="math inline">\(X,Y\)</span> son variables aleatorias con funciones generadoras de momentos respectivas <span class="math inline">\(M_X\)</span> y <span class="math inline">\(M_Y\)</span> que existen en un dominio común <span class="math inline">\(|t| &lt; d\)</span>, entonces la f.g.m. de la suma <span class="math inline">\(X+Y\)</span> está dada por <!-- <a id="eq:5.5"></a>  --> <!-- <table align="center"> --> <!--   <tr> --> <!--     <td align="center"> --> <span class="math display">\[
\begin{align}
M_{X+Y}(t)&amp;= \mathbb{E}\bigl[e^{t(X+Y)}\bigr]\\
&amp;= \mathbb{E}\bigl[e^{tX}\,e^{tY}\bigr]\\
&amp;=\mathbb{E}\bigl[e^{tX}\bigr]\mathbb{E}\bigl[e^{tY}\bigr]\\
&amp;= M_X(t)\,M_Y(t).
\end{align}
\tag{1}
\]</span> <!--   </td> --> <!--     <td valign="bottom"> --> <!--       (5.5) --> <!--     </td> --> <!--   </tr> --> <!-- </table> --></p>
<p>Este resultado se extiende a la suma de <span class="math inline">\(n\)</span> variables aleatorias independientes. Si</p>
<p><span class="math display">\[S_n = X_1 + \cdots + X_n,\]</span></p>
<p>entonces</p>
<p><span class="math display">\[M_{S_n}(t)= \mathbb{E}\bigl[e^{tS_n}\bigr]= \mathbb{E}\Bigl[e^{t\sum_{i=1}^n X_i}\Bigr]= \prod_{i=1}^n\mathbb{E}\bigl[e^{tX_i}\bigr]= \prod_{i=1}^n M_{X_i}(t).\]</span></p>
<p>La función generadora de momentos resulta particularmente útil cuando consideramos sucesiones de variables aleatorias, como lo muestra el siguiente teorema que enunciamos sin demostración:</p>
<hr>
<div id="thm-2" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.2</strong></span> <strong>(de Continuidad)</strong> Sea <span class="math inline">\(F_n(x)\)</span>, <span class="math inline">\(n\ge1\)</span>, una sucesión de funciones de distribución con funciones generadoras de momentos respectivas <span class="math inline">\(M_n(t)\)</span>, definidas en <span class="math inline">\(|t|&lt;b\)</span>. Supongamos que cuando <span class="math inline">\(n\to\infty\)</span>,</p>
<p><span class="math display">\[
M_n(t)\,\longrightarrow\,M(t)
\quad\text{para }|t|\le a,
\]</span></p>
<p>donde <span class="math inline">\(M(t)\)</span> es la función generadora de momentos de la distribución límite <span class="math inline">\(F(x)\)</span>. Entonces</p>
<p><span class="math display">\[
F_n(x)\,\longrightarrow\,F(x)
\quad\text{cuando }n\to\infty
\]</span></p>
<p>para todo punto <span class="math inline">\(x\)</span> en el cual <span class="math inline">\(F\)</span> es continua.</p>
</div>
<div id="thm-3" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.3</strong></span> <strong>Laplace–Moivre</strong> Sea <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> una sucesión de variables aleatorias <strong>i.i.d.</strong> con distribución ( (p) ), donde ( 0 &lt; p &lt; 1 ). Sea:</p>
<p><span class="math display">\[
S_n = X_1 + X_2 + \cdots + X_n \sim \text{Binomial}(n, p)
\]</span></p>
<p>y consideremos la variable tipificada:</p>
<p><span class="math display">\[
Z_n = \frac{S_n - np}{\sqrt{np(1 - p)}}
\]</span></p>
<p>Entonces, cuando ( n ), se tiene convergencia en distribución a una normal estándar:</p>
<p><span class="math display">\[
Z_n \xrightarrow{d} \mathcal{N}(0, 1)
\]</span></p>
<p>es decir,</p>
<p><span class="math display">\[
\lim_{n \to \infty} \mathbb{P}(Z_n \leq z) = \Phi(z), \quad \text{para todo } z \in \mathbb{R}
\]</span></p>
<p>donde ( (z) ) es la función de distribución acumulada de la normal estándar.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span><strong>Demostración usando funciones generadoras de momentos</strong></p>
<p>La función generadora de momentos (mgf) de <span class="math inline">\(S_n \sim \text{Binomial}(n, p)\)</span> es:</p>
<p><span class="math display">\[
M_{S_n}(t) = \left(1 - p + p e^t\right)^n
\]</span></p>
<p>Queremos obtener la mgf de la variable tipificada ( Z_n ). Usamos la propiedad de cambio de variable de la mgf:</p>
<p><span class="math display">\[
M_{Z_n}(t) = \mathbb{E}\left[ e^{t Z_n} \right]
= \mathbb{E}\left[ e^{t \cdot \frac{S_n - np}{\sqrt{np(1 - p)}}} \right]
= e^{-t \cdot \frac{np}{\sqrt{np(1 - p)}}} \cdot M_{S_n}\left( \frac{t}{\sqrt{np(1 - p)}} \right)
\]</span></p>
<p>Sustituimos la mgf de ( S_n ):</p>
<p><span class="math display">\[
M_{Z_n}(t) = \exp\left( -t \cdot \frac{np}{\sqrt{np(1 - p)}} \right)
\cdot \left( 1 - p + p e^{t / \sqrt{np(1 - p)}} \right)^n
\]</span></p>
<p><strong>Aproximación por series de Taylor</strong></p>
<p>Expandimos <span class="math inline">\(e^{t / \sqrt{np(1 - p)}}\)</span> para <span class="math inline">\(n\)</span> grande:</p>
<p><span class="math display">\[
e^{t / \sqrt{np(1 - p)}} = 1 + \frac{t}{\sqrt{np(1 - p)}} + \frac{t^2}{2np(1 - p)} + \cdots
\]</span></p>
<p>Entonces:</p>
<p><span class="math display">\[
1 - p + p e^{t / \sqrt{np(1 - p)}} \approx 1 + \frac{pt}{\sqrt{np(1 - p)}} + \frac{pt^2}{2np(1 - p)} + \cdots
\]</span></p>
<p>Usamos que <span class="math inline">\(\log(1 + x) \approx x - \frac{x^2}{2} + \cdots\)</span> para <span class="math inline">\(x \approx 0\)</span>:</p>
<p><span class="math display">\[\log M_{Z_n}(t) \approx -t \cdot \frac{np}{\sqrt{np(1 - p)}}+ n \left( \frac{pt}{\sqrt{np(1 - p)}} + \frac{pt^2}{2np(1 - p)} \right)\]</span></p>
<p>Simplificamos:</p>
<ul>
<li>El término lineal se cancela:</li>
</ul>
<p><span class="math display">\[
-t \cdot \frac{np}{\sqrt{np(1 - p)}} + n \cdot \frac{pt}{\sqrt{np(1 - p)}} = 0
\]</span></p>
<ul>
<li>Queda:</li>
</ul>
<p><span class="math display">\[
\log M_{Z_n}(t) \to \frac{t^2}{2}, \quad \text{cuando } n \to \infty
\]</span></p>
<p>Por tanto:</p>
<p><span class="math display">\[
M_{Z_n}(t) \to e^{t^2 / 2}
\]</span> <strong>Conclusión</strong></p>
<p>Como <span class="math inline">\(e^{t^2/2}\)</span> es la mgf de <span class="math inline">\(\mathcal{N}(0, 1)\)</span>, y por el teorema de unicidad de la función generadora de momentos:</p>
<p><span class="math display">\[
Z_n \xrightarrow{d} \mathcal{N}(0, 1)
\]</span></p>
<p>Esto concluye la demostración del <strong>Teorema de Laplace–Moivre</strong> utilizando funciones generadoras de momentos.</p>
</div>
</section><section id="muestra-aleatoria-simple" class="level2" data-number="3.5"><h2 data-number="3.5" class="anchored" data-anchor-id="muestra-aleatoria-simple">
<span class="header-section-number">3.5</span> Muestra aleatoria simple</h2>
<p>Sea <span class="math inline">\(\underset{\sim}{X} =(X_1 ,..., X_n)\)</span> un vector aleatorio. Se dice que sus componentes <span class="math inline">\(X_1 ,..., X_n\)</span> son si <span class="math inline">\(P(X_1\leq x_1 ,..., X_n\leq x_n)=P(X_1\leq x_1)...P(X_n\leq x_n)\)</span> para cualesquiera valores <span class="math inline">\(x_1,..., x_n\)</span> .</p>
<p>Si además la distribución de las <span class="math inline">\(n\)</span> variables aleatorias <span class="math inline">\(X_i\)</span> es la misma, se dice que <span class="math inline">\(X_1 ,...,X_n\)</span> son variables aleatorias <strong>independientes e idénticamente distribuidas</strong>, o bien que son v.a.i.i.d o simplemente i.i.d.</p>
<p>Si <span class="math inline">\(\underset{\sim}{X} =(X_1 ,..., X_n)\)</span> y <span class="math inline">\(X_1 ,..., X_n\)</span> son i.i.d. con función de densidad (en su caso, de masa) <span class="math inline">\(f_X\)</span> , la distribución conjunta de <span class="math inline">\(\underset{\sim}{X}\)</span> viene dada por la función de densidad (en su caso, de masa) conjunta <span class="math display">\[
\begin{align*}
f_{\underset{\sim}{X}}(\underset{\sim}{x})&amp;=f_{(X_1 ,..., X_n)}(x_1 ,..., x_n)\\
&amp;=f_{(X_1)}(x_1)...f_{(X_n)}(x_n)\\
&amp;=\prod_{i=1}^{n}f_{(X_i)}(x_i)
\end{align*}
\]</span></p>
<p>A un vector <span class="math inline">\(\underset{\sim}{X} =(X_1 ,..., X_n)\)</span> de v.a.i.i.d. con distribución igual a la de la variable aleatoria <span class="math inline">\(X\)</span> se le denomina también <strong>muestra aleatoria simple</strong> de <span class="math inline">\(X\)</span> (m.a.s de <span class="math inline">\(X\)</span>).</p>
<p>Esto responde al hecho siguiente. Supongamos que se desea estudiar la característica <span class="math inline">\(X\)</span> de los individuos de una población de tamaño infinito. Definimos el experimento consistente en elegir aleatoriamente un individuo de la población y llamamos <span class="math inline">\(X\)</span> al valor de la característica de interés en ese individuo. X es una variable aleatoria.</p>
<p>Si definimos un nuevo experimento consistente en elegir una muestra aleatoria de n individuos y se anota <span class="math inline">\(X_i\)</span>, el valor de la característica en el individuo i-ésimo, entonces <strong>X</strong> <span class="math inline">\(=(X_1 ,..., X_n)\)</span> es una colección de n v.a.i.i.d. con distribución igual a la de la variable aleatoria <span class="math inline">\(X\)</span>, es decir, <span class="math inline">\(X_1 ,..., X_n\)</span> es una m.a.s. de X.</p>
</section><section id="modelo-paramétrico" class="level2" data-number="3.6"><h2 data-number="3.6" class="anchored" data-anchor-id="modelo-paramétrico">
<span class="header-section-number">3.6</span> Modelo paramétrico</h2>
<p>Usualmente la ley de probabilidad de una variable aleatoria se supone perteneciente a un modelo matemático que depende sólo de un número finito de parámetros: <span class="math inline">\(f_X \in\{f(x|\theta):\theta \in \Theta \subseteq \mathbb{R}^k\}\)</span>. Escribiremos alternativamente <span class="math inline">\(f(x;\theta)\)</span>, <span class="math inline">\(f(x|\theta)\)</span> o <span class="math inline">\(f_\theta(x)\)</span>.</p>
<div id="def-1.3" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.3</strong></span> El conjunto de distribuciones dadas por <span class="math inline">\(f_\theta(x)\)</span>, <span class="math inline">\(\theta \in \Theta\)</span> se llama familia paramétrica de distribuciones. <span class="math inline">\(\Theta\)</span> es el conjunto de parámetros.</p>
</div>
<div id="def-1.4" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.4</strong></span> La correspondiente distribución conjunta de una muestra aleatoria simple de <span class="math inline">\(X\)</span> viene dada por la función de densidad (o función de masa de probabilidad, según el caso)</p>
<p><span class="math display">\[
f_{\underset{\sim}{X}}(\underset{\sim}{x} \mid \theta) = \prod_{i=1}^{n} f_{\theta}(x_i)
\]</span></p>
<p>A esta función la llamaremos <strong>función de verosimilitud</strong> de la muestra <span class="math inline">\(X_{\sim}\)</span>. Utilizaremos este término para referirnos indistintamente a la función de densidad conjunta (si las variables aleatorias son continuas) o a la función de masa conjunta (si son discretas).</p>
</div>
</section><section id="sumas-de-variables-aleatorias" class="level2" data-number="3.7"><h2 data-number="3.7" class="anchored" data-anchor-id="sumas-de-variables-aleatorias">
<span class="header-section-number">3.7</span> Sumas de variables aleatorias</h2>
<p>Cuando se obtiene una muestra aleatoria simple <span class="math inline">\(X_{1},X_{2},\ldots,X_{n}\)</span> normalmente se calculan a partir de ellas cantidades que resumen los valores observados. Cualquiera de estos resúmenes se puede expresar como una función <span class="math inline">\(T(x_1,\ldots,x_n)\)</span> definida en el espacio <span class="math inline">\(\mathcal{X}^n\subseteq\mathbb{R}^n\)</span> donde están las imágenes del vector <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span>.</p>
<p>Esta función <span class="math inline">\(T\)</span> puede devolver valores de <span class="math inline">\(\mathbb{R}\)</span>, <span class="math inline">\(\mathbb{R}^2\)</span> o, en general, <span class="math inline">\(\mathbb{R}^k\)</span>.</p>
<p><span class="math display">\[T(X_1 , \ldots, X_n)=\sum_{i=1}^{n}X_i,\bar{X},\bar{X}+3, \min{X_1 , \ldots, X_n},\]</span> <span class="math display">\[T(X_1 , \ldots, X_n)=\left(\sum_{i=1}^{n}X_i,\sum_{i=1}^{n}(X_i-\bar{X})^2\right),\]</span> <span class="math display">\[T(X_1 , \ldots, X_n)=\left(\min\{X_1 , \ldots, X_n\},\sum_{i=1}^{n}X_i,\sum_{i=1}^{n}(X_i-\bar{X})^2\right),\]</span> <span class="math display">\[T(X_1 , \ldots, X_n)= (X_1 , \ldots, X_n)\]</span></p>
<div id="def-1.5" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.5</strong></span> <strong>(Definición de estadísticos)</strong> Las funciones <span class="math inline">\(T\)</span> que dependen de una muestra aleatoria simple <span class="math inline">\(X_1 , \ldots, X_n\)</span> se llaman <strong>estadísticos</strong>. Dependen de los valores observados, pero no de los parámetros desconocidos que determinan la distribución de <span class="math inline">\(X_i\)</span> .</p>
</div>
<p>Cuando un estadístico <span class="math inline">\(T\)</span> es utilizado con el propósito de estimar un parámetro <span class="math inline">\(\theta\)</span> diremos que <span class="math inline">\(T\)</span> es un estimador de <span class="math inline">\(\theta\)</span>.</p>
<p><strong>Ejemplo de estadístico</strong></p>
<p><span class="math inline">\(T(X_1 , \ldots, X_n)=\bar{X}\)</span> es un estimador de <span class="math inline">\(E(X)=\mu\)</span>.</p>
<p>En inferencia estadística interesa saber qué estadísticos son suficientes para recoger toda la información que la muestra aporta sobre la distribución de la variable aleatoria X muestreada. La respuesta depende de la distribución de X.</p>
<div id="def-1.6" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.6</strong></span> <strong>(Definición distribución en el muestreo)</strong> Dado que <span class="math inline">\(\underset{\sim}{X} =(X_1 ,..., X_n)\)</span> es una variable aleatoria, se tiene que <span class="math inline">\(Y=T(\underset{\sim}{X})=T(X_1 ,..., X_n)\)</span> será también una variable aleatoria. La ley de probabilidad de <span class="math inline">\(Y\)</span> se denomina <strong>distribución en el muestreo de <span class="math inline">\(Y\)</span></strong> (o distribución muestral). Los siguientes resultados dan información sobre algunas características de estadísticos definidos a partir de sumas de variables aleatorias.</p>
</div>
</section><section id="estadísticos-definidos-a-partir-de-sumas-de-variables-aleatorias" class="level2" data-number="3.8"><h2 data-number="3.8" class="anchored" data-anchor-id="estadísticos-definidos-a-partir-de-sumas-de-variables-aleatorias">
<span class="header-section-number">3.8</span> Estadísticos definidos a partir de sumas de variables aleatorias</h2>
<div id="thm-4" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.4</strong></span> Sean <span class="math inline">\(X_1,\ldots, X_n\)</span>,n números reales, sea <span class="math inline">\(\bar{x} = \frac{1}{n} \sum_{i=1}^{n}x_i\)</span> su media aritmética y sea <span class="math inline">\(S_n^2=\frac{\sum_{i=1}^{n}(x_i-\bar{x})^2}{n-1}\)</span> su varianza muestral.</p>
<ol type="1">
<li><span class="math inline">\(\min_a\sum_{i=1}^{n}(x_i-a)^2=\sum_{i=1}^{n}(x_i-\bar{x})^2\)</span></li>
<li><span class="math inline">\((n-1)S_n^2=\sum_{i=1}^{n}(x_i-\bar{x})^2=\sum_{i=1}^{n}x_i^2-n\bar{x}^2\)</span></li>
</ol>
</div>
<div id="lem-1" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 3.1</strong></span> Sea <span class="math inline">\(X_1,\ldots, X_n\)</span> una muestra aleatoria simple de <span class="math inline">\(X\)</span> y sea <span class="math inline">\(g(x)\)</span> una función tal que <span class="math inline">\(E(g(X))\)</span> y <span class="math inline">\(Var(g(X))\)</span> existen. Entonces,</p>
<ol type="1">
<li>
<span class="math inline">\(E(\sum_{i=1}^{n}g(X_i))=nE(g(X))\)</span>,</li>
<li>
<span class="math inline">\(Var(\sum_{i=1}^{n}g(X_i))=nVar(g(X))\)</span>.</li>
</ol>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Para la demostración ver Gómez et al.&nbsp;(2006)</p>
</div>
<div id="thm-5" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.5</strong></span> Sea <span class="math inline">\(X 1,\ldots, X_n\)</span> una muestra aleatoria simple de una población <span class="math inline">\(X\)</span> con esperanza <span class="math inline">\(\mu\)</span> y varianza <span class="math inline">\(\sigma^2 &lt; \infty\)</span>. Sean <span class="math display">\[
        \begin{align*}
        &amp;\bar{X}=\frac{1}{n}\sum_{i=1}^{n}X_i,\ \
        S^2=\frac{\sum_{i=1}^{n}(X_i-\bar{X})^2}{n-1},
        \end{align*}    
\]</span> la media y la varianza muestrales, respectivamente. Entonces,</p>
<ol type="a">
<li><span class="math inline">\(E(\bar{X}) = \mu,\)</span></li>
<li><span class="math inline">\(Var(\bar{X}) = \frac{\sigma^2}{n},\)</span></li>
<li>
<span class="math inline">\(E(S^2) = \sigma^2\)</span>.</li>
</ol>
</div>
<div id="thm-6" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.6</strong></span> Sea <span class="math inline">\(X 1,\ldots, X_n\)</span> una muestra aleatoria simple de una población <span class="math inline">\(X\)</span> con función generadora de momentos <span class="math inline">\(M_X(t)\)</span>. La función generatriz de momentos de <span class="math inline">\(X\)</span> es <span class="math display">\[\begin{align*}
        &amp;M_{\bar{X}}(t)=\left(M_X\left(\frac{t}{n}\right)\right)^n
        \end{align*}
\]</span></p>
</div>
<div id="thm-7" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.7</strong></span> <strong>(Combinación lineal de normales es normal)</strong> (Wackerly et al.&nbsp;(2008)) Sean <span class="math inline">\(Y_1,\,Y_2,\cdots,\,Y_n\)</span> variables aleatorias independientes normalmente distribuidas <span class="math inline">\(E(Y_i)=\mu_i\)</span> y <span class="math inline">\(V(Y_i)=\sigma_i^2\)</span>ara <span class="math inline">\(i=1,\cdots,\,n\)</span> y sean <span class="math inline">\(a_1,\,a_2,\cdots,\,a_n\)</span> constantes. Si <span class="math display">\[U=\sum_{i=1}^na_iY_i\]</span></p>
<p>entonces <span class="math inline">\(U\)</span> es una variable aleatoria normalmente distribuida con <span class="math display">\[E(U)=\sum_{i=1}^na_i\mu_i\]</span> y <span class="math display">\[V(U)=\sum_{i=1}^na_i^2\sigma^2_i\]</span></p>
</div>
<p><strong>Ejemplo</strong> <span class="math inline">\(X 1,\ldots, X_n\)</span> m.a.s. de <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>. Entonces, <span class="math inline">\(M_{X}(t)=\exp\left\{\mu t+ \frac{\sigma^2t^2}{2}\right\}\)</span>. De ahí que</p>
<p><span class="math display">\[
    \begin{align*}
    M_{\bar{X}}(t)
    &amp;=\left(\exp\left\{\mu \frac{t}{n}+ \frac{\sigma^2\left(\frac{t}{n}\right)^2}{2}\right\}\right)^n
    \end{align*}
\]</span></p>
<p><span class="math inline">\(X 1,\ldots, X_n\)</span> m.a.s. de <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>. Entonces, <span class="math inline">\(M_{X}(t)=\exp\left\{\mu t+ \frac{\sigma^2t^2}{2}\right\}\)</span>. De ahí que <span class="math display">\[
        \begin{align*}
        M_{\bar{X}}(t)&amp;=\exp\left\{\mu t+ \frac{\sigma^2t^2}{2n}\right\}
        \end{align*}
\]</span> De ahí que <span class="math inline">\(\bar{X}\sim N(\mu,\frac{\sigma^2}{n})\)</span>.</p>
</section><section id="muestreo-de-una-distribución-normal" class="level2" data-number="3.9"><h2 data-number="3.9" class="anchored" data-anchor-id="muestreo-de-una-distribución-normal">
<span class="header-section-number">3.9</span> Muestreo de una distribución normal</h2>
<section id="definición-de-distribución-chi-cuadrada" class="level3" data-number="3.9.1"><h3 data-number="3.9.1" class="anchored" data-anchor-id="definición-de-distribución-chi-cuadrada">
<span class="header-section-number">3.9.1</span> Definición de distribución Chi cuadrada</h3>
<div id="def-1.7" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.7</strong></span> (Wackerly et al.&nbsp;(2008)) Sea <span class="math inline">\(\nu\)</span> un entero positivo. Se dice que una v.a <span class="math inline">\(Y\)</span> tiene distribuci'on <strong>chi cuadrada con <span class="math inline">\(\nu\)</span> grados de libertad</strong> si y sólo si <span class="math inline">\(Y\)</span> es una vriable aleatoria con distribución gamma y parámetros <span class="math inline">\(\alpha=\nu/2\)</span> y <span class="math inline">\(\beta=2\)</span>.</p>
</div>
<div id="thm-8" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.8</strong></span> <strong>(Teorema de Fisher)</strong> En el resto del tema supondremos que <span class="math inline">\(X 1,\ldots, X_n\)</span> m.a.s. de una <span class="math inline">\(N(\mu, \sigma^2)\)</span>.</p>
<ol type="a">
<li>
<span class="math inline">\(\bar{X}\)</span> y <span class="math inline">\(S_n^2\)</span> son variables aleatorias independientes.</li>
<li><span class="math inline">\(\bar{X}\sim N(\mu, \frac{\sigma^2}{n})\)</span></li>
<li><span class="math inline">\(\frac{(n-1)S_n^2}{\sigma^2}\sim \mathcal{X}^2_{n-1}.\)</span></li>
</ol>
</div>
</section><section id="distribuciones-asociadas-a-la-normal" class="level3" data-number="3.9.2"><h3 data-number="3.9.2" class="anchored" data-anchor-id="distribuciones-asociadas-a-la-normal">
<span class="header-section-number">3.9.2</span> Distribuciones asociadas a la normal</h3>
<div id="thm-9" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.9</strong></span> (Wackerly et al.&nbsp;(2008)) Sean <span class="math inline">\(Y_1,\,Y_2,\cdots,\,Y_n\)</span> definidas como en el Teorema <a href="#thm-7" class="quarto-xref">Theorem&nbsp;<span>3.7</span></a> de Wackerly et al.&nbsp;(2008) y definimos <span class="math inline">\(Z_i\)</span> por <span class="math display">\[Z_i=\frac{Y_i-\mu_i}{\sigma_i}\]</span> con <span class="math inline">\(i=1,\,2,\cdots,\,n\)</span>. Entonces <span class="math inline">\(\sum_{i=1}^nZ_i^2\)</span> tiene distribuici'on <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\(n\)</span> grados de libertad.</p>
</div>
<div id="thm-10" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.10</strong></span> (Wackerly et al.&nbsp;(2008)) Si <span class="math inline">\(Y_1,\,Y_2,\cdots,\,Y_n\)</span> es una muestra aleatoria de una distribuci'on normal con media <span class="math inline">\(\mu\)</span> y varianza <span class="math inline">\(\sigma^2\)</span>, <span class="math inline">\(Y_i\)</span>, <span class="math inline">\(i=1,\,2,\cdots,n\)</span> son v.a’s independientes distribu'idas normalmente, con <span class="math inline">\(E(Y_i)=\mu\)</span> y <span class="math inline">\(V(Y_i)=\sigma^2\)</span>.</p>
<p>Entonces <span class="math display">\[Z_i=\frac{Y_i-\mu}{\sigma}\]</span> son v.a’s independientes, <span class="math inline">\(i=1,\,2,\cdots,n\)</span> y <span class="math display">\[\sum_{i=1}^nZ_i^2=\sum_{i=1}^n\left(\frac{Y_i-\mu}{\sigma}\right)^2\]</span>tienen una distribuci'on <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\(n\)</span> grados de libertad (gl).</p>
</div>
<div id="thm-11" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.11</strong></span> (Wackerly et al.&nbsp;(2008)) Sea <span class="math inline">\(Y_1,\,Y_2,\cdots,\,Y_n\)</span> una muestra aleatoria con media <span class="math inline">\(\mu\)</span> y varianza <span class="math inline">\(\sigma^2\)</span>. Entonces <span class="math display">\[\frac{(n-1)S^2}{\sigma^2}=\frac{1}{\sigma^2}\sum_{i=1}^n(Y_i-\overline{Y})^2\]</span> tiene una distribuci'on <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\((n-1)\)</span> gl. <span class="math inline">\(\overline{Y}\)</span> y <span class="math inline">\(S^2\)</span> son v.a independientes.</p>
</div>
<div id="def-1.8" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.8</strong></span> (Wackerly et al.&nbsp;(2008)) Sea <span class="math inline">\(Z\)</span> una v.a normal est'andar y sea <span class="math inline">\(W\)</span> una v.a con distribuci'on <span class="math inline">\(\chi^2_\nu\)</span>. Entonces, si <span class="math inline">\(W\)</span> y <span class="math inline">\(Z\)</span> son ind <span class="math display">\[T=\frac{Z}{\sqrt{W/\nu}}\]</span> se dice que tiene una distribuci'on <span class="math inline">\(t\)</span> con <span class="math inline">\(\nu\)</span> grados de libertad.</p>
</div>
<div id="obs-1" class="callout callout-style-default callout-note no-icon callout-titled" title="Observación 1">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Observación 1
</div>
</div>
<div class="callout-body-container callout-body">
<p>Si <span class="math inline">\(Y_1,\,Y_2,\cdots,\,Y_n\sim N(\mu,\sigma^2)\)</span> del <a href="@teo6-3">Teorema (Combinación lineal de normales es normal)</a> <span class="math display">\[Z=\frac{\sqrt{n}(\overline{Y}-\mu)}{\sigma}\sim N(0,1)\]</span> El teorema <a href="#teo7-3">Observación 1</a> nos dice que <span class="math display">\[W=\frac{(n-1)S^2}{\sigma^2}\sim\chi^2_{n-1}\]</span> y que <span class="math inline">\(Z\)</span> y <span class="math inline">\(W\)</span> son ind.</p>
</div>
</div>
<div id="obs-2" class="callout callout-style-default callout-note no-icon callout-titled" title="Observación 2">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Observación 2
</div>
</div>
<div class="callout-body-container callout-body">
<p>Por tanto, de la definición 7.2 se tiene la siguiente expresión: <span class="math display">\[
\begin{aligned}
T &amp;= \frac{Z}{\sqrt{W/\nu}} \\
  &amp;= \frac{\sqrt{n}(\overline{Y}-\mu)/\sigma}{\sqrt{\left[\frac{(n-1)S^2}{\sigma^2}\right]/(n-1)}} \\
  &amp;= \sqrt{n}\left(\frac{\overline{Y}-\mu}{S}\right)
\end{aligned}
\]</span></p>
<p>Tiene distribución <span class="math inline">\(t\)</span> con <span class="math inline">\((n-1)\)</span> grados de libertad.</p>
</div>
</div>
<p>Como se indica en la <a href="#obs-normal">Observación 7.1</a>, esta propiedad…</p>
<div id="def-1.9" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.9</strong></span> Sean <span class="math inline">\(W_1\)</span> y <span class="math inline">\(W_2\)</span> v.a’s independientes con distribución <span class="math inline">\(\chi^2\)</span>, con <span class="math inline">\(\nu_1\)</span> y <span class="math inline">\(\nu_2\)</span> grados de libertad respectivamente. Entonces se dice que: <span class="math display">\[F=\frac{W_1/\nu_1}{W_2/\nu_2}\]</span> tiene una distribuc'on <span class="math inline">\(F\)</span> con <span class="math inline">\(\nu_1\)</span> grados de libertad en el numerador y <span class="math inline">\(\nu_2\)</span> grados de libertad en el denominador.</p>
</div>
<div id="rem-3" class="proof remark">
<p><span class="proof-title"><em>Remark 3.1</em>. </span>Considerando dos muestras aleatorias independientes tomadas de distribuiciones normales <span class="math display">\[W_1=\frac{(n_1-1)S_1^2}{\sigma_1^2}\sim\chi^2_{n_1-1}\]</span> <span class="math display">\[W_1=\frac{(n_2-1)S_2^2}{\sigma_2^2}\sim\chi^2_{n_2-1}\]</span> <span class="math inline">\(W_1\bot W_2\)</span>.</p>
</div>
<div id="rem-4" class="proof remark">
<p><span class="proof-title"><em>Remark 3.2</em>. </span><span class="math display">\[
\begin{eqnarray*}
            F&amp;=&amp;\frac{W_1/\nu_1}{W_2/\nu_2}\\
            &amp;=&amp;\frac{[(n_1-1)S_1^2/\sigma_1^2]/(n_1-1)}{[(n_2-1)S_2^2/\sigma_2^2]/(n_2-1)}\\
            &amp;=&amp;\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2}
        \end{eqnarray*}
\]</span> tiene distribuci'on <span class="math inline">\(F\)</span> con <span class="math inline">\((n_1-1)\)</span> gl en el numerador y <span class="math inline">\((n_2-1)\)</span> gl en el denominador</p>
</div>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">figura_densidad_asimetrica</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">alpha</span> <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">shape</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span>  <span class="va">rate</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span>  </span>
<span>  <span class="co"># Cuantil de interés</span></span>
<span>  <span class="va">F_alpha</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">qgamma</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span>, shape <span class="op">=</span> <span class="va">shape</span>, rate <span class="op">=</span> <span class="va">rate</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Datos para la densidad</span></span>
<span>  <span class="va">x_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span>  <span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="va">x_vals</span>,</span>
<span>    y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">dgamma</a></span><span class="op">(</span><span class="va">x_vals</span>, shape <span class="op">=</span> <span class="va">shape</span>, rate <span class="op">=</span> <span class="va">rate</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Datos para el sombreado</span></span>
<span>  <span class="va">df_shaded</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html">subset</a></span><span class="op">(</span><span class="va">df</span>, <span class="va">x</span> <span class="op">&gt;=</span> <span class="va">F_alpha</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Altura de la flecha</span></span>
<span>  <span class="va">y_arrow</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">dgamma</a></span><span class="op">(</span><span class="va">F_alpha</span>, <span class="va">shape</span>, <span class="va">rate</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_ribbon.html">geom_area</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">df_shaded</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span>, fill <span class="op">=</span> <span class="st">"black"</span>, alpha <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span> <span class="op">+</span></span>
<span>    </span>
<span>    <span class="co"># Flecha vertical</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x <span class="op">=</span> <span class="va">F_alpha</span>, xend <span class="op">=</span> <span class="va">F_alpha</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="va">y_arrow</span>,</span>
<span>             arrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grid/arrow.html">arrow</a></span><span class="op">(</span>length <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grid/unit.html">unit</a></span><span class="op">(</span><span class="fl">0.15</span>, <span class="st">"cm"</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    </span>
<span>    <span class="co"># Etiqueta F_α</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">F_alpha</span>, y <span class="op">=</span> <span class="fl">0</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="cn">F</span><span class="op">[</span><span class="va">alpha</span><span class="op">]</span><span class="op">)</span>,</span>
<span>             vjust <span class="op">=</span> <span class="fl">1.5</span>, hjust <span class="op">=</span> <span class="fl">1.1</span>, size <span class="op">=</span> <span class="fl">5</span><span class="op">)</span> <span class="op">+</span></span>
<span>    </span>
<span>    <span class="co"># Etiqueta α</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">F_alpha</span>, y <span class="op">=</span> <span class="va">y_arrow</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>,</span>
<span>             vjust <span class="op">=</span> <span class="op">-</span><span class="fl">1</span>, size <span class="op">=</span> <span class="fl">5</span><span class="op">)</span> <span class="op">+</span></span>
<span>    </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"u"</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu">f</span><span class="op">(</span><span class="va">u</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu">figura_densidad_asimetrica</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression
Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="index_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Ejercicios con la distribución F en R</strong></p>
<p>A continuación se presentan dos ejercicios típicos en los que anteriormente se utilizaban tablas de valores críticos de la distribución F. Ahora, gracias a funciones como <code><a href="https://rdrr.io/r/stats/Fdist.html">qf()</a></code> y <code><a href="https://rdrr.io/r/stats/var.test.html">var.test()</a></code> en R, estos análisis pueden hacerse de manera precisa y automática.</p>
<hr>
<p><strong>Ejercicio 1: Contrastar dos varianzas</strong></p>
<p><strong>Enunciado:</strong><br>
Se tienen dos muestras independientes con: - Tamaños: <span class="math inline">\(n_1 = 6\)</span>, <span class="math inline">\(n_2 = 10\)</span> - Varianzas muestrales: <span class="math inline">\(s_1^2 = 25\)</span>, <span class="math inline">\(s_2^2 = 10\)</span></p>
<p>¿Existe evidencia para afirmar que las varianzas poblacionales son diferentes al nivel de significancia del 5%?</p>
<p><strong>Solución en R:</strong></p>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Datos</span></span>
<span><span class="va">s1_sq</span> <span class="op">&lt;-</span> <span class="fl">25</span></span>
<span><span class="va">s2_sq</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">n1</span> <span class="op">&lt;-</span> <span class="fl">6</span></span>
<span><span class="va">n2</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Estadístico F observado (mayor varianza sobre menor)</span></span>
<span><span class="va">F_obs</span> <span class="op">&lt;-</span> <span class="va">s1_sq</span> <span class="op">/</span> <span class="va">s2_sq</span></span>
<span><span class="va">gl1</span> <span class="op">&lt;-</span> <span class="va">n1</span> <span class="op">-</span> <span class="fl">1</span></span>
<span><span class="va">gl2</span> <span class="op">&lt;-</span> <span class="va">n2</span> <span class="op">-</span> <span class="fl">1</span></span>
<span></span>
<span><span class="co"># Cuantiles críticos para prueba bilateral al 5%</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span></span>
<span><span class="va">F_inf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">qf</a></span><span class="op">(</span><span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df1 <span class="op">=</span> <span class="va">gl1</span>, df2 <span class="op">=</span> <span class="va">gl2</span><span class="op">)</span></span>
<span><span class="va">F_sup</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">qf</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, df1 <span class="op">=</span> <span class="va">gl1</span>, df2 <span class="op">=</span> <span class="va">gl2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Decisión</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"F observado:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">F_obs</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>F observado: 2.5 </code></pre>
</div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Intervalo de aceptación: ["</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">F_inf</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">","</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">F_sup</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"]\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Intervalo de aceptación: [ 0.15 , 4.484 ]</code></pre>
</div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw">if</span> <span class="op">(</span><span class="va">F_obs</span> <span class="op">&lt;</span> <span class="va">F_inf</span> <span class="op">||</span> <span class="va">F_obs</span> <span class="op">&gt;</span> <span class="va">F_sup</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Se rechaza H0: las varianzas son significativamente diferentes.\n"</span><span class="op">)</span></span>
<span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"No se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.\n"</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>No se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.</code></pre>
</div>
</div>
<p><strong>Ejercicio 2: Obtener un valor crítico F directamente</strong></p>
<p><strong>Enunciado:</strong><br>
Calcular el valor crítico <span class="math inline">\(F_{0.05,\,5,\,9}\)</span> para una prueba unilateral con nivel de significancia del 5%.</p>
<p>Este valor se usa, por ejemplo, cuando se contrasta si una varianza es significativamente mayor que otra, con: - <span class="math inline">\(\alpha = 0.05\)</span> - <span class="math inline">\(\text{gl}_1 = 5\)</span> (grados de libertad del numerador) - <span class="math inline">\(\text{gl}_2 = 9\)</span> (grados de libertad del denominador)</p>
<p><strong>Cálculo en R:</strong></p>
<div class="cell">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Valor crítico F para prueba unilateral con alpha = 0.05</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">qf</a></span><span class="op">(</span><span class="fl">0.95</span>, df1 <span class="op">=</span> <span class="fl">5</span>, df2 <span class="op">=</span> <span class="fl">9</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.481659</code></pre>
</div>
</div>
<p>El valor crítico es <span class="math inline">\(F_{0.05,\,5,\,9}=3.478\)</span>. Si el estadístico F observado es mayor que este valor, se rechaza la hipótesis nula de igualdad de varianzas a favor de que la varianza del numerador es mayor.</p>
<div id="exm-1" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.1</strong></span> <span class="math display">\[Y_1^1,\,Y_2^1\,\cdots,\,Y_{n_1}^1\sim N(\mu_1,\,\sigma^2)\]</span> <span class="math display">\[Y_1^2,\,Y_2^2\,\cdots,\,Y_{n_2}^2\sim N(\mu_2,\,\sigma^2)\]</span> <span class="math inline">\(P\left(\frac{S_1^2}{S_2^2}\leq b\right)=0.95\)</span> con <span class="math inline">\(n_1=6\)</span> y <span class="math inline">\(n_2=10\)</span>, ?`<span class="math inline">\(b\)</span>?</p>
<p>Como <span class="math inline">\(n_1=6\)</span> y <span class="math inline">\(n_2=10\)</span> y las varianzas poblacionales son iguales, entonces <span class="math inline">\(\frac{S_1^2/\sigma_1^2}{S_2^2/\sigma_2^2}=\frac{S_1^2}{S_2^2}\sim F_{5,9}\)</span> <span class="math display">\[P\left(\frac{S_1^2}{S_2^2}\leq b\right)= F_{5,9}(b)=0.95\]</span> entonces <span class="math inline">\(qf(0.95,\,5,\,9)=b\)</span>, <span class="math inline">\(b=3.48\)</span>.</p>
</div>
<p><strong>Simulación del comportamiento del promedio muestral</strong></p>
<p>Simulamos 1000 repeticiones del promedio muestral a partir de una distribución exponencial con media ( = 10 ), para distintos tamaños de muestra ( n ).</p>
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">simular_promedios</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span>, <span class="va">repeticiones</span> <span class="op">=</span> <span class="fl">1000</span>, <span class="va">media</span> <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">promedios</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="va">repeticiones</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span><span class="va">n</span>, rate <span class="op">=</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">media</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    `n` <span class="op">=</span> <span class="va">n</span>,</span>
<span>    `Promedio repetido` <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">promedios</span><span class="op">)</span>,</span>
<span>    `Media teórica` <span class="op">=</span> <span class="va">media</span>,</span>
<span>    `Varianza repetida` <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">promedios</span><span class="op">)</span>,</span>
<span>    `Varianza teórica` <span class="op">=</span> <span class="va">media</span><span class="op">^</span><span class="fl">2</span> <span class="op">/</span> <span class="va">n</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Evaluar para varios tamaños</span></span>
<span><span class="va">tamaños</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">10</span>, <span class="fl">25</span>, <span class="fl">50</span>, <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">resultados</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="va">rbind</span>, <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="va">tamaños</span>, <span class="va">simular_promedios</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="va">resultados</span>, digits <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 5%">
<col style="width: 25%">
<col style="width: 19%">
<col style="width: 25%">
<col style="width: 23%">
</colgroup>
<thead><tr class="header">
<th style="text-align: right;">n</th>
<th style="text-align: right;">Promedio.repetido</th>
<th style="text-align: right;">Media.teórica</th>
<th style="text-align: right;">Varianza.repetida</th>
<th style="text-align: right;">Varianza.teórica</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: right;">9.99864</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">20.01904</td>
<td style="text-align: right;">20</td>
</tr>
<tr class="even">
<td style="text-align: right;">10</td>
<td style="text-align: right;">10.03311</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">9.93028</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="odd">
<td style="text-align: right;">25</td>
<td style="text-align: right;">10.08266</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">4.06604</td>
<td style="text-align: right;">4</td>
</tr>
<tr class="even">
<td style="text-align: right;">50</td>
<td style="text-align: right;">10.02669</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">2.10706</td>
<td style="text-align: right;">2</td>
</tr>
<tr class="odd">
<td style="text-align: right;">100</td>
<td style="text-align: right;">10.01883</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">0.97999</td>
<td style="text-align: right;">1</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="thm-12" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.12</strong></span> Sean <span class="math inline">\(Y_1,\,Y_2,\cdots,\,Y_n\)</span> v.a’s con funciones generadoras de momentos <span class="math inline">\(m(t)\)</span> y <span class="math inline">\(m_1(t),\,m_2(t),\cdots,\)</span> respectivamente. Si <span class="math display">\[\lim_{n\rightarrow\infty}m_n(t)=m(t)\mbox{ para toda $t$ real,}\]</span> entonces la funci'on de distribuci'on de <span class="math inline">\(Y_n\)</span> converge hacia la funci'on de distribuci'on de <span class="math inline">\(Y\)</span> cuando <span class="math inline">\(n\rightarrow\infty\)</span></p>
</div>
</section></section><section id="leyes-de-los-grandes-números-y-teorema-central-del-límite" class="level2" data-number="3.10"><h2 data-number="3.10" class="anchored" data-anchor-id="leyes-de-los-grandes-números-y-teorema-central-del-límite">
<span class="header-section-number">3.10</span> Leyes de los Grandes Números y Teorema Central del Límite</h2>
<section id="leyes-de-los-grandes-números" class="level3" data-number="3.10.1"><h3 data-number="3.10.1" class="anchored" data-anchor-id="leyes-de-los-grandes-números">
<span class="header-section-number">3.10.1</span> Leyes de los grandes números</h3>
<div id="def-1.10" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.10</strong></span> Una sucesión de variables aleatorias converge en media a <span class="math inline">\(X\)</span>, y se denota por <span class="math inline">\(X_{n}\xrightarrow{cm}X\)</span> , si para cualquier <span class="math inline">\(\epsilon&gt;0\)</span> se tiene que:<br>
[<em>{n}E(|X</em>{n}-X|)=0,] siempre que dicha esperanza exista.\</p>
<p>De forma análoga se define convergencia en media de orden r si: <span class="math display">\[\lim _{n\to \infty }E(\left|X_{n}-X\right|^r)=0,\]</span></p>
<p>Cuando <span class="math inline">\(r=2\)</span> se dice que se tiene convergencia en media cuadrática</p>
<p><span class="math display">\[\lim _{n\to \infty }E(\left|X_{n}-X\right|^2)=0,\]</span></p>
</div>
</section><section id="relaciones-entre-tipos-de-convergencias" class="level3" data-number="3.10.2"><h3 data-number="3.10.2" class="anchored" data-anchor-id="relaciones-entre-tipos-de-convergencias">
<span class="header-section-number">3.10.2</span> Relaciones entre tipos de convergencias</h3>
</section></section><section id="diagrama-de-convergencias" class="level2" data-number="3.11"><h2 data-number="3.11" class="anchored" data-anchor-id="diagrama-de-convergencias">
<span class="header-section-number">3.11</span> Diagrama de convergencias</h2>
<section id="diagrama-de-relaciones-entre-tipos-de-convergencia" class="level3" data-number="3.11.1"><h3 data-number="3.11.1" class="anchored" data-anchor-id="diagrama-de-relaciones-entre-tipos-de-convergencia">
<span class="header-section-number">3.11.1</span> Diagrama de relaciones entre tipos de convergencia</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><figcaption>Diagrama de convergencias</figcaption><p><img src="images/esquema.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section><section id="ley-débil-de-los-grandes-números" class="level3" data-number="3.11.2"><h3 data-number="3.11.2" class="anchored" data-anchor-id="ley-débil-de-los-grandes-números">
<span class="header-section-number">3.11.2</span> Ley débil de los grandes números</h3>
<div id="thm-13" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.13</strong></span> Sea <span class="math inline">\(X 1,\ldots, X_n\)</span> una sucesión de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante <span class="math inline">\(C\)</span>, independiente de <span class="math inline">\(n\)</span>. Sea <span class="math inline">\(S_n = \sum_{i=1  }^{n}X_i\)</span>. Entonces <span class="math display">\[
\begin{align}
E\left(\left|\frac{S_n-E(S_n)}{n}\right|^2\right)\leq \frac{C}{n}
\end{align}
\]</span> y, como consecuencia <span class="math display">\[\lim _{n\to \infty }\frac{S_n-E(S_n)}{n}=0\]</span> en el sentido de la convergencia en <strong>media cuadrática</strong>.</p>
</div>
<p>Los resultados que garantizan la convergencia casi segura de la media muestral se conocen como leyes fuertes de los grandes números. Se enuncia a continuación una <strong>ley fuerte</strong> para variables con segundos momentos finitos e incorreladas.</p>
</section><section id="ley-fuerte-de-los-grandes-números" class="level3" data-number="3.11.3"><h3 data-number="3.11.3" class="anchored" data-anchor-id="ley-fuerte-de-los-grandes-números">
<span class="header-section-number">3.11.3</span> Ley fuerte de los grandes números</h3>
<div id="thm-line" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.14</strong></span> Sea <span class="math inline">\(X 1,\ldots, X_n\)</span> una sucesión de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante <span class="math inline">\(C\)</span>, independiente de <span class="math inline">\(n\)</span>. Sea <span class="math inline">\(S_n = \sum_{i=1  }^{n}X_i\)</span>. Entonces <span class="math display">\[
        \begin{align}
        E\left(\left|\frac{S_n-E(S_n)}{n}\right|^2\right)\leq \frac{C}{n}
        \end{align}
        \]</span> y, como consecuencia <span class="math display">\[\lim _{n\to \infty }\frac{S_n-E(S_n)}{n}=0\]</span> en el sentido de la <strong>casi segura</strong>.</p>
</div>
</section></section><section id="teorema-central-del-límite" class="level2" data-number="3.12"><h2 data-number="3.12" class="anchored" data-anchor-id="teorema-central-del-límite">
<span class="header-section-number">3.12</span> Teorema central del límite</h2>
<div id="thm-line" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.15</strong></span> <strong>Central de Límite</strong> Sean <span class="math inline">\(Y_1,\,Y_2,\cdots,\,Y_n\)</span> v.a’s iid ( no se precisa de que distribuci'on se generan) con <span class="math inline">\(E[Y_i]=\mu\)</span> y <span class="math inline">\(V[Y_i]=\sigma^2&lt;\infty\)</span>. Definamos <span class="math display">\[U_n=\frac{\sum_{i=1}^nY_i-n\mu}{\sigma\sqrt{n}}=\frac{\overline{Y}-\mu}{\sigma/\sqrt{n}}\mbox{ donde} \overline{Y}=\frac{1}{n}\sum_{i=1}^nY_i\]</span> Entonces la función de distribución de <span class="math inline">\(U_n\)</span> converge hacia la función de distribución normal estándar cuando n tiende a infinito . Esto es, <span class="math display">\[\lim_{n\rightarrow\infty}P(U_n\leq u)=\int_{-\infty}^u\frac{1}{\sqrt{2\pi}}e^{-t^2/2}dt, \forall u\]</span></p>
</div>
<!-- ## Ejemplo -->
<!-- ::: {#thm-line} -->
<!-- The equation of any straight line, called a linear equation, can be written as: -->
<!-- $$ -->
<!-- y = mx + b -->
<!-- $$ -->
<!-- ::: -->
<!-- See @thm-line. -->
<hr></section><section id="referencias" class="level2" data-number="3.13"><h2 data-number="3.13" class="anchored" data-anchor-id="referencias">
<span class="header-section-number">3.13</span> Referencias</h2>
<ul>
<li><p><strong>Gómez, Guadalupe</strong>, &amp; <strong>Delicado, Pedro</strong> (2006). <em>Curso de Inferencia y Decisión</em>. Departament d’Estadística i Investigació Operativa, Universitat Politècnica de Catalunya.</p></li>
<li><p><strong>Wackerly, D. D., Mendenhall, W.</strong>, &amp; <strong>Scheaffer, R. L.</strong> (2008). <strong>Estadística matemática con aplicaciones</strong> (7ª ed.). Cengage Learning.</p></li>
<li><p><strong>Roussas, G. G.</strong> (1997). <strong>A Course in Mathematical Statistics</strong> (2nd ed.). Academic Press.</p></li>
</ul>


</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->



</body></html>