<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>3&nbsp; Estimación puntual – Inferencia Estadística</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-241b0f728d524ab724cf38981e173e36.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter2.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Estimación puntual</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Inferencia Estadística</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">INTRODUCCIÓN</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Principios para reducir los datos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Estimación puntual</span></span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#la-funci%C3%B3n-de-distribuci%C3%B3n-emp%C3%ADrica-y-el-m%C3%A9todo-de-los-momentos" id="toc-la-función-de-distribución-empírica-y-el-método-de-los-momentos" class="nav-link active" data-scroll-target="#la-funci%C3%B3n-de-distribuci%C3%B3n-emp%C3%ADrica-y-el-m%C3%A9todo-de-los-momentos"><span class="header-section-number">3.1</span> La función de distribución empírica y el método de los momentos</a></li>
  <li><a href="#teorema-de-glivenko-cantelli" id="toc-teorema-de-glivenko-cantelli" class="nav-link" data-scroll-target="#teorema-de-glivenko-cantelli"><span class="header-section-number">3.2</span> Teorema de Glivenko-Cantelli</a></li>
  <li>
<a href="#la-funci%C3%B3n-de-distribuci%C3%B3n-emp%C3%ADrica-y-el-m%C3%A9todo-de-los-momentos-1" id="toc-la-función-de-distribución-empírica-y-el-método-de-los-momentos-1" class="nav-link" data-scroll-target="#la-funci%C3%B3n-de-distribuci%C3%B3n-emp%C3%ADrica-y-el-m%C3%A9todo-de-los-momentos-1"><span class="header-section-number">3.3</span> La función de distribución empírica y el método de los momentos</a>
  <ul class="collapse">
<li><a href="#principio-de-sustituci%C3%B3n" id="toc-principio-de-sustitución" class="nav-link" data-scroll-target="#principio-de-sustituci%C3%B3n"><span class="header-section-number">3.3.1</span> Principio de sustitución</a></li>
  </ul>
</li>
  <li><a href="#m%C3%A9todo-de-momentos" id="toc-método-de-momentos" class="nav-link" data-scroll-target="#m%C3%A9todo-de-momentos"><span class="header-section-number">3.4</span> Método de momentos</a></li>
  <li><a href="#estimadores-de-m%C3%A1xima-verosimilitud" id="toc-estimadores-de-máxima-verosimilitud" class="nav-link" data-scroll-target="#estimadores-de-m%C3%A1xima-verosimilitud"><span class="header-section-number">3.5</span> Estimadores de máxima verosimilitud</a></li>
  <li>
<a href="#c%C3%A1lculo-del-estimador-m%C3%A1ximo-veros%C3%ADmil" id="toc-cálculo-del-estimador-máximo-verosímil" class="nav-link" data-scroll-target="#c%C3%A1lculo-del-estimador-m%C3%A1ximo-veros%C3%ADmil"><span class="header-section-number">3.6</span> Cálculo del estimador máximo verosímil</a>
  <ul class="collapse">
<li><a href="#preguntas-sobre-x" id="toc-preguntas-sobre-x" class="nav-link" data-scroll-target="#preguntas-sobre-x"><span class="header-section-number">3.6.1</span> Preguntas sobre <span class="math inline">\(X\)</span></a></li>
  <li><a href="#principio-de-invarianza-del-estimador-m%C3%A1ximo-veros%C3%ADmil" id="toc-principio-de-invarianza-del-estimador-máximo-verosímil" class="nav-link" data-scroll-target="#principio-de-invarianza-del-estimador-m%C3%A1ximo-veros%C3%ADmil"><span class="header-section-number">3.6.2</span> Principio de invarianza del estimador máximo verosímil</a></li>
  </ul>
</li>
  <li>
<a href="#error-cuadr%C3%A1tico-medio" id="toc-error-cuadrático-medio" class="nav-link" data-scroll-target="#error-cuadr%C3%A1tico-medio"><span class="header-section-number">3.7</span> Error cuadrático medio</a>
  <ul class="collapse">
<li><a href="#observaciones-sobre-el-ecm" id="toc-observaciones-sobre-el-ecm" class="nav-link" data-scroll-target="#observaciones-sobre-el-ecm"><span class="header-section-number">3.7.1</span> Observaciones sobre el ECM</a></li>
  </ul>
</li>
  <li><a href="#eficiencia-relativa" id="toc-eficiencia-relativa" class="nav-link" data-scroll-target="#eficiencia-relativa"><span class="header-section-number">3.8</span> Eficiencia relativa</a></li>
  <li><a href="#mejor-estimador-insesgado." id="toc-mejor-estimador-insesgado." class="nav-link" data-scroll-target="#mejor-estimador-insesgado."><span class="header-section-number">3.9</span> Mejor estimador insesgado.</a></li>
  <li><a href="#teorema-de-cram%C3%A9r-rao.-informaci%C3%B3n-de-fisher" id="toc-teorema-de-cramér-rao.-información-de-fisher" class="nav-link" data-scroll-target="#teorema-de-cram%C3%A9r-rao.-informaci%C3%B3n-de-fisher"><span class="header-section-number">3.10</span> Teorema de Cramér-Rao. Información de Fisher</a></li>
  <li>
<a href="#evaluaci%C3%B3n-de-estimadores" id="toc-evaluación-de-estimadores" class="nav-link" data-scroll-target="#evaluaci%C3%B3n-de-estimadores"><span class="header-section-number">3.11</span> Evaluación de estimadores</a>
  <ul class="collapse">
<li><a href="#mejor-estimador-insesgado.-1" id="toc-mejor-estimador-insesgado.-1" class="nav-link" data-scroll-target="#mejor-estimador-insesgado.-1"><span class="header-section-number">3.11.1</span> Mejor estimador insesgado.</a></li>
  <li><a href="#otra-versi%C3%B3n-del-teorema-de-rao-blackwell" id="toc-otra-versión-del-teorema-de-rao-blackwell" class="nav-link" data-scroll-target="#otra-versi%C3%B3n-del-teorema-de-rao-blackwell"><span class="header-section-number">3.11.2</span> Otra versión del teorema de Rao-Blackwell</a></li>
  </ul>
</li>
  <li>
<a href="#comportamiento-asint%C3%B3tico" id="toc-comportamiento-asintótico" class="nav-link" data-scroll-target="#comportamiento-asint%C3%B3tico"><span class="header-section-number">3.12</span> Comportamiento asintótico</a>
  <ul class="collapse">
<li><a href="#consistencia" id="toc-consistencia" class="nav-link" data-scroll-target="#consistencia"><span class="header-section-number">3.12.1</span> Consistencia</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Estimación puntual</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><section id="la-función-de-distribución-empírica-y-el-método-de-los-momentos" class="level2" data-number="3.1"><h2 data-number="3.1" class="anchored" data-anchor-id="la-función-de-distribución-empírica-y-el-método-de-los-momentos">
<span class="header-section-number">3.1</span> La función de distribución empírica y el método de los momentos</h2>
<p>Sea la variable aleatoria <span class="math inline">\(X\)</span> con función de distribución <span class="math inline">\(F\)</span>. Consideramos una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span>, es decir, <span class="math inline">\(X_1 ,\ldots, X_n\)</span> v.a.i.i.d. con distribución dada por <span class="math inline">\(F\)</span> . Sea <span class="math inline">\(x_1 ,\ldots, x_n\)</span> una realización de esa m.a.s. Se llama función de <strong>distribución empírica</strong> a la función <span class="math display">\[
\begin{align}
F_{n}(x)=\dfrac{1}{n}\displaystyle\sum_{i=1}^{n}\mathbf{I}_{(-\infty,x]}(x_{i})¸
\end{align}
\]</span> que a cada número real x le asigna la proporción de valores observados que son menores o iguales que x.</p>
<p>Es inmediato comprobar que la función <span class="math inline">\(F_n\)</span> así definida es una función de distribución:</p>
<ol type="1">
<li>
<span class="math inline">\(F_n(x) \in [0, 1]\)</span> para todo <span class="math inline">\(x \in \mathbb{R}\)</span>.</li>
<li>
<span class="math inline">\(F_n\)</span> es continua por la derecha.</li>
<li>
<span class="math inline">\(F_n\)</span> es no decreciente.</li>
<li><span class="math inline">\(\lim _{x\to -\infty }F_{n}(x)=0\)</span></li>
<li><span class="math inline">\(\lim _{x\to \infty }F_{n}(x)=1\)</span></li>
</ol>
<p>Concretamente, <span class="math inline">\(F_n\)</span> es la función de distribución de una variable aleatoria discreta (que podemos llamar <span class="math inline">\(X_e\)</span> ) que pone masa <span class="math inline">\(\frac{1}{n}\)</span> en cada uno de los n puntos <span class="math inline">\(x_i\)</span> observados:</p>
<table class="caption-top table">
<thead><tr class="header">
<th><span class="math inline">\(x_i\)</span></th>
<th><span class="math inline">\(1\)</span></th>
<th><span class="math inline">\(2\)</span></th>
<th><span class="math inline">\(\ldots\)</span></th>
<th><span class="math inline">\(n\)</span></th>
</tr></thead>
<tbody><tr class="odd">
<td><span class="math inline">\(p_i = P(X_e = x_i)\)</span></td>
<td><span class="math inline">\(1/n\)</span></td>
<td><span class="math inline">\(1/n\)</span></td>
<td><span class="math inline">\(\ldots\)</span></td>
<td><span class="math inline">\(1/n\)</span></td>
</tr></tbody>
</table>
<p>A la distribución de <span class="math inline">\(X_e\)</span> e se le llama <strong>distribución empírica</strong> asociada al conjunto de valores <span class="math inline">\({x_1 ,\ldots, x_n}\)</span>.</p>
<p>Obsérvese que si fijamos el valor de <span class="math inline">\(x\)</span> y dejamos variar la muestra, lo que obtenemos es una variable aleatoria. En efecto, se tiene entonces que</p>
<p><span class="math display">\[
\begin{align}
F_{n}(x)=\dfrac{1}{n}\displaystyle\sum_{i=1}^{n}\mathbf{I}_{(-\infty,x]}(x_{i})¸
\end{align}
\]</span></p>
<p>donde</p>
<p><span class="math display">\[
\begin{align}
\mathbf{I}_{(-\infty,x]}(X_{i})= \left\{ \begin{array}{lcc}
1 &amp;   si  &amp; X_{i}\leq x \\
\\ 0 &amp;  si &amp;X_{i}&gt; x\\
\end{array}
\right.
\end{align}
\]</span> y, por lo tanto, cada término <span class="math inline">\(\mathbf{I}_{(-\infty,x]}(X_{i})\)</span> es una variable aleatoria de Bernoulli con probabilidad de éxito</p>
<p><span class="math display">\[
\begin{align}
p&amp;=P(\mathbf{I}_{(-\infty,x]}(X_{i})=1)\\
&amp;=P(X_{i}\leq x)\\
&amp;=F(x)
\end{align}
\]</span> De ahí se deduce que <span class="math inline">\(F_n\)</span> es una variable aleatoria y que <span class="math inline">\(nF_n(x)\)</span> tiene distribución binomial con parámetros <span class="math inline">\(n\)</span> y <span class="math inline">\(p = F(x)\)</span>.</p>
</section><section id="teorema-de-glivenko-cantelli" class="level2" data-number="3.2"><h2 data-number="3.2" class="anchored" data-anchor-id="teorema-de-glivenko-cantelli">
<span class="header-section-number">3.2</span> Teorema de Glivenko-Cantelli</h2>
<p>El siguiente teorema recoge algunas de las propiedades de la función de distribución empírica.</p>
<div id="thm-3.1" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.1</strong></span> Sea <span class="math inline">\(\{X_n\}\)</span> para <span class="math inline">\(n\geq 1\)</span> , sucesión de variables aleatorias independientes e idénticamente distribuidas definidas en el espacio de probabilidad <span class="math inline">\((\Omega, \mathcal{A}, P)\)</span> con función de distribución común <span class="math inline">\(F\)</span> . Se denota por <span class="math inline">\(F_n\)</span> la función de distribución empírica obtenida de las <span class="math inline">\(n\)</span> primeras variables aleatorias <span class="math inline">\(X_1 ,\ldots, X_n\)</span> . Sea <span class="math inline">\(x\in\mathbb{R}\)</span>. Se verifica lo siguiente:</p>
</div>
<ol type="a">
<li>
<span class="math inline">\(P(nF_n(x)=j)=P(F_n(x)=\frac{j}{n})=\binom{n}{j}(F(x))^j(1-F(x))^{n-j}\)</span>, <span class="math inline">\(j=1,\ldots,n\)</span>\</li>
<li>
<span class="math inline">\(E(F_n(x))=F(x)\)</span>; <span class="math inline">\(Var(F_n(x))=\frac{1}{n}F(x)(1-F(x))\)</span>.</li>
<li><span class="math inline">\(\lim _{n\to \infty }F_{n}(x)=F(x)\)</span></li>
<li>
<span class="math inline">\(\lim _{n\to \infty }\frac{F_{n}(x)-F(x)}{\sqrt{\frac{F(x)(1-F(x))}{n}}}=Z\)</span>, donde <span class="math inline">\(Z\)</span> es una variable aleatoria con distribución normal estándar y la convergencia es convergencia en distribución.</li>
</ol>
<p>El siguiente teorema refuerza el resultado (c) anterior, puesto que afirma que la convergencia de <span class="math inline">\(F_n(x)\)</span> a <span class="math inline">\(F(x)\)</span> se da uniformemente.</p>
<div id="thm-3.2" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.2</strong></span> Sea <span class="math inline">\(\{X_n\}\)</span> para <span class="math inline">\(n\geq 1\)</span> , sucesión de variables aleatorias independientes e idénticamente distribuidas definidas en el espacio de probabilidad <span class="math inline">\((\Omega, \mathcal{A}, P)\)</span> con función de distribución común <span class="math inline">\(F\)</span> . Se denota por <span class="math inline">\(F_n\)</span> la función de distribución empírica obtenida de las <span class="math inline">\(n\)</span> primeras variables aleatorias <span class="math inline">\(X_1 ,\ldots, X_n\)</span> . Sea <span class="math inline">\(x\in\mathbb{R}\)</span>. Entonces <span class="math display">\[Sup_{x\in\mathbb{R}} |F_{n}(x)-F(x)|\xrightarrow{c.s}0\]</span></p>
</div>
<div id="nte-3.1" class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note&nbsp;3.1
</div>
</div>
<div class="callout-body-container callout-body">
<p>Obsérvese que según el apartado (c) del teorema <a href="#thm-3.1" class="quarto-xref">Theorem&nbsp;<span>3.1</span></a>, las distribuciones empíricas asociadas a muestras de tamaño n convergen débilmente a la distribución de probabilidad teórica identificada por <span class="math inline">\(F\)</span>, para casi todas las muestras de tamaño infinito que se extraigan de <span class="math inline">\(F\)</span> . Ésta es una de las consecuencias más importantes del citado teorema: la distribución empírica converge débilmente con probabilidad 1 a la poblacional cuando el tamaño de la muestra tiende a infinito: <span class="math display">\[F_{n}(x)\xrightarrow{c.s}F(x)\]</span> Esto garantiza la posibilidad de realizar inferencia estadística:</p>
<ol type="1">
<li>Los aspectos probabilísticos de una característica <span class="math inline">\(X\)</span>, medida en una población, se resumen de forma estilizada en una distribución de probabilidad <span class="math inline">\(F\)</span>.</li>
<li>La distribución de probabilidad <span class="math inline">\(F\)</span>, puede ser aproximada mediante las distribuciones empíricas <span class="math inline">\(F_n\)</span> obtenidas por muestreo de la población en estudio.</li>
<li>El teorema de Glivenko-Cantelli afirma que esas aproximaciones son uniformes en x.</li>
<li>Por esta razón el teorema de Glivenko-Cantelli se llama a veces Teorema Fundamental de la Estadística Matemática.</li>
</ol>
</div>
</div>
<p><strong>Podemos ver a continuación cómo, a medida que aumentamos el tamaño de la muestra (n=10,30,100,1000), la función de distribución empírica se ajusta cada vez mejor a la distribución teórica normal estándar N(0,1), tal como afirma el teorema.</strong></p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Cargar librería para gráficos</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Definir función para graficar ECDF vs distribución teórica</span></span>
<span><span class="va">comparar_ecdf_teorica</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span>, <span class="va">distribucion</span> <span class="op">=</span> <span class="st">"normal"</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span>  <span class="co"># Para reproducibilidad</span></span>
<span></span>
<span>  <span class="co"># Muestra de tamaño n desde N(0,1)</span></span>
<span>  <span class="va">muestra</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Dominio común</span></span>
<span>  <span class="va">x_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">3</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Distribución teórica</span></span>
<span>  <span class="va">F_teorica</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="va">x_vals</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Distribución empírica</span></span>
<span>  <span class="va">ecdf_muestra</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html">ecdf</a></span><span class="op">(</span><span class="va">muestra</span><span class="op">)</span></span>
<span>  <span class="va">F_empirica</span> <span class="op">&lt;-</span> <span class="fu">ecdf_muestra</span><span class="op">(</span><span class="va">x_vals</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Construir data frame para ggplot</span></span>
<span>  <span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">x_vals</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>    F <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">F_empirica</span>, <span class="va">F_teorica</span><span class="op">)</span>,</span>
<span>    Tipo <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Empírica"</span>, <span class="st">"Teórica"</span><span class="op">)</span>, each <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">x_vals</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Graficar</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="cn">F</span>, color <span class="op">=</span> <span class="va">Tipo</span>, linetype <span class="op">=</span> <span class="va">Tipo</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>      title <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"ECDF vs F(x) — Tamaño de muestra n ="</span>, <span class="va">n</span><span class="op">)</span>,</span>
<span>      x <span class="op">=</span> <span class="st">"x"</span>, y <span class="op">=</span> <span class="st">"Probabilidad acumulada"</span></span>
<span>    <span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_color_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Empírica"</span> <span class="op">=</span> <span class="st">"red"</span>, <span class="st">"Teórica"</span> <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_linetype_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Empírica"</span> <span class="op">=</span> <span class="st">"dashed"</span>, <span class="st">"Teórica"</span> <span class="op">=</span> <span class="st">"solid"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Generar gráficos para diferentes tamaños de muestra</span></span>
<span><span class="fu">comparar_ecdf_teorica</span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">comparar_ecdf_teorica</span><span class="op">(</span><span class="fl">30</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-1-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">comparar_ecdf_teorica</span><span class="op">(</span><span class="fl">100</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-1-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">comparar_ecdf_teorica</span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-1-4.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>El Teorema Fundamental de la Estadística Matemática: da una fundamentación de la inferencia estadística, cuyo objetivo principal consiste en extraer información sobre <span class="math inline">\(F\)</span> a partir de las observaciones muestrales.</strong></p>
<p><strong>¿Por qué esto es importante?</strong></p>
<p>Porque sin conocer <span class="math inline">\(F(x)\)</span> explícitamente, <strong>podemos estimarla a partir de los datos</strong>.<br>
Esto es la base de:</p>
<ul>
<li>los <strong>histogramas acumulados</strong>,</li>
<li>las <strong>pruebas no paramétricas</strong>,</li>
<li>los <strong>intervalos de confianza empíricos</strong>, y</li>
<li>toda la <strong>inferencia estadística basada en datos reales</strong>.</li>
</ul>
<p>🎯 <strong>Ejemplo: Estimación del percentil 90 del ingreso mensual</strong></p>
<p>📌 Contexto Supón que quieres estimar el ingreso mensual <strong>por debajo del cual se encuentran el 90% de las personas</strong> en una ciudad.<br>
No conoces la distribución real del ingreso $ F(x) $, pero tienes una muestra de datos.</p>
<hr>
<p><strong>Paso a paso</strong></p>
<ol type="1">
<li>Simulamos una población Vamos a suponer que el ingreso sigue una distribución log-normal:</li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">poblacion</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Lognormal.html">rlnorm</a></span><span class="op">(</span><span class="fl">1e6</span>, meanlog <span class="op">=</span> <span class="fl">10</span>, sdlog <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="2" type="1">
<li>Tomamos una muestra aleatoria</li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">muestra</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">poblacion</span>, size <span class="op">=</span> <span class="fl">20000</span>, replace <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="3" type="1">
<li>Estimamos la distribución empírica</li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Fn</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html">ecdf</a></span><span class="op">(</span><span class="va">muestra</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="4" type="1">
<li>Estimamos el percentil 90 (cuantil 0.9)</li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cuantil_90_empirico</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">muestra</span>, probs <span class="op">=</span> <span class="fl">0.9</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="5" type="1">
<li>Comparamos con el valor verdadero en la población</li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cuantil_90_real</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">poblacion</span>, probs <span class="op">=</span> <span class="fl">0.9</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="6" type="1">
<li>Resultado</li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Cuantil 90 estimado (empírico):"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">cuantil_90_empirico</span>, <span class="fl">2</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cuantil 90 estimado (empírico): 41926.83 </code></pre>
</div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Cuantil 90 real (poblacional):"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">cuantil_90_real</span>, <span class="fl">2</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cuantil 90 real (poblacional): 41805.56 </code></pre>
</div>
</div>
</section><section id="la-función-de-distribución-empírica-y-el-método-de-los-momentos-1" class="level2" data-number="3.3"><h2 data-number="3.3" class="anchored" data-anchor-id="la-función-de-distribución-empírica-y-el-método-de-los-momentos-1">
<span class="header-section-number">3.3</span> La función de distribución empírica y el método de los momentos</h2>
<section id="principio-de-sustitución" class="level3" data-number="3.3.1"><h3 data-number="3.3.1" class="anchored" data-anchor-id="principio-de-sustitución">
<span class="header-section-number">3.3.1</span> Principio de sustitución</h3>
<p>En esta sección presentamos una consecuencia importante de la convergencia de <span class="math inline">\(F_n\)</span> a <span class="math inline">\(F\)</span> , la definición de estimadores mediante el principio de sustitución.</p>
<ol type="a">
<li>La convergencia de <span class="math inline">\(F_n\)</span> a <span class="math inline">\(F\)</span> permite construir versiones factibles de características poblacionales desconocidas.</li>
<li>Supongamos que estudiamos una característica <span class="math inline">\(X\)</span> en una población y que el resultado de la observación de <span class="math inline">\(X\)</span> puede ser modelado como una variable aleatoria con distribución desconocida, digamos <span class="math inline">\(F\)</span>.</li>
<li>Muchas de las preguntas relevantes acerca de la característica <span class="math inline">\(X\)</span> podrían ser contestadas si su función de distribución <span class="math inline">\(F\)</span> fuese conocida.</li>
</ol>
<div id="imp-3.1" class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important&nbsp;3.1
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Preguntas sobre <span class="math inline">\(X\)</span></strong></p>
<ul>
<li>el valor esperado,</li>
<li>el número de modas de la distribución o</li>
<li>la probabilidad de que <span class="math inline">\(X\)</span> sea negativa</li>
</ul>
<p>Para fijar ideas podemos pensar que nos interesa conocer cantidades numéricas (parámetros) que dependen únicamente de la función de distribución desconocida <span class="math inline">\(F\)</span>:</p>
<p><span class="math display">\[
    \begin{align}
    \theta=\psi(F)
    \end{align}
\]</span> <strong>El teorema de Glivenko-Cantelli</strong> nos dice que <span class="math inline">\(F_n\)</span> se acerca a <span class="math inline">\(F\)</span>, a medida que el tamaño muestral crece. Así, podemos esperar que también se verifique que <span class="math display">\[
    \begin{align}
    \hat{\theta}_n=\psi(F_n)\rightarrow\theta=\psi(F)
    \end{align}
    \]</span></p>
<p>Es decir, esperamos que las cantidades numéricas calculadas para la distribución empírica (estimadores) se aproximen a las cantidades desconocidas a medida que el tamaño muestral crezca.</p>
<p>Esta forma de obtener estimadores de parámetros poblacionales desconocidos se denomina principio de sustitución (plug-in principle en inglés). Es un procedimiento muy general de obtención de estimadores.</p>
</div>
</div>
<p>Sea <span class="math inline">\(X\sim U(0,\theta)\)</span>. Se toma una m.a.s. de <span class="math inline">\(X\)</span> de tamaño n para estimar <span class="math inline">\(\theta\)</span>. Un estimador razonable de <span class="math inline">\(\theta\)</span> es el máximo de las observaciones, que es estadístico minimal suficiente para <span class="math inline">\(\theta\)</span>: <span class="math display">\[
\begin{align}
    \hat{\theta}_2 = \max_i {X_i}.
\end{align}
\]</span> El siguiente código muestra:</p>
<ul>
<li><p>Para cada tamaño de muestra n, simula valores de <span class="math inline">\(X_i\)</span>∼U(0,θ),</p></li>
<li><p>Calcula <span class="math display">\[\hat{\theta} = \max_i {X_i}\]</span></p></li>
<li><p>Compara con el valor real de <span class="math inline">\(\theta=10\)</span>.</p></li>
<li><p>Muestra cómo, al aumentar n, el estimador se acerca a <span class="math inline">\(\theta\)</span>.</p></li>
</ul>
<div class="cell">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Simulación para estimar theta en una uniforme (0, theta)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">theta_real</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Tamaños de muestra</span></span>
<span><span class="va">n_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">10</span>, <span class="fl">30</span>, <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simular y comparar</span></span>
<span><span class="va">estimadores</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">n_vals</span>, <span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">muestra</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="va">theta_real</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">muestra</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Mostrar resultados</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  Tamaño_muestra <span class="op">=</span> <span class="va">n_vals</span>,</span>
<span>  Estimador_maximo <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">estimadores</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>  Error <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">theta_real</span> <span class="op">-</span> <span class="va">estimadores</span>, <span class="fl">3</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Tamaño_muestra Estimador_maximo Error
1              5            9.371 0.629
2             10            9.347 0.653
3             30            9.889 0.111
4            100            9.828 0.172</code></pre>
</div>
</div>
<p><strong>Convergencia del estimador plug-in en la distribución uniforme</strong></p>
<p>En este ejemplo, estimamos el parámetro <span class="math inline">\(\theta\)</span> de una distribución <span class="math inline">\(X \sim \mathcal{U}(0, \theta)\)</span> usando el estimador <span class="math inline">\(\hat{\theta}_n = \max(X_i)\)</span>. Este es un estimador tipo plug-in: se usa la distribución empírica para estimar una característica de la distribución teórica.</p>
<p>A continuación, simulamos cómo este estimador converge al verdadero valor <span class="math inline">\(\theta = 10\)</span> a medida que el tamaño de muestra <span class="math inline">\(n\)</span> crece.</p>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Chunk de R — solo código</span></span>
<span><span class="co">#| label: fig-convergencia-max</span></span>
<span><span class="co">#| fig-cap: 'Convergencia del estimador plug-in $ \hat{\theta}_n = \max X_i $ hacia el valor real $ \theta = 10 $'</span></span>
<span><span class="co">#| fig-align: center</span></span>
<span><span class="co">#| message: false</span></span>
<span><span class="co">#| warning: false</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">theta_real</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Vector de tamaños de muestra crecientes</span></span>
<span><span class="va">n_seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">500</span>, by <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calcular el estimador para cada n</span></span>
<span><span class="va">estimadores</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">n_seq</span>, <span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">muestra</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="va">theta_real</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">muestra</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Crear data frame para graficar</span></span>
<span><span class="va">df_estimacion</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  n <span class="op">=</span> <span class="va">n_seq</span>,</span>
<span>  estimador <span class="op">=</span> <span class="va">estimadores</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Graficar</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df_estimacion</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">n</span>, y <span class="op">=</span> <span class="va">estimador</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"steelblue"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="va">theta_real</span>, color <span class="op">=</span> <span class="st">"red"</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="st">"Convergencia de "</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">[</span><span class="va">n</span><span class="op">]</span> <span class="op">*</span> <span class="st">" al valor real "</span> <span class="op">*</span> <span class="va">theta</span><span class="op">)</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"Tamaño de muestra (n)"</span>,</span>
<span>    y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">[</span><span class="va">n</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section></section><section id="método-de-momentos" class="level2" data-number="3.4"><h2 data-number="3.4" class="anchored" data-anchor-id="método-de-momentos">
<span class="header-section-number">3.4</span> Método de momentos</h2>
<p>Una aplicación del principio de sustitución es la definición de los estimadores basados en momentos. El momento <strong>no centrado</strong> de orden <span class="math inline">\(k\)</span> de una variable aleatoria <span class="math inline">\(X\)</span> con distribución <span class="math inline">\(F\)</span> se define como <span class="math display">\[
\begin{align}
\mu_k=E_F(X^k)=\int x^kdF(x)
    \end{align}
\]</span> Si <span class="math inline">\(X_e\)</span> es una variable aleatoria con función de distribución igual a <span class="math inline">\(F_n\)</span> , la función de distribución empírica de una m.a.s. de tamaño <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span>, se tiene que sus (a los que llamaremos <span class="math inline">\(m_{k,n}\)</span>) son de la forma <span class="math display">\[\begin{align}
    m_{k,n}=E_{F_n}(X_e^k)=\int x^kdF_n(x)=\frac{1}{n}\sum_{i=1}^{n}X_i^k,
    \end{align}\]</span> y se denominan momentos muestrales no centrados de orden <span class="math inline">\(k\)</span>. Por ejemplo, <span class="math inline">\(µ_1\)</span> es la esperanza poblacional y <span class="math inline">\(m_{1,n}\)</span> la media muestral.</p>
<p>La siguiente proposición garantiza que los momentos muestrales convergen a los poblacionales.</p>
<div id="prp-3.1" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.1</strong></span> Sea <span class="math inline">\(X\)</span> variable aleatoria con <span class="math inline">\(E(X^{2k}) &lt; \infty\)</span>. Entonces se verifica que <span class="math inline">\(m_{k,n} \rightarrow \mu_k\)</span> casi seguro. Además, <span class="math display">\[
\begin{align}
\frac{\sqrt{n}(m_{k,n}-\mu_k)}{\sqrt{\mu_{2k}-\mu_k^2}}\xrightarrow{d}Z,
\end{align}
\]</span> con <span class="math inline">\(Z\sim N(0,1)\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Si <span class="math inline">\(Y_i=X_i^k\)</span> entonces <span class="math inline">\(m_{k,n}=E_{k,n}(Y_i)=E_{n}(X_i^k)=\frac{1}{n}\sum_{i=1}^{n}X_i^k=\frac{1}{n}\sum_{i=1}^{n}Y_i=\bar{Y}_n\)</span>.\</p>
<p>Aplicando la ley fuerte de los grandes números se tiene que <span class="math display">\[\begin{align}
\lim _{n\to \infty }\frac{S_n-E(S_n)}{n}&amp;=\lim _{n\to \infty }\frac{\sum_{i=1}^{n}X_i^k-E(\sum_{i=1}^{n}X_i^k)}{n}\nonumber\\
&amp;=\lim _{n\to \infty }\left[\frac{\sum_{i=1}^{n}X_i^k}{n}-\frac{E(\sum_{i=1}^{n}X_i^k)}{n}\right]\nonumber\\
&amp;=\lim _{n\to \infty }\left[\bar{Y}_n-\frac{\sum_{i=1}^{n}E(X_i^k)}{n}\right]\nonumber\\
&amp;=\lim _{n\to \infty }\left[\bar{Y}_n-\frac{nE(X^k)}{n}\right]\mbox{Por ser las $X_i$ una mas de X}\nonumber\\
&amp;=\lim _{n\to \infty }\left[\bar{Y}_n-\bar{Y}\right]=0   \mbox{ Aplicando L.F.G.N}
\end{align}\]</span></p>
<p>Por lo anterior, se tiene que <span class="math inline">\(m_{k,n}=\bar{Y}_n\xrightarrow{c.s} \mu_k=\bar{Y}=E_F(X^k)\)</span>. Por otro lado, veamos <span class="math display">\[\begin{align}
\frac{S_n-E(S_n)}{\sqrt{Var(S_n)}}=\frac{m_{k,n}-E(X^k)}{\sqrt{\frac{Var(X^k)}{n}}}\xrightarrow{d}Z
\end{align}\]</span> donde <span class="math inline">\(S_n=\sum_{i=1}^{n}X_i^k\)</span>. Sabemos que <span class="math inline">\(E(X^k)=\mu_k\)</span> y que <span class="math inline">\(Var(X^k)=E[(X^k)^2]-[E(X^k)]^2=\mu_{2k}-\mu_k^2\)</span>, de ahí se sigue el resultado.</p>
</div>
<p>Muchas características poblacionales de interés se pueden expresar como función de los momentos no centrados de órdenes <span class="math inline">\(1,\ldots, k\)</span>: <span class="math inline">\(\theta=h(\mu_1, \ldots, \mu_k)\)</span>. Por ejemplo, la varianza de <span class="math inline">\(X\)</span> se expresa como <span class="math inline">\(\sigma^2 = h(\mu_1, \mu_2) = \mu_2-\mu_1^2\)</span>.</p>
<p><strong>El estimador de <span class="math inline">\(\theta\)</span> basado en el principio de sustitución se conoce como estimador de los momentos de <span class="math inline">\(\theta\)</span> y será <span class="math display">\[\begin{align}
\hat{\theta}_n = h(m_{1,n} ,\ldots, m_{k,n}).
    \end{align}\]</span> Obsérvese que el estimador de los momentos de <span class="math inline">\(\theta\)</span> puede no ser único, porque diferentes funciones <span class="math inline">\(h\)</span> pueden conducir al mismo valor <span class="math inline">\(\theta\)</span>.</strong></p>
<div id="prp-3.2" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 3.2</strong></span> Consideremos la variable aleatoria <span class="math inline">\(X\)</span> con <span class="math inline">\(E(X_{2k})&lt; \infty\)</span>. Sea <span class="math inline">\(\theta=h(\mu_{n} ,\ldots, \mu_{n})\)</span>. Si <span class="math inline">\(h\)</span> es continua en <span class="math inline">\((\mu_{n} ,\ldots, \mu_{n})\)</span>, entonces <span class="math inline">\(\hat{\theta}_n=h(m_{1,n} ,\ldots, m_{k,n})\)</span> converge a <span class="math inline">\(\theta\)</span> casi seguro. Además, si <span class="math inline">\(h\)</span> es derivable en <span class="math inline">\((\mu_{n} ,\ldots, \mu_{n})\)</span>, entonces la distribución límite de <span class="math inline">\(\hat{\theta}_n\)</span> es normal: <span class="math display">\[\begin{align}
\sqrt{n}(\hat{\theta}_n-\theta)\xrightarrow{d} N(0, \sigma_{h,\theta}^2)
\end{align}\]</span></p>
</div>
<div id="exm-3.1" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.1</strong></span> Sea <span class="math inline">\(X\sim U(0,\theta)\)</span>. Se toma una m.a.s. de <span class="math inline">\(X\)</span> de tamaño n para estimar <span class="math inline">\(\theta\)</span>. Un estimador de momentos <span class="math inline">\(\hat{\theta}_M\)</span> de <span class="math inline">\(\theta\)</span> viene dado por la siguiente relación <span class="math display">\[\begin{align}
    E(X)=\frac{\theta}{2}\Longrightarrow m_{1,n}=\frac{\hat{\theta}_M}{2}\Longrightarrow 2m_{1,n}=\hat{\theta}_M\Longrightarrow 2\bar{X}=\hat{\theta}_M
    \end{align}\]</span></p>
</div>
<div id="exm-3.2" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.2</strong></span> &nbsp;</p>
<p>Para la variable aleatoria <span class="math inline">\(X\)</span> con varianza finita, un estimador para <span class="math inline">\(\theta=Var(X)\)</span> es <span class="math display">\[\begin{align}
\hat{\theta}=h(m_{1,n}, m_{2,n})&amp;=m_{2,n}-m_{1,n}^2\nonumber\\
&amp;=\frac{1}{n}\sum_{i=1}^{n}x_i^2-\bar{x}^2\nonumber\\
&amp;=\frac{\sum_{i=1}^{n}x_i^2-n\bar{x}^2}{n}\nonumber\\
&amp;=\frac{\sum_{i=1}^{n}(x_i-\bar{x})^2}{n}\nonumber\\
&amp;=\frac{(n-1)S_n^2}{n}\nonumber\\
\end{align}\]</span></p>
</div>
<div id="exm-3.3" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.3</strong></span> &nbsp;</p>
Si <span class="math inline">\(X\sim Exp(\lambda)\)</span> con <span class="math inline">\(E(X)=\frac{1}{\lambda}\)</span>, entonces <span class="math inline">\(m_{1,n}=\frac{1}{\hat{\lambda}_M}\)</span> <span class="math inline">\(\Longrightarrow \hat{\lambda}_M=\frac{1}{m_{1,n}}\Longrightarrow \hat{\lambda}_M=\frac{1}{\bar{X}}\)</span>.
<p>Si <span class="math inline">\(X\sim B(n,p)\)</span>, con <span class="math inline">\(E(X)=np\)</span> y <span class="math inline">\(Var(X)=npq\)</span>, entonces <span class="math inline">\(m_{1,n}=n\hat{p}\)</span> <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(\frac{m_{1,n}}{n}=\hat{p}\)</span> <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(\frac{\bar{X}}{n}=\hat{p}\)</span> <span class="math inline">\(\Longrightarrow\)</span> <span class="math inline">\(\hat{Var(X)}=n\hat{p}(1-\hat{p})\)</span>.</p>
</div>
</section><section id="estimadores-de-máxima-verosimilitud" class="level2" data-number="3.5"><h2 data-number="3.5" class="anchored" data-anchor-id="estimadores-de-máxima-verosimilitud">
<span class="header-section-number">3.5</span> Estimadores de máxima verosimilitud</h2>
</section><section id="cálculo-del-estimador-máximo-verosímil" class="level2" data-number="3.6"><h2 data-number="3.6" class="anchored" data-anchor-id="cálculo-del-estimador-máximo-verosímil">
<span class="header-section-number">3.6</span> Cálculo del estimador máximo verosímil</h2>
<p>Sea <span class="math inline">\(\underset{\sim}{X} =(X_1,\ldots, X_n)\)</span> una muestra aleatoria simple de una variable aleatoria <span class="math inline">\(X\)</span> con función de densidad (o de masa de probabilidad) <span class="math inline">\(f(\underset{\sim}{x}|\theta)\)</span>, con <span class="math inline">\(\theta = (\theta_1,\ldots,\theta_k) \in \Theta \subseteq \mathbb{R}^k\)</span> . Sea <span class="math inline">\(\mathcal{X}\)</span> el espacio muestral, es decir, el conjunto de todos los posibles valores de <span class="math inline">\(\underset{\sim}{X}\)</span> . Hemos definido la para <span class="math inline">\(\underset{\sim}{x} =(x_1,\ldots, x_n )\in \mathcal{X}\)</span> como <span class="math display">\[
    \begin{align}
    L(\cdot|\underset{\sim}{x}):&amp;\Theta\rightarrow \mathbb{R}^+\nonumber\\
    &amp;\theta\rightarrow L(\theta|\underset{\sim}{x})=f(\underset{\sim}{x}|\theta)=\prod_{i=1}^{n}f(x_i|\theta)
    \end{align}
\]</span></p>
<section id="preguntas-sobre-x" class="level3" data-number="3.6.1"><h3 data-number="3.6.1" class="anchored" data-anchor-id="preguntas-sobre-x">
<span class="header-section-number">3.6.1</span> Preguntas sobre <span class="math inline">\(X\)</span>
</h3>
<p>Para cada muestra <span class="math inline">\(\underset{\sim}{x} \in \underset{\sim}{X}\)</span> , el estimador de máxima verosimilitud <span class="math inline">\(\hat{\theta}\)</span> de <span class="math inline">\(\theta\)</span> es el valor de <span class="math inline">\(\Theta\)</span> que hace máxima la verosimilitud <span class="math inline">\(L(\cdot|\underset{\sim}{x})\)</span>: <span class="math display">\[
\begin{align}
L(\hat{\theta}| \underset{\sim}{x} ) = \max_{\theta \in \Theta} L(\theta|\underset{\sim}{x}).
\end{align}
\]</span> Intuitivamente <span class="math inline">\(\hat{\theta}\)</span> es el valor del parámetro que hace más verosímil la muestra observada. Veremos más adelante que los estimadores de máxima verosimilitud son muy buenos estimadores y que en general tienen propiedades de optimalidad. Además, en muchas ocasiones el estimador máximo verosímil es el que el sentido común nos llevaría a proponer.</p>
<div id="exm-3.4" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.4</strong></span> Si <span class="math inline">\(X\sim Exp(\lambda)\Longrightarrow f(x|\lambda)=\lambda\exp\{-\lambda x\}I_{[0,\infty)}(x)\)</span>, <span class="math inline">\(\lambda&gt;0\)</span></p>
<p>Se toma una muestra de tamaño <span class="math inline">\(n=1\)</span> y se observa que <span class="math inline">\(x=3\)</span>. Estudiamos la función de verosimilitud <span class="math inline">\(L(\lambda|3)=\lambda\exp\{-3\lambda\}\)</span> y buscamos su máximo para <span class="math inline">\(\lambda&gt;0\)</span>.</p>
<p>Buscamos los valores de <span class="math inline">\(\lambda\)</span> que hacen la derivada cero de <span class="math inline">\(L(\lambda|3)\)</span>: <span id="eq-maxver_exp"><span class="math display">\[  
\begin{align}
\label{maxver_exp}
L^{'}(\lambda|3)&amp;=\exp\{-3\lambda\}(1-3\lambda)
\end{align}
\tag{3.1}\]</span></span> Igualando a cero la expresión (<a href="#eq-maxver_exp" class="quarto-xref">Equation&nbsp;<span>3.1</span></a>) se tiene que <span class="math inline">\(\lambda=\frac{1}{3}\)</span>. Como <span class="math inline">\(L^{'}(\lambda|3)\geq 0\)</span> y <span class="math display">\[
\begin{align}
\lim _{\lambda\to 0}L(\lambda|3)=\lim _{\lambda\to \infty}L(\lambda|3)=0
\end{align}
\]</span> Se sigue que el punto crítico de <span class="math inline">\(L(\lambda|3)\)</span> es un máximo. Así, <span class="math inline">\(\hat{\lambda}=\frac{1}{3}\)</span></p>
</div>
<div id="exm-3.5" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.5</strong></span> Suponga que deseamos estimar <span class="math inline">\(\theta\)</span>, la proporción de personas con tuberulosis en una gran población homogénea. Para hacer esto, seleccionamos de manera aleatoria <span class="math inline">\(n\)</span> personas para hacer pruebas y encontrar <span class="math inline">\(x\)</span> de estos que tienen la enfermedad.</p>
<p>Ya que la población es grande y homogénea, asumimos que los <span class="math inline">\(n\)</span> individuos observados son independiente y que cada uno tiene probabilidad <span class="math inline">\(\theta\)</span> de tener tuberculosis.</p>
<p>Si <span class="math inline">\(E\)</span> es el evento tiene tuberculosis <span id="eq-Kalbfleish1"><span class="math display">\[
\begin{align}
P(E;\theta)&amp;=P(\mbox{x entre n tienen tuberculosis})\nonumber\\
&amp;=\binom{n}{x}\theta^x(1-\theta)^{n-x}
\end{align}
\tag{3.2}\]</span></span> Observe que <span class="math inline">\(\binom{n}{x}\)</span> es un factor constante no tendrá efecto sobre la maximización de la expresión (<a href="#eq-Kalbfleish1" class="quarto-xref">Equation&nbsp;<span>3.2</span></a>) sobre <span class="math inline">\(\theta\)</span>, ver (kalbfleisch et al.&nbsp;(1985)). La función de verosimilitud de <span class="math inline">\(\theta\)</span> es definida como sigue: <span id="eq-ver"><span class="math display">\[
\begin{align}
L(\theta)=cP(E;\theta)
\end{align}
\tag{3.3}\]</span></span> Acá <span class="math inline">\(c\)</span> es alguna constante positiva con respecto a <span class="math inline">\(\theta\)</span>; esto es, <span class="math inline">\(c\)</span> no es función de <span class="math inline">\(\theta\)</span>, sin embargo esta debe ser función de los datos. Escogemos <span class="math inline">\(c\)</span> para obtener una expresión simple para <span class="math inline">\(L(\theta)\)</span>, y resultados subsecuentes no dependerán de la escogencia específica hecha.</p>
<p>Usualmente <span class="math inline">\(P(E;\theta)\)</span> y <span class="math inline">\(L(\theta)\)</span> son productos de términos y será más conveniente trabajar con logaritmos. La función <strong>logverosimilitud</strong> es el logaritmo de <span class="math inline">\(L\)</span>:</p>
<p><span id="eq-logver"><span class="math display">\[
\begin{align}
l(\theta)=log L(\theta)
\end{align}
\tag{3.4}\]</span></span> Observe que, por (<a href="#eq-ver" class="quarto-xref">Equation&nbsp;<span>3.3</span></a>) <span id="eq-logver2"><span class="math display">\[
\begin{align}
l(\theta)=c^{'}+log P(E;\theta)
\end{align}
\tag{3.5}\]</span></span> donde <span class="math inline">\(c^{'}=log c\)</span> no es una función de <span class="math inline">\(\theta\)</span>.</p>
<p>Por la expresión (<a href="#eq-Kalbfleish1" class="quarto-xref">Equation&nbsp;<span>3.2</span></a>) se tiene que</p>
<p><span class="math display">\[
\begin{align}
c=\frac{1}{\binom{n}{x}},
\end{align}
\]</span> entonces <span id="eq-ver2"><span class="math display">\[
\begin{align}
L(\theta)=\theta^x(1-\theta)^{n-x}, \mbox{para } 0\leq\theta\leq1
\end{align}
\tag{3.6}\]</span></span> La función de log verosimilitud es ahora <span id="eq-logver2"><span class="math display">\[
\begin{align}
l(\theta)=xlog(\theta)+(n-x)log(1-\theta), \mbox{para } 0\leq\theta\leq1
\end{align}
\tag{3.7}\]</span></span> El estimador de máxima verosimilitud (MDL) <span class="math inline">\(\hat{\theta}\)</span> es el valor de <span class="math inline">\(\theta\)</span> el cual maximiza <span class="math inline">\(l(\theta)\)</span>.</p>
<p>Tomando la derivada respecto a <span class="math inline">\(\theta\)</span> de (<a href="#eq-logver" class="quarto-xref">Equation&nbsp;<span>3.4</span></a>) se tiene que <span id="eq-Score"><span class="math display">\[
    \begin{align}
    S(\theta)&amp;=\frac{dl(\theta)}{d\theta}\nonumber\\
    &amp;=\frac{x}{\theta}-\frac{n-x}{1-\theta}
    \end{align}
\tag{3.8}\]</span></span> Haciendo cero a <span class="math inline">\(S(\theta)\)</span> tiene una única solución <span class="math inline">\(\theta=\frac{x}{n}\)</span>, para <span class="math inline">\(1\leq x\leq n-1\)</span>. Bajo estas mismas condiciones tomamos la segunda derivada y la multiplicamos por <span class="math inline">\(-1\)</span> en la siguiente expresión</p>
<p><span id="eq-Inf"><span class="math display">\[
\begin{align}
\mathscr{I}(\theta)&amp;=-\frac{dS(\theta)}{d\theta}\nonumber\\
&amp;=\frac{x}{\theta^2}+\frac{n-x}{(1-\theta)^2}
\end{align}
\tag{3.9}\]</span></span></p>
<p>Ya que <span class="math inline">\(\mathscr{I}(\theta)&gt;0\)</span> en <span class="math inline">\(\theta=\frac{x}{n}\)</span>, la función de verosimilitud tiene un máximo relativo en <span class="math inline">\(\theta=\frac{x}{n}\)</span>. Más aún, <span class="math inline">\(L(\theta)=0\)</span> para <span class="math inline">\(\theta=0\)</span> y para <span class="math inline">\(\theta=1\)</span>, hemos encontrado con esto un máximo global en <span class="math inline">\(\hat{\theta}=\frac{x}{n}\)</span>.</p>
<p>A las funciones <span class="math inline">\(S(\theta)\)</span> y <span class="math inline">\(\mathscr{I}(\theta)\)</span> definidas en (<a href="#eq-Score" class="quarto-xref">Equation&nbsp;<span>3.8</span></a>}) y (<a href="#eq-Inf" class="quarto-xref">Equation&nbsp;<span>3.9</span></a>), se les llama <strong>función Score</strong> y <strong>función de información</strong> respectivamente.</p>
</div>
</section><section id="principio-de-invarianza-del-estimador-máximo-verosímil" class="level3" data-number="3.6.2"><h3 data-number="3.6.2" class="anchored" data-anchor-id="principio-de-invarianza-del-estimador-máximo-verosímil">
<span class="header-section-number">3.6.2</span> Principio de invarianza del estimador máximo verosímil</h3>
<p>Sea <span class="math inline">\(X_1,\ldots, X_n\)</span> muestra aleatoria simple de <span class="math inline">\(X\sim f(x|\theta)\)</span> y sea <span class="math inline">\(\hat{\theta}\)</span> el estimador máximo verosímil de <span class="math inline">\(\theta\)</span>. Si estamos interesados en estimar una función <span class="math inline">\(\tau(\theta)\)</span> del parámetro, podemos hacerlo mediante <span class="math inline">\(\tau(\hat{\theta})\)</span>. Éste es el resultado que garantiza el siguiente teorema y se conoce como <strong>principio de invariancia</strong>.</p>
<div id="thm-3.3" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.3</strong></span> Si <span class="math inline">\(\hat{\theta}\)</span> es el estimador de máxima verosimilitud de <span class="math inline">\(\theta\)</span>, entonces para cualquier función <span class="math inline">\(\tau\)</span> el estimador de máxima verosimilitud de <span class="math inline">\(\tau(\theta)\)</span> es <span class="math inline">\(\tau(\hat{\theta})\)</span>.</p>
</div>
<div id="exm-3.6" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.6</strong></span> Sea <span class="math inline">\(X_1,\ldots,X_n\)</span> una m.a.s de <span class="math inline">\(X\sim N(\mu,\sigma^2)\)</span>. Podemos probar que el estimador de máxima verosimilitud para <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\hat{\mu}=\bar{X}\)</span>. ¿Cuál es el estimador de máxima verosimilitud de <span class="math inline">\(\theta_1=3\mu\)</span>, <span class="math inline">\(\theta_2=\mu^2\)</span> y <span class="math inline">\(\theta_3=1/\mu\)</span>?</p>
<p>Por el principio de invarianza tenemos que <span class="math inline">\(\hat{\theta_1}=3\bar{X}\)</span>, <span class="math inline">\(\hat{\theta_2}=\bar{X}^2\)</span> y <span class="math inline">\(\hat{\theta_3}=\frac{1}{\bar{X}}\)</span>.</p>
</div>
</section></section><section id="error-cuadrático-medio" class="level2" data-number="3.7"><h2 data-number="3.7" class="anchored" data-anchor-id="error-cuadrático-medio">
<span class="header-section-number">3.7</span> Error cuadrático medio</h2>
<p><strong>Una vez se han presentado diferentes métodos de estimación surge la necesidad de desarrollar criterios para evaluarlos y compararlos de acuerdo a estos criterios. En este tema estudiaremos medidas de la calidad de un estimador. Lo haremos primero para muestras finitas para pasar después a proponer medidas asintóticas de calidad.</strong></p>
<p>Se define el error cuadrático medio (ECM) de un estimador <span class="math inline">\(W\)</span> de un parámetro <span class="math inline">\(\theta\)</span> como <span class="math display">\[
\begin{align}
    E_\theta((W-\theta)^2)
\end{align}
\]</span> Ésta es una medida intuitiva del comportamiento de un estimador: cuanto menor sea el <strong>error cuadrático medio</strong> mejor será el estadístico <span class="math inline">\(W\)</span>. De hecho, para cualquier función <span class="math inline">\(\phi\)</span> creciente con <span class="math inline">\(\phi(0) = 0\)</span>, <span class="math inline">\(E_\theta(\phi(|W- \theta|))\)</span> es una medida razonable de lo alejadas que estarán, en promedio, las estimaciones de <span class="math inline">\(\theta\)</span> que proporcione W.</p>
<p>En general, se prefiere el error cuadrático medio a otras medidas por ser más tratable analíticamente. Además el error cuadrático medio puede descomponerse <span class="math display">\[\begin{align}
E_\theta((W-\theta)^2)&amp;=E_\theta((W-E_\theta(W))^2)+E_\theta((E_\theta(W)-\theta)^2)\nonumber\\
&amp;=Var_\theta(W)+(B_\theta(W))^2
\end{align}\]</span> El término <span class="math inline">\(B_\theta(W) = E_\theta(W)-\theta\)</span> se llama (en inglés bias) de <span class="math inline">\(W\)</span> cuando se estima <span class="math inline">\(\theta\)</span> y es una medida de la desviación sistemática que se tiene cuando se estima <span class="math inline">\(\theta\)</span> por <span class="math inline">\(W\)</span>. Si un estimador tiene sesgo nulo para cualquier valor del parámetro se dice que es un estimador <strong>insesgado</strong>. En tal caso, <span class="math inline">\(E_\theta((W-\theta)^2)=Var_\theta(W)\)</span>.</p>
<section id="observaciones-sobre-el-ecm" class="level3" data-number="3.7.1"><h3 data-number="3.7.1" class="anchored" data-anchor-id="observaciones-sobre-el-ecm">
<span class="header-section-number">3.7.1</span> Observaciones sobre el ECM</h3>
<ol type="1">
<li><p>Así, el error cuadrático medio de un estimador es la suma de su varianza (una medida de su dispersión) más el cuadrado de su sesgo (medida de la desviación sistemática o de la exactitud del estimador).</p></li>
<li><p>Es una medida conjunta de precisión y exactitud del estimador.</p></li>
<li><p>Por lo tanto, parece sensato buscar estimadores que tengan error cuadrático medio pequeño, porque de esta manera controlaremos tanto la dispersión como la exactitud de las estimaciones.</p></li>
</ol>
<div id="fig-Precision_vs_exactitud" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-Precision_vs_exactitud-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1: Comparación entre precisión y exactitud
</figcaption><div aria-describedby="fig-Precision_vs_exactitud-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-Precision_vs_exactitud" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-Precision_vs_exactitud" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure"><figcaption class="quarto-float-caption-top quarto-subfloat-caption quarto-subfloat-fig" id="fig-Precision_vs_exactitud-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Exactitud vs precisión
</figcaption><div aria-describedby="fig-Precision_vs_exactitud-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Precision_vs_exactitud.jpg" class="img-fluid figure-img" data-ref-parent="fig-Precision_vs_exactitud">
</div>
</figure>
</div>
</div>
</div>
</div>
</figure>
</div>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># install.packages("ggplot2")  # si hace falta</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">theta</span>    <span class="op">&lt;-</span> <span class="fl">0</span>      <span class="co"># valor "verdadero"</span></span>
<span><span class="va">thetahat</span> <span class="op">&lt;-</span> <span class="fl">1.2</span>    <span class="co"># estimación</span></span>
<span></span>
<span><span class="va">x</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">theta</span> <span class="op">-</span> <span class="fl">3</span>, <span class="va">thetahat</span> <span class="op">+</span> <span class="fl">3</span>, length.out <span class="op">=</span> <span class="fl">500</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>,</span>
<span>                 y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, mean <span class="op">=</span> <span class="va">thetahat</span>, sd <span class="op">=</span> <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, linewidth <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># marquitas en el eje para theta y theta-hat</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>,    xend <span class="op">=</span> <span class="va">theta</span>,    y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">*</span><span class="fl">0.03</span><span class="op">)</span>,</span>
<span>               inherit.aes <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">thetahat</span>, xend <span class="op">=</span> <span class="va">thetahat</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">*</span><span class="fl">0.03</span><span class="op">)</span>,</span>
<span>               inherit.aes <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">theta</span>,    y <span class="op">=</span> <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">*</span><span class="fl">0.05</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">thetahat</span>, y <span class="op">=</span> <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">*</span><span class="fl">0.05</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Distribución de estimaciones"</span>, x <span class="op">=</span> <span class="cn">NULL</span>, y <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">*</span><span class="fl">0.08</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">*</span><span class="fl">1.05</span><span class="op">)</span>, clip <span class="op">=</span> <span class="st">"off"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span></span>
<span>    axis.text.y  <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_blank</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    axis.ticks.y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_blank</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    plot.margin  <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">margin</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">20</span>, <span class="fl">25</span>, <span class="fl">20</span><span class="op">)</span> <span class="co"># deja espacio para las etiquetas bajo el eje</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_segment(aes(x = theta, xend = theta, y = 0, yend = max(y) * : All aesthetics have length 1, but the data has 500 rows.
ℹ Please consider using `annotate()` or provide this layer with data containing
  a single row.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_segment(aes(x = thetahat, xend = thetahat, y = 0, yend = max(y) * : All aesthetics have length 1, but the data has 500 rows.
ℹ Please consider using `annotate()` or provide this layer with data containing
  a single row.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression
Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Estimador de <span class="math inline">\(\theta\)</span> estará indicado por <span class="math inline">\(\hat{\theta}\)</span>.</p>
<p><strong>Quisieramos que <span class="math inline">\(E(\hat{\theta})=\theta\)</span>.</strong></p>
<p>La distribución muestral para un estimador puntual sesgado positivamente, para el que <span class="math inline">\(E(\hat{\theta})&gt;\theta\)</span>, se muestra en la siguiente figura</p>
<div class="cell">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># --- Parámetros editables ---</span></span>
<span><span class="va">theta</span>       <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="va">E_thetahat</span>  <span class="op">&lt;-</span> <span class="fl">0.5</span>      <span class="co"># sesgo: centro de la densidad</span></span>
<span><span class="va">thetahat</span>    <span class="op">&lt;-</span> <span class="fl">1.2</span></span>
<span><span class="va">sd0</span>         <span class="op">&lt;-</span> <span class="fl">0.7</span>      <span class="co"># dispersión</span></span>
<span><span class="co"># ----------------------------</span></span>
<span></span>
<span><span class="co"># Curva de densidad (normal centrada en E(\hat{theta}))</span></span>
<span><span class="va">x_min</span> <span class="op">&lt;-</span> <span class="va">theta</span> <span class="op">-</span> <span class="fl">1.2</span></span>
<span><span class="va">x_max</span> <span class="op">&lt;-</span> <span class="va">thetahat</span> <span class="op">+</span> <span class="fl">1.2</span></span>
<span><span class="va">x</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">x_min</span>, <span class="va">x_max</span>, length.out <span class="op">=</span> <span class="fl">800</span><span class="op">)</span></span>
<span><span class="va">y</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, mean <span class="op">=</span> <span class="va">E_thetahat</span>, sd <span class="op">=</span> <span class="va">sd0</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span>
<span><span class="va">ymax</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Alturas EXACTAS de las barras (tocar la curva)</span></span>
<span><span class="va">y_theta</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">theta</span>,      mean <span class="op">=</span> <span class="va">E_thetahat</span>, sd <span class="op">=</span> <span class="va">sd0</span><span class="op">)</span>  <span class="co"># altura en theta</span></span>
<span><span class="va">y_Ethetahat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">E_thetahat</span>, mean <span class="op">=</span> <span class="va">E_thetahat</span>, sd <span class="op">=</span> <span class="va">sd0</span><span class="op">)</span>  <span class="co"># pico</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.1</span>, lineend <span class="op">=</span> <span class="st">"round"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># ejes "a mano"</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x <span class="op">=</span> <span class="va">x_min</span>, xend <span class="op">=</span> <span class="va">x_max</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="fl">0</span>, linewidth <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x <span class="op">=</span> <span class="va">x_min</span>, xend <span class="op">=</span> <span class="va">x_min</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="fl">1.05</span><span class="op">*</span><span class="va">ymax</span>, linewidth <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># barra corta en theta (hasta la curva)</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, xend <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="va">y_theta</span><span class="op">)</span>, inherit.aes <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># barra larga en E(thetahat) (hasta el pico)</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">E_thetahat</span>, xend <span class="op">=</span> <span class="va">E_thetahat</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="va">y_Ethetahat</span><span class="op">)</span>,</span>
<span>               inherit.aes <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># etiquetas bajo el eje x</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">theta</span>,      y <span class="op">=</span> <span class="op">-</span><span class="fl">0.06</span><span class="op">*</span><span class="va">ymax</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">E_thetahat</span>, y <span class="op">=</span> <span class="op">-</span><span class="fl">0.06</span><span class="op">*</span><span class="va">ymax</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu">E</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">thetahat</span>,   y <span class="op">=</span> <span class="op">-</span><span class="fl">0.06</span><span class="op">*</span><span class="va">ymax</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># etiqueta del eje y</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>,</span>
<span>           x <span class="op">=</span> <span class="va">x_min</span> <span class="op">-</span> <span class="fl">0.03</span><span class="op">*</span><span class="op">(</span><span class="va">x_max</span> <span class="op">-</span> <span class="va">x_min</span><span class="op">)</span>, y <span class="op">=</span> <span class="fl">0.9</span><span class="op">*</span><span class="va">ymax</span>,</span>
<span>           label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu">f</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="cn">NULL</span>, y <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x_min</span>, <span class="va">x_max</span><span class="op">)</span>,</span>
<span>                  ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.10</span><span class="op">*</span><span class="va">ymax</span>, <span class="fl">1.08</span><span class="op">*</span><span class="va">ymax</span><span class="op">)</span>, clip <span class="op">=</span> <span class="st">"off"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_void</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>plot.margin <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">margin</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">20</span>, <span class="fl">35</span>, <span class="fl">45</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_segment(aes(x = theta, xend = theta, y = 0, yend = y_theta), : All aesthetics have length 1, but the data has 800 rows.
ℹ Please consider using `annotate()` or provide this layer with data containing
  a single row.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_segment(aes(x = E_thetahat, xend = E_thetahat, y = 0, yend = y_Ethetahat), : All aesthetics have length 1, but the data has 800 rows.
ℹ Please consider using `annotate()` or provide this layer with data containing
  a single row.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression
Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression
Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression
Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://patchwork.data-imaginist.com">patchwork</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># ===== Panel (a): arco =====</span></span>
<span><span class="co"># soporte con ~5% a la izquierda y 95% a la derecha</span></span>
<span><span class="va">xL</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">0.10</span></span>
<span><span class="va">xR</span> <span class="op">&lt;-</span>  <span class="fl">2.10</span></span>
<span><span class="va">theta</span>     <span class="op">&lt;-</span> <span class="op">(</span><span class="va">xL</span> <span class="op">+</span> <span class="va">xR</span><span class="op">)</span><span class="op">/</span><span class="fl">2</span>    <span class="co"># centro del arco: ahí debe ir la barra</span></span>
<span><span class="va">thetahat1</span> <span class="op">&lt;-</span> <span class="va">xR</span></span>
<span></span>
<span><span class="co"># definir el arco (semicircunferencia escalada)</span></span>
<span><span class="va">c_a</span>  <span class="op">&lt;-</span> <span class="op">(</span><span class="va">xL</span> <span class="op">+</span> <span class="va">xR</span><span class="op">)</span><span class="op">/</span><span class="fl">2</span></span>
<span><span class="va">R_a</span>  <span class="op">&lt;-</span> <span class="op">(</span><span class="va">xR</span> <span class="op">-</span> <span class="va">xL</span><span class="op">)</span><span class="op">/</span><span class="fl">2</span></span>
<span><span class="va">x_a</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">xL</span>, <span class="va">xR</span>, length.out <span class="op">=</span> <span class="fl">700</span><span class="op">)</span></span>
<span><span class="va">hsca</span> <span class="op">&lt;-</span> <span class="fl">0.95</span></span>
<span><span class="va">y_a</span>  <span class="op">&lt;-</span> <span class="va">hsca</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">pmax</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">R_a</span><span class="op">^</span><span class="fl">2</span> <span class="op">-</span> <span class="op">(</span><span class="va">x_a</span> <span class="op">-</span> <span class="va">c_a</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">dfa</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_a</span>, y <span class="op">=</span> <span class="va">y_a</span><span class="op">)</span></span>
<span><span class="va">ymax_a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">dfa</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># altura de la curva en theta</span></span>
<span><span class="va">y_theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/approxfun.html">approx</a></span><span class="op">(</span><span class="va">x_a</span>, <span class="va">y_a</span>, xout <span class="op">=</span> <span class="va">theta</span><span class="op">)</span><span class="op">$</span><span class="va">y</span></span>
<span></span>
<span><span class="va">p_a</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">dfa</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span>, lineend <span class="op">=</span> <span class="st">"round"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># ejes</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x <span class="op">=</span> <span class="va">xL</span><span class="op">-</span><span class="fl">0.3</span>, xend <span class="op">=</span> <span class="va">xR</span><span class="op">+</span><span class="fl">0.3</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="fl">0</span>, linewidth <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x <span class="op">=</span> <span class="fl">0</span>, xend <span class="op">=</span> <span class="fl">0</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="fl">1.05</span><span class="op">*</span><span class="va">ymax_a</span>, linewidth <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># barra en el centro (theta)</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta</span>, xend <span class="op">=</span> <span class="va">theta</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="va">y_theta</span><span class="op">)</span>, inherit.aes <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># etiquetas</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">theta</span>,     y <span class="op">=</span> <span class="op">-</span><span class="fl">0.08</span><span class="op">*</span><span class="va">ymax_a</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">thetahat1</span>, y <span class="op">=</span> <span class="op">-</span><span class="fl">0.08</span><span class="op">*</span><span class="va">ymax_a</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="op">-</span><span class="fl">0.15</span>, y <span class="op">=</span> <span class="fl">0.9</span><span class="op">*</span><span class="va">ymax_a</span>,</span>
<span>           label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu">f</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="op">(</span><span class="va">xL</span> <span class="op">+</span> <span class="va">xR</span><span class="op">)</span><span class="op">/</span><span class="fl">2</span>, y <span class="op">=</span> <span class="op">-</span><span class="fl">0.22</span><span class="op">*</span><span class="va">ymax_a</span>, label <span class="op">=</span> <span class="st">"(a)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">xL</span><span class="op">-</span><span class="fl">0.2</span>, <span class="va">xR</span><span class="op">+</span><span class="fl">0.2</span><span class="op">)</span>,</span>
<span>                  ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.25</span><span class="op">*</span><span class="va">ymax_a</span>, <span class="fl">1.1</span><span class="op">*</span><span class="va">ymax_a</span><span class="op">)</span>, clip <span class="op">=</span> <span class="st">"off"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_void</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>plot.margin <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">margin</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">20</span>, <span class="fl">40</span>, <span class="fl">45</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># ===== Panel (b): normal (sin cambios) =====</span></span>
<span><span class="va">theta_b</span>    <span class="op">&lt;-</span> <span class="fl">1.00</span></span>
<span><span class="va">thetahat2</span>  <span class="op">&lt;-</span> <span class="fl">1.60</span></span>
<span><span class="va">sd_b</span>       <span class="op">&lt;-</span> <span class="fl">0.25</span></span>
<span><span class="va">x_b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">theta_b</span> <span class="op">+</span> <span class="fl">3.2</span><span class="op">*</span><span class="va">sd_b</span>, length.out <span class="op">=</span> <span class="fl">700</span><span class="op">)</span></span>
<span><span class="va">y_b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x_b</span>, mean <span class="op">=</span> <span class="va">theta_b</span>, sd <span class="op">=</span> <span class="va">sd_b</span><span class="op">)</span></span>
<span><span class="va">dfb</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_b</span>, y <span class="op">=</span> <span class="va">y_b</span><span class="op">)</span></span>
<span><span class="va">ymax_b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">dfb</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_b</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">dfb</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>linewidth <span class="op">=</span> <span class="fl">1.2</span>, lineend <span class="op">=</span> <span class="st">"round"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x <span class="op">=</span> <span class="fl">0</span>, xend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x_b</span><span class="op">)</span><span class="op">+</span><span class="fl">0.3</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="fl">0</span>, linewidth <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"segment"</span>, x <span class="op">=</span> <span class="fl">0</span>, xend <span class="op">=</span> <span class="fl">0</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="fl">1.05</span><span class="op">*</span><span class="va">ymax_b</span>, linewidth <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">theta_b</span>, xend <span class="op">=</span> <span class="va">theta_b</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">theta_b</span>, <span class="va">theta_b</span>, <span class="va">sd_b</span><span class="op">)</span><span class="op">)</span>,</span>
<span>               inherit.aes <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">theta_b</span>,   y <span class="op">=</span> <span class="op">-</span><span class="fl">0.08</span><span class="op">*</span><span class="va">ymax_b</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">thetahat2</span>, y <span class="op">=</span> <span class="op">-</span><span class="fl">0.08</span><span class="op">*</span><span class="va">ymax_b</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="op">-</span><span class="fl">0.15</span>, y <span class="op">=</span> <span class="fl">0.9</span><span class="op">*</span><span class="va">ymax_b</span>,</span>
<span>           label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu">f</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">hat</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">x_b</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x_b</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fl">2</span>, y <span class="op">=</span> <span class="op">-</span><span class="fl">0.22</span><span class="op">*</span><span class="va">ymax_b</span>, label <span class="op">=</span> <span class="st">"(b)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x_b</span><span class="op">)</span><span class="op">+</span><span class="fl">0.2</span><span class="op">)</span>,</span>
<span>                  ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.25</span><span class="op">*</span><span class="va">ymax_b</span>, <span class="fl">1.1</span><span class="op">*</span><span class="va">ymax_b</span><span class="op">)</span>, clip <span class="op">=</span> <span class="st">"off"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_void</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">14</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>plot.margin <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">margin</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">20</span>, <span class="fl">40</span>, <span class="fl">45</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># ===== Combinar =====</span></span>
<span><span class="va">p_a</span> <span class="op">|</span> <span class="va">p_b</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_segment(aes(x = theta, xend = theta, y = 0, yend = y_theta), : All aesthetics have length 1, but the data has 700 rows.
ℹ Please consider using `annotate()` or provide this layer with data containing
  a single row.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression
Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression
Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_segment(aes(x = theta_b, xend = theta_b, y = 0, yend = dnorm(theta_b, : All aesthetics have length 1, but the data has 700 rows.
ℹ Please consider using `annotate()` or provide this layer with data containing
  a single row.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression
Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression
Warning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de
tipo 'expression</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>La figura (b) es la distribución deseada porque una varianza pequeña garantiza que, en un muestreo repetido, una fracción más alta de valores <span class="math inline">\(\hat{\theta}_2\)</span> estará ``cerca’’ de <span class="math inline">\(\theta\)</span>.</p>
<p>Por consiguiente, además de preferir un estimador insesgado, necesitamos que la varianza de la distribución del estimador <span class="math inline">\(V(\hat{\theta})\)</span> sea lo más pequeña posible. Dados dos estimadores insesgados de un parámetro <span class="math inline">\(\theta\)</span> seleccionamos el estimador con la menor varianza, mientras todos los demás parece igual.</p>
<div id="exm-3.7" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.7</strong></span> Suponga que <span class="math inline">\(Y_1,Y_2,Y_3\)</span> denotan una muestra aleatoria ind de una distribuci'on exponencial con funci'on de densidad <span class="math display">\[f(y)=\left\{\begin{array}{ll}\left(\frac{1}{\theta}\right)e^{-y/\theta},&amp; y&gt;0,\\0,&amp;\mbox{ en cualquier otro punto}\end{array}\right.\]</span> Considere los siguientes estimadores de <span class="math inline">\(\theta\)</span>: <span class="math display">\[\hat{\theta}_1=Y_1,\,\,\,\,\,\,\,\,\,\,\hat{\theta}_2=\frac{Y_1+Y_2}{2},\,\,\,\,\,\,\,\,\,\,\hat{\theta}_3=\frac{Y_1+2Y_2}{3},\,\,\,\,\,\,\,\,\,\,\]</span></p>
<p><span class="math display">\[\hat{\theta}_4=\min(Y_1,\,Y_2,\,Y_3),\,\,\,\,\,\,\,\,\,\,\hat{\theta}_5=\overline{Y}\]</span></p>
<ol type="a">
<li>¿Cuáles son insesgados?</li>
</ol>
<p><strong>Sol:</strong> Determinemos si <span class="math inline">\(\hat{\theta}_4=\min(Y_1,\,Y_2,\,Y_3)\)</span> es insesgado. Para esto, determinemos la distribución de <span class="math inline">\(\hat{\theta}_4\)</span>. Supongamos que <span class="math inline">\(Y_i\sim Exp(\lambda_i)\)</span> con <span class="math inline">\(i=1,2,3\)</span>. <span class="math display">\[
        \begin{align}
        P(\hat{\theta}_4&gt;a)&amp;=P(\min(Y_1,\,Y_2,\,Y_3)&gt;a)\nonumber\\
        &amp;=P(Y_1&gt;a)P(Y_2&gt;a)P(Y_3&gt;a)\nonumber\\
        &amp;=\exp\{-a\lambda_1\}\exp\{-a\lambda_2\}\exp\{-a\lambda_3\}\nonumber\\
        &amp;\exp\left\{-a\left(\sum_{i=1}^{3}\lambda_i\right)\right\}
        \end{align}
\]</span> Así que <span class="math display">\[
\begin{align}
F_{\hat{\theta}_4}(a)&amp;=1-P(\hat{\theta}_4&gt;a)\nonumber\\
&amp;=1-\exp\left\{-a\left(\sum_{i=1}^{3}\lambda_i\right)\right\}
\end{align}
\]</span> De ahí que <span class="math inline">\(\hat{\theta}_4\sim Exp\left(\sum_{i=1}^{3}\lambda_i\right)\)</span> entonces, <span class="math inline">\(E(\hat{\theta}_4)=\frac{1}{\sum_{i=1}^{3}\lambda_i}\)</span>. Pero por hipótesis <span class="math inline">\(\lambda_i=\frac{1}{\theta}\)</span>, para todo <span class="math inline">\(i=1,2,3\)</span>. Luego,</p>
</div>
<p><span class="math display">\[
\begin{align}
    E(\hat{\theta}_4)&amp;=\frac{1}{\sum_{i=1}^{3}\lambda_i}\nonumber\\
    &amp;=\frac{1}{3\lambda} \mbox{ por ser las $Y_i$ son iid}\nonumber\\
    &amp;=\frac{1}{\frac{3}{\theta}}\nonumber\\
    &amp;=\frac{\theta}{3}
    \end{align}
\]</span> Luego <span class="math inline">\(\hat{\theta}_4\)</span> no es insesgado, es sesgado.</p>
</section></section><section id="eficiencia-relativa" class="level2" data-number="3.8"><h2 data-number="3.8" class="anchored" data-anchor-id="eficiencia-relativa">
<span class="header-section-number">3.8</span> Eficiencia relativa</h2>
<div id="def-3.1" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.1</strong></span> Un estimador <span class="math inline">\(W\)</span> de <span class="math inline">\(\theta\)</span> se denomina <strong>inadmisible</strong> si existe otro estimador <span class="math inline">\(V\)</span> de <span class="math inline">\(\theta\)</span> tal que <span class="math display">\[
\begin{align}
E_\theta((V-\theta)^2)\leq E_\theta((W-\theta)^2) \mbox{ para todo $\theta \in \Theta$}
\end{align}
\]</span></p>
</div>
</section><section id="mejor-estimador-insesgado." class="level2" data-number="3.9"><h2 data-number="3.9" class="anchored" data-anchor-id="mejor-estimador-insesgado.">
<span class="header-section-number">3.9</span> Mejor estimador insesgado.</h2>
<div id="def-3.2" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.2</strong></span> Sean <span class="math inline">\(\hat{\theta}_1\)</span> y <span class="math inline">\(\hat{\theta}_2\)</span> dos estimadores insesgados de un parámetro <span class="math inline">\(\theta\)</span>, con varianzas <span class="math inline">\(V (\hat{\theta}_1)\)</span> y <span class="math inline">\(V (\hat{\theta}_2)\)</span>, respectivamente. Entonces la eficiencia de <span class="math inline">\(\hat{\theta}_1\)</span> con respecto a <span class="math inline">\(\hat{\theta}_2\)</span> denotada como <span class="math inline">\(eff(\hat{\theta}_1,\,\hat{\theta}_2)\)</span> se defiene por la expresión</p>
<p><span class="math display">\[eff (\hat{\theta}_1,\, \hat{\theta}_2)=\frac{V(\hat{\theta}_1)}{V(\hat{\theta}_2)}.\]</span></p>
</div>
<div id="exm-3.8" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.8</strong></span> Diremos que <span class="math inline">\(\hat{\theta}_1\)</span> es más eficiente que <span class="math inline">\(\hat{\theta}_2\)</span> si <span class="math display">\[eff(\hat{\theta}_1,\,\hat{\theta}_2)&lt;1\mbox{ si y sólo si }V(\hat{\theta}_2)&gt;V(\hat{\theta}_1)\]</span> luego <span class="math inline">\(\hat{\theta}_1\)</span> es un mejor estimador insesgado que <span class="math inline">\(\hat{\theta}_2\)</span>.</p>
</div>
<div id="exm-3.9" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.9</strong></span> Si <span class="math inline">\(eff(\hat{\theta}_1,\,\hat{\theta}_2)=1.8\)</span> entonces <span class="math inline">\(V(\hat{\theta}_1)=1.8V(\hat{\theta}_2)\)</span> entonces <span class="math inline">\(\hat{\theta}_2\)</span> se prefiere a <span class="math inline">\(\hat{\theta}_1\)</span>.</p>
<p>Si <span class="math inline">\(eff(\hat{\theta}_1,\,\hat{\theta}_2)=0.73\)</span> entonces <span class="math inline">\(V(\hat{\theta}_1)=0.73V(\hat{\theta}_2)\)</span> entonces <span class="math inline">\(\hat{\theta}_1\)</span> se prefiere a <span class="math inline">\(\hat{\theta}_2\)</span>.</p>
</div>
<div id="thm-3.4" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.4</strong></span> <strong>Teorema de Lehmann-Scheffé</strong> Si <span class="math inline">\(\hat{\theta}\)</span> es un estimador insesgado para <span class="math inline">\(\theta\)</span> y si <span class="math inline">\(U\)</span> es un estadístico suficiente para <span class="math inline">\(\theta\)</span>, entonces hay una función de <span class="math inline">\(U\)</span> que también es un estimador insesgado para <span class="math inline">\(\theta\)</span> y tiene una varianza no mayor que <span class="math inline">\(\hat{\theta}\)</span>.</p>
<p>En símbolos:</p>
<p>Si <span class="math inline">\(E(\hat{\theta})=\theta\)</span> y <span class="math inline">\(U\)</span> es suficiente para <span class="math inline">\(\theta\)</span> entonces existe una <span class="math inline">\(f(U)\)</span> tal que <span class="math display">\[E(f(U))=\theta\]</span> y <span class="math display">\[Var(\hat{\theta})\geq Var(f(U))\]</span></p>
</div>
<div id="exm-3.10" class="theorem example">
<p><span class="theorem-title"><strong>Example 3.10</strong></span> <strong>Contexto del teorema</strong></p>
<p>Un <strong>estimador insesgado</strong> de <span class="math inline">\(\theta\)</span> es una variable aleatoria <span class="math inline">\(\hat{\theta}\)</span> que cumple:</p>
<p><span class="math display">\[
E(\hat{\theta}) = \theta.
\]</span></p>
<p>Un <strong>estadístico suficiente</strong> <span class="math inline">\(U\)</span> para <span class="math inline">\(\theta\)</span> contiene toda la información de la muestra acerca de <span class="math inline">\(\theta\)</span>. Es decir, dados <span class="math inline">\(U\)</span>, la muestra completa no aporta nada más sobre <span class="math inline">\(\theta\)</span>.</p>
<p>El <strong>Teorema de Lehmann–Scheffé</strong> dice que si combinas estos dos elementos:</p>
<ul>
<li>Un estimador insesgado cualquiera <span class="math inline">\(\hat{\theta}\)</span>.</li>
<li>Un estadístico suficiente <span class="math inline">\(U\)</span>.</li>
</ul>
<p>Entonces puedes construir una función de <span class="math inline">\(U\)</span>, digamos <span class="math inline">\(f(U)\)</span>, que:</p>
<ul>
<li>también es insesgado,</li>
<li>tiene varianza menor o igual a la de <span class="math inline">\(\hat{\theta}\)</span>.</li>
</ul>
<p>De hecho, el resultado formal se apoya en el <strong>Teorema de Rao–Blackwell</strong>:</p>
<p><span class="math display">\[
f(U) = E(\hat{\theta} \mid U).
\]</span></p>
<p>Esta transformación se llama <strong>Rao-Blackwellización</strong>.<br>
Y el teorema de Lehmann–Scheffé añade que, si <span class="math inline">\(U\)</span> además de suficiente es <strong>completo</strong>, entonces ese <span class="math inline">\(f(U)\)</span> es el <strong>único estimador insesgado de varianza mínima</strong> (UMVUE: <em>Uniformly Minimum Variance Unbiased Estimator</em>).</p>
<hr>
<p><strong>2. Intuición</strong></p>
<ul>
<li>Empiezas con cualquier estimador insesgado <span class="math inline">\(\hat{\theta}\)</span>.</li>
<li>Si “condicionas” en la estadística suficiente <span class="math inline">\(U\)</span>, eliminas ruido innecesario que no aporta información sobre <span class="math inline">\(\theta\)</span>.</li>
<li>Eso reduce (o al menos no aumenta) la varianza del estimador.</li>
<li>El resultado es un estimador más eficiente.</li>
</ul>
<hr>
<p><strong>3. Ejemplo clásico</strong></p>
<p><strong>Contexto</strong> Supongamos que:</p>
<p><span class="math display">\[
X_1, X_2, \dots, X_n \overset{iid}{\sim} \text{Bernoulli}(p),
\]</span></p>
<p>donde el parámetro de interés es <span class="math inline">\(p\)</span>.</p>
<hr>
<p><strong>Paso 1: un estimador insesgado cualquiera</strong></p>
<p>Consideremos el estimador basado sólo en el primer dato:</p>
<p><span class="math display">\[
\hat{p} = X_1.
\]</span></p>
<p>Claramente:</p>
<p><span class="math display">\[
E(\hat{p}) = E(X_1) = p.
\]</span></p>
<p>Así que es insesgado, pero muy ineficiente (usa un solo dato).</p>
<hr>
<p><strong>Paso 2: estadístico suficiente</strong></p>
<p>El número total de éxitos:</p>
<p><span class="math display">\[
U = \sum_{i=1}^n X_i
\]</span></p>
<p>es un estadístico suficiente para <span class="math inline">\(p\)</span> (por factorización de la verosimilitud).</p>
<hr>
<p><strong>Paso 3: aplicar Rao–Blackwell</strong></p>
<p>Construimos:</p>
<p><span class="math display">\[
f(U) = E(\hat{p} \mid U).
\]</span></p>
<p>Como <span class="math inline">\(\hat{p} = X_1\)</span>, necesitamos <span class="math inline">\(E(X_1 \mid U)\)</span>.<br>
Por simetría, dado que hay <span class="math inline">\(U\)</span> éxitos en total entre <span class="math inline">\(n\)</span> ensayos, cada <span class="math inline">\(X_i\)</span> tiene la misma probabilidad de ser 1. Entonces:</p>
<p><span class="math display">\[
E(X_1 \mid U) = \frac{U}{n}.
\]</span></p>
<p>Así:</p>
<p><span class="math display">\[
f(U) = \frac{U}{n}.
\]</span></p>
<hr>
<p><strong>Paso 4: verificar propiedades</strong></p>
<ul>
<li><strong>Insesgado:</strong></li>
</ul>
<p><span class="math display">\[
E\left(\frac{U}{n}\right) = \frac{1}{n}E(U) = \frac{1}{n}(np) = p.
\]</span></p>
<ul>
<li><strong>Varianza:</strong></li>
</ul>
<p><span class="math display">\[
Var(X_1) = p(1-p),
\]</span></p>
<p><span class="math display">\[
Var\left(\frac{U}{n}\right) = \frac{1}{n^2} Var(U) = \frac{1}{n^2}(np(1-p)) = \frac{p(1-p)}{n}.
\]</span></p>
<p>Y efectivamente:</p>
<p><span class="math display">\[
\frac{p(1-p)}{n} \leq p(1-p).
\]</span></p>
<hr>
<p><strong>4. Conclusión</strong></p>
<p>El estimador inicial <span class="math inline">\(\hat{p} = X_1\)</span> era insesgado pero ineficiente.</p>
<p>Rao–Blackwellizando con el suficiente <span class="math inline">\(U\)</span>, obtuvimos:</p>
<p><span class="math display">\[
f(U) = \frac{U}{n},
\]</span></p>
<p>que es la <strong>media muestral</strong>.</p>
<p>Por Lehmann–Scheffé, como <span class="math inline">\(U\)</span> es suficiente y completo, <span class="math inline">\(\bar{X} = U/n\)</span> es el <strong>UMVUE de <span class="math inline">\(p\)</span></strong>.</p>
</div>
</section><section id="teorema-de-cramér-rao.-información-de-fisher" class="level2" data-number="3.10"><h2 data-number="3.10" class="anchored" data-anchor-id="teorema-de-cramér-rao.-información-de-fisher">
<span class="header-section-number">3.10</span> Teorema de Cramér-Rao. Información de Fisher</h2>
<div id="def-3.3" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.3</strong></span> Diremos que un estimador <span class="math inline">\(W^{*}\)</span> es el mejor estimador insesgado de <span class="math inline">\(\tau(\theta)\)</span>, o el UMVUE (Uniformly Minimum Variance Unbiased Estimator) <strong>(estimador insesgado de <span class="math inline">\(\tau(\theta)\)</span> uniformemente de mínima varianza)</strong> , si <span class="math inline">\(E_\theta(W^{*}) = \tau(\theta)\)</span> para todo <span class="math inline">\(\theta\in\Theta\)</span> y si para cualquier otro estimador <span class="math inline">\(W\)</span> , tal que <span class="math inline">\(E_\theta(W) = \tau(\theta)\)</span> para todo <span class="math inline">\(\theta\in\Theta\)</span>, se tiene que <span class="math inline">\(V_\theta(W^{*}) \leq V_\theta(W)\)</span>, para todo <span class="math inline">\(\theta\in\Theta\)</span>.</p>
</div>
<p><strong>La búsqueda del UMVUE no debe consistir en repasar todos los estimadores insesgados posibles. El siguiente resultado aborda el problema de un modo diferente: establece una cota inferior para la varianza de todos los estimadores insesgados de un parámetro. Así, si encontramos un estimador insesgado cuya varianza iguale esa cota podremos concluir que ese estimador es el UMVUE.</strong></p>
<div id="thm-3.5" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.5</strong></span> Sea <span class="math inline">\(\underset{\sim}{X} =(X_1,\ldots, X_n)\)</span> una variable aleatoria n-dimensional con función de densidad conjunta <span class="math inline">\(f ( \underset{\sim}{x}|\theta)\)</span>, <span class="math inline">\(\theta\in\Theta\subseteq\mathbb{R}\)</span>. Sea <span class="math inline">\(W(\underset{\sim}{X} )\)</span> un estimador insesgado para <span class="math inline">\(\tau(\theta)\)</span>, es decir, <span class="math inline">\(E_\theta(W(\underset{\sim}{X})) = \tau(\theta)\)</span> para todo <span class="math inline">\(\theta\)</span>, donde <span class="math inline">\(\tau\)</span> es una función de <span class="math inline">\(\theta\)</span> que cumple:</p>
<p>H1: <span class="math inline">\(\tau(\theta)\)</span> es diferenciable en <span class="math inline">\(\theta\)</span>.</p>
<p>H2: Se supone además que la verosimilitud conjunta <span class="math inline">\(f(\underset{\sim}{x}|\theta)\)</span> verifica que para cualquier función <span class="math inline">\(h(\underset{\sim}{x})\)</span> tal que <span class="math inline">\(E_\theta|h(\underset{\sim}{X})| &lt; \infty\)</span> se tiene que</p>
<p><span class="math display">\[
\begin{align}
&amp;\frac{d}{d\theta}\int\dotsc\int h(\underset{\sim}{x})f (\underset{\sim}{x}|\theta)dx_1\ldots dx_n\nonumber\\
&amp;=\int\dotsc\int h(\underset{\sim}{x})\left[\frac{\partial}{\partial\theta}f (\underset{\sim}{x}|\theta)\right]dx_1\ldots dx_n
\end{align}
\]</span></p>
<p>Entonces, <span class="math display">\[\begin{align}
V_\theta(W(\underset{\sim}{X} ))\geq\frac{\left(\frac{d}{d\theta}\tau(\theta)\right)^2}{E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f(\underset{\sim}{X}|\theta)\right)^2\right]}
\end{align}\]</span> A la cantidad del lado derecho de la desigualdad anterior se la denomina <strong>Cota de Cramér-Rao</strong>.</p>
</div>
<div id="nte-3.2" class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note&nbsp;3.2
</div>
</div>
<div class="callout-body-container callout-body">
<p>Nota: El teorema de Cramér-Rao es igualmente válido en el caso discreto. En este caso la hipótesis H2 afirma que pueden intercambiarse el sumatorio y la diferenciación.</p>
</div>
</div>
<ol type="1">
<li><p>Un estimador insesgado para <span class="math inline">\(\tau(\theta)\)</span> se denomina si su varianza es la mínima posible, es decir, si es igual a la cota de Cramér-Rao.</p></li>
<li><p>La eficiencia de un estimador insesgado se define como el cociente entre la cota de Cramér-Rao y su varianza.</p></li>
<li><p>Es un valor menor o igual que 1 si se dan las hipótesis del teorema de Cramér-Rao.</p></li>
</ol>
<p>En la demostración del teorema de Cramér-Rao se ha probado que</p>
<p><span class="math display">\[
\begin{align}
E_\theta(S(\theta))&amp;=E_\theta(S(\theta|\underset{\sim}{X}))\nonumber\\
&amp;=E_\theta\left(\frac{\partial}{\partial \theta}\log L(\theta|\underset{\sim}{X})\right)=0
\end{align}
\]</span> Obsérvese que para obtener el estimador máximo verosímil de <span class="math inline">\(\theta\)</span> lo que se hace es resolver la ecuación <span class="math display">\[\begin{align}
    S(\theta|\underset{\sim}{X})=0
\end{align}\]</span> lo que equivale a buscar el valor de <span class="math inline">\(\theta\)</span> para el cual el valor de <span class="math inline">\(S(\theta|\underset{\sim}{X})\)</span> coincide con su valor esperado.</p>
<p>A la cantidad que aparece en el denominador de la cota de Cramér-Rao se le denomina cantidad de <strong>información de Fisher</strong> que sobre <span class="math inline">\(\theta\)</span> contiene el vector <span class="math inline">\(\underset{\sim}{X}\)</span>:</p>
<p><span class="math display">\[
\begin{align}
\mathscr{I}_{E}(\theta)=\mathscr{I}_{\underset{\sim}{X}}(\theta)&amp;=E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{\underset{\sim}{X}}(\underset{\sim}{X}|\theta)\right)^2\right]\\
&amp;=V\left(\frac{\partial}{\partial \theta}\log f_{\underset{\sim}{X}}(\underset{\sim}{X}|\theta)\right)\\
&amp;=V(S(\theta|\underset{\sim}{X}))
\end{align}
\]</span></p>
<p>Se denomina <strong>cantidad de información de Fisher</strong> que sobre <span class="math inline">\(\theta\)</span> contiene la variable <span class="math inline">\(X_i\)</span> a <span class="math display">\[
\begin{align}
    &amp;=E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{X_i}(X|\theta)\right)^2\right]\\
    &amp;=V\left(\frac{\partial}{\partial \theta}\log f_{X_i}(X|\theta)\right)\\
    &amp;=V(S(\theta|X_i))
    \end{align}
\]</span></p>
<p>Cuando <span class="math inline">\(\underset{\sim}{X}=(X_1,\ldots, X_n)\)</span> es una muestra aleatoria simple de <span class="math inline">\(X\)</span> se verifica que la información de Fisher contenida en la muestra es la suma de las informaciones contenidas en cada una de las observaciones y, dado que éstas son idénticamente distribuidas, se tiene que</p>
<p><span class="math display">\[
\begin{align}
\mathscr{I}_{E}(\theta)=\mathscr{I}_{\underset{\sim}{X}}(\theta)=n\mathscr{I}_{X}(\theta)
\end{align}
\]</span> Este resultado es consecuencia del siguiente corolario del teorema de Cramér-Rao:</p>
<div id="cor-3.1" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 3.1</strong></span> Bajo las hipótesis del teorema de Cramér-Rao, si <span class="math inline">\(\underset{\sim}{X}=(X_1,\ldots, X_n)\)</span> es una muestra aleatoria simple de <span class="math inline">\(X\)</span> con distribución dada por <span class="math inline">\(f(x|\theta)\)</span> entonces <span class="math display">\[
\begin{align*}
\mathscr{I}_{E}(\theta)=\mathscr{I}_{\underset{\sim}{X}}(\theta)&amp;=E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{\underset{\sim}{X}}(\underset{\sim}{X}|\theta)\right)^2\right]\\
&amp;=nE_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{X}(X|\theta)\right)^2\right]\\
&amp;=n\mathscr{I}_{X}(\theta)
\end{align*}
\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Por independencia, la verosimilitud de <span class="math inline">\(\underset{\sim}{X}\)</span> es el producto de verosimilitudes, luego <span class="math display">\[\begin{align}
    \frac{\partial}{\partial \theta}\log f_{\underset{\sim}{X}}(\underset{\sim}{x}|\theta)&amp;=\frac{\partial}{\partial \theta}\sum_{i=1}^{n}\log f_{X}(x_i|\theta)\nonumber\\
    &amp;=\sum_{i=1}^{n}\frac{\partial}{\partial \theta}\log f_{X}(x_i|\theta)
    \end{align}\]</span> Por lo tanto,</p>
<p><span id="eq-col3"><span class="math display">\[
\begin{align}
E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{\underset{\sim}{X}}(\underset{\sim}{x}|\theta)\right)^2\right]&amp;=E_\theta\left[\left(\sum_{i=1}^{n}\frac{\partial}{\partial \theta}\log f_{X_i}(x_i|\theta)\right)^2\right]\nonumber\\
=&amp;\sum_{i=1}^{n}E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{X_i}(x_i|\theta)\right)^2\right]\nonumber\\
+&amp;\sum_{i\neq j}E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{X_i}(x_i|\theta)\frac{\partial}{\partial \theta}\log f_{X_j}(x_j|\theta)\right)\right]
\end{align}
\tag{3.10}\]</span></span></p>
<p>La segunga igualdad de <a href="#eq-col3" class="quarto-xref">Equation&nbsp;<span>3.10</span></a> se tiene por que <span class="math inline">\(\left(\sum_{i=1}^{n}a_i\right)^2=\sum_{i=1}^{n}a_i^2+\sum_{i\neq j}a_ia_j\)</span>. Pero la segunda sumatoria es igual a cero debido a la independencia entre <span class="math inline">\(X_i\)</span> y <span class="math inline">\(X_j\)</span> y dado que las funciones score tienen esperanza 0, según se vio en la demostración del teorema de Cramér-Rao. <span id="eq-col31"><span class="math display">\[
\begin{align}
E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{\underset{\sim}{X}}(\underset{\sim}{x}|\theta)\right)^2\right]
        =&amp;\sum_{i=1}^{n}E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{X_i}(x_i|\theta)\right)^2\right]\nonumber\\
        +&amp;\sum_{i\neq j}E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{X_i}(x_i|\theta)\right)\left(\frac{\partial}{\partial \theta}\log f_{X_j}(x_j|\theta)\right)\right]\nonumber\\
        =&amp;\sum_{i=1}^{n}E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{X_i}(x_i|\theta)\right)^2\right]\nonumber\\
\end{align}
\tag{3.11}\]</span></span></p>
</div>
<div id="lem-3.1" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 3.1</strong></span> Si la función de verosimilitud satisface:</p>
<p>H3: Se supone que la verosimilitud conjunta <span class="math inline">\(f (\underset{\sim}{x}|\theta)\)</span> verifica que para cualquier función <span class="math inline">\(h(\underset{\sim}{x})\)</span> tal que <span class="math inline">\(E_\theta|h(\underset{\sim}{X})| &lt; \infty\)</span> se tiene que <span class="math display">\[
\begin{align}
&amp;\frac{\partial^2}{\partial\theta^2}\int\dotsc\int h(\underset{\sim}{x})f (\underset{\sim}{x}|\theta)dx_1\ldots dx_n\nonumber\\
&amp;=\int\dotsc\int h(\underset{\sim}{x})\left[\frac{\partial^2}{\partial\theta^2}f (\underset{\sim}{x}|\theta)\right]dx_1\ldots dx_n
\end{align}
\]</span></p>
<p>Entonces <span class="math display">\[
\begin{align}
\mathscr{I}_{X}(\theta)=E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{X}(x|\theta)\right)^2\right]=-E_\theta\left[\frac{\partial^2}{\partial \theta^2}\log f_{X}(x|\theta)\right]
\end{align}
\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span><span class="math display">\[
\begin{align}
        \frac{\partial^2}{\partial \theta^2}\log f_{X}(x|\theta)&amp;=\frac{\partial}{\partial \theta}\left[\frac{1}{f_{X}(x|\theta)}\left(\frac{\partial}{\partial \theta}f_{X}(x|\theta)\right)\right]\nonumber\\
        &amp;=-\frac{1}{f^2_{X}(x|\theta)}\left(\frac{\partial}{\partial \theta}f_{X}(x|\theta)\right)^2\nonumber\\
        &amp;+\frac{1}{f_{X}(x|\theta)}\frac{\partial^2}{\partial \theta^2}f_{X}(x|\theta)
\end{align}
\]</span> Por otro lado, <span class="math display">\[
\begin{align}
    E_\theta\left[\frac{1}{f_{X}(x|\theta)}\frac{\partial^2}{\partial \theta^2}f_{X}(x|\theta)\right]&amp;=\int\frac{\partial^2}{\partial \theta^2}f_{X}(x|\theta)dx\nonumber\\
    &amp;\overset{\text{H3}}{=}\frac{d^2}{d \theta^2}\int f_{X}(x|\theta)dx\nonumber\\
    &amp;=\frac{d^2}{d \theta^2}1 =0
\end{align}
\]</span> Así pues, <span class="math display">\[
\begin{align}
        E_\theta\left[\frac{\partial^2}{\partial \theta^2}\log f_{X}(x|\theta)\right]
        &amp;=-E_\theta\left[\frac{1}{f^2_{X}(x|\theta)}\left(\frac{\partial}{\partial \theta}f_{X}(x|\theta)\right)^2\right]\nonumber\\
        &amp;=-E_\theta\left[\left(\frac{\partial}{\partial \theta}\log f_{X}(x|\theta)\right)^2\right]\nonumber\\
        &amp;=-\mathscr{I}_{X}(\theta)
        \end{align}
\]</span></p>
</div>
<ol type="1">
<li><p>En general, el teorema de Cramér-Rao no es aplicable si el soporte de <span class="math inline">\(f(x|\theta)\)</span> depende del parámetro <span class="math inline">\(\theta\)</span> debido a que la derivada y la integral no son intercambiables si los límites de integración dependen de <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Aunque el teorema de Cramér-Rao pueda ser aplicado y la cota de Cramér-Rao sea efectiva, no hay garantías de que esta cota sea alcanzada por algún estimador insesgado del parámetro.</p></li>
</ol>
<div id="cor-3.2" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 3.2</strong></span> Sea <span class="math inline">\(X_1 , \ldots, X_n\)</span> una muestra aleatoria simple de <span class="math inline">\(X\)</span> con distribución dada por <span class="math inline">\(f(x|\theta)\)</span>, <span class="math inline">\(\theta\in\mathbb{R}\)</span>, donde <span class="math inline">\(f\)</span> satisface las hipótesis del teorema de Cramér-Rao. Sea <span class="math inline">\(L(\theta|\underset{\sim}{x}) = \prod_{i=1}^{n}f(x_i|\theta)\)</span> la función de verosimilitud. Sea <span class="math inline">\(W (\underset{\sim}{x}) = W(X_1 , \ldots, X_n)\)</span> un estimador insesgado de <span class="math inline">\(\tau(\theta)\)</span>. Entonces <span class="math inline">\(W(\underset{\sim}{x})\)</span> alcanza la cota de Cramér-Rao si y sólo si existe una función <span class="math inline">\(a(\theta)\)</span> tal que se tiene la igualdad <span class="math display">\[
\begin{align}
a(\theta)(W(\underset{\sim}{x})-\tau(\theta))=\frac{\partial}{\partial\theta}\log L(\theta|\underset{\sim}{x}) \mbox{ para todo $\theta$}
\end{align}
\]</span></p>
</div>
<p>Además, el enunciado del corolario <a href="#cor-3.2" class="quarto-xref">Corollary&nbsp;<span>3.2</span></a> ocurre sí y sólo sí existen funciones <span class="math inline">\(h(\theta)\)</span>, <span class="math inline">\(k(\theta)\)</span> y <span class="math inline">\(u(\underset{\sim}{x})\)</span> tales que</p>
<p><span class="math display">\[
\begin{align}
L(\theta|\underset{\sim}{x})=u(\underset{\sim}{x})h(\theta)\exp\{W(\underset{\sim}{x})k(\theta)\}
\end{align}
\]</span> es decir, si y sólo si la distribución de partida pertenece a <strong>la familia exponencial</strong>.</p>
</section><section id="evaluación-de-estimadores" class="level2" data-number="3.11"><h2 data-number="3.11" class="anchored" data-anchor-id="evaluación-de-estimadores">
<span class="header-section-number">3.11</span> Evaluación de estimadores</h2>
<section id="mejor-estimador-insesgado.-1" class="level3" data-number="3.11.1"><h3 data-number="3.11.1" class="anchored" data-anchor-id="mejor-estimador-insesgado.-1">
<span class="header-section-number">3.11.1</span> Mejor estimador insesgado.</h3>
<p><strong>Teorema de Rao-Blackwell. Teorema de Lehmann-Scheffé</strong></p>
<p>Si buscamos estimadores insesgados con varianzas pequeñas, podemos restringir nuestra búsqueda a estimadores que sean funciones de estadísticos suficientes.</p>
<div id="thm-3.6" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.6</strong></span> Si <span class="math inline">\(Y_1\)</span> y <span class="math inline">\(Y_2\)</span> son dos variables aleatorias, entonces</p>
<p><span class="math inline">\(E(Y_1) = E[E(Y_1 \mid Y_2)]\)</span>,</p>
<p>donde en el lado derecho de la ecuación el valor esperado interior es con respecto a la distribución condicional de <span class="math inline">\(Y_1\)</span> dada <span class="math inline">\(Y_2\)</span>, y el valor esperado exterior es con respecto a la distribución de <span class="math inline">\(Y_2\)</span>.</p>
</div>
<hr>
<div id="thm-3.7" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.7</strong></span> Si <span class="math inline">\(Y_1\)</span> y <span class="math inline">\(Y_2\)</span> representan variables aleatorias, entonces</p>
<p><span class="math inline">\(V(Y_1) = E[V(Y_1 \mid Y_2)] + V[E(Y_1 \mid Y_2)]\)</span>.</p>
</div>
<div id="thm-3.8" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.8</strong></span> <strong>El Teorema de Rao-Blackwell</strong> Sea <span class="math inline">\(\hat{\theta}\)</span> un estimador insesgado para <span class="math inline">\(\theta\)</span> tal que <span class="math inline">\(V (\hat{\theta}) &lt;\infty\)</span> . Si <span class="math inline">\(U\)</span> es un estadístico suficiente para <span class="math inline">\(\theta\)</span>, definamos <span class="math inline">\(\hat{\theta}^* = E(\hat{\theta} |U)\)</span>. Entonces, para toda <span class="math inline">\(\theta\)</span>, <span class="math display">\[E(\hat{\theta}^*) =\theta\mbox{ y }V(\hat{\theta}^*) \leq V(\hat{\theta})\]</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Como <span class="math inline">\(U\)</span> es suficiente para <span class="math inline">\(\theta\)</span>, la distribución condicional de cualquier estadístico (incluyendo <span class="math inline">\(\hat{\theta}\)</span>), dada <span class="math inline">\(U\)</span> no depende de <span class="math inline">\(\theta\)</span>. Entonces, <span class="math inline">\(\hat{\theta}^*=E(\hat{\theta}|U)\)</span> no es función de <span class="math inline">\(\theta\)</span> y es por tanto un estadístico.</p>
<p>Como <span class="math inline">\(\hat{\theta}\)</span> es un estimador insesgado para <span class="math inline">\(\theta\)</span> entonces de los Teoremas <a href="#thm-3.6" class="quarto-xref">Theorem&nbsp;<span>3.6</span></a> y <a href="#thm-3.7" class="quarto-xref">Theorem&nbsp;<span>3.7</span></a>, tenemos <span class="math display">\[E(\hat{\theta}^*)=E[E(\hat{\theta}|U)]=E(\hat{\theta})=\theta.\]</span> Entonces <span class="math inline">\(\hat{\theta}^*\)</span> es un estimador insesgado para <span class="math inline">\(\theta\)</span>. El Teorema <a href="#thm-3.7" class="quarto-xref">Theorem&nbsp;<span>3.7</span></a> implica que <span class="math display">\[\begin{eqnarray*}
V(\hat{\theta})&amp;=&amp;V[E(\hat{\theta}|U)]+E[V(\hat{\theta}|U)]\\
            &amp;=&amp;V(\hat{\theta}^*)+E[V(\hat{\theta}|U)].
\end{eqnarray*}\]</span> Como <span class="math inline">\(V(\hat{\theta} |U = u) \geq 0\)</span> para toda <span class="math inline">\(u\)</span>, se deduce que <span class="math inline">\(E[V(\hat{\theta} |U)]\geq 0\)</span> y por lo tanto que <span class="math display">\[\begin{eqnarray*}
V(\hat{\theta})&amp;=&amp;V(\hat{\theta}^*)+E[V(\hat{\theta}|U)]\\
&amp;\geq&amp;V(\hat{\theta}^*)+0
\end{eqnarray*}\]</span> luego <span class="math inline">\(V (\hat{\theta}) \geq V (\hat{\theta}^*)\)</span>.</p>
</div>
<p>El Teorema de Rao-Blackwell implica que un estimador insesgado para <span class="math inline">\(\theta\)</span> con una varianza pequeña es, o puede llegar a ser, una función de un estadístico suficiente. Si <span class="math inline">\(U\)</span> es un estadístico suficiente para <span class="math inline">\(\theta\)</span>, <span class="math inline">\(E(\hat{\theta}|U)=\hat{\theta}^*\)</span> entonces <span class="math inline">\(E(\hat{\theta}^*)=\theta\)</span> y <span class="math inline">\(V(\hat{\theta}^*)\leq V(\hat{\theta})\)</span>. <strong><span class="math inline">\(\theta^*\)</span> Estimador insesgado, <span class="math inline">\(\hat{\theta}^*=h(U)\)</span> entonces <span class="math inline">\(E(h(U)|U)=h(U)=\hat{\theta}^*\)</span></strong>.</p>
<p>En general, <span class="math inline">\(E(h(U)|U)=h(U)\)</span>, vemos que usando de nuevo el teorema de Rao-Blackwell nuestro nuevo estimador es simplemente <span class="math inline">\(h(U)=\hat{\theta}^*\)</span>. No ganamos nada después de la primera aplicación.</p>
<p>Debido a que numerosos estadísticos son suficientes para un parámetro <span class="math inline">\(\theta\)</span> asociado con una distribución ¿qué estadístico suficiente debemos usar cuando aplicamos este teorema?</p>
<p>El criterio de factorización de manera típica identifica un estadístico <span class="math inline">\(U\)</span> que mejor resume la información de los datos acerca del parámetro <span class="math inline">\(\theta\)</span>. Tales estadísticos reciben el nombre de <strong>estadísticos suficinetes mínimos</strong>.</p>
<p>Si aplicamos el Teoremo <a href="#thm-3.8" class="quarto-xref">Theorem&nbsp;<span>3.8</span></a> usando <span class="math inline">\(U\)</span>, no sólo obtenemos un estimador con varianza más pequeña si no un estimador insesgado para <span class="math inline">\(\theta\)</span> con varianza mínima, este se le llama <strong>Estimador Insesgado de Varianza Mínima EIVM (MVUE)</strong>.</p>
<div id="nte-3.3" class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note&nbsp;3.3
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>El Teorema de Rao–Blackwell es uno de esos resultados hermosos que nos dicen: “Siempre puedes mejorar tus estimadores, si aprovechas la información disponible en un estadístico suficiente”.</strong></p>
<p>Supongamos que queremos estimar la media <span class="math inline">\(\theta = \mu\)</span> de una distribución <strong>Bernoulli(<span class="math inline">\(p\)</span>)</strong>.</p>
<p><strong>Estimador inicial ingenuo:</strong><br>
Tomemos una muestra de tamaño <span class="math inline">\(n\)</span> y digamos que solo miramos la primera observación <span class="math inline">\(X_1\)</span>.<br>
Como <span class="math inline">\(E(X_1) = p\)</span>, este es un estimador insesgado, pero claramente tiene varianza muy grande.</p>
<p><strong>Estadístico suficiente:</strong><br>
La suma <span class="math inline">\(U = \sum_{i=1}^n X_i\)</span> es suficiente para <span class="math inline">\(p\)</span>.</p>
<p><strong>Estimador Rao–Blackwellizado:</strong><br>
Calculamos:</p>
<p><span class="math display">\[\hat{p}^* = E(X_1 \mid U) = \frac{U}{n}.\]</span></p>
<p>Es decir, hemos pasado de un estimador ingenuo (<span class="math inline">\(X_1\)</span>) a la <strong>media muestral</strong>, que sabemos es mucho más eficiente.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Teorema de Rao–Blackwell: ejemplo Bernoulli ----</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Parámetros verdaderos</span></span>
<span><span class="va">p</span>     <span class="op">&lt;-</span> <span class="fl">0.6</span></span>
<span><span class="va">n</span>     <span class="op">&lt;-</span> <span class="fl">20</span>         <span class="co"># tamaño de muestra</span></span>
<span><span class="va">Nsim</span>  <span class="op">&lt;-</span> <span class="fl">10000</span>      <span class="co"># número de simulaciones</span></span>
<span></span>
<span><span class="co"># Vectores para guardar los estimadores</span></span>
<span><span class="va">est_naive</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">Nsim</span><span class="op">)</span>  <span class="co"># usa solo la primera observación X1</span></span>
<span><span class="va">est_RB</span>    <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">Nsim</span><span class="op">)</span>  <span class="co"># E[X1 | U] = U/n  (media muestral)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">s</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">Nsim</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">U</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">est_naive</span><span class="op">[</span><span class="va">s</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span>  <span class="va">est_RB</span><span class="op">[</span><span class="va">s</span><span class="op">]</span>    <span class="op">&lt;-</span> <span class="va">U</span> <span class="op">/</span> <span class="va">n</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Resumen empírico</span></span>
<span><span class="va">mean_naive</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">est_naive</span><span class="op">)</span></span>
<span><span class="va">var_naive</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">est_naive</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mean_RB</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">est_RB</span><span class="op">)</span></span>
<span><span class="va">var_RB</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">est_RB</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Valores teóricos</span></span>
<span><span class="va">var_naive_theo</span> <span class="op">&lt;-</span> <span class="va">p</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">p</span><span class="op">)</span>            <span class="co"># Var(X1)</span></span>
<span><span class="va">var_RB_theo</span>    <span class="op">&lt;-</span> <span class="va">p</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">p</span><span class="op">)</span> <span class="op">/</span> <span class="va">n</span>        <span class="co"># Var(U/n)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"==== Resultados (empíricos vs teóricos) ====\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>==== Resultados (empíricos vs teóricos) ====</code></pre>
</div>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"E[X1]            empírico = %.4f  (teórico = %.4f)\n"</span>, <span class="va">mean_naive</span>, <span class="va">p</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>E[X1]            empírico = 0.6006  (teórico = 0.6000)</code></pre>
</div>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Var(X1)          empírico = %.4f  (teórico = %.4f)\n\n"</span>, <span class="va">var_naive</span>, <span class="va">var_naive_theo</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Var(X1)          empírico = 0.2399  (teórico = 0.2400)</code></pre>
</div>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"E[U/n]           empírico = %.4f  (teórico = %.4f)\n"</span>, <span class="va">mean_RB</span>, <span class="va">p</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>E[U/n]           empírico = 0.6004  (teórico = 0.6000)</code></pre>
</div>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Var(U/n)         empírico = %.4f  (teórico = %.4f)\n\n"</span>, <span class="va">var_RB</span>, <span class="va">var_RB_theo</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Var(U/n)         empírico = 0.0119  (teórico = 0.0120)</code></pre>
</div>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Reducción de varianza (empírica): Var(U/n) / Var(X1) = %.4f\n"</span>, <span class="va">var_RB</span> <span class="op">/</span> <span class="va">var_naive</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Reducción de varianza (empírica): Var(U/n) / Var(X1) = 0.0494</code></pre>
</div>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Reducción de varianza (teórica) : Var(U/n) / Var(X1) = %.4f\n"</span>, <span class="va">var_RB_theo</span> <span class="op">/</span> <span class="va">var_naive_theo</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Reducción de varianza (teórica) : Var(U/n) / Var(X1) = 0.0500</code></pre>
</div>
</div>
<p>Si empezamos con un estimador insesgado para <span class="math inline">\(\theta\)</span> y el estadístico suficiente obtenido por medio del criterio de factorización, la aplicación del Teorema de Rao-Blackwell en general lleva a un MVUE para el parámetro.</p>
<p>Sea <span class="math inline">\(\hat{\theta}\)</span> el parámetro insesgado para <span class="math inline">\(\theta\)</span>. <span class="math display">\[E(\hat{\theta})=\theta\]</span> <span class="math inline">\(U\)</span> igual al obtenido por el método de factorización <span class="math display">\[\hat{\theta}^*=E(\hat{\theta}|U)\]</span> donde <span class="math inline">\(\hat{\theta}^*\)</span> es el MVUE (Aplicar Blackwell).</p>
<p><strong>La consecuencia fundamental de este teorema es que en la búsqueda del estimador UMVUE, basta con restringirnos a aquellos estimadores insesgados que son función de un estadístico suficiente: si trabajamos con un estadístico insesgado que no es función de uno suficiente, tomando esperanzas condicionadas podemos conseguir otro que sea al menos tan bueno como el anterior y sea función del estadístico suficiente. Este proceso se llama a veces Rao-Blackwellización.</strong></p>
</section><section id="otra-versión-del-teorema-de-rao-blackwell" class="level3" data-number="3.11.2"><h3 data-number="3.11.2" class="anchored" data-anchor-id="otra-versión-del-teorema-de-rao-blackwell">
<span class="header-section-number">3.11.2</span> Otra versión del teorema de Rao-Blackwell</h3>
<div id="thm-3.9" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.9</strong></span> <strong>Otra versión del teorema de Rao-Blackwell</strong> Sea una m.a.s. de <span class="math inline">\(X\)</span>, con densidad (o masa de probabilidad) <span class="math inline">\(f(x|\theta)\)</span>. Sea <span class="math inline">\(T(\underset{\sim}{X})\)</span> un estadístico suficiente para <span class="math inline">\(\theta\)</span> y sea <span class="math inline">\(W(\underset{\sim}{X})\)</span> un estimador insesgado de <span class="math inline">\(\tau(\theta)\)</span>. Definimos <span class="math display">\[\begin{align}
W_T=E_\theta(W|T)
\end{align}\]</span> Entonces,</p>
<ul>
<li>
<span class="math inline">\(W_T\)</span> es función unicamente de <span class="math inline">\(T(\underset{\sim}{X})\)</span> (Es decir, no depende de <span class="math inline">\(\theta\)</span> y no depende de la muestra <span class="math inline">\(\underset{\sim}{X}\)</span> sólo a través del valor de <span class="math inline">\(T(\underset{\sim}{X})\)</span>)</li>
<li>
<span class="math inline">\(E_\theta(W_T)=\tau(\theta)\)</span>.</li>
<li>
<span class="math inline">\(V_\theta(W_T)\leq V_\theta(W)\)</span> .</li>
</ul>
</div>
<p><strong>La consecuencia fundamental de este teorema es que en la búsqueda del estimador UMVUE, basta con restringirnos a aquellos estimadores insesgados que son función de un estadístico suficiente: si trabajamos con un estadístico insesgado que no es función de uno suficiente, tomando esperanzas condicionadas podemos conseguir otro que es al menos tan bueno como el anterior y es función del estadístico suficiente. Este proceso se llama a veces Rao-Blackwellización.</strong></p>
</section></section><section id="comportamiento-asintótico" class="level2" data-number="3.12"><h2 data-number="3.12" class="anchored" data-anchor-id="comportamiento-asintótico">
<span class="header-section-number">3.12</span> Comportamiento asintótico</h2>
<section id="consistencia" class="level3" data-number="3.12.1"><h3 data-number="3.12.1" class="anchored">
<span class="header-section-number">3.12.1</span> Consistencia</h3>
<div id="def-3.4" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.4</strong></span> Se dice que el estimador <span class="math inline">\(\hat{\theta}_n\)</span> es un estimador consistente de <span class="math inline">\(\theta\)</span> si, para cualquier número positivo <span class="math inline">\(\varepsilon\)</span>, <span class="math display">\[\lim_{n\rightarrow\infty}P(|\hat{\theta}_n-\theta|\leq\varepsilon)=1\]</span> o bien, de forma equivalente, <span class="math display">\[\lim_{n\rightarrow\infty}P(|\hat{\theta}_n-\theta|&gt;\varepsilon)=0\]</span></p>
</div>
<p><strong>La consistencia es la misma convergencia en probabilidad!!</strong></p>
<div id="thm-3.10" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.10</strong></span> Un estimador insesgado <span class="math inline">\(\hat{\theta}_n\)</span> para <span class="math inline">\(\theta\)</span> es un estimador consistente de <span class="math inline">\(\theta\)</span> si <span class="math display">\[\lim_{n\rightarrow\infty}V(\hat{\theta}_n)=0.\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span><span class="math inline">\(E(\hat{\theta}_n)=\theta\)</span>. Sea <span class="math inline">\(\sigma_{\hat{\theta}_n}=\sqrt{V(\hat{\theta}_n)}\)</span> aplicando el Teorema Tchebysheff para la v.a <span class="math inline">\(\hat{\theta}_n\)</span>, obtenemos <span class="math display">\[P(|\hat{\theta}_n-\theta|&gt;k\sigma_{\hat{\theta}_n}
    )\leq \frac{1}{k^2}\]</span> Para cualquier número positivo <span class="math inline">\(\varepsilon\)</span>, y <span class="math inline">\(n\)</span> cualquier tamaño muestral <span class="math display">\[\varepsilon=k\sigma_{\hat{\theta}_n}\Rightarrow k=\frac{\varepsilon}{\sigma_{\hat{\theta}_n}}\]</span> luego <span class="math inline">\(k&gt;0\)</span>.</p>
<p>La aplicación del teorema de Chebyshev para esta <span class="math inline">\(n\)</span> fija y esta selección de <span class="math inline">\(k\)</span> muestra que <span class="math display">\[\begin{eqnarray*}
    P(|\hat{\theta}_n-\theta|&gt;\varepsilon)&amp;=&amp;P\left(|\hat{\theta}_n-\theta|&gt;\left[\frac{\varepsilon}{\sigma_{\hat{\theta}_n}}\right]\sigma_{\hat{\theta}_n}\right)\\
    &amp;\leq&amp;\frac{1}{(\varepsilon/\sigma_{\hat{\theta}_n})^2}\\
    &amp;=&amp;\frac{V(\hat{\theta}_n)}{\varepsilon^2}
\end{eqnarray*}\]</span> Entonces, para cualquier <span class="math inline">\(n\)</span> fija <span class="math display">\[0\leq P(|\hat{\theta}_n-\theta|&gt;\varepsilon)\leq \frac{V(\hat{\theta}_n)}{\varepsilon^2}\]</span> Si <span class="math inline">\(\lim_{n\rightarrow\infty}V(\hat{\theta}_n)=0\)</span> entonces <span class="math display">\[\lim_{n\rightarrow\infty}0\leq \lim_{n\rightarrow\infty}P(|\hat{\theta}_n-\theta|&gt;\varepsilon)\leq\lim_{n\rightarrow\infty} \frac{V(\hat{\theta}_n)}{\varepsilon^2}=0\]</span> Luego <span class="math display">\[\lim_{n\rightarrow\infty}P(|\hat{\theta}_n-\theta|&gt;\varepsilon)=0\]</span> luego <span class="math inline">\(\hat{\theta}_n\)</span> es un estimador consistente para <span class="math inline">\(\theta\)</span>.</p>
</div>
<div id="thm-3.11" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.11</strong></span> <span class="math inline">\(\displaystyle{\hat{\theta}_n \stackrel{P}{\rightarrow} \theta}\)</span> y <span class="math inline">\(\displaystyle{\hat{\theta}'_n \stackrel{P}{\rightarrow} \theta'}\)</span> entonces</p>
<ol type="a">
<li>
<span class="math inline">\(\displaystyle{\hat{\theta}_n +\hat{\theta}'_n \stackrel{P}{\longrightarrow} \theta+\theta'}\)</span>.</li>
<li>
<span class="math inline">\(\displaystyle{\hat{\theta}_n \times\hat{\theta}'_n \stackrel{P}{\longrightarrow} \theta\times\theta'}\)</span>.</li>
<li>Si <span class="math inline">\(\theta'\neq 0\)</span>, <span class="math inline">\(\displaystyle{\frac{\hat{\theta}_n}{\hat{\theta}'_n}\stackrel{P}{\longrightarrow} \frac{\theta}{\theta'}}\)</span>.</li>
<li>Si <span class="math inline">\(g (\cdot)\)</span> es una funci'on de valor real que es continua en <span class="math inline">\(\theta\)</span>, entonces <span class="math inline">\(g (\hat{\theta}_n )\)</span> converge en probabilidad en <span class="math inline">\(g (\theta)\)</span>.</li>
</ol>
</div>
<div id="tip-3.1" class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip&nbsp;3.1
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>El teorema de Rao-Blackwell establece que basta con buscar el estimador UMVUE entre aquellos estimadores que son función de un estadístico suficiente.</li>
<li>Bajo ciertas condiciones (existencia de estadísticos suficientes y completos y de estimadores insesgados), esta combinación de los conceptos de estadístico completo y de estadístico suficiente garantiza la existencia de estimadores UMVUE de una función <span class="math inline">\(\tau(\theta)\)</span> del parámetro y da un método para construirlos. <strong>El siguiente teorema establece este resultado. Podemos decir que este teorema resuelve teóricamente el problema de la estimación puntual, entendida ésta como la búsqueda del UMVUE.</strong>
</li>
</ol>
</div>
</div>
<div id="def-3.4" class="definition theorem">
<p><span class="theorem-title"><strong>Definition 3.5 (estadístico completo)</strong></span> Sea <span class="math inline">\(f_T(t|\theta)\)</span> la función de densidad (o de masa de probabilidad) de un estadístico <span class="math inline">\(T\)</span> . Diremos que la familia de distribuciones <span class="math inline">\({f_T(t|\theta) : \theta\in \Theta}\)</span> es completa si se da la implicación siguiente: <span class="math display">\[\begin{align}
E_\theta(g(T))=0 \mbox{para todo $\theta$ entonces}  P_\theta(g(T) = 0) = 1 \mbox{para todo $\theta$}.
\end{align}\]</span></p>
<p>En ese caso diremos que <span class="math inline">\(T\)</span> es un estadístico completo.</p>
<div class="cell">
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Completitud para T ~ Binomial(n, p)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span>     <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">gridp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">N</span>     <span class="op">&lt;-</span> <span class="fl">100000</span>  <span class="co"># simulaciones por p</span></span>
<span></span>
<span><span class="co"># Dos funciones no triviales de T (no dependen de p)</span></span>
<span><span class="va">g1</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">T</span><span class="op">)</span> <span class="cn">T</span> <span class="op">-</span> <span class="va">n</span><span class="op">/</span><span class="fl">2</span></span>
<span><span class="va">g2</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">T</span><span class="op">)</span> <span class="op">(</span><span class="cn">T</span> <span class="op">-</span> <span class="va">n</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="cn">T</span> <span class="op">-</span> <span class="va">n</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Función trivial (cero) para contraste</span></span>
<span><span class="va">g0</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">T</span><span class="op">)</span> <span class="fl">0</span> <span class="op">*</span> <span class="cn">T</span></span>
<span></span>
<span><span class="va">sim_mean_g</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">gfun</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">gridp</span>, <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="cn">T</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">N</span>, size <span class="op">=</span> <span class="va">n</span>, prob <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="fu">gfun</span><span class="op">(</span><span class="cn">T</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Medias empíricas</span></span>
<span><span class="va">m0</span> <span class="op">&lt;-</span> <span class="fu">sim_mean_g</span><span class="op">(</span><span class="va">g0</span><span class="op">)</span></span>
<span><span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu">sim_mean_g</span><span class="op">(</span><span class="va">g1</span><span class="op">)</span></span>
<span><span class="va">m2</span> <span class="op">&lt;-</span> <span class="fu">sim_mean_g</span><span class="op">(</span><span class="va">g2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Valores teóricos (para comparar)</span></span>
<span><span class="co"># E[T] = n p; Var[T] = n p (1-p); E[T^2] = Var[T] + (E[T])^2</span></span>
<span><span class="va">theo_g1</span> <span class="op">&lt;-</span> <span class="va">n</span> <span class="op">*</span> <span class="op">(</span><span class="va">gridp</span> <span class="op">-</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span>  <span class="co"># E[g1(T)] = n(p - 1/2)</span></span>
<span></span>
<span><span class="va">ET</span>   <span class="op">&lt;-</span> <span class="va">n</span> <span class="op">*</span> <span class="va">gridp</span></span>
<span><span class="va">VarT</span> <span class="op">&lt;-</span> <span class="va">n</span> <span class="op">*</span> <span class="va">gridp</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">gridp</span><span class="op">)</span></span>
<span><span class="va">ET2</span>  <span class="op">&lt;-</span> <span class="va">VarT</span> <span class="op">+</span> <span class="va">ET</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">theo_g2</span> <span class="op">&lt;-</span> <span class="va">ET2</span> <span class="op">-</span> <span class="op">(</span><span class="va">n</span><span class="op">/</span><span class="fl">2</span> <span class="op">+</span> <span class="va">n</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span> <span class="op">*</span> <span class="va">ET</span> <span class="op">+</span> <span class="op">(</span><span class="va">n</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="fl">6</span><span class="op">)</span>  <span class="co"># expandir (T - n/2)(T - n/3)</span></span>
<span></span>
<span><span class="co"># Mostrar resultados</span></span>
<span><span class="va">tab</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  p <span class="op">=</span> <span class="va">gridp</span>,</span>
<span>  E_g0_emp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">m0</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>  E_g1_emp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">m1</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>  E_g1_teo <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">theo_g1</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>  E_g2_emp <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">m2</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>  E_g2_teo <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">theo_g2</span>, <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">tab</span>, row.names <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   p E_g0_emp E_g1_emp E_g1_teo E_g2_emp E_g2_teo
 0.1        0 -4.00184       -4 10.24421 10.23333
 0.2        0 -2.99891       -3  5.61325  5.60000
 0.3        0 -2.00216       -2  2.77471  2.76667
 0.4        0 -1.00631       -1  1.74363  1.73333
 0.5        0 -0.00727        0  2.50485  2.50000
 0.6        0  1.00466        1  5.09209  5.06667
 0.7        0  1.99571        2  9.43229  9.43333
 0.8        0  3.00090        3 15.55946 15.60000
 0.9        0  3.99831        4 23.58862 23.56667</code></pre>
</div>
</div>
<div id="tip-3.2" class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip&nbsp;3.2: Qué observar
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Para <span class="math inline">\(g_0(T)\equiv 0\)</span>, la media empírica es <span class="math inline">\(\approx 0\)</span> para todos los <span class="math inline">\(p\)</span>.</p></li>
<li><p>Para <span class="math inline">\(g_1(T) = T - \tfrac{n}{2}\)</span>, la esperanza teórica es <span class="math inline">\(n(p - \tfrac{1}{2})\)</span>:<br>
solo vale <span class="math inline">\(0\)</span> cuando <span class="math inline">\(p = \tfrac{1}{2}\)</span>; <strong>no</strong> es <span class="math inline">\(0\)</span> para los demás <span class="math inline">\(p\)</span>.</p></li>
<li><p>Para <span class="math inline">\(g_2(T) = (T - \tfrac{n}{2})(T - \tfrac{n}{3})\)</span>, la esperanza es un polinomio en <span class="math inline">\(p\)</span> que <strong>no</strong> es idénticamente cero; de nuevo, no se anula para todos los <span class="math inline">\(p\)</span>.</p></li>
</ul>
<hr>
<p>Esto ilustra la <strong>completitud</strong>: si alguna <span class="math inline">\(g(T)\)</span> (que no depende de <span class="math inline">\(p\)</span>) tuviera<br><span class="math inline">\(E_p[g(T)] = 0\)</span> para todo <span class="math inline">\(p \in (0,1)\)</span>, entonces esa <span class="math inline">\(g\)</span> debe ser (casi seguro) la función <strong>cero</strong>.</p>
<p>➡️ De ahí que, con <strong>suficiencia + completitud</strong>, el estimador insesgado derivado es el <strong>único UMVUE</strong> (Teorema de Lehmann–Scheffé).</p>
</div>
</div>
<p><strong>La definición de completitud refuerza la de suficiencia en el sentido de que si un estadístico es suficiente y completo entonces, es suficiente minimal (el recíproco no es cierto)</strong></p>
<div id="thm-3.12" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.12 (Teorema de Lehmann-Scheffé)</strong></span> Si <span class="math inline">\(T(\underset{\sim}{X})\)</span> es un estadístico suficiente y completo para <span class="math inline">\(\theta\)</span> y <span class="math inline">\(W(\underset{\sim}{X})\)</span> es un estimador insesgado cualquiera de <span class="math inline">\(\tau(\theta)\)</span>, entonces <span class="math display">\[\begin{align}
W_T(\underset{\sim}{X})=E_\theta(W|T)
\end{align}\]</span> es el mejor estimador insesgado (UMVUE) de <span class="math inline">\(\tau(\theta)\)</span>. Si, además, <span class="math inline">\(V(W_T) &lt; \infty\)</span> para todo <span class="math inline">\(\theta\)</span>, entonces <span class="math inline">\(W_T\)</span> es único.</p>
</div>
<ol type="1">
<li>La demostración del teorema de Lehmann-Scheffé se basa en el hecho de que, si existen estimadores insesgados, esencialmente sólo existe uno que sea función del estadístico suficiente y completo, pues condicionando cualquiera de los insesgados al estadístico suficiente y completo se obtiene siempre el mismo resultado.</li>
<li>El teorema de Rao-Blackwell garantiza que al tomar esperanzas condicionadas se ha reducido la varianza, llegando así al UMVUE.</li>
<li>La principal conclusión del teorema de Lehmann-Scheffé es que si existe un estimador insesgado de <span class="math inline">\(\tau(\theta)\)</span> que sea función de un estadístico suficiente y completo, entonces es el único UMVUE de <span class="math inline">\(\tau(\theta)\)</span>.</li>
</ol>
<div id="tip-3.3" class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip&nbsp;3.3: Recreando Lehmann–Scheffé en R
</div>
</div>
<div class="callout-body-container callout-body">
<p>¡Vamos a “recrear” Lehmann–Scheffé en R con un ejemplo clásico y totalmente replicable!</p>
<p>Usaremos <span class="math inline">\(X_1,\dots,X_n \sim \text{i.i.d. Poisson}(\lambda)\)</span>.<br>
Entonces</p>
<p><span class="math display">\[
T=\sum_{i=1}^n X_i \sim \text{Poisson}(n\lambda)
\]</span></p>
<p>es suficiente y completo para <span class="math inline">\(\lambda\)</span>.</p>
<p>Veremos dos blancos <span class="math inline">\(\tau(\theta)\)</span>:</p>
<ul>
<li>
<span class="math inline">\(\tau(\lambda)=\lambda\)</span><br>
</li>
<li><span class="math inline">\(\tau(\lambda)=e^{-\lambda}\)</span></li>
</ul>
<p>En cada caso partimos de un estimador insesgado cualquiera <span class="math inline">\(W(\mathbf X)\)</span> y lo “Rao–Blackwellizamos” con <span class="math inline">\(T\)</span>:</p>
<p><span class="math display">\[
W_T(\mathbf X)=\mathbb{E}_\theta[W \mid T].
\]</span></p>
<p>Por <strong>Lehmann–Scheffé</strong>, <span class="math inline">\(W_T\)</span> es el <strong>UMVUE</strong>.</p>
<p><strong>Idea teórica rápida</strong></p>
<ul>
<li>Para <span class="math inline">\(\tau(\lambda)=\lambda\)</span>:<br>
Un estimador insesgado simple es <span class="math inline">\(W=X_1\)</span> (pues <span class="math inline">\(\mathbb{E}[X_1]=\lambda\)</span>).<br>
Condicionando en <span class="math inline">\(T\)</span>:</li>
</ul>
<p><span class="math display">\[
  W_T = \mathbb{E}[X_1 \mid T] = \tfrac{T}{n} \quad \Longrightarrow \quad \text{UMVUE}.
\]</span></p>
<ul>
<li>Para <span class="math inline">\(\tau(\lambda)=e^{-\lambda}\)</span>:<br>
Un insesgado simple es <span class="math inline">\(W=\mathbf 1\{X_1=0\}\)</span> (pues <span class="math inline">\(\Pr(X_1=0)=e^{-\lambda}\)</span>).<br>
Dado <span class="math inline">\(T=t\)</span>,</li>
</ul>
<p><span class="math display">\[
  (X_1,\dots,X_n)\mid T=t \sim \text{Multinomial}\Big(t;\tfrac{1}{n},\dots,\tfrac{1}{n}\Big),
\]</span></p>
<p>así que</p>
<p><span class="math display">\[
  \Pr(X_1=0 \mid T=t)=\Big(1-\tfrac{1}{n}\Big)^t.
\]</span></p>
<p>Por ende,</p>
<p><span class="math display">\[
  W_T = \mathbb{E}[\,\mathbf 1\{X_1=0\}\mid T]
  = \Big(1-\tfrac{1}{n}\Big)^T,
\]</span></p>
<p>que es el <strong>UMVUE de <span class="math inline">\(e^{-\lambda}\)</span></strong>.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Lehmann–Scheffé con Poisson ----</span></span>
<span><span class="co">## X_i ~ Poisson(lambda).  T = sum X_i ~ Poisson(n*lambda) es suficiente y completo.</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Parámetros</span></span>
<span><span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fl">2</span></span>
<span><span class="va">n</span>      <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">Nsim</span>   <span class="op">&lt;-</span> <span class="fl">20000</span></span>
<span></span>
<span><span class="co"># Contenedores</span></span>
<span><span class="va">W1_naive</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">Nsim</span><span class="op">)</span>  <span class="co"># para tau1(lambda)=lambda, W = X1</span></span>
<span><span class="va">W1_RB</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">Nsim</span><span class="op">)</span>  <span class="co"># W_T = E[X1|T] = T/n</span></span>
<span></span>
<span><span class="va">W2_naive</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">Nsim</span><span class="op">)</span>  <span class="co"># para tau2(lambda)=exp(-lambda), W = 1{X1=0}</span></span>
<span><span class="va">W2_RB</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">Nsim</span><span class="op">)</span>  <span class="co"># W_T = E[1{X1=0} | T] = ((n-1)/n)^T</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">s</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">Nsim</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">lambda</span><span class="op">)</span></span>
<span>  <span class="va">Tsum</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Caso 1: tau(lambda) = lambda</span></span>
<span>  <span class="va">W1_naive</span><span class="op">[</span><span class="va">s</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span>  <span class="va">W1_RB</span><span class="op">[</span><span class="va">s</span><span class="op">]</span>    <span class="op">&lt;-</span> <span class="va">Tsum</span> <span class="op">/</span> <span class="va">n</span></span>
<span>  </span>
<span>  <span class="co"># Caso 2: tau(lambda) = exp(-lambda)</span></span>
<span>  <span class="va">W2_naive</span><span class="op">[</span><span class="va">s</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span></span>
<span>  <span class="va">W2_RB</span><span class="op">[</span><span class="va">s</span><span class="op">]</span>    <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span><span class="op">/</span><span class="va">n</span><span class="op">)</span><span class="op">^</span><span class="va">Tsum</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co">## Resúmenes empíricos</span></span>
<span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  Estimador <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"W = X1"</span>, <span class="st">"W_T = T/n"</span>, <span class="st">"W = 1{X1=0}"</span>, <span class="st">"W_T = ((n-1)/n)^T"</span><span class="op">)</span>,</span>
<span>  Objetivo  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lambda"</span>, <span class="st">"lambda"</span>, <span class="st">"exp(-lambda)"</span>, <span class="st">"exp(-lambda)"</span><span class="op">)</span>,</span>
<span>  Media     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">W1_naive</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">W1_RB</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">W2_naive</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">W2_RB</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  Varianza  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">W1_naive</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">W1_RB</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">W2_naive</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">W2_RB</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">res</span>, row.names <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         Estimador     Objetivo    Media    Varianza
            W = X1       lambda 2.015250 2.036219248
         W_T = T/n       lambda 1.999100 0.197314056
       W = 1{X1=0} exp(-lambda) 0.131500 0.114213461
 W_T = ((n-1)/n)^T exp(-lambda) 0.135274 0.003988959</code></pre>
</div>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Valores teóricos para comparación</span></span>
<span><span class="co"># Caso 1 (lambda):</span></span>
<span><span class="va">var_W1_naive_theo</span> <span class="op">&lt;-</span> <span class="va">lambda</span>            <span class="co"># Var(X1)</span></span>
<span><span class="va">var_W1_RB_theo</span>    <span class="op">&lt;-</span> <span class="va">lambda</span> <span class="op">/</span> <span class="va">n</span>        <span class="co"># Var(T/n)</span></span>
<span></span>
<span><span class="co"># Caso 2 (exp(-lambda)):</span></span>
<span><span class="co"># Var(1{X1=0}) = e^{-lambda}(1 - e^{-lambda})</span></span>
<span><span class="va">var_W2_naive_theo</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">lambda</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">lambda</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Var(((n-1)/n)^T) = E[a^{2T}] - (E[a^T])^2, con a = (n-1)/n y T~Poisson(n*lambda)</span></span>
<span><span class="va">a</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span><span class="op">/</span><span class="va">n</span></span>
<span><span class="va">E_aT</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">lambda</span> <span class="op">*</span> <span class="op">(</span><span class="va">a</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>        <span class="co"># = exp(n*lambda*(-1/n)) = exp(-lambda)</span></span>
<span><span class="va">E_a2T</span>    <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">lambda</span> <span class="op">*</span> <span class="op">(</span><span class="va">a</span><span class="op">^</span><span class="fl">2</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>      <span class="co"># = exp(-2*lambda + lambda/n)</span></span>
<span><span class="va">var_W2_RB_theo</span> <span class="op">&lt;-</span> <span class="va">E_a2T</span> <span class="op">-</span> <span class="va">E_aT</span><span class="op">^</span><span class="fl">2</span>             <span class="co"># = e^{-2lambda}(e^{lambda/n} - 1)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"\n--- Teórico ---\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- Teórico ---</code></pre>
</div>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Var(W=X1)                 = %.5f\n"</span>, <span class="va">var_W1_naive_theo</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Var(W=X1)                 = 2.00000</code></pre>
</div>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Var(W_T=T/n)              = %.5f\n"</span>, <span class="va">var_W1_RB_theo</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Var(W_T=T/n)              = 0.20000</code></pre>
</div>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Var(W=1{X1=0})            = %.5f\n"</span>, <span class="va">var_W2_naive_theo</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Var(W=1{X1=0})            = 0.11702</code></pre>
</div>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Var(W_T=((n-1)/n)^T)      = %.5f\n\n"</span>, <span class="va">var_W2_RB_theo</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Var(W_T=((n-1)/n)^T)      = 0.00406</code></pre>
</div>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Relaciones esperadas (Rao–Blackwell):\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Relaciones esperadas (Rao–Blackwell):</code></pre>
</div>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Var(T/n)  &lt;= Var(X1):           %.5f &lt;= %.5f\n"</span>, <span class="va">var_W1_RB_theo</span>, <span class="va">var_W1_naive_theo</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Var(T/n)  &lt;= Var(X1):           0.20000 &lt;= 2.00000</code></pre>
</div>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"Var(((n-1)/n)^T) &lt;= Var(1{X1=0}): %.5f &lt;= %.5f\n"</span>, <span class="va">var_W2_RB_theo</span>, <span class="va">var_W2_naive_theo</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Var(((n-1)/n)^T) &lt;= Var(1{X1=0}): 0.00406 &lt;= 0.11702</code></pre>
</div>
</div>
<p><strong>Qué comprueba el script</strong></p>
<ul>
<li><p><strong>Insesgadez:</strong> las medias empíricas de <span class="math inline">\(W\)</span> y <span class="math inline">\(W_T\)</span> aproximan <span class="math inline">\(\tau(\lambda)\)</span> (ya sea <span class="math inline">\(\lambda\)</span> o <span class="math inline">\(e^{-\lambda}\)</span>).</p></li>
<li><p><strong>Mejor varianza:</strong><br><span class="math display">\[\mathrm{Var}(W_T) \leq \mathrm{Var}(W)\]</span><br>
en ambos casos (se ve empíricamente y con fórmulas teóricas).</p></li>
<li>
<p><strong>Forma cerrada del UMVUE:</strong></p>
<ul>
<li>Para <span class="math inline">\(\tau(\lambda)=\lambda\)</span>: <span class="math inline">\(W_T = T/n\)</span>.<br>
</li>
<li>Para <span class="math inline">\(\tau(\lambda)=e^{-\lambda}\)</span>: <span class="math inline">\(W_T = \Big(\tfrac{n-1}{n}\Big)^T\)</span>.</li>
</ul>
</li>
</ul>
<p>Y, por <strong>Lehmann–Scheffé</strong>, como <span class="math inline">\(T\)</span> es suficiente y completo y <span class="math inline">\(\mathrm{Var}(W_T)&lt;\infty\)</span>, este UMVUE es <strong>único</strong>.</p>
<div class="cell">
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># --- Preparación ----</span></span>
<span><span class="co"># install.packages("ggplot2") # si no lo tienes</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">explore_LS</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">lambda</span> <span class="op">=</span> <span class="fl">2</span>, <span class="va">n</span> <span class="op">=</span> <span class="fl">10</span>, <span class="va">Nsim</span> <span class="op">=</span> <span class="fl">20000</span>, <span class="va">seed</span> <span class="op">=</span> <span class="fl">123</span>,</span>
<span>                       <span class="va">show_plots</span> <span class="op">=</span> <span class="cn">TRUE</span>, <span class="va">save_plots</span> <span class="op">=</span> <span class="cn">FALSE</span>, <span class="va">prefix</span> <span class="op">=</span> <span class="st">"LS"</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="va">seed</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># ---- Simulación ----</span></span>
<span>  <span class="co"># Generamos Nsim muestras, cada una de tamaño n (Poisson(lambda))</span></span>
<span>  <span class="co"># Para eficiencia, simulamos Nsim*n y damos forma de matriz.</span></span>
<span>  <span class="va">Xmat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span><span class="va">Nsim</span> <span class="op">*</span> <span class="va">n</span>, <span class="va">lambda</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">Nsim</span>, ncol <span class="op">=</span> <span class="va">n</span><span class="op">)</span></span>
<span>  <span class="va">Tsum</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">Xmat</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Caso 1: tau(lambda) = lambda</span></span>
<span>  <span class="va">W1</span>  <span class="op">&lt;-</span> <span class="va">Xmat</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>          <span class="co"># estimador ingenuo: X1</span></span>
<span>  <span class="va">WT1</span> <span class="op">&lt;-</span> <span class="va">Tsum</span> <span class="op">/</span> <span class="va">n</span>           <span class="co"># Rao-Blackwell: E[X1 | T] = T/n  (UMVUE)</span></span>
<span></span>
<span>  <span class="co"># Caso 2: tau(lambda) = exp(-lambda)</span></span>
<span>  <span class="va">W2</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">Xmat</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span>        <span class="co"># ingenuo: 1{X1=0}</span></span>
<span>  <span class="va">WT2</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span><span class="op">/</span><span class="va">n</span><span class="op">)</span><span class="op">^</span><span class="va">Tsum</span>                    <span class="co"># RB: ((n-1)/n)^T  (UMVUE)</span></span>
<span></span>
<span>  <span class="co"># ---- Resúmenes empíricos ----</span></span>
<span>  <span class="va">tab</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    Estimador <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"W = X1"</span>, <span class="st">"W_T = T/n"</span>, <span class="st">"W = 1{X1=0}"</span>, <span class="st">"W_T = ((n-1)/n)^T"</span><span class="op">)</span>,</span>
<span>    Objetivo  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"lambda"</span>, <span class="st">"lambda"</span>, <span class="st">"exp(-lambda)"</span>, <span class="st">"exp(-lambda)"</span><span class="op">)</span>,</span>
<span>    Media     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">W1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">WT1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">W2</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">WT2</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    Varianza  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">W1</span><span class="op">)</span>,  <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">WT1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">W2</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">WT2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="co"># ---- Valores teóricos ----</span></span>
<span>  <span class="co"># Caso 1:</span></span>
<span>  <span class="va">var_W1_theo</span>  <span class="op">&lt;-</span> <span class="va">lambda</span>           <span class="co"># Var(X1)</span></span>
<span>  <span class="va">var_WT1_theo</span> <span class="op">&lt;-</span> <span class="va">lambda</span> <span class="op">/</span> <span class="va">n</span>       <span class="co"># Var(T/n)</span></span>
<span></span>
<span>  <span class="co"># Caso 2:</span></span>
<span>  <span class="co"># Var(1{X1=0}) = e^{-lambda}(1 - e^{-lambda})</span></span>
<span>  <span class="va">var_W2_theo</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">lambda</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">lambda</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Var(((n-1)/n)^T) = E[a^{2T}] - (E[a^T])^2 con T ~ Poisson(n*lambda), a=(n-1)/n</span></span>
<span>  <span class="va">a</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span><span class="op">/</span><span class="va">n</span></span>
<span>  <span class="va">E_aT</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">lambda</span> <span class="op">*</span> <span class="op">(</span><span class="va">a</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>           <span class="co"># = exp(-lambda)</span></span>
<span>  <span class="va">E_a2T</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">lambda</span> <span class="op">*</span> <span class="op">(</span><span class="va">a</span><span class="op">^</span><span class="fl">2</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>         <span class="co"># = exp(-2*lambda + lambda/n)</span></span>
<span>  <span class="va">var_WT2_theo</span> <span class="op">&lt;-</span> <span class="va">E_a2T</span> <span class="op">-</span> <span class="va">E_aT</span><span class="op">^</span><span class="fl">2</span>               <span class="co"># = e^{-2lambda}(e^{lambda/n} - 1)</span></span>
<span></span>
<span>  <span class="va">tab_teo</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    Estimador <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"W = X1"</span>, <span class="st">"W_T = T/n"</span>, <span class="st">"W = 1{X1=0}"</span>, <span class="st">"W_T = ((n-1)/n)^T"</span><span class="op">)</span>,</span>
<span>    Var_teor  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">var_W1_theo</span>, <span class="va">var_WT1_theo</span>, <span class="va">var_W2_theo</span>, <span class="va">var_WT2_theo</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="co"># ---- Data para gráficas ----</span></span>
<span>  <span class="va">df1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>valor <span class="op">=</span> <span class="va">W1</span>,  tipo <span class="op">=</span> <span class="st">"W = X1"</span>,        objetivo <span class="op">=</span> <span class="st">"lambda"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>valor <span class="op">=</span> <span class="va">WT1</span>, tipo <span class="op">=</span> <span class="st">"W_T = T/n"</span>,     objetivo <span class="op">=</span> <span class="st">"lambda"</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="va">df2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>valor <span class="op">=</span> <span class="va">W2</span>,  tipo <span class="op">=</span> <span class="st">"W = 1{X1=0}"</span>,           objetivo <span class="op">=</span> <span class="st">"exp(-lambda)"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>valor <span class="op">=</span> <span class="va">WT2</span>, tipo <span class="op">=</span> <span class="st">"W_T = ((n-1)/n)^T"</span>,     objetivo <span class="op">=</span> <span class="st">"exp(-lambda)"</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="co"># ---- Gráficas ----</span></span>
<span>  <span class="va">p_dens_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df1</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">valor</span>, fill <span class="op">=</span> <span class="va">tipo</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.35</span>, adjust <span class="op">=</span> <span class="fl">1.1</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">lambda</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>      title <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="st">"Distribuciones de "</span> <span class="op">*</span> <span class="va">W</span> <span class="op">~</span> <span class="st">"vs"</span> <span class="op">~</span> <span class="va">W</span><span class="op">[</span><span class="cn">T</span><span class="op">]</span> <span class="op">~</span> <span class="st">" para "</span> <span class="op">~</span> <span class="fu">tau</span><span class="op">(</span><span class="va">lambda</span><span class="op">)</span> <span class="op">==</span> <span class="va">lambda</span><span class="op">)</span>,</span>
<span>      subtitle <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="va">lambda</span> <span class="op">==</span> <span class="fu">.</span><span class="op">(</span><span class="va">lambda</span><span class="op">)</span> <span class="op">~</span> <span class="st">", "</span> <span class="op">~</span> <span class="va">n</span> <span class="op">==</span> <span class="fu">.</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="op">~</span> <span class="st">", "</span> <span class="op">~</span> <span class="va">N</span><span class="op">[</span><span class="va">sim</span><span class="op">]</span> <span class="op">==</span> <span class="fu">.</span><span class="op">(</span><span class="va">Nsim</span><span class="op">)</span><span class="op">)</span>,</span>
<span>      x <span class="op">=</span> <span class="st">"valor"</span>, y <span class="op">=</span> <span class="st">"densidad"</span></span>
<span>    <span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">p_box_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df1</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">tipo</span>, y <span class="op">=</span> <span class="va">valor</span>, fill <span class="op">=</span> <span class="va">tipo</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.4</span>, width <span class="op">=</span> <span class="fl">0.6</span>, outlier.alpha <span class="op">=</span> <span class="fl">0.25</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="va">lambda</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>      title   <span class="op">=</span> <span class="st">"Boxplots: W vs W_T (objetivo: lambda)"</span>,</span>
<span>      x <span class="op">=</span> <span class="cn">NULL</span>, y <span class="op">=</span> <span class="st">"valor"</span></span>
<span>    <span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Para el caso indicador es discreto; usamos barras y boxplot (WT2 es continuo en [0,1])</span></span>
<span>  <span class="va">p_bar_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df2</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">valor</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>, fill <span class="op">=</span> <span class="va">tipo</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span>position <span class="op">=</span> <span class="st">"dodge"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>      title <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="st">"Distribuciones de "</span> <span class="op">*</span> <span class="va">W</span> <span class="op">~</span> <span class="st">"vs"</span> <span class="op">~</span> <span class="va">W</span><span class="op">[</span><span class="cn">T</span><span class="op">]</span> <span class="op">~</span> <span class="st">" para "</span> <span class="op">~</span> <span class="fu">tau</span><span class="op">(</span><span class="va">lambda</span><span class="op">)</span> <span class="op">==</span> <span class="va">e</span><span class="op">^</span><span class="op">{</span><span class="op">-</span><span class="va">lambda</span><span class="op">}</span><span class="op">)</span>,</span>
<span>      subtitle <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html">bquote</a></span><span class="op">(</span><span class="va">lambda</span> <span class="op">==</span> <span class="fu">.</span><span class="op">(</span><span class="va">lambda</span><span class="op">)</span> <span class="op">~</span> <span class="st">", "</span> <span class="op">~</span> <span class="va">n</span> <span class="op">==</span> <span class="fu">.</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="op">~</span> <span class="st">", "</span> <span class="op">~</span> <span class="va">N</span><span class="op">[</span><span class="va">sim</span><span class="op">]</span> <span class="op">==</span> <span class="fu">.</span><span class="op">(</span><span class="va">Nsim</span><span class="op">)</span><span class="op">)</span>,</span>
<span>      x <span class="op">=</span> <span class="st">"valor (redondeado a 3 decimales)"</span>, y <span class="op">=</span> <span class="st">"frecuencia"</span></span>
<span>    <span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"top"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">p_box_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df2</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">tipo</span>, y <span class="op">=</span> <span class="va">valor</span>, fill <span class="op">=</span> <span class="va">tipo</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.4</span>, width <span class="op">=</span> <span class="fl">0.6</span>, outlier.alpha <span class="op">=</span> <span class="fl">0.25</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">lambda</span><span class="op">)</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>      title <span class="op">=</span> <span class="st">"Boxplots: W vs W_T (objetivo: exp(-lambda))"</span>,</span>
<span>      x <span class="op">=</span> <span class="cn">NULL</span>, y <span class="op">=</span> <span class="st">"valor"</span></span>
<span>    <span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">show_plots</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">p_dens_1</span><span class="op">)</span>; <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">p_box_1</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">p_bar_2</span><span class="op">)</span>;  <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">p_box_2</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">save_plots</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggsave.html">ggsave</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"%s_dens_lambda.png"</span>, <span class="va">prefix</span><span class="op">)</span>, <span class="va">p_dens_1</span>, width <span class="op">=</span> <span class="fl">7</span>, height <span class="op">=</span> <span class="fl">4.5</span>, dpi <span class="op">=</span> <span class="fl">150</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggsave.html">ggsave</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"%s_box_lambda.png"</span>,  <span class="va">prefix</span><span class="op">)</span>, <span class="va">p_box_1</span>,  width <span class="op">=</span> <span class="fl">6</span>, height <span class="op">=</span> <span class="fl">4.5</span>, dpi <span class="op">=</span> <span class="fl">150</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggsave.html">ggsave</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"%s_bar_expl.png"</span>,    <span class="va">prefix</span><span class="op">)</span>, <span class="va">p_bar_2</span>,  width <span class="op">=</span> <span class="fl">7</span>, height <span class="op">=</span> <span class="fl">4.5</span>, dpi <span class="op">=</span> <span class="fl">150</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggsave.html">ggsave</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html">sprintf</a></span><span class="op">(</span><span class="st">"%s_box_expl.png"</span>,    <span class="va">prefix</span><span class="op">)</span>, <span class="va">p_box_2</span>,  width <span class="op">=</span> <span class="fl">6</span>, height <span class="op">=</span> <span class="fl">4.5</span>, dpi <span class="op">=</span> <span class="fl">150</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="co"># ---- Salida ----</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>    resumen_empirico <span class="op">=</span> <span class="va">tab</span>,</span>
<span>    resumen_teorico  <span class="op">=</span> <span class="va">tab_teo</span>,</span>
<span>    plots <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>dens_lambda <span class="op">=</span> <span class="va">p_dens_1</span>, box_lambda <span class="op">=</span> <span class="va">p_box_1</span>,</span>
<span>                 bar_expl <span class="op">=</span> <span class="va">p_bar_2</span>, box_expl <span class="op">=</span> <span class="va">p_box_2</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># ===== Ejemplo de uso =====</span></span>
<span><span class="va">out</span> <span class="op">&lt;-</span> <span class="fu">explore_LS</span><span class="op">(</span>lambda <span class="op">=</span> <span class="fl">2</span>, n <span class="op">=</span> <span class="fl">10</span>, Nsim <span class="op">=</span> <span class="fl">20000</span>, seed <span class="op">=</span> <span class="fl">123</span>, show_plots <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-16-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-16-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="chapter2_files/figure-html/unnamed-chunk-16-4.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Mira los resúmenes:</span></span>
<span><span class="va">out</span><span class="op">$</span><span class="va">resumen_empirico</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Estimador     Objetivo     Media    Varianza
1            W = X1       lambda 1.9870500 1.961480372
2         W_T = T/n       lambda 1.9991000 0.199480164
3       W = 1{X1=0} exp(-lambda) 0.1354500 0.117109153
4 W_T = ((n-1)/n)^T exp(-lambda) 0.1354626 0.004083226</code></pre>
</div>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">out</span><span class="op">$</span><span class="va">resumen_teorico</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Estimador    Var_teor
1            W = X1 2.000000000
2         W_T = T/n 0.200000000
3       W = 1{X1=0} 0.117019644
4 W_T = ((n-1)/n)^T 0.004055133</code></pre>
</div>
</div>
<p><strong>Qué muestra</strong></p>
<ul>
<li><p><strong>Densidad y boxplot (objetivo <span class="math inline">\(\lambda\)</span>):</strong><br>
Compara <span class="math inline">\(W = X_1\)</span> vs <span class="math inline">\(W_T = T/n\)</span>.<br>
Ambos se centran en <span class="math inline">\(\lambda\)</span>, pero verás <strong>menor varianza</strong> para <span class="math inline">\(W_T\)</span>.</p></li>
<li><p><strong>Barras/boxplot (objetivo <span class="math inline">\(e^{-\lambda}\)</span>):</strong><br>
Compara <span class="math inline">\(W = \mathbf{1}\{X_1=0\}\)</span> vs <span class="math inline">\(W_T = \Big(\tfrac{n-1}{n}\Big)^T\)</span>.<br>
Ambos centrados en <span class="math inline">\(e^{-\lambda}\)</span>, con <strong>varianza menor</strong> para <span class="math inline">\(W_T\)</span>.</p></li>
</ul>
<hr>
<p><strong>Sugerencia:</strong> juega con <span class="math inline">\(\lambda\)</span> y <span class="math inline">\(n\)</span> en <code>explore_LS(lambda, n, ...)</code> para ver cómo cambia la varianza.<br>
Por <strong>Lehmann–Scheffé</strong>, <span class="math inline">\(W_T\)</span> es el <strong>UMVUE</strong> y único (bajo varianza finita) cuando <span class="math inline">\(T\)</span> es suficiente y completo.</p>
<section id="referencias" class="level2" data-number="3.13"><h2 data-number="3.13" class="anchored" data-anchor-id="referencias">
<span class="header-section-number">3.13</span> Referencias</h2>
<ul>
<li><p><strong>Gómez, Guadalupe</strong>, &amp; <strong>Delicado, Pedro</strong> (2006). <em>Curso de Inferencia y Decisión</em>. Departament d’Estadística i Investigació Operativa, Universitat Politècnica de Catalunya.</p></li>
<li><p><strong>Wackerly, D. D., Mendenhall, W.</strong>, &amp; <strong>Scheaffer, R. L.</strong> (2008). <strong>Estadística matemática con aplicaciones</strong> (7ª ed.). Cengage Learning.</p></li>
<li><p><strong>Roussas, G. G.</strong> (1997). <strong>A Course in Mathematical Statistics</strong> (2nd ed.). Academic Press.</p></li>
<li><p><strong>Kalbfleisch, J. G. Probability and Statistical Inference</strong>. Springer-Verlag, 1985.</p></li>
</ul>


</section>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./chapter1.html" class="pagination-link" aria-label="Principios para reducir los datos">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Principios para reducir los datos</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>