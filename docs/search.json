[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inferencia Estad√≠stica",
    "section": "",
    "text": "1 INTRODUCCI√ìN\nEste libro ha sido concebido como un recurso integral para el estudio riguroso y aplicado de la inferencia estad√≠stica. Est√° dirigido a estudiantes de programas de estad√≠stica, matem√°ticas aplicadas y disciplinas afines, y busca fortalecer la comprensi√≥n conceptual y t√©cnica de los fundamentos que sustentan el an√°lisis estad√≠stico moderno.\nA lo largo de sus cap√≠tulos, el lector encontrar√° un desarrollo progresivo de los siguientes temas:\nEl material combina el rigor formal con ejemplos y aplicaciones que ilustran c√≥mo los m√©todos estad√≠sticos permiten extraer conclusiones v√°lidas a partir de datos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#c√≥mo-navegar-este-libro",
    "href": "index.html#c√≥mo-navegar-este-libro",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.1 ¬øC√≥mo navegar este libro?",
    "text": "1.1 ¬øC√≥mo navegar este libro?\n\nUsa el √≠ndice lateral izquierdo para acceder a cada cap√≠tulo y subcap√≠tulo.\nHaz uso del buscador para encontrar conceptos o t√©rminos clave.\nRevisa los apartados de ‚ÄúLista de problemas‚Äù incluidos al final de cada secci√≥n para practicar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#bienvenidao",
    "href": "index.html#bienvenidao",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.2 ¬°Bienvenida/o!",
    "text": "1.2 ¬°Bienvenida/o!\nTe invito a recorrer este texto con atenci√≥n, curiosidad y sentido cr√≠tico.\nEspero que este libro te acompa√±e, rete y apoye en tu formaci√≥n como profesional en ciencias de datos o √°reas relacionadas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#fen√≥meno-aleatorio-y-variable-observada",
    "href": "index.html#fen√≥meno-aleatorio-y-variable-observada",
    "title": "Inferencia Estad√≠stica",
    "section": "\n2.1 Fen√≥meno aleatorio y variable observada",
    "text": "2.1 Fen√≥meno aleatorio y variable observada\n‚ÄúSe observa una realizaci√≥n de un fen√≥meno aleatorio, digamos X. Este puede ser un elemento aleatorio de varios tipos: n√∫mero (variable aleatoria), un vector de dimensi√≥n finita (vector aleatorio), una funci√≥n, etc.\nLa premisa principal es que el car√°cter aleatorio de X se concibe como una realizaci√≥n de un fen√≥meno aleatorio que tiene una distribuci√≥n de probabilidad P, donde la distribuci√≥n P es desconocida ya sea en su totalidad o en alg√∫n detalle espec√≠fico (por ejemplo, su soporte, su media, etc.). Es de inter√©s conocer P. Si la medida de probabilidad P fuese conocida, entonces no hay problema estad√≠stico propiamente, pues el problema estad√≠stico tiene que ver con inferir la propiedad desconocida de P con base en X.‚Äù [Ver referencia 1]\n\n\nDefinici√≥n de X\n\n\nX puede ser un valor real \\(X \\in \\mathbb{R}\\), un vector en \\(\\mathbb{R}^n\\), o incluso una funci√≥n \\(\\;X: [0,1]\\to\\mathbb{R}\\).\n\n\n\n\nMedida de probabilidad P\n\nDesconocida: soporte, media, varianza, etc.\n\nObjetivo estad√≠stico: inferir caracter√≠sticas de (P) a partir de la muestra (la realizaci√≥n de X).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#incertidumbre-inductiva-vs.-estoc√°stica",
    "href": "index.html#incertidumbre-inductiva-vs.-estoc√°stica",
    "title": "Inferencia Estad√≠stica",
    "section": "\n2.2 Incertidumbre inductiva vs.¬†estoc√°stica",
    "text": "2.2 Incertidumbre inductiva vs.¬†estoc√°stica\n‚ÄúLa observaci√≥n X est√° dada, por lo que no hay incertidumbre tal como la hay en la teor√≠a de probabilidad desarrollada anteriormente en el curso. Antes, fue concebida una estructura \\((\\Omega, \\mathcal{F}, P)\\) para enfrentar el que haya incertidumbre acerca del valor de X. En el problema estad√≠stico, el valor de X ha sido observado, y la incertidumbre radica en otro punto: radica en que existe duda acerca de cu√°l P es la que produjo el valor X. En algunas ocasiones se utilizan los t√©rminos incertidumbre estoc√°stica e incertidumbre inductiva para distinguir estos dos tipos. Es com√∫n que estos se confundan entre s√≠, porque en estad√≠stica matem√°tica la teor√≠a de probabilidad constituye tambi√©n una de las maneras naturales de afrontar la cuantificaci√≥n de incertidumbre inductiva. En cualquier caso, el concebir a P como medida de probabilidad es la base para formular soluciones a la incertidumbre inductiva. Con este lenguaje, probabilidad y estad√≠stica son problemas diferentes y de cierta manera inversos. Teor√≠a de probabilidad tiene que ver con cuantificar incertidumbre acerca de X y teor√≠a estad√≠stica con cuantificar incertidumbre acerca de P a la luz de haber ya observado X.‚Äù[Ver referencia 1]\n\n\nIncertidumbre estoc√°stica: duda previa sobre el valor de X, modelada por \\((\\Omega,\\mathcal{F},P)\\).\n\n\nIncertidumbre inductiva: tras observar X, la incertidumbre se desplaza a la ley generadora P.\n\n\n\n2.2.0.1 Ejemplos en Matem√°tica Aplicada e Ingenier√≠a de Sistemas\n\n\nModelado de tiempos de respuesta en redes\n\n\n\\(X\\): tiempo de llegada de paquetes (variable continua).\n\n\n\\(P\\): distribuci√≥n de retardo desconocida; objetivo: estimar par√°metros de una ley de colas M/M/1.\n\n\n\nEstimaci√≥n de par√°metros en ecuaciones diferenciales estoc√°sticas\n\n\n\\(X(t)\\): trayectoria observada de un proceso de It√¥.\n\n\n\\(P\\): ley del proceso (por ejemplo, coeficientes de difusi√≥n y deriva), inferidos a partir de trayectorias discretas.\n\n\n\nCalibraci√≥n de sensores en sistemas de control\n\n\n\\(X\\): lecturas del sensor (vector aleatorio).\n\n\n\\(P\\): distribuci√≥n conjunta desconocida de ruido; se estima para dise√±ar filtros de Kalman √≥ptimos.\n\n\n\n\nCon esta distinci√≥n clara entre dato observado y modelo probabil√≠stico, estamos listos para construir estimadores y desarrollar la inferencia estad√≠stica en las secciones siguientes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#variables-y-vectores-aleatorios",
    "href": "index.html#variables-y-vectores-aleatorios",
    "title": "Inferencia Estad√≠stica",
    "section": "\n3.1 Variables y vectores aleatorios",
    "text": "3.1 Variables y vectores aleatorios\nConsideramos un experimento aleatorio cuyos resultados pertenecen al espacio muestral Œ©. Modelamos este proceso suponiendo que existe una terna \\((\\Omega, \\mathcal{A}, P),\\) donde:\n\n\n\\(\\Omega\\) es el espacio muestra,\n\n\n\\(\\mathcal{P}(\\Omega)\\) es el conjunto de partes de Œ©,\n\n\n\\(\\mathcal{A}\\in\\mathcal{P}(\\Omega)\\) es una œÉ-√°lgebra,\n\n\n\\(P\\colon \\mathcal{A} \\to [0,1]\\) es una medida de probabilidad que refleja las caracter√≠sticas aleatorias del experimento realizado.\n\nA esta terna se le llama espacio de probabilidad.\nLos resultados de un experimento aleatorio no son analizados ‚Äúen bruto‚Äù, sino que se les da una representaci√≥n num√©rica que facilita su tratamiento. Esto se logra introduciendo variables aleatorias, que asocian cada resultado \\(\\omega\\in \\Omega\\) con un valor num√©rico o vectorial, y sobre las cuales luego aplicamos t√©cnicas de inferencia estad√≠stica.\nEn todo estudio estad√≠stico partimos de un experimento aleatorio cuyo conjunto de resultados posibles se denomina espacio muestral Œ©. Para cuantificar dichos resultados definimos las siguientes estructuras:\n\nDefinition 3.1 (Variables Aleatorias) Sea \\((\\Omega,\\mathcal{A},P)\\) un espacio de probabilidad. Una variable aleatoria es una funci√≥n \\(X\\colon (\\Omega,\\mathcal{A})\\;\\longrightarrow\\; (\\mathbb{R},\\mathcal{B}),\\) tal que para todo \\(B\\in\\mathcal{B}\\) (la \\(\\sigma\\)-√°lgebra de Borel en ‚Ñù), \\(X^{-1}(B)\\;=\\;\\{\\omega\\in\\Omega : X(\\omega)\\in B\\}\\;\\in\\;\\mathcal{A}.\\)\n\nSi el espacio muestral \\(\\Omega\\) es finito o numerable, diremos que es un espacio discreto y las variables aleatorias asociadas al experimento normalmente estar√°n definidas como \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{Z}.\\)\nSi \\(\\Omega\\) es no numerable, entonces diremos que es un espacio continuo y \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{R}.\\)\n\n\nDefinition 3.2 Un vector aleatorio de dimensi√≥n \\(n\\) es \\(\\mathbf{X} = (X_1,\\dots,X_n)\\colon(\\Omega,\\mathcal{A})\\longrightarrow(\\mathbb{R}^n,\\mathcal{B}^n),\\) donde cada componente \\(X_i\\) es variable aleatoria y \\(\\mathcal{B}^n\\) la \\(\\sigma\\)-√°lgebra de Borel en ‚Ñù‚Åø.\n\n\nEjemplos Lanzamiento de dos monedas\nSea \\(\\Omega =\\{\\,CC,\\;C-,\\;-C,\\;--\\},\\) donde \\(C\\) = ‚Äúcara‚Äù y \\(-\\) = ‚Äúcruz‚Äù. Podemos definir:\\(X_1(\\omega) = \\text{n√∫mero de caras en }\\omega.\\) \\(X_2(\\omega) = 2 - X_1(\\omega)\\;=\\; \\text{n√∫mero de cruces}.\\) \\(X_3(\\omega) = \\bigl(X_1(\\omega)\\bigr)^2.\\)\nEntonces \\((X_1,X_2,X_3)\\) es un vector aleatorio de dimensi√≥n 3.\nTiempos de servicio en un servidor\nSean \\(T_i\\) los tiempos de servicio (en segundos) de las peticiones \\(i=1,2,3\\). Definimos\\(\\mathbf{T}=(T_1,T_2,T_3),\\quad S = T_1 + T_2 + T_3,\\quad M = \\max\\{T_1,T_2,T_3\\}.\\)\nLecturas de sensores en red distribuida\nEn tres nodos \\(i=1,2,3\\) medimos temperatura \\(X_{i,1}\\), presi√≥n \\(X_{i,2}\\) y humedad \\(X_{i,3}\\). El vector global es \\(\\mathbf{X} = (X_{1,1},X_{1,2},X_{1,3},\\,X_{2,1},\\dots,X_{3,3}) \\in \\mathbb{R}^9.\\)\n\nCon estas definiciones rigurosas disponemos ya de los objetos b√°sicos para, en las siguientes secciones, construir estimadores, estudiar su comportamiento asint√≥tico y contrastar hip√≥tesis sobre la distribuci√≥n subyacente \\(P\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#distribuci√≥n-de-una-variable-aleatoria.-funciones-de-distribuci√≥n-de-probabilidad-y-de-densidad",
    "href": "index.html#distribuci√≥n-de-una-variable-aleatoria.-funciones-de-distribuci√≥n-de-probabilidad-y-de-densidad",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.5 Distribuci√≥n de una variable aleatoria. Funciones de distribuci√≥n, de probabilidad y de densidad",
    "text": "1.5 Distribuci√≥n de una variable aleatoria. Funciones de distribuci√≥n, de probabilidad y de densidad\nDistribuci√≥n de una Variable Aleatoria\nLa realizaci√≥n de un experimento aleatorio da lugar a un resultado \\(\\omega\\in\\Omega\\) que es aleatorio. Por lo tanto, \\(X(\\omega)\\) es un valor de \\(\\mathbb{R}\\) tambi√©n aleatorio. Es decir, la variable aleatoria \\(X\\) induce una medida de probabilidad en \\(\\mathbb{R}\\). A esa medida de probabilidad se le llama distribuci√≥n de \\(X\\) o ley de \\(X\\). Una de las formas de caracterizar la distribuci√≥n de una variable aleatoria es dar su funci√≥n de distribuci√≥n \\(F_X\\), que est√° definida as√≠:\n\\(F_X(x) \\;=\\; P(X \\le x)\\;=\\; P\\bigl(\\{\\omega \\in \\Omega : X(\\omega) \\le x\\}\\bigr)\\;=\\; P\\bigl(X^{-1}((-\\infty, x])\\bigr).\\)$\nEn el caso de que \\(X\\) sea una variable aleatoria discreta, es decir, en el caso de que \\(X\\) solo tome una cantidad finita o numerable de valores de \\(\\mathbb{R}\\), su distribuci√≥n tambi√©n puede caracterizarse por su funci√≥n de probabilidad (o funci√≥n de masa de probabilidad) \\(f_X\\), definida como\n\\[f_X : \\mathbb{R} \\longrightarrow [0,1],\\qquad f_X(x) = P(X = x).\\]\nEsa funci√≥n solo es no nula en un conjunto finito o numerable. Supondremos en adelante, sin p√©rdida de generalidad, que ese conjunto est√° contenido en \\(\\mathbb{Z}\\). A partir de la funci√≥n de masa de probabilidad se puede calcular la probabilidad de que la variable aleatoria \\(X\\) tome valores en cualquier elemento \\(A \\subseteq \\mathbb{B}\\):\n\\(P(X \\in A) = \\sum_{x \\in A} f_X(x).\\) me\nLa funci√≥n de distribuci√≥n y la funci√≥n de masa de probabilidad se relacionan de la siguiente forma:\n\\(F_X(x) = \\sum_{u \\leq x} f_X(u), \\quad f_X(x) = F_X(x) - F_X(x^-),\\) donde \\(F_X(x^-) = \\lim_{h \\to 0^+} F_X(x - h)\\).\nUna clase relevante de variables aleatorias no discretas son las que poseen funci√≥n de densidad, es decir, aquellas cuya distribuci√≥n de probabilidad puede caracterizarse por una funci√≥n \\(f_X(x) \\geq 0\\) que cumple que:\n\\(P(X \\in A) = \\int_{x \\in A} f_X(x) \\, dx, \\quad \\text{para todo } A \\subseteq \\mathbb{B}.\\)\nLa relaci√≥n entre \\(F_X\\) y \\(f_X\\) es la siguiente:\n\\(F_X(x) = \\int_{-\\infty}^{x} f_X(u) \\, du, \\quad f_X(x) = \\frac{d}{dx} F_X(x),\\)\nsalvo quiz√°s en un n√∫mero finito de puntos \\(x \\in \\mathbb{R}\\). Las variables aleatorias que poseen funci√≥n de densidad se llaman variables aleatorias absolutamente continuas. Abusando del lenguaje, aqu√≠ nos referiremos a ellas como variables aleatorias continuas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#esperanza-y-varianza",
    "href": "index.html#esperanza-y-varianza",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.6 Esperanza y varianza",
    "text": "1.6 Esperanza y varianza\nSi se desea describir totalmente la distribuci√≥n de probabilidad de una variable aleatoria \\(X\\) acabamos de ver que podemos dar su funci√≥n de distribuci√≥n o su funci√≥n de masa o de densidad, seg√∫n el caso. Una descripci√≥n parcial puede efectuarse calculando algunas caracter√≠sticas de la variable aleatoria \\(X\\), como por ejemplo medidas de posici√≥n o de dispersi√≥n. Estudiaremos algunas de ellas.\nSe define la esperanza de una variable aleatoria \\(X\\) como la integral de Lebesgue de \\(X\\):\n\\(E(X) = \\int_{\\Omega} X(w) dP(w).\\)\nEn el caso de variables aleatorias discretas la esperanza puede calcularse como:\n\\(E(X) = \\sum_{w \\in \\Omega} X(w) P(w) = \\sum_{k \\in \\mathbb{Z}} k P(X = k) = \\sum_{k \\in \\mathbb{Z}} k f_X(k).\\)\nPor otro lado, la esperanza de una variable aleatoria continua se puede calcular as√≠:\n\\(E(X) = \\int_{\\mathbb{R}} x f_X(x) dx.\\)\nLa esperanza de una variable aleatoria \\(X\\) es una medida de posici√≥n de \\(X\\): es el centro de gravedad de la distribuci√≥n de probabilidad de \\(X\\).\nSi \\(h\\) es una funci√≥n medible \\(h : \\mathbb{R} \\rightarrow \\mathbb{R}\\), entonces \\(Y = h(X)\\) es tambi√©n variable aleatoria y su esperanza se puede calcular a partir de la distribuci√≥n de \\(X\\):\n\\(E(h(X)) = \\int_{\\Omega} h(X(w)) dP(w)\\) que en el caso de que \\(X\\) sea discreta puede reescribirse como\n\\(E(h(X)) = \\sum_{k \\in \\mathbb{Z}} h(k) f_X(k).\\)\nSi \\(X\\) es una variable aleatoria continua entonces\n\\(E(h(X)) = \\int_{\\mathbb{R}} h(x) f_X(x) dx.\\)\nSi existe \\(\\mu = E(X)\\) y es finita puede definirse una medida de dispersi√≥n de la variable aleatoria \\(X\\) a partir de una transformaci√≥n \\(h\\) de \\(X\\). Es lo que se denomina varianza de \\(X\\) y se define as√≠:\n\\(V(X) = E((X - \\mu)^2) = E(X^2) - \\mu^2 = E(X^2) - (E(X))^2.\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#funci√≥n-generadora-de-momentos",
    "href": "index.html#funci√≥n-generadora-de-momentos",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.7 Funci√≥n generadora de momentos",
    "text": "1.7 Funci√≥n generadora de momentos\nDada una variable aleatoria \\(X\\), o su funci√≥n de distribuci√≥n \\(F\\), vamos a definir otra funci√≥n generadora, como\n\\(M_X(t) = \\mathbb{E}(e^{tX}),\\) siempre que este valor esperado exista.\nNotemos que cuando \\(X\\) toma valores en los enteros no-negativos, \\(M_X(t) = \\phi_X(e^t)\\), donde \\(\\phi_X(s)=E[s^X]=\\sum_{k=0}^{\\infty}p_ks^k\\) para \\(s\\in[0,1]\\) es la funci√≥n generadora de probabilidad (f.g.p.) de la variable \\(X\\), con \\(p_k=P(X=k)\\). Si \\(X\\) est√° acotada, \\(M_X\\) est√° bien definida para todo \\(t\\) real; en cambio, si \\(X\\) no est√° acotada, es posible que el dominio de \\(M_X\\) no sea el conjunto de todos los reales. En todo caso, \\(\\phi\\) siempre est√° definida en cero, y \\(M(0) = 1\\).\nEs posible demostrar que si la f.g.m. de la v.a. \\(X\\) existe en un entorno de 0, entonces para todo \\(k &gt; 0\\),\n\\(\\mathbb{E}[|X|^k] &lt; \\infty.\\)\nM√°s a√∫n, la serie\n\\(M_X(t) =\n\\mathbb{E}(e^{tX})\n= \\mathbb{E}\\left(1 + \\sum_{k=1}^{\\infty} \\frac{t^k X^k}{k!}\\right)\n= 1 + \\sum_{n=1}^{\\infty} \\frac{t^k}{k!} \\mathbb{E}(X^k)\n\\tag{5.1}\\)\nes convergente y se puede derivar t√©rmino a t√©rmino. Obtenemos\n\\(M'_X(0) = \\mathbb{E}(X); \\quad M''_X(0) = \\mathbb{E}(X^2)\\)\ny en general\n\\(M_X^{(k)}(0) = \\mathbb{E}(X^k).\\)\nEs por esta √∫ltima propiedad que esta funci√≥n se conoce como funci√≥n generadora de momentos (f.g.m.).\nüé≤ Ejemplo: f.g.m. de la distribuci√≥n Binomial\nSea \\(X \\sim \\text{Binomial}(n, p)\\), es decir, la suma de \\(n\\) ensayos de Bernoulli con probabilidad de √©xito \\(p\\). La funci√≥n generadora de momentos es: Ejemplo fgm binomial\n\\(M_X(t) = \\mathbb{E}[e^{tX}] = (1 - p + p e^t)^n\\)\n ```` \nüìà Ejemplo: f.g.m. de la distribuci√≥n Normal Est√°ndar\nSea \\(X \\sim \\mathcal{N}(0, 1)\\). Su funci√≥n generadora de momentos es:\n\\(M_X(t) = \\mathbb{E}[e^{tX}] = e^{\\frac{t^2}{2}}\\)\nEsta expresi√≥n se obtiene usando la forma cerrada del momento de una normal est√°ndar.\n ```` \n‚ùì Preguntas gu√≠a sobre la gr√°fica de la funci√≥n generadora de momentos\nüìå ¬øQu√© representa la gr√°fica de la f.g.m. \\(M_X(t)\\)?\nLa gr√°fica muestra c√≥mo evoluciona el valor esperado de \\(e^{tX}\\) cuando \\(t\\) var√≠a. Esta funci√≥n codifica todos los momentos de la variable aleatoria \\(X\\), y por tanto, contiene informaci√≥n completa sobre su distribuci√≥n (si existe un entorno donde la f.g.m. es finita).\n\nüß≠ ¬øQu√© se observa en la f.g.m. de una distribuci√≥n Binomial? \n![Gr√°fica MGF Binomial]\n#Preguntas y respuestas\n\n\n¬øC√≥mo es el comportamiento de la f.g.m. cerca de \\(t = 0\\)?\nEn \\(t = 0\\), siempre se cumple que \\(M_X(0) = 1\\), ya que:\n\\(M_X(0) = \\mathbb{E}[e^{0 \\cdot X}] = \\mathbb{E}[1] = 1\\)\n\n\n¬øQu√© indica la curvatura de la gr√°fica?\nLa curvatura refleja el crecimiento exponencial de los momentos. Si la curva crece r√°pidamente hacia la derecha, significa que los momentos (media, varianza, etc.) tambi√©n crecen con rapidez.\n\n\n¬øPor qu√© la gr√°fica es convexa?\nTodas las funciones generadoras de momentos son estrictamente convexas en el intervalo donde est√°n definidas. Esto es una consecuencia de que derivadas sucesivas representan momentos positivos.\n\n\n¬øQu√© pasa si cambio los par√°metros \\(n\\) y \\(p\\)?\nAumentar $ n $ o \\(p\\) tiende a elevar la f.g.m. en el lado derecho, reflejando una mayor media y varianza.\n\n\n\nüìà ¬øC√≥mo se comporta la f.g.m. para la Normal Est√°ndar? \n![Gr√°fica MGF Normal]\nPreguntas y respuestas\n\n\n¬øPor qu√© es sim√©trica respecto al eje $ t = 0 $?\nPorque la normal est√°ndar es sim√©trica alrededor de su media $ = 0 $, y su f.g.m. tiene la forma:\n\n\n\\(M_X(t) = e^{t^2 / 2}\\)\nlo cual es una funci√≥n par: \\(M_X(-t)= M_X(t)\\).\n\n\n¬øQu√© tan r√°pido crece la funci√≥n?\nMuy r√°pido. El crecimiento es exponencial cuadr√°tico. Esto implica que los momentos de la normal crecen r√°pidamente en magnitud.\n\n\n¬øC√≥mo se relaciona esta gr√°fica con los momentos de la normal?\nDerivando sucesivamente la f.g.m. en $ t = 0 $, se obtiene:\n\\(\\mathbb{E}[X^k] = M_X^{(k)}(0)\\)\nPor tanto, la gr√°fica ‚Äúencierra‚Äù toda la informaci√≥n sobre los momentos.\n\n\n\nüß† Conclusi√≥n\nEstas gr√°ficas te permiten visualizar la informaci√≥n estad√≠stica codificada en una variable aleatoria. La f.g.m. no es solo una herramienta algebraica para obtener momentos, sino una forma poderosa de describir el comportamiento global de la variable.\n\n¬øQu√© pasa si dos variables tienen la misma f.g.m.?\n¬°Tienen la misma distribuci√≥n! (si la f.g.m. est√° definida en un entorno de 0).\n\nEjemplo: Distribuci√≥n uniforme \\(U(a,b)\\)\nSi \\[X \\sim U(a,b),\\]\nsu densidad es\\[f(x) = \\frac{1}{b - a}\\quad\\text{para }a &lt; x &lt; b,\\]\ny su funci√≥n generadora de momentos viene dada por\n\n\n\n\\[M(t)= \\int_a^b \\frac{e^{t x}}{b - a}\\,dx= \\frac{e^{b t} - e^{a t}}{t\\,(b - a)}.\\]\n\n\n(5.2)\n\n\nEn el caso particular de la distribuci√≥n uniforme en \\((0,1)\\) se obtiene\\[M(t) = \\frac{e^t - 1}{t}.\\]\n\nPara derivar la f√≥rmula #(5.2) y obtener los momentos, podemos usar el desarrollo en serie de la funci√≥n exponencial:\n\\[\n\\begin{align}\nM(t)&= \\frac{1}{t\\,(b - a)}\\bigl(e^{b t} - e^{a t}\\bigr) \\\\\n&= \\frac{1}{t\\,(b - a)}\\Bigl[\\bigl(1 + \\sum_{n=1}^\\infty \\tfrac{(b t)^n}{n!}\\bigr)\n                    -\\bigl(1 + \\sum_{n=1}^\\infty \\tfrac{(a t)^n}{n!}\\bigr)\\Bigr] \\\\\n&= \\frac{1}{b - a}\\sum_{n=1}^\\infty \\frac{b^n - a^n}{n!}\\,t^{n-1}.\n\\end{align}\n\\]\nEste es el desarrollo de Maclaurin de \\(M(t)\\) en \\(t=0\\); por tanto, sus derivadas en cero satisfacen\n\n\n\\[M^{(k)}(0)= \\frac{b^{k+1} - a^{k+1}}{(k+1)\\,(b - a)}.\\]\n\n\n(5.3)\n\n\nEn particular:\n\n\\[M'(0)= \\frac{b^2 - a^2}{2\\,(b - a)}= \\frac{a + b}{2},\\] que coincide con \\(\\mathbb{E}(X)\\).\n\\[M''(0)= \\frac{b^3 - a^3}{3\\,(b - a)}= \\frac{a^2 + a b + b^2}{3},\\]\n\ny un c√°lculo directo muestra que la varianza es\n\\[\\mathrm{Var}(X)= \\mathbb{E}(X^2) - \\bigl(\\mathbb{E}(X)\\bigr)^2= \\frac{(a + b)^2}{12}.\\]\nObservaci√≥n importante Sea \\(X\\) una v.a. con f.g.m. \\(M_X\\) y sea \\(Y=aX+b\\) una transformaci√≥n lineal de \\(X\\), entonces\n\\[M_Y(t)=E(e^{tY})=E(e^{t(aX+b)})=E(e^{taX}e^{tb})=e^{tb}E(e^{taX})=e^{tb}M_X(at)\\]\n\nTheorem 1.1 (fgm de suma de v.a.s) Si \\(X\\) tiene funci√≥n generadora de momentos \\(M(t)\\) que est√° definida en un entorno \\((-a,a)\\) de 0, entonces \\(M(t)\\) caracteriza a la distribuci√≥n de \\(X\\); es decir, si otra variable \\(Y\\) tiene la misma funci√≥n generadora de momentos, las distribuciones de \\(X\\) e \\(Y\\) coinciden.\n\n\nSi \\(X,Y\\) son variables aleatorias con funciones generadoras de momentos respectivas \\(M_X\\) y \\(M_Y\\) que existen en un dominio com√∫n \\(|t| &lt; d\\), entonces la f.g.m. de la suma \\(X+Y\\) est√° dada por     \\[\n\\begin{align}\nM_{X+Y}(t)&= \\mathbb{E}\\bigl[e^{t(X+Y)}\\bigr]\\\\\n&= \\mathbb{E}\\bigl[e^{tX}\\,e^{tY}\\bigr]\\\\\n&=\\mathbb{E}\\bigl[e^{tX}\\bigr]\\mathbb{E}\\bigl[e^{tY}\\bigr]\\\\\n&= M_X(t)\\,M_Y(t).\n\\end{align}\n\\tag{1}\n\\]      \nEste resultado se extiende a la suma de \\(n\\) variables aleatorias independientes. Si\n\\[S_n = X_1 + \\cdots + X_n,\\]\nentonces\n\\[M_{S_n}(t)= \\mathbb{E}\\bigl[e^{tS_n}\\bigr]= \\mathbb{E}\\Bigl[e^{t\\sum_{i=1}^n X_i}\\Bigr]= \\prod_{i=1}^n\\mathbb{E}\\bigl[e^{tX_i}\\bigr]= \\prod_{i=1}^n M_{X_i}(t).\\]\nLa funci√≥n generadora de momentos resulta particularmente √∫til cuando consideramos sucesiones de variables aleatorias, como lo muestra el siguiente teorema que enunciamos sin demostraci√≥n:\n\n\nTheorem 1.2 (de Continuidad) Sea \\(F_n(x)\\), \\(n\\ge1\\), una sucesi√≥n de funciones de distribuci√≥n con funciones generadoras de momentos respectivas \\(M_n(t)\\), definidas en \\(|t|&lt;b\\). Supongamos que cuando \\(n\\to\\infty\\),\n\\[\nM_n(t)\\,\\longrightarrow\\,M(t)\n\\quad\\text{para }|t|\\le a,\n\\]\ndonde \\(M(t)\\) es la funci√≥n generadora de momentos de la distribuci√≥n l√≠mite \\(F(x)\\). Entonces\n\\[\nF_n(x)\\,\\longrightarrow\\,F(x)\n\\quad\\text{cuando }n\\to\\infty\n\\]\npara todo punto \\(x\\) en el cual \\(F\\) es continua.\n\n\nTheorem 1.3 Laplace‚ÄìMoivre Sea \\(X_1, X_2, \\ldots, X_n\\) una sucesi√≥n de variables aleatorias i.i.d. con distribuci√≥n ( (p) ), donde ( 0 &lt; p &lt; 1 ). Sea:\n\\[\nS_n = X_1 + X_2 + \\cdots + X_n \\sim \\text{Binomial}(n, p)\n\\]\ny consideremos la variable tipificada:\n\\[\nZ_n = \\frac{S_n - np}{\\sqrt{np(1 - p)}}\n\\]\nEntonces, cuando ( n ), se tiene convergencia en distribuci√≥n a una normal est√°ndar:\n\\[\nZ_n \\xrightarrow{d} \\mathcal{N}(0, 1)\n\\]\nes decir,\n\\[\n\\lim_{n \\to \\infty} \\mathbb{P}(Z_n \\leq z) = \\Phi(z), \\quad \\text{para todo } z \\in \\mathbb{R}\n\\]\ndonde ( (z) ) es la funci√≥n de distribuci√≥n acumulada de la normal est√°ndar.\n\n\nProof. Demostraci√≥n usando funciones generadoras de momentos\nLa funci√≥n generadora de momentos (mgf) de \\(S_n \\sim \\text{Binomial}(n, p)\\) es:\n\\[\nM_{S_n}(t) = \\left(1 - p + p e^t\\right)^n\n\\]\nQueremos obtener la mgf de la variable tipificada ( Z_n ). Usamos la propiedad de cambio de variable de la mgf:\n\\[\nM_{Z_n}(t) = \\mathbb{E}\\left[ e^{t Z_n} \\right]\n= \\mathbb{E}\\left[ e^{t \\cdot \\frac{S_n - np}{\\sqrt{np(1 - p)}}} \\right]\n= e^{-t \\cdot \\frac{np}{\\sqrt{np(1 - p)}}} \\cdot M_{S_n}\\left( \\frac{t}{\\sqrt{np(1 - p)}} \\right)\n\\]\nSustituimos la mgf de ( S_n ):\n\\[\nM_{Z_n}(t) = \\exp\\left( -t \\cdot \\frac{np}{\\sqrt{np(1 - p)}} \\right)\n\\cdot \\left( 1 - p + p e^{t / \\sqrt{np(1 - p)}} \\right)^n\n\\]\nAproximaci√≥n por series de Taylor\nExpandimos \\(e^{t / \\sqrt{np(1 - p)}}\\) para \\(n\\) grande:\n\\[\ne^{t / \\sqrt{np(1 - p)}} = 1 + \\frac{t}{\\sqrt{np(1 - p)}} + \\frac{t^2}{2np(1 - p)} + \\cdots\n\\]\nEntonces:\n\\[\n1 - p + p e^{t / \\sqrt{np(1 - p)}} \\approx 1 + \\frac{pt}{\\sqrt{np(1 - p)}} + \\frac{pt^2}{2np(1 - p)} + \\cdots\n\\]\nUsamos que \\(\\log(1 + x) \\approx x - \\frac{x^2}{2} + \\cdots\\) para \\(x \\approx 0\\):\n\\[\\log M_{Z_n}(t) \\approx -t \\cdot \\frac{np}{\\sqrt{np(1 - p)}}+ n \\left( \\frac{pt}{\\sqrt{np(1 - p)}} + \\frac{pt^2}{2np(1 - p)} \\right)\\]\nSimplificamos:\n\nEl t√©rmino lineal se cancela:\n\n\\[\n-t \\cdot \\frac{np}{\\sqrt{np(1 - p)}} + n \\cdot \\frac{pt}{\\sqrt{np(1 - p)}} = 0\n\\]\n\nQueda:\n\n\\[\n\\log M_{Z_n}(t) \\to \\frac{t^2}{2}, \\quad \\text{cuando } n \\to \\infty\n\\]\nPor tanto:\n\\[\nM_{Z_n}(t) \\to e^{t^2 / 2}\n\\] Conclusi√≥n\nComo \\(e^{t^2/2}\\) es la mgf de \\(\\mathcal{N}(0, 1)\\), y por el teorema de unicidad de la funci√≥n generadora de momentos:\n\\[\nZ_n \\xrightarrow{d} \\mathcal{N}(0, 1)\n\\]\nEsto concluye la demostraci√≥n del Teorema de Laplace‚ÄìMoivre utilizando funciones generadoras de momentos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#muestra-aleatoria-simple",
    "href": "index.html#muestra-aleatoria-simple",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.8 Muestra aleatoria simple",
    "text": "1.8 Muestra aleatoria simple\nSea \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) un vector aleatorio. Se dice que sus componentes \\(X_1 ,..., X_n\\) son si \\(P(X_1\\leq x_1 ,..., X_n\\leq x_n)=P(X_1\\leq x_1)...P(X_n\\leq x_n)\\) para cualesquiera valores \\(x_1,..., x_n\\) .\nSi adem√°s la distribuci√≥n de las \\(n\\) variables aleatorias \\(X_i\\) es la misma, se dice que \\(X_1 ,...,X_n\\) son variables aleatorias independientes e id√©nticamente distribuidas, o bien que son v.a.i.i.d o simplemente i.i.d.\nSi \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) y \\(X_1 ,..., X_n\\) son i.i.d. con funci√≥n de densidad (en su caso, de masa) \\(f_X\\) , la distribuci√≥n conjunta de \\(\\underset{\\sim}{X}\\) viene dada por la funci√≥n de densidad (en su caso, de masa) conjunta \\[\n\\begin{align*}\nf_{\\underset{\\sim}{X}}(\\underset{\\sim}{x})&=f_{(X_1 ,..., X_n)}(x_1 ,..., x_n)\\\\\n&=f_{(X_1)}(x_1)...f_{(X_n)}(x_n)\\\\\n&=\\prod_{i=1}^{n}f_{(X_i)}(x_i)\n\\end{align*}\n\\]\nA un vector \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) de v.a.i.i.d. con distribuci√≥n igual a la de la variable aleatoria \\(X\\) se le denomina tambi√©n muestra aleatoria simple de \\(X\\) (m.a.s de \\(X\\)).\nEsto responde al hecho siguiente. Supongamos que se desea estudiar la caracter√≠stica \\(X\\) de los individuos de una poblaci√≥n de tama√±o infinito. Definimos el experimento consistente en elegir aleatoriamente un individuo de la poblaci√≥n y llamamos \\(X\\) al valor de la caracter√≠stica de inter√©s en ese individuo. X es una variable aleatoria.\nSi definimos un nuevo experimento consistente en elegir una muestra aleatoria de n individuos y se anota \\(X_i\\), el valor de la caracter√≠stica en el individuo i-√©simo, entonces X \\(=(X_1 ,..., X_n)\\) es una colecci√≥n de n v.a.i.i.d. con distribuci√≥n igual a la de la variable aleatoria \\(X\\), es decir, \\(X_1 ,..., X_n\\) es una m.a.s. de X.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#modelo-param√©trico",
    "href": "index.html#modelo-param√©trico",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.9 Modelo param√©trico",
    "text": "1.9 Modelo param√©trico\nUsualmente la ley de probabilidad de una variable aleatoria se supone perteneciente a un modelo matem√°tico que depende s√≥lo de un n√∫mero finito de par√°metros: \\(f_X \\in\\{f(x|\\theta):\\theta \\in \\Theta \\subseteq \\mathbb{R}^k\\}\\). Escribiremos alternativamente \\(f(x;\\theta)\\), \\(f(x|\\theta)\\) o \\(f_\\theta(x)\\).\n\nDefinition 1.3 El conjunto de distribuciones dadas por \\(f_\\theta(x)\\), \\(\\theta \\in \\Theta\\) se llama familia param√©trica de distribuciones. \\(\\Theta\\) es el conjunto de par√°metros.\n\n\nDefinition 1.4 La correspondiente distribuci√≥n conjunta de una muestra aleatoria simple de \\(X\\) viene dada por la funci√≥n de densidad (o funci√≥n de masa de probabilidad, seg√∫n el caso)\n\\[\nf_{\\underset{\\sim}{X}}(\\underset{\\sim}{x} \\mid \\theta) = \\prod_{i=1}^{n} f_{\\theta}(x_i)\n\\]\nA esta funci√≥n la llamaremos funci√≥n de verosimilitud de la muestra \\(X_{\\sim}\\). Utilizaremos este t√©rmino para referirnos indistintamente a la funci√≥n de densidad conjunta (si las variables aleatorias son continuas) o a la funci√≥n de masa conjunta (si son discretas).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#sumas-de-variables-aleatorias",
    "href": "index.html#sumas-de-variables-aleatorias",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.10 Sumas de variables aleatorias",
    "text": "1.10 Sumas de variables aleatorias\nCuando se obtiene una muestra aleatoria simple \\(X_{1},X_{2},\\ldots,X_{n}\\) normalmente se calculan a partir de ellas cantidades que resumen los valores observados. Cualquiera de estos res√∫menes se puede expresar como una funci√≥n \\(T(x_1,\\ldots,x_n)\\) definida en el espacio \\(\\mathcal{X}^n\\subseteq\\mathbb{R}^n\\) donde est√°n las im√°genes del vector \\((X_{1},X_{2},\\ldots,X_{n})\\).\nEsta funci√≥n \\(T\\) puede devolver valores de \\(\\mathbb{R}\\), \\(\\mathbb{R}^2\\) o, en general, \\(\\mathbb{R}^k\\).\n\\[T(X_1 , \\ldots, X_n)=\\sum_{i=1}^{n}X_i,\\bar{X},\\bar{X}+3, \\min{X_1 , \\ldots, X_n},\\] \\[T(X_1 , \\ldots, X_n)=\\left(\\sum_{i=1}^{n}X_i,\\sum_{i=1}^{n}(X_i-\\bar{X})^2\\right),\\] \\[T(X_1 , \\ldots, X_n)=\\left(\\min\\{X_1 , \\ldots, X_n\\},\\sum_{i=1}^{n}X_i,\\sum_{i=1}^{n}(X_i-\\bar{X})^2\\right),\\] \\[T(X_1 , \\ldots, X_n)= (X_1 , \\ldots, X_n)\\]\n\nDefinition 1.5 (Definici√≥n de estad√≠sticos) Las funciones \\(T\\) que dependen de una muestra aleatoria simple \\(X_1 , \\ldots, X_n\\) se llaman estad√≠sticos. Dependen de los valores observados, pero no de los par√°metros desconocidos que determinan la distribuci√≥n de \\(X_i\\) .\n\nCuando un estad√≠stico \\(T\\) es utilizado con el prop√≥sito de estimar un par√°metro \\(\\theta\\) diremos que \\(T\\) es un estimador de \\(\\theta\\).\nEjemplo de estad√≠stico\n\\(T(X_1 , \\ldots, X_n)=\\bar{X}\\) es un estimador de \\(E(X)=\\mu\\).\nEn inferencia estad√≠stica interesa saber qu√© estad√≠sticos son suficientes para recoger toda la informaci√≥n que la muestra aporta sobre la distribuci√≥n de la variable aleatoria X muestreada. La respuesta depende de la distribuci√≥n de X.\n\nDefinition 1.6 (Definici√≥n distribuci√≥n en el muestreo) Dado que \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) es una variable aleatoria, se tiene que \\(Y=T(\\underset{\\sim}{X})=T(X_1 ,..., X_n)\\) ser√° tambi√©n una variable aleatoria. La ley de probabilidad de \\(Y\\) se denomina distribuci√≥n en el muestreo de \\(Y\\) (o distribuci√≥n muestral). Los siguientes resultados dan informaci√≥n sobre algunas caracter√≠sticas de estad√≠sticos definidos a partir de sumas de variables aleatorias.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#estad√≠sticos-definidos-a-partir-de-sumas-de-variables-aleatorias",
    "href": "index.html#estad√≠sticos-definidos-a-partir-de-sumas-de-variables-aleatorias",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.11 Estad√≠sticos definidos a partir de sumas de variables aleatorias",
    "text": "1.11 Estad√≠sticos definidos a partir de sumas de variables aleatorias\n\nTheorem 1.4 Sean \\(X_1,\\ldots, X_n\\),n n√∫meros reales, sea \\(\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n}x_i\\) su media aritm√©tica y sea \\(S_n^2=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n-1}\\) su varianza muestral.\n\n\\(\\min_a\\sum_{i=1}^{n}(x_i-a)^2=\\sum_{i=1}^{n}(x_i-\\bar{x})^2\\)\n\\((n-1)S_n^2=\\sum_{i=1}^{n}(x_i-\\bar{x})^2=\\sum_{i=1}^{n}x_i^2-n\\bar{x}^2\\)\n\n\n\nLemma 1.1 Sea \\(X_1,\\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) y sea \\(g(x)\\) una funci√≥n tal que \\(E(g(X))\\) y \\(Var(g(X))\\) existen. Entonces,\n\n\n\\(E(\\sum_{i=1}^{n}g(X_i))=nE(g(X))\\),\n\n\\(Var(\\sum_{i=1}^{n}g(X_i))=nVar(g(X))\\).\n\n\n\nProof. Para la demostraci√≥n ver G√≥mez et al.¬†(2006)\n\n\nTheorem 1.5 Sea \\(X 1,\\ldots, X_n\\) una muestra aleatoria simple de una poblaci√≥n \\(X\\) con esperanza \\(\\mu\\) y varianza \\(\\sigma^2 &lt; \\infty\\). Sean \\[\n        \\begin{align*}\n        &\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_i,\\ \\\n        S^2=\\frac{\\sum_{i=1}^{n}(X_i-\\bar{X})^2}{n-1},\n        \\end{align*}    \n\\] la media y la varianza muestrales, respectivamente. Entonces,\n\n\\(E(\\bar{X}) = \\mu,\\)\n\\(Var(\\bar{X}) = \\frac{\\sigma^2}{n},\\)\n\n\\(E(S^2) = \\sigma^2\\).\n\n\n\nTheorem 1.6 Sea \\(X 1,\\ldots, X_n\\) una muestra aleatoria simple de una poblaci√≥n \\(X\\) con funci√≥n generadora de momentos \\(M_X(t)\\). La funci√≥n generatriz de momentos de \\(X\\) es \\[\\begin{align*}\n        &M_{\\bar{X}}(t)=\\left(M_X\\left(\\frac{t}{n}\\right)\\right)^n\n        \\end{align*}\n\\]\n\n\nTheorem 1.7 (Combinaci√≥n lineal de normales es normal) (Wackerly et al.¬†(2008)) Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) variables aleatorias independientes normalmente distribuidas \\(E(Y_i)=\\mu_i\\) y \\(V(Y_i)=\\sigma_i^2\\)ara \\(i=1,\\cdots,\\,n\\) y sean \\(a_1,\\,a_2,\\cdots,\\,a_n\\) constantes. Si \\[U=\\sum_{i=1}^na_iY_i\\]\nentonces \\(U\\) es una variable aleatoria normalmente distribuida con \\[E(U)=\\sum_{i=1}^na_i\\mu_i\\] y \\[V(U)=\\sum_{i=1}^na_i^2\\sigma^2_i\\]\n\nEjemplo \\(X 1,\\ldots, X_n\\) m.a.s. de \\(X \\sim N(\\mu,\\sigma^2)\\). Entonces, \\(M_{X}(t)=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2}\\right\\}\\). De ah√≠ que\n\\[\n    \\begin{align*}\n    M_{\\bar{X}}(t)\n    &=\\left(\\exp\\left\\{\\mu \\frac{t}{n}+ \\frac{\\sigma^2\\left(\\frac{t}{n}\\right)^2}{2}\\right\\}\\right)^n\n    \\end{align*}\n\\]\n\\(X 1,\\ldots, X_n\\) m.a.s. de \\(X \\sim N(\\mu,\\sigma^2)\\). Entonces, \\(M_{X}(t)=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2}\\right\\}\\). De ah√≠ que \\[\n        \\begin{align*}\n        M_{\\bar{X}}(t)&=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2n}\\right\\}\n        \\end{align*}\n\\] De ah√≠ que \\(\\bar{X}\\sim N(\\mu,\\frac{\\sigma^2}{n})\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#muestreo-de-una-distribuci√≥n-normal",
    "href": "index.html#muestreo-de-una-distribuci√≥n-normal",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.12 Muestreo de una distribuci√≥n normal",
    "text": "1.12 Muestreo de una distribuci√≥n normal\n\n1.12.1 Definici√≥n de distribuci√≥n Chi cuadrada\n\nDefinition 1.7 (Wackerly et al.¬†(2008)) Sea \\(\\nu\\) un entero positivo. Se dice que una v.a \\(Y\\) tiene distribuci'on chi cuadrada con \\(\\nu\\) grados de libertad si y s√≥lo si \\(Y\\) es una vriable aleatoria con distribuci√≥n gamma y par√°metros \\(\\alpha=\\nu/2\\) y \\(\\beta=2\\).\n\n\nTheorem 1.8 (Teorema de Fisher) En el resto del tema supondremos que \\(X 1,\\ldots, X_n\\) m.a.s. de una \\(N(\\mu, \\sigma^2)\\).\n\n\n\\(\\bar{X}\\) y \\(S_n^2\\) son variables aleatorias independientes.\n\\(\\bar{X}\\sim N(\\mu, \\frac{\\sigma^2}{n})\\)\n\\(\\frac{(n-1)S_n^2}{\\sigma^2}\\sim \\mathcal{X}^2_{n-1}.\\)\n\n\n\n1.12.2 Distribuciones asociadas a la normal\n\nTheorem 1.9 (Wackerly et al.¬†(2008)) Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) definidas como en el Teorema Theorem¬†1.7 de Wackerly et al.¬†(2008) y definimos \\(Z_i\\) por \\[Z_i=\\frac{Y_i-\\mu_i}{\\sigma_i}\\] con \\(i=1,\\,2,\\cdots,\\,n\\). Entonces \\(\\sum_{i=1}^nZ_i^2\\) tiene distribuici'on \\(\\chi^2\\) con \\(n\\) grados de libertad.\n\n\nTheorem 1.10 (Wackerly et al.¬†(2008)) Si \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) es una muestra aleatoria de una distribuci'on normal con media \\(\\mu\\) y varianza \\(\\sigma^2\\), \\(Y_i\\), \\(i=1,\\,2,\\cdots,n\\) son v.a‚Äôs independientes distribu'idas normalmente, con \\(E(Y_i)=\\mu\\) y \\(V(Y_i)=\\sigma^2\\).\nEntonces \\[Z_i=\\frac{Y_i-\\mu}{\\sigma}\\] son v.a‚Äôs independientes, \\(i=1,\\,2,\\cdots,n\\) y \\[\\sum_{i=1}^nZ_i^2=\\sum_{i=1}^n\\left(\\frac{Y_i-\\mu}{\\sigma}\\right)^2\\]tienen una distribuci'on \\(\\chi^2\\) con \\(n\\) grados de libertad (gl).\n\n\nTheorem 1.11 (Wackerly et al.¬†(2008)) Sea \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) una muestra aleatoria con media \\(\\mu\\) y varianza \\(\\sigma^2\\). Entonces \\[\\frac{(n-1)S^2}{\\sigma^2}=\\frac{1}{\\sigma^2}\\sum_{i=1}^n(Y_i-\\overline{Y})^2\\] tiene una distribuci'on \\(\\chi^2\\) con \\((n-1)\\) gl. \\(\\overline{Y}\\) y \\(S^2\\) son v.a independientes.\n\n\nDefinition 1.8 (Wackerly et al.¬†(2008)) Sea \\(Z\\) una v.a normal est'andar y sea \\(W\\) una v.a con distribuci'on \\(\\chi^2_\\nu\\). Entonces, si \\(W\\) y \\(Z\\) son ind \\[T=\\frac{Z}{\\sqrt{W/\\nu}}\\] se dice que tiene una distribuci'on \\(t\\) con \\(\\nu\\) grados de libertad.\n\n\n\n\n\n\n\nObservaci√≥n 1\n\n\n\nSi \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\sim N(\\mu,\\sigma^2)\\) del Teorema (Combinaci√≥n lineal de normales es normal) \\[Z=\\frac{\\sqrt{n}(\\overline{Y}-\\mu)}{\\sigma}\\sim N(0,1)\\] El teorema Observaci√≥n 1 nos dice que \\[W=\\frac{(n-1)S^2}{\\sigma^2}\\sim\\chi^2_{n-1}\\] y que \\(Z\\) y \\(W\\) son ind.\n\n\n\n\n\n\n\n\nObservaci√≥n 2\n\n\n\nPor tanto, de la definici√≥n 7.2 se tiene la siguiente expresi√≥n: \\[\n\\begin{aligned}\nT &= \\frac{Z}{\\sqrt{W/\\nu}} \\\\\n  &= \\frac{\\sqrt{n}(\\overline{Y}-\\mu)/\\sigma}{\\sqrt{\\left[\\frac{(n-1)S^2}{\\sigma^2}\\right]/(n-1)}} \\\\\n  &= \\sqrt{n}\\left(\\frac{\\overline{Y}-\\mu}{S}\\right)\n\\end{aligned}\n\\]\nTiene distribuci√≥n \\(t\\) con \\((n-1)\\) grados de libertad.\n\n\nComo se indica en la Observaci√≥n 7.1, esta propiedad‚Ä¶\n\nDefinition 1.9 Sean \\(W_1\\) y \\(W_2\\) v.a‚Äôs independientes con distribuci√≥n \\(\\chi^2\\), con \\(\\nu_1\\) y \\(\\nu_2\\) grados de libertad respectivamente. Entonces se dice que: \\[F=\\frac{W_1/\\nu_1}{W_2/\\nu_2}\\] tiene una distribuc'on \\(F\\) con \\(\\nu_1\\) grados de libertad en el numerador y \\(\\nu_2\\) grados de libertad en el denominador.\n\n\nRemark 1.1. Considerando dos muestras aleatorias independientes tomadas de distribuiciones normales \\[W_1=\\frac{(n_1-1)S_1^2}{\\sigma_1^2}\\sim\\chi^2_{n_1-1}\\] \\[W_1=\\frac{(n_2-1)S_2^2}{\\sigma_2^2}\\sim\\chi^2_{n_2-1}\\] \\(W_1\\bot W_2\\).\n\n\nRemark 1.2. \\[\n\\begin{eqnarray*}\n            F&=&\\frac{W_1/\\nu_1}{W_2/\\nu_2}\\\\\n            &=&\\frac{[(n_1-1)S_1^2/\\sigma_1^2]/(n_1-1)}{[(n_2-1)S_2^2/\\sigma_2^2]/(n_2-1)}\\\\\n            &=&\\frac{S_1^2/\\sigma_1^2}{S_2^2/\\sigma_2^2}\n        \\end{eqnarray*}\n\\] tiene distribuci'on \\(F\\) con \\((n_1-1)\\) gl en el numerador y \\((n_2-1)\\) gl en el denominador\n\n\nlibrary(ggplot2)\n\nfigura_densidad_asimetrica &lt;- function(alpha = 0.05) {\n  shape &lt;- 2\n  rate &lt;- 1\n  \n  # Cuantil de inter√©s\n  F_alpha &lt;- qgamma(1 - alpha, shape = shape, rate = rate)\n  \n  # Datos para la densidad\n  x_vals &lt;- seq(0, 10, length.out = 1000)\n  df &lt;- data.frame(\n    x = x_vals,\n    y = dgamma(x_vals, shape = shape, rate = rate)\n  )\n  \n  # Datos para el sombreado\n  df_shaded &lt;- subset(df, x &gt;= F_alpha)\n  \n  # Altura de la flecha\n  y_arrow &lt;- dgamma(F_alpha, shape, rate)\n  \n  ggplot(df, aes(x, y)) +\n    geom_line(linewidth = 1.2) +\n    geom_area(data = df_shaded, aes(x, y), fill = \"black\", alpha = 0.3) +\n    \n    # Flecha vertical\n    annotate(\"segment\", x = F_alpha, xend = F_alpha, y = 0, yend = y_arrow,\n             arrow = arrow(length = unit(0.15, \"cm\")), color = \"black\") +\n    \n    # Etiqueta F_Œ±\n    annotate(\"text\", x = F_alpha, y = 0, label = expression(F[alpha]),\n             vjust = 1.5, hjust = 1.1, size = 5) +\n    \n    # Etiqueta Œ±\n    annotate(\"text\", x = F_alpha, y = y_arrow, label = expression(alpha),\n             vjust = -1, size = 5) +\n    \n    labs(x = \"u\", y = expression(f(u))) +\n    theme_minimal(base_size = 14)\n}\nfigura_densidad_asimetrica()\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\n\n\n\n\n\n\nEjercicios con la distribuci√≥n F en R\nA continuaci√≥n se presentan dos ejercicios t√≠picos en los que anteriormente se utilizaban tablas de valores cr√≠ticos de la distribuci√≥n F. Ahora, gracias a funciones como qf() y var.test() en R, estos an√°lisis pueden hacerse de manera precisa y autom√°tica.\n\nEjercicio 1: Contrastar dos varianzas\nEnunciado:\nSe tienen dos muestras independientes con: - Tama√±os: \\(n_1 = 6\\), \\(n_2 = 10\\) - Varianzas muestrales: \\(s_1^2 = 25\\), \\(s_2^2 = 10\\)\n¬øExiste evidencia para afirmar que las varianzas poblacionales son diferentes al nivel de significancia del 5%?\nSoluci√≥n en R:\n\n# Datos\ns1_sq &lt;- 25\ns2_sq &lt;- 10\nn1 &lt;- 6\nn2 &lt;- 10\n\n# Estad√≠stico F observado (mayor varianza sobre menor)\nF_obs &lt;- s1_sq / s2_sq\ngl1 &lt;- n1 - 1\ngl2 &lt;- n2 - 1\n\n# Cuantiles cr√≠ticos para prueba bilateral al 5%\nalpha &lt;- 0.05\nF_inf &lt;- qf(alpha / 2, df1 = gl1, df2 = gl2)\nF_sup &lt;- qf(1 - alpha / 2, df1 = gl1, df2 = gl2)\n\n# Decisi√≥n\ncat(\"F observado:\", round(F_obs, 3), \"\\n\")\n\nF observado: 2.5 \n\ncat(\"Intervalo de aceptaci√≥n: [\", round(F_inf, 3), \",\", round(F_sup, 3), \"]\\n\")\n\nIntervalo de aceptaci√≥n: [ 0.15 , 4.484 ]\n\nif (F_obs &lt; F_inf || F_obs &gt; F_sup) {\n  cat(\"Se rechaza H0: las varianzas son significativamente diferentes.\\n\")\n} else {\n  cat(\"No se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.\\n\")\n}\n\nNo se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.\n\n\nEjercicio 2: Obtener un valor cr√≠tico F directamente\nEnunciado:\nCalcular el valor cr√≠tico \\(F_{0.05,\\,5,\\,9}\\) para una prueba unilateral con nivel de significancia del 5%.\nEste valor se usa, por ejemplo, cuando se contrasta si una varianza es significativamente mayor que otra, con: - \\(\\alpha = 0.05\\) - \\(\\text{gl}_1 = 5\\) (grados de libertad del numerador) - \\(\\text{gl}_2 = 9\\) (grados de libertad del denominador)\nC√°lculo en R:\n\n# Valor cr√≠tico F para prueba unilateral con alpha = 0.05\nqf(0.95, df1 = 5, df2 = 9)\n\n[1] 3.481659\n\n\nEl valor cr√≠tico es \\(F_{0.05,\\,5,\\,9}=3.478\\). Si el estad√≠stico F observado es mayor que este valor, se rechaza la hip√≥tesis nula de igualdad de varianzas a favor de que la varianza del numerador es mayor.\n\nExample 1.1 \\[Y_1^1,\\,Y_2^1\\,\\cdots,\\,Y_{n_1}^1\\sim N(\\mu_1,\\,\\sigma^2)\\] \\[Y_1^2,\\,Y_2^2\\,\\cdots,\\,Y_{n_2}^2\\sim N(\\mu_2,\\,\\sigma^2)\\] \\(P\\left(\\frac{S_1^2}{S_2^2}\\leq b\\right)=0.95\\) con \\(n_1=6\\) y \\(n_2=10\\), ?`\\(b\\)?\nComo \\(n_1=6\\) y \\(n_2=10\\) y las varianzas poblacionales son iguales, entonces \\(\\frac{S_1^2/\\sigma_1^2}{S_2^2/\\sigma_2^2}=\\frac{S_1^2}{S_2^2}\\sim F_{5,9}\\) \\[P\\left(\\frac{S_1^2}{S_2^2}\\leq b\\right)= F_{5,9}(b)=0.95\\] entonces \\(qf(0.95,\\,5,\\,9)=b\\), \\(b=3.48\\).\n\nSimulaci√≥n del comportamiento del promedio muestral\nSimulamos 1000 repeticiones del promedio muestral a partir de una distribuci√≥n exponencial con media ( = 10 ), para distintos tama√±os de muestra ( n ).\n\nsimular_promedios &lt;- function(n, repeticiones = 1000, media = 10) {\n  promedios &lt;- replicate(repeticiones, mean(rexp(n, rate = 1 / media)))\n  data.frame(\n    `n` = n,\n    `Promedio repetido` = mean(promedios),\n    `Media te√≥rica` = media,\n    `Varianza repetida` = var(promedios),\n    `Varianza te√≥rica` = media^2 / n\n  )\n}\n\n# Evaluar para varios tama√±os\ntama√±os &lt;- c(5, 10, 25, 50, 100)\nresultados &lt;- do.call(rbind, lapply(tama√±os, simular_promedios))\nknitr::kable(resultados, digits = 5)\n\n\n\n\n\n\n\n\n\n\nn\nPromedio.repetido\nMedia.te√≥rica\nVarianza.repetida\nVarianza.te√≥rica\n\n\n\n5\n10.09576\n10\n20.62900\n20\n\n\n10\n10.11620\n10\n10.25720\n10\n\n\n25\n9.97786\n10\n3.89759\n4\n\n\n50\n9.97908\n10\n1.89860\n2\n\n\n100\n10.00337\n10\n1.06474\n1\n\n\n\n\n\n\nTheorem 1.12 Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) v.a‚Äôs con funciones generadoras de momentos \\(m(t)\\) y \\(m_1(t),\\,m_2(t),\\cdots,\\) respectivamente. Si \\[\\lim_{n\\rightarrow\\infty}m_n(t)=m(t)\\mbox{ para toda $t$ real,}\\] entonces la funci'on de distribuci'on de \\(Y_n\\) converge hacia la funci'on de distribuci'on de \\(Y\\) cuando \\(n\\rightarrow\\infty\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#leyes-de-los-grandes-n√∫meros-y-teorema-central-del-l√≠mite",
    "href": "index.html#leyes-de-los-grandes-n√∫meros-y-teorema-central-del-l√≠mite",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.13 Leyes de los Grandes N√∫meros y Teorema Central del L√≠mite",
    "text": "1.13 Leyes de los Grandes N√∫meros y Teorema Central del L√≠mite\n\n1.13.1 Leyes de los grandes n√∫meros\n\nDefinition 1.10 Una sucesi√≥n de variables aleatorias converge en media a \\(X\\), y se denota por \\(X_{n}\\xrightarrow{cm}X\\) , si para cualquier \\(\\epsilon&gt;0\\) se tiene que:\n[{n}E(|X{n}-X|)=0,] siempre que dicha esperanza exista.\\\nDe forma an√°loga se define convergencia en media de orden r si: \\[\\lim _{n\\to \\infty }E(\\left|X_{n}-X\\right|^r)=0,\\]\nCuando \\(r=2\\) se dice que se tiene convergencia en media cuadr√°tica\n\\[\\lim _{n\\to \\infty }E(\\left|X_{n}-X\\right|^2)=0,\\]\n\n\n1.13.2 Relaciones entre tipos de convergencias",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#diagrama-de-convergencias",
    "href": "index.html#diagrama-de-convergencias",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.14 Diagrama de convergencias",
    "text": "1.14 Diagrama de convergencias\n\n1.14.1 Diagrama de relaciones entre tipos de convergencia\n\nDiagrama de convergencias\n\n\n\n1.14.2 Ley d√©bil de los grandes n√∫meros\n\nTheorem 1.13 Sea \\(X 1,\\ldots, X_n\\) una sucesi√≥n de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante \\(C\\), independiente de \\(n\\). Sea \\(S_n = \\sum_{i=1  }^{n}X_i\\). Entonces \\[\n\\begin{align}\nE\\left(\\left|\\frac{S_n-E(S_n)}{n}\\right|^2\\right)\\leq \\frac{C}{n}\n\\end{align}\n\\] y, como consecuencia \\[\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}=0\\] en el sentido de la convergencia en media cuadr√°tica.\n\nLos resultados que garantizan la convergencia casi segura de la media muestral se conocen como leyes fuertes de los grandes n√∫meros. Se enuncia a continuaci√≥n una ley fuerte para variables con segundos momentos finitos e incorreladas.\n\n1.14.3 Ley fuerte de los grandes n√∫meros\n\nTheorem 1.14 Sea \\(X 1,\\ldots, X_n\\) una sucesi√≥n de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante \\(C\\), independiente de \\(n\\). Sea \\(S_n = \\sum_{i=1  }^{n}X_i\\). Entonces \\[\n        \\begin{align}\n        E\\left(\\left|\\frac{S_n-E(S_n)}{n}\\right|^2\\right)\\leq \\frac{C}{n}\n        \\end{align}\n        \\] y, como consecuencia \\[\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}=0\\] en el sentido de la casi segura.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#teorema-central-del-l√≠mite",
    "href": "index.html#teorema-central-del-l√≠mite",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.15 Teorema central del l√≠mite",
    "text": "1.15 Teorema central del l√≠mite\n\nTheorem 1.15 Central de L√≠mite Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) v.a‚Äôs iid ( no se precisa de que distribuci'on se generan) con \\(E[Y_i]=\\mu\\) y \\(V[Y_i]=\\sigma^2&lt;\\infty\\). Definamos \\[U_n=\\frac{\\sum_{i=1}^nY_i-n\\mu}{\\sigma\\sqrt{n}}=\\frac{\\overline{Y}-\\mu}{\\sigma/\\sqrt{n}}\\mbox{ donde} \\overline{Y}=\\frac{1}{n}\\sum_{i=1}^nY_i\\] Entonces la funci√≥n de distribuci√≥n de \\(U_n\\) converge hacia la funci√≥n de distribuci√≥n normal est√°ndar cuando n tiende a infinito . Esto es, \\[\\lim_{n\\rightarrow\\infty}P(U_n\\leq u)=\\int_{-\\infty}^u\\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2}dt, \\forall u\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#referencias",
    "href": "index.html#referencias",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.16 Referencias",
    "text": "1.16 Referencias\n\nG√≥mez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisi√≥n. Departament d‚ÄôEstad√≠stica i Investigaci√≥ Operativa, Universitat Polit√®cnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estad√≠stica matem√°tica con aplicaciones (7¬™ ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "2¬† Principios para reducir los datos",
    "section": "",
    "text": "2.1 Principio de suficiencia",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#principio-de-suficiencia",
    "href": "chapter1.html#principio-de-suficiencia",
    "title": "2¬† Principios para reducir los datos",
    "section": "",
    "text": "2.1.1 Estad√≠sticos suficientes minimales\n¬øEste proceso de resumir los datos a los dos estad√≠sticos \\(\\overline{Y}\\) y \\(S^2\\) conserva la informaci√≥n de \\(\\mu\\) y \\(\\sigma^2\\) en el conjunto original de \\(n\\) observaciones muestrales? O bien ¬øSe ha perdido u ocultado alguna informaci√≥n acerca de estos par√°metros en el proceso de reducir los datos?\nPresentamos m√©todos para hallar estad√≠sticos que en cierto sentido resumen toda la informaci√≥n de una muestra acerca de un par√°metro objetivo. Se dice que estos estad√≠sticos tienen la propiedad de suficiencia o son estad√≠sticos suficientes.\n\nExample 2.1 Sean \\(n\\) experimentos binomiales, \\(X_1,\\,X_2,\\cdots,\\,X_n\\), donde \\[\n\\begin{eqnarray*}\n        X_i&=&\\left\\{\\begin{array}{ll}1,&\\mbox{si el $i$-\\'esimo intento es un \\'exito,}\\\\0,&\\mbox{si el $i$-\\'esimo intento es un fracaso.}\\end{array}\\right.\\\\\n        X_i&=&\\left\\{\\begin{array}{ll}1,&\\mbox{con probabilidad $p$,}\\\\0,&\\mbox{con probabilidad $q=1-p$.}\\end{array}\\right.\n    \\end{eqnarray*}\n\\] Sea \\(Y=\\sum_{i=1}^n X_i\\) el n√∫mero de √©xitos en los \\(n\\) intentos. Si conocemos el valor de \\(Y\\), ¬øPodemos obtener alguna informaci√≥n adicional acerca de \\(p\\) al ver otras funciones de \\(X_1,\\,X_2,\\cdots,\\,X_n\\)?\n\\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n|Y=y)\\\\\n&=\\frac{P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)}{P(Y=y)}\n\\end{align*}\n\\] El numerador es \\(0\\) si \\(\\sum_{i=1}^nx_i\\neq y\\) dado que no pueden suceder los eventos al mismo tiempo.\nSi \\(\\sum_{i=1}^nx_i= y\\) entonces \\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)\\\\\n&=P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n)\n\\end{align*}\n\\] Por tanto el numerador queda \\(p^y(1-p)^{n-y}\\), dado que hay \\(y\\) unos y \\(n-y\\) ceros.\nEl denominador \\[P(Y=y)=\\displaystyle{a\\choose b} p^y(1-p)^{n-y}\\] porque \\(Y\\sim Bin(n,p)\\). \\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)\\\\\n&=\\left\\{\\begin{array}{ll}\\frac{p^y(1-p)^{n-y}}{\\left({n \\atop y}\\right) p^y(1-p)^{n-y}}=\\frac{1}{\\left({n \\atop y}\\right)},& si\\sum_{i=1}^nx_i= y\\\\0,&\\mbox{ en cualquier otro punto.}\\end{array}\\right.\n\\end{align*}\n\\] \\(\\frac{1}{\\left({n \\atop y}\\right)}\\) no depende de \\(p\\)\n\nUna vez que se conozca \\(Y\\), ninguna otra funci√≥n de \\(X_1,\\,X_2,\\cdots,\\,X_n\\) proporcionara m√°s informaci√≥n sobre el posible valor de \\(p\\). En este sentido, \\(Y\\) contiene toda la informaci√≥n acerca de \\(p\\).\n\nDefinition 2.1 Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) una muestra aleatoria de una distribuci√≥n de probabilidad con par√°metro desconocido \\(\\theta\\). Entonces se dice que el estad√≠stico \\(U = T(Y_1,\\, Y_2,\\cdots,\\, Y_n)\\) es suficiente para \\(\\theta\\) si la distribuci√≥n condicional de \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\), dada \\(U\\), no depende de \\(\\theta\\).\n\n\nRemark 2.1. El uso de cualquier estad√≠stico \\(T(\\underset{\\sim}{X})\\) implica una reducci√≥n de los datos muestrales. Sea \\(\\underset{\\sim}{X} =(X_1 ,\\ldots, X_n)\\) una muestra aleatoria simple (un vector aleatorio) y sean \\(\\underset{\\sim}{x} = (x_1 ,\\ldots, x_n)\\), y \\(\\underset{\\sim}{y} = (y_1 ,\\ldots, y_n)\\) muestras observadas (realizaciones de \\(X\\)). Si decidimos usar el estad√≠stico \\(T(\\underset{\\sim}{X})\\) en vez de toda la muestra, ser√°n tratadas igual dos muestras observadas cualesquiera \\(\\underset{\\sim}{x}\\), \\(\\underset{\\sim}{y}\\), siempre que \\(T(\\underset{\\sim}{x})=T(\\underset{\\sim}{y})\\). Es decir, al usar el estad√≠stico \\(T\\), en lugar de toda la muestra, se pierde informaci√≥n.\nSe plantea as√≠ el problema de buscar estad√≠sticos \\(T\\) tales que la informaci√≥n que se pierde al usarlos sea irrelevante para los fines que nos hayamos marcado.\n\n\nRemark 2.2. Igualdad de estad√≠sticos = Tratamiento indistinguible\nLa afirmaci√≥n:\n\n‚ÄúSer√°n tratadas igual dos muestras observadas cualesquiera \\(\\underset{\\sim}{x}\\) y \\(\\underset{\\sim}{y}\\), siempre que \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\)‚Äù\n\nsignifica que si solo observamos el valor de \\(T\\), entonces no podemos distinguir entre dos muestras diferentes que arrojen el mismo valor de ese estad√≠stico.\nPor ejemplo:\nSupongamos que \\(\\bar{x} = \\bar{y} = 5\\), pero los vectores muestrales son diferentes:\n\\[\n\\underset{\\sim}{x} = (3,\\ 5,\\ 7), \\quad \\underset{\\sim}{y} = (4,\\ 5,\\ 6).\n\\]\nAmbos tienen la misma media, pero claramente no son la misma muestra. Sin embargo, si solo usamos la media como resumen, tratamos a ambas muestras como si fueran ‚Äúiguales‚Äù.\n\n¬øQu√© se pierde?\nSe pierde la estructura interna de la muestra, incluyendo:\n\nLa variabilidad.\nEl sesgo o simetr√≠a.\nLa existencia de valores extremos.\nLa informaci√≥n sobre la distribuci√≥n conjunta de los datos.\n\nTodo eso queda oculto si solo consideramos el estad√≠stico \\(T(\\underset{\\sim}{X})\\).\n\nTodo estad√≠stico implica una compresi√≥n de la muestra, y con ello una p√©rdida de informaci√≥n.\nPor eso, en inferencia estad√≠stica buscamos estad√≠sticos que sean:\n\nSuficientes: capturan toda la informaci√≥n relevante sobre un par√°metro.\nEficientes: minimizan la p√©rdida de informaci√≥n.\nInsesgados: representan fielmente el par√°metro que estiman.\n\n\nNotaci√≥n \\[\n    \\begin{eqnarray*}\n        p(y|\\theta)&:&\\mbox{ funci√≥n de masa de probabilidad}\\\\\n        f(y|\\theta)&:&\\mbox{ funci√≥n de densidad}\n    \\end{eqnarray*}\n\\]\n\nLa definicion Definition¬†2.1 nos dice como comprobar que un estad√≠stico es suficiente pero no nos dice c√≥mo calcularlo.\n\n\n\n\n\n\nTip¬†2.1\n\n\n\n\\(p(y_1,\\, y_2,\\cdots,\\, y_n)\\) funci√≥n de probabilidad de v.a‚Äôs discretas.\n\\(p(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) funci√≥n de probabilidad o verosimilitud de observar el evento \\(Y_1=y_1,\\, Y_2=y_2,\\cdots,\\, Y_n=y_n\\) cuando el valor del par'ametro es \\(\\theta\\).\n\\(f(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) caso continuo.\n\n\n\nDefinition 2.2 Sean \\(y_1,\\, y_2,\\cdots,\\, y_n\\) observaciones muestrales tomadas de variables aleatorias correspondientes \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) cuya distribuci√≥n depende de un par√°metro \\(\\theta\\). Entonces, si \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) son variables aleatorias discretas, la verosimilitud de la muestra, \\(L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\), se define como la probabilidad conjunta de \\(y_1,\\, y_2,\\cdots,\\, y_n\\).\nSi \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) son v.a‚Äôs continuas, la verosimilitud \\(L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) se define como la densidad conjunta evaluada en \\(y_1,\\, y_2,\\cdots,\\, y_n\\)\n\n\n\n\n\n\n\nImportant¬†2.1\n\n\n\nSi el conjunto de v.a‚Äôs iid \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) denota una muestra aleatoria de distribuci√≥n discreta con funci√≥n de probabilidad \\(p(y|\\theta)\\) entonces \\[\n\\begin{eqnarray*}\n    L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&p (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\\\\n    &=&p(y_1|\\theta)p(y_2|\\theta)\\cdots p(y_n|\\theta)\n\\end{eqnarray*}\n\\] Mientras que si \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) iid tienen distribuci√≥n continua con funci√≥n de densidad \\(f(y|\\theta)\\) entonces \\[\\begin{eqnarray*}\n    L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&f (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\\\\n    &=&f(y_1|\\theta)f(y_2|\\theta)\\cdots f(y_n|\\theta)\n\\end{eqnarray*}\\]\n\n\n\nTheorem 2.1 Si \\(f(\\underset{\\sim}{x}|\\theta)\\) es la verosimilitud de un vector aleatorio \\(X\\) y \\(q(t|\\theta)\\) es la verosimilitud (funci√≥n de densidad o de masa) de un estad√≠stico \\(T(\\underset{\\sim}{X})\\), se tiene la siguiente equivalencia. \\(T(\\underset{\\sim}{X})\\) es un estad√≠stico suficiente para \\(\\theta\\) si y s√≥lo si para cada \\(\\underset{\\sim}{x}\\) del espacio muestral \\(\\mathcal{X}\\) el cociente \\[\\begin{align}\n\\frac{f(\\underset{\\sim}{x}|\\theta)}{q(T(\\underset{\\sim}{x})|\\theta)}\n\\end{align}\\] no depende de \\(\\theta\\).\n\n\nRemark. El cociente del teorema\nEl cociente\n\\[\n\\frac{f(\\underset{\\sim}{x} \\mid \\theta)}{q(T(\\underset{\\sim}{x}) \\mid \\theta)}\n\\]\ncompara cu√°nta verosimilitud aporta la muestra completa respecto a la verosimilitud que se concentra solamente en el estad√≠stico.\nüîÅ Si este cociente no depende de \\(\\theta\\), eso significa que toda la informaci√≥n sobre \\(\\theta\\) contenida en \\(f(\\underset{\\sim}{x} \\mid \\theta)\\) ya est√° contenida en \\(q(T(\\underset{\\sim}{x}) \\mid \\theta)\\).\n\n\nTheorem 2.2 Sea \\(U\\) un estad√≠stico basado en la muestra aleatoria \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\). Entonces \\(U\\) es un estad√≠stico suficiente para la estimaci√≥n de un par√°metro \\(\\theta\\) s√≠ y s√≥lo si la verosimilitud \\(L(\\theta)=L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) se puede factorizar en dos funciones no negativas, \\[L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)=g(u,\\,\\theta)\\times h(y_1,\\, y_2,\\cdots,\\, y_n)\\] donde \\(g(u,\\,\\theta)\\) es una funci√≥n s√≥lo de \\(u\\) y \\(\\theta\\) y \\(h(y_1,\\, y_2,\\cdots,\\, y_n)\\) no es una funci√≥n de \\(\\theta\\)\n\n\nRemark (Interpretaci√≥n: ¬øPor qu√© esto implica suficiencia?). Cuando se cumple la factorizaci√≥n:\n\nLa funci√≥n \\(g(u, \\theta)\\) contiene toda la informaci√≥n sobre \\(\\theta\\).\nEl resto de la muestra solo afecta a \\(h(\\cdot)\\), que no contiene ninguna informaci√≥n sobre \\(\\theta\\).\n\nPor lo tanto, si ya conocemos \\(u\\), no necesitamos el resto de la muestra para inferir \\(\\theta\\).\n\nüß© Conclusi√≥n:\n\\(U\\) es suficiente ‚áî no se pierde informaci√≥n sobre \\(\\theta\\) al reemplazar la muestra por \\(U\\).\n\n\nExample 2.2 Sean \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) una muestra aleatoria en la que \\(Y_i\\) posee la funci√≥n de densidad de probabilidad \\[f(y_i|\\theta)=\\left\\{\\begin{array}{ll}(1/\\theta)e^{-y_i/\\theta},& 0\\leq y_i&lt;\\infty\\\\0,&\\mbox{ en cualquier otro punto.}\\end{array}\\right.\\] donde \\(\\theta&gt;0,\\,i=1,\\cdots,\\,n\\). Demuestre que \\(\\overline{Y}\\) es un estad√≠stico suficiente para el par√°metro \\(\\theta\\).\n\n\nProof. \\[\\begin{eqnarray*}\n    L(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&f(y_1|\\theta)f(y_2|\\theta)\\cdots f(y_n|\\theta)\\\\\n    &=&\\frac{1}{\\theta}e^{-y_1/\\theta}\\frac{1}{\\theta}e^{-y_2/\\theta}\\cdots\\frac{1}{\\theta}e^{-y_n/\\theta}\\\\\n    &=&\\left(\\frac{1}{\\theta}\\right)^ne^{-\\sum_{i=1}^ny_i/\\theta}\\\\\n    &=&\\left(\\frac{1}{\\theta}\\right)^ne^{-n\\overline{y}/\\theta}\\\\\n\\end{eqnarray*}\\] As√≠ que \\(g(\\overline{y},\\,\\theta)=\\frac{e^{-n\\overline{y}/\\theta}}{\\theta^n}\\) y \\(h(y_1,\\, y_2,\\cdots,\\, y_n)=1\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#notaci√≥n",
    "href": "chapter1.html#notaci√≥n",
    "title": "2¬† Principios para reducir los datos",
    "section": "2.2 Notaci√≥n",
    "text": "2.2 Notaci√≥n\n\\[\n    \\begin{eqnarray*}\n        p(y|\\theta)&:&\\mbox{ funci√≥n de masa de probabilidad}\\\\\n        f(y|\\theta)&:&\\mbox{ funci√≥n de densidad}\n    \\end{eqnarray*}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#estad√≠sticos-suficientes-minimales-1",
    "href": "chapter1.html#estad√≠sticos-suficientes-minimales-1",
    "title": "2¬† Principios para reducir los datos",
    "section": "2.2 Estad√≠sticos suficientes minimales",
    "text": "2.2 Estad√≠sticos suficientes minimales\nLa factorizaci√≥n de la funci√≥n de verosimilitud no es √∫nica y como consecuencia de ello, tampoco es √∫nico el estad√≠stico suficiente para un par√°metro.\nYa vimos que cualquier transformaci√≥n biyectiva de un estad√≠stico suficiente da lugar a otro estad√≠stico suficiente. Pero a√∫n hay muchos m√°s estad√≠sticos suficientes. Por ejemplo, la muestra completa \\(X\\) tambi√©n es estad√≠stico suficiente para el par√°metro: \\[\n\\begin{align*}\nf(x|\\theta)=g(x|\\theta)h(x)\n\\end{align*}\n\\]\ndonde \\(h( x )=1\\), \\(T(x)=x\\) y \\(g(x|\\theta)=f(x|\\theta)\\).\n\n2.2.1 Estad√≠stico minimal\nUn estad√≠stico suficiente \\(T(\\underset{\\sim}{X})\\) se llama minimal si para cualquier otro estad√≠stico \\(S(\\underset{\\sim}{X})\\) se tiene que \\(T(\\underset{\\sim}{X})\\) es funci√≥n de \\(S(\\underset{\\sim}{X})\\). Es decir, si ocurre que \\(S( \\underset{\\sim}{x}) = S(\\underset{\\sim}{y})\\) entonces forzosamente se tiene que \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\).\nEl siguiente teorema proporciona un m√©todo para encontrar el estad√≠stico suficiente minimal.\n\nTheorem 2.3 Sea \\(f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)\\) la funci√≥n de verosimilitud conjunta de \\(\\underset{\\sim}{X}\\) (discreta o continua). Supongamos que existe una funci√≥n \\(T(\\underset{\\sim}{x})\\) tal que para cualquier par de elementos del espacio muestral \\(\\underset{\\sim}{x}\\) , \\(\\underset{\\sim}{y}\\) , el cociente \\[\n\\begin{align}\n\\frac{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)}{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{y}|\\theta)}\n\\end{align}\n\\] es constante como funci√≥n de \\(\\theta\\), si y s√≥lo si \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\). Entonces \\(T(\\underset{\\sim}{x})\\) es estad√≠stico suficiente minimal para \\(\\theta\\).\n\n\nExample 2.3 Determinar un estad√≠stico minimal para el par√°metro \\(\\theta\\), cuando \\(X_1,\\, X_2,\\cdots,\\, X_n\\) es una muestra aleatoria de una poblaci√≥n con distribuci√≥n de Poisson. \\[\n\\begin{align*}\n\\frac{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)}{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{y}|\\theta)}\n&=\\frac{\\prod_{i=1}^{n}\\frac{\\theta^{x_i} e^{-\\theta}}{x_i!}}{\\prod_{i=1}^{n}\\frac{\\theta^{y_i} e^{-\\theta}}{y_i!}}\\\\\n&=\\frac{e^{-n\\theta}\\prod_{i=1}^{n}\\frac{\\theta^{x_i} }{x_i!}}{e^{-n\\theta}\\prod_{i=1}^{n}\\frac{\\theta^{y_i} }{y_i!}}\\\\\n&=\\frac{\\frac{\\theta^{\\sum_{i=1}^{n}x_i} }{\\prod_{i=1}^{n}x_i!}}{\\frac{\\theta^{\\sum_{i=1}^{n}y_i} }{\\prod_{i=1}^{n}y_i!}}\\\\\n&=\\frac{\\frac{\\theta^{n\\bar{x}} }{\\prod_{i=1}^{n}x_i!}}{\\frac{\\theta^{n\\bar{y}} }{\\prod_{i=1}^{n}y_i!}}\\\\\n&=\\theta^{n(\\bar{x}-\\bar{y})}\\frac{\\prod_{i=1}^{n}y_i!}{\\prod_{i=1}^{n}x_i!}\n\\end{align*}\n\\]\n\nEl cociente de la √∫ltima igualdad no depende de \\(\\theta\\), s√≠ y s√≥lo si \\(\\bar{x}-\\bar{y}=0\\); es decir si \\(\\bar{X}_n\\) es un estad√≠stica suficiente minimal para \\(\\theta\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "",
    "text": "3.1 La funci√≥n de distribuci√≥n emp√≠rica y el m√©todo de los momentos\nSea la variable aleatoria \\(X\\) con funci√≥n de distribuci√≥n \\(F\\). Consideramos una muestra aleatoria simple de tama√±o \\(n\\) de \\(X\\), es decir, \\(X_1 ,\\ldots, X_n\\) v.a.i.i.d. con distribuci√≥n dada por \\(F\\) . Sea \\(x_1 ,\\ldots, x_n\\) una realizaci√≥n de esa m.a.s. Se llama funci√≥n de distribuci√≥n emp√≠rica a la funci√≥n \\[\n\\begin{align}\nF_{n}(x)=\\dfrac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\mathbf{I}_{(-\\infty,x]}(x_{i})¬∏\n\\end{align}\n\\] que a cada n√∫mero real x le asigna la proporci√≥n de valores observados que son menores o iguales que x.\nEs inmediato comprobar que la funci√≥n \\(F_n\\) as√≠ definida es una funci√≥n de distribuci√≥n:\nConcretamente, \\(F_n\\) es la funci√≥n de distribuci√≥n de una variable aleatoria discreta (que podemos llamar \\(X_e\\) ) que pone masa \\(\\frac{1}{n}\\) en cada uno de los n puntos \\(x_i\\) observados:\nA la distribuci√≥n de \\(X_e\\) e se le llama distribuci√≥n emp√≠rica asociada al conjunto de valores \\({x_1 ,\\ldots, x_n}\\).\nObs√©rvese que si fijamos el valor de \\(x\\) y dejamos variar la muestra, lo que obtenemos es una variable aleatoria. En efecto, se tiene entonces que\n\\[\n\\begin{align}\nF_{n}(x)=\\dfrac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\mathbf{I}_{(-\\infty,x]}(x_{i})¬∏\n\\end{align}\n\\]\ndonde\n\\[\n\\begin{align}\n\\mathbf{I}_{(-\\infty,x]}(X_{i})= \\left\\{ \\begin{array}{lcc}\n1 &   si  & X_{i}\\leq x \\\\\n\\\\ 0 &  si &X_{i}&gt; x\\\\\n\\end{array}\n\\right.\n\\end{align}\n\\] y, por lo tanto, cada t√©rmino \\(\\mathbf{I}_{(-\\infty,x]}(X_{i})\\) es una variable aleatoria de Bernoulli con probabilidad de √©xito\n\\[\n\\begin{align}\np&=P(\\mathbf{I}_{(-\\infty,x]}(X_{i})=1)\\\\\n&=P(X_{i}\\leq x)\\\\\n&=F(x)\n\\end{align}\n\\] De ah√≠ se deduce que \\(F_n\\) es una variable aleatoria y que \\(nF_n(x)\\) tiene distribuci√≥n binomial con par√°metros \\(n\\) y \\(p = F(x)\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#la-funci√≥n-de-distribuci√≥n-emp√≠rica-y-el-m√©todo-de-los-momentos",
    "href": "chapter2.html#la-funci√≥n-de-distribuci√≥n-emp√≠rica-y-el-m√©todo-de-los-momentos",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "",
    "text": "\\(F_n(x) \\in [0, 1]\\) para todo \\(x \\in \\mathbb{R}\\).\n\n\\(F_n\\) es continua por la derecha.\n\n\\(F_n\\) es no decreciente.\n\\(\\lim _{x\\to -\\infty }F_{n}(x)=0\\)\n\\(\\lim _{x\\to \\infty }F_{n}(x)=1\\)\n\n\n\n\n\\(x_i\\)\n\\(1\\)\n\\(2\\)\n\\(\\ldots\\)\n\\(n\\)\n\n\n\\(p_i = P(X_e = x_i)\\)\n\\(1/n\\)\n\\(1/n\\)\n\\(\\ldots\\)\n\\(1/n\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#teorema-de-glivenko-cantelli",
    "href": "chapter2.html#teorema-de-glivenko-cantelli",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.2 Teorema de Glivenko-Cantelli",
    "text": "3.2 Teorema de Glivenko-Cantelli\nEl siguiente teorema recoge algunas de las propiedades de la funci√≥n de distribuci√≥n emp√≠rica.\n\nTheorem 3.1 Sea \\(\\{X_n\\}\\) para \\(n\\geq 1\\) , sucesi√≥n de variables aleatorias independientes e id√©nticamente distribuidas definidas en el espacio de probabilidad \\((\\Omega, \\mathcal{A}, P)\\) con funci√≥n de distribuci√≥n com√∫n \\(F\\) . Se denota por \\(F_n\\) la funci√≥n de distribuci√≥n emp√≠rica obtenida de las \\(n\\) primeras variables aleatorias \\(X_1 ,\\ldots, X_n\\) . Sea \\(x\\in\\mathbb{R}\\). Se verifica lo siguiente:\n\n\n\n\\(P(nF_n(x)=j)=P(F_n(x)=\\frac{j}{n})=\\binom{n}{j}(F(x))^j(1-F(x))^{n-j}\\), \\(j=1,\\ldots,n\\)\\\n\n\\(E(F_n(x))=F(x)\\); \\(Var(F_n(x))=\\frac{1}{n}F(x)(1-F(x))\\).\n\\(\\lim _{n\\to \\infty }F_{n}(x)=F(x)\\)\n\n\\(\\lim _{n\\to \\infty }\\frac{F_{n}(x)-F(x)}{\\sqrt{\\frac{F(x)(1-F(x))}{n}}}=Z\\), donde \\(Z\\) es una variable aleatoria con distribuci√≥n normal est√°ndar y la convergencia es convergencia en distribuci√≥n.\n\nEl siguiente teorema refuerza el resultado (c) anterior, puesto que afirma que la convergencia de \\(F_n(x)\\) a \\(F(x)\\) se da uniformemente.\n\nTheorem 3.2 Sea \\(\\{X_n\\}\\) para \\(n\\geq 1\\) , sucesi√≥n de variables aleatorias independientes e id√©nticamente distribuidas definidas en el espacio de probabilidad \\((\\Omega, \\mathcal{A}, P)\\) con funci√≥n de distribuci√≥n com√∫n \\(F\\) . Se denota por \\(F_n\\) la funci√≥n de distribuci√≥n emp√≠rica obtenida de las \\(n\\) primeras variables aleatorias \\(X_1 ,\\ldots, X_n\\) . Sea \\(x\\in\\mathbb{R}\\). Entonces \\[Sup_{x\\in\\mathbb{R}} |F_{n}(x)-F(x)|\\xrightarrow{c.s}0\\]\n\n\n\n\n\n\n\nNote¬†3.1\n\n\n\nObs√©rvese que seg√∫n el apartado (c) del teorema Theorem¬†3.1, las distribuciones emp√≠ricas asociadas a muestras de tama√±o n convergen d√©bilmente a la distribuci√≥n de probabilidad te√≥rica identificada por \\(F\\), para casi todas las muestras de tama√±o infinito que se extraigan de \\(F\\) . √âsta es una de las consecuencias m√°s importantes del citado teorema: la distribuci√≥n emp√≠rica converge d√©bilmente con probabilidad 1 a la poblacional cuando el tama√±o de la muestra tiende a infinito: \\[F_{n}(x)\\xrightarrow{c.s}F(x)\\] Esto garantiza la posibilidad de realizar inferencia estad√≠stica:\n\nLos aspectos probabil√≠sticos de una caracter√≠stica \\(X\\), medida en una poblaci√≥n, se resumen de forma estilizada en una distribuci√≥n de probabilidad \\(F\\).\nLa distribuci√≥n de probabilidad \\(F\\), puede ser aproximada mediante las distribuciones emp√≠ricas \\(F_n\\) obtenidas por muestreo de la poblaci√≥n en estudio.\nEl teorema de Glivenko-Cantelli afirma que esas aproximaciones son uniformes en x.\nPor esta raz√≥n el teorema de Glivenko-Cantelli se llama a veces Teorema Fundamental de la Estad√≠stica Matem√°tica.\n\n\n\nPodemos ver a continuaci√≥n c√≥mo, a medida que aumentamos el tama√±o de la muestra (n=10,30,100,1000), la funci√≥n de distribuci√≥n emp√≠rica se ajusta cada vez mejor a la distribuci√≥n te√≥rica normal est√°ndar N(0,1), tal como afirma el teorema.\n\n# Cargar librer√≠a para gr√°ficos\nlibrary(ggplot2)\n\n# Definir funci√≥n para graficar ECDF vs distribuci√≥n te√≥rica\ncomparar_ecdf_teorica &lt;- function(n, distribucion = \"normal\") {\n  set.seed(123)  # Para reproducibilidad\n\n  # Muestra de tama√±o n desde N(0,1)\n  muestra &lt;- rnorm(n)\n  \n  # Dominio com√∫n\n  x_vals &lt;- seq(-3, 3, length.out = 1000)\n\n  # Distribuci√≥n te√≥rica\n  F_teorica &lt;- pnorm(x_vals)\n\n  # Distribuci√≥n emp√≠rica\n  ecdf_muestra &lt;- ecdf(muestra)\n  F_empirica &lt;- ecdf_muestra(x_vals)\n\n  # Construir data frame para ggplot\n  df &lt;- data.frame(\n    x = rep(x_vals, 2),\n    F = c(F_empirica, F_teorica),\n    Tipo = rep(c(\"Emp√≠rica\", \"Te√≥rica\"), each = length(x_vals))\n  )\n\n  # Graficar\n  ggplot(df, aes(x = x, y = F, color = Tipo, linetype = Tipo)) +\n    geom_line(size = 1) +\n    labs(\n      title = paste(\"ECDF vs F(x) ‚Äî Tama√±o de muestra n =\", n),\n      x = \"x\", y = \"Probabilidad acumulada\"\n    ) +\n    theme_minimal() +\n    scale_color_manual(values = c(\"Emp√≠rica\" = \"red\", \"Te√≥rica\" = \"black\")) +\n    scale_linetype_manual(values = c(\"Emp√≠rica\" = \"dashed\", \"Te√≥rica\" = \"solid\"))\n}\n\n# Generar gr√°ficos para diferentes tama√±os de muestra\ncomparar_ecdf_teorica(10)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\ncomparar_ecdf_teorica(30)\n\n\n\n\n\n\ncomparar_ecdf_teorica(100)\n\n\n\n\n\n\ncomparar_ecdf_teorica(1000)\n\n\n\n\n\n\n\nEl Teorema Fundamental de la Estad√≠stica Matem√°tica: da una fundamentaci√≥n de la inferencia estad√≠stica, cuyo objetivo principal consiste en extraer informaci√≥n sobre \\(F\\) a partir de las observaciones muestrales.\n¬øPor qu√© esto es importante?\nPorque sin conocer \\(F(x)\\) expl√≠citamente, podemos estimarla a partir de los datos.\nEsto es la base de:\n\nlos histogramas acumulados,\nlas pruebas no param√©tricas,\nlos intervalos de confianza emp√≠ricos, y\ntoda la inferencia estad√≠stica basada en datos reales.\n\nüéØ Ejemplo: Estimaci√≥n del percentil 90 del ingreso mensual\nüìå Contexto Sup√≥n que quieres estimar el ingreso mensual por debajo del cual se encuentran el 90% de las personas en una ciudad.\nNo conoces la distribuci√≥n real del ingreso $ F(x) $, pero tienes una muestra de datos.\n\nPaso a paso\n\nSimulamos una poblaci√≥n Vamos a suponer que el ingreso sigue una distribuci√≥n log-normal:\n\n\nset.seed(123)\npoblacion &lt;- rlnorm(1e6, meanlog = 10, sdlog = 0.5)\n\n\nTomamos una muestra aleatoria\n\n\nmuestra &lt;- sample(poblacion, size = 20000, replace = FALSE)\n\n\nEstimamos la distribuci√≥n emp√≠rica\n\n\nFn &lt;- ecdf(muestra)\n\n\nEstimamos el percentil 90 (cuantil 0.9)\n\n\ncuantil_90_empirico &lt;- quantile(muestra, probs = 0.9)\n\n\nComparamos con el valor verdadero en la poblaci√≥n\n\n\ncuantil_90_real &lt;- quantile(poblacion, probs = 0.9)\n\n\nResultado\n\n\ncat(\"Cuantil 90 estimado (emp√≠rico):\", round(cuantil_90_empirico, 2), \"\\n\")\n\nCuantil 90 estimado (emp√≠rico): 41926.83 \n\ncat(\"Cuantil 90 real (poblacional):\", round(cuantil_90_real, 2), \"\\n\")\n\nCuantil 90 real (poblacional): 41805.56",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#ejemplo-estimaci√≥n-del-percentil-90-del-ingreso-mensual",
    "href": "chapter2.html#ejemplo-estimaci√≥n-del-percentil-90-del-ingreso-mensual",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.3 üéØ Ejemplo: Estimaci√≥n del percentil 90 del ingreso mensual",
    "text": "3.3 üéØ Ejemplo: Estimaci√≥n del percentil 90 del ingreso mensual\n\n3.3.1 üìå Contexto\nSup√≥n que quieres estimar el ingreso mensual por debajo del cual se encuentran el 90% de las personas en una ciudad.\nNo conoces la distribuci√≥n real del ingreso ( F(x) ), pero tienes una muestra de datos.\n\n3.3.2 ‚öôÔ∏è Paso a paso\n\n3.3.2.1 1. Simulamos una poblaci√≥n\nVamos a suponer que el ingreso sigue una distribuci√≥n log-normal:\n\nset.seed(123)\npoblacion &lt;- rlnorm(1e6, meanlog = 10, sdlog = 0.5)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#la-funci√≥n-de-distribuci√≥n-emp√≠rica-y-el-m√©todo-de-los-momentos-1",
    "href": "chapter2.html#la-funci√≥n-de-distribuci√≥n-emp√≠rica-y-el-m√©todo-de-los-momentos-1",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.3 La funci√≥n de distribuci√≥n emp√≠rica y el m√©todo de los momentos",
    "text": "3.3 La funci√≥n de distribuci√≥n emp√≠rica y el m√©todo de los momentos\n\n3.3.1 Principio de sustituci√≥n\nEn esta secci√≥n presentamos una consecuencia importante de la convergencia de \\(F_n\\) a \\(F\\) , la definici√≥n de estimadores mediante el principio de sustituci√≥n.\n\nLa convergencia de \\(F_n\\) a \\(F\\) permite construir versiones factibles de caracter√≠sticas poblacionales desconocidas.\nSupongamos que estudiamos una caracter√≠stica \\(X\\) en una poblaci√≥n y que el resultado de la observaci√≥n de \\(X\\) puede ser modelado como una variable aleatoria con distribuci√≥n desconocida, digamos \\(F\\).\nMuchas de las preguntas relevantes acerca de la caracter√≠stica \\(X\\) podr√≠an ser contestadas si su funci√≥n de distribuci√≥n \\(F\\) fuese conocida.\n\n\n\n\n\n\n\nImportant¬†3.1\n\n\n\nPreguntas sobre \\(X\\)\n\nel valor esperado,\nel n√∫mero de modas de la distribuci√≥n o\nla probabilidad de que \\(X\\) sea negativa\n\nPara fijar ideas podemos pensar que nos interesa conocer cantidades num√©ricas (par√°metros) que dependen √∫nicamente de la funci√≥n de distribuci√≥n desconocida \\(F\\):\n\\[\n    \\begin{align}\n    \\theta=\\psi(F)\n    \\end{align}\n\\] El teorema de Glivenko-Cantelli nos dice que \\(F_n\\) se acerca a \\(F\\), a medida que el tama√±o muestral crece. As√≠, podemos esperar que tambi√©n se verifique que \\[\n    \\begin{align}\n    \\hat{\\theta}_n=\\psi(F_n)\\rightarrow\\theta=\\psi(F)\n    \\end{align}\n    \\]\nEs decir, esperamos que las cantidades num√©ricas calculadas para la distribuci√≥n emp√≠rica (estimadores) se aproximen a las cantidades desconocidas a medida que el tama√±o muestral crezca.\nEsta forma de obtener estimadores de par√°metros poblacionales desconocidos se denomina principio de sustituci√≥n (plug-in principle en ingl√©s). Es un procedimiento muy general de obtenci√≥n de estimadores.\n\n\nSea \\(X\\sim U(0,\\theta)\\). Se toma una m.a.s. de \\(X\\) de tama√±o n para estimar \\(\\theta\\). Un estimador razonable de \\(\\theta\\) es el m√°ximo de las observaciones, que es estad√≠stico minimal suficiente para \\(\\theta\\): \\[\n\\begin{align}\n    \\hat{\\theta}_2 = \\max_i {X_i}.\n\\end{align}\n\\] El siguiente c√≥digo muestra:\n\nPara cada tama√±o de muestra n, simula valores de \\(X_i\\)‚àºU(0,Œ∏),\nCalcula \\[\\hat{\\theta} = \\max_i {X_i}\\]\nCompara con el valor real de \\(\\theta=10\\).\nMuestra c√≥mo, al aumentar n, el estimador se acerca a \\(\\theta\\).\n\n\n# Simulaci√≥n para estimar theta en una uniforme (0, theta)\nset.seed(42)\ntheta_real &lt;- 10\n\n# Tama√±os de muestra\nn_vals &lt;- c(5, 10, 30, 100)\n\n# Simular y comparar\nestimadores &lt;- sapply(n_vals, function(n) {\n  muestra &lt;- runif(n, min = 0, max = theta_real)\n  max(muestra)\n})\n\n# Mostrar resultados\ndata.frame(\n  Tama√±o_muestra = n_vals,\n  Estimador_maximo = round(estimadores, 3),\n  Error = round(theta_real - estimadores, 3)\n)\n\n  Tama√±o_muestra Estimador_maximo Error\n1              5            9.371 0.629\n2             10            9.347 0.653\n3             30            9.889 0.111\n4            100            9.828 0.172\n\n\nConvergencia del estimador plug-in en la distribuci√≥n uniforme\nEn este ejemplo, estimamos el par√°metro \\(\\theta\\) de una distribuci√≥n \\(X \\sim \\mathcal{U}(0, \\theta)\\) usando el estimador \\(\\hat{\\theta}_n = \\max(X_i)\\). Este es un estimador tipo plug-in: se usa la distribuci√≥n emp√≠rica para estimar una caracter√≠stica de la distribuci√≥n te√≥rica.\nA continuaci√≥n, simulamos c√≥mo este estimador converge al verdadero valor \\(\\theta = 10\\) a medida que el tama√±o de muestra \\(n\\) crece.\n\n# Chunk de R ‚Äî solo c√≥digo\n#| label: fig-convergencia-max\n#| fig-cap: 'Convergencia del estimador plug-in $ \\hat{\\theta}_n = \\max X_i $ hacia el valor real $ \\theta = 10 $'\n#| fig-align: center\n#| message: false\n#| warning: false\n\nset.seed(42)\ntheta_real &lt;- 10\n\n# Vector de tama√±os de muestra crecientes\nn_seq &lt;- seq(5, 500, by = 5)\n\n# Calcular el estimador para cada n\nestimadores &lt;- sapply(n_seq, function(n) {\n  muestra &lt;- runif(n, min = 0, max = theta_real)\n  max(muestra)\n})\n\n# Crear data frame para graficar\ndf_estimacion &lt;- data.frame(\n  n = n_seq,\n  estimador = estimadores\n)\n\n# Graficar\nlibrary(ggplot2)\nggplot(df_estimacion, aes(x = n, y = estimador)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_hline(yintercept = theta_real, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = expression(\"Convergencia de \" * hat(theta)[n] * \" al valor real \" * theta),\n    x = \"Tama√±o de muestra (n)\",\n    y = expression(hat(theta)[n])\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#convergencia-del-estimador-plug-in-en-la-distribuci√≥n-uniforme",
    "href": "chapter2.html#convergencia-del-estimador-plug-in-en-la-distribuci√≥n-uniforme",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.4 üìä Convergencia del estimador plug-in en la distribuci√≥n uniforme",
    "text": "3.4 üìä Convergencia del estimador plug-in en la distribuci√≥n uniforme\nEn este ejemplo, estimamos el par√°metro () de una distribuci√≥n (X (0, )) usando el estimador (_n = (X_i)). Este es un estimador tipo plug-in: se usa la distribuci√≥n emp√≠rica para estimar una caracter√≠stica de la distribuci√≥n te√≥rica.\nA continuaci√≥n, simulamos c√≥mo este estimador converge al verdadero valor (= 10) a medida que el tama√±o de muestra (n) crece.\n\n# Chunk de R ‚Äî solo c√≥digo\n#| label: fig-convergencia-max\n#| fig-cap: 'Convergencia del estimador plug-in $ \\hat{\\theta}_n = \\max X_i $ hacia el valor real $ \\theta = 10 $'\n#| fig-align: center\n#| message: false\n#| warning: false\n\nset.seed(42)\ntheta_real &lt;- 10\n\n# Vector de tama√±os de muestra crecientes\nn_seq &lt;- seq(5, 200, by = 5)\n\n# Calcular el estimador para cada n\nestimadores &lt;- sapply(n_seq, function(n) {\n  muestra &lt;- runif(n, min = 0, max = theta_real)\n  max(muestra)\n})\n\n# Crear data frame para graficar\ndf_estimacion &lt;- data.frame(\n  n = n_seq,\n  estimador = estimadores\n)\n\n# Graficar\nlibrary(ggplot2)\nggplot(df_estimacion, aes(x = n, y = estimador)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_hline(yintercept = theta_real, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = expression(\"Convergencia de \" * hat(theta)[n] * \" al valor real \" * theta),\n    x = \"Tama√±o de muestra (n)\",\n    y = expression(hat(theta)[n])\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#m√©todo-de-momentos",
    "href": "chapter2.html#m√©todo-de-momentos",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.4 M√©todo de momentos",
    "text": "3.4 M√©todo de momentos\nUna aplicaci√≥n del principio de sustituci√≥n es la definici√≥n de los estimadores basados en momentos. El momento no centrado de orden \\(k\\) de una variable aleatoria \\(X\\) con distribuci√≥n \\(F\\) se define como \\[\n\\begin{align}\n\\mu_k=E_F(X^k)=\\int x^kdF(x)\n    \\end{align}\n\\] Si \\(X_e\\) es una variable aleatoria con funci√≥n de distribuci√≥n igual a \\(F_n\\) , la funci√≥n de distribuci√≥n emp√≠rica de una m.a.s. de tama√±o \\(n\\) de \\(X\\), se tiene que sus (a los que llamaremos \\(m_{k,n}\\)) son de la forma \\[\\begin{align}\n    m_{k,n}=E_{F_n}(X_e^k)=\\int x^kdF_n(x)=\\frac{1}{n}\\sum_{i=1}^{n}X_i^k,\n    \\end{align}\\] y se denominan momentos muestrales no centrados de orden \\(k\\). Por ejemplo, \\(¬µ_1\\) es la esperanza poblacional y \\(m_{1,n}\\) la media muestral.\nLa siguiente proposici√≥n garantiza que los momentos muestrales convergen a los poblacionales.\n\nProposition 3.1 Sea \\(X\\) variable aleatoria con \\(E(X^{2k}) &lt; \\infty\\). Entonces se verifica que \\(m_{k,n} \\rightarrow \\mu_k\\) casi seguro. Adem√°s, \\[\n\\begin{align}\n\\frac{\\sqrt{n}(m_{k,n}-\\mu_k)}{\\sqrt{\\mu_{2k}-\\mu_k^2}}\\xrightarrow{d}Z,\n\\end{align}\n\\] con \\(Z\\sim N(0,1)\\).\n\n\nProof. Si \\(Y_i=X_i^k\\) entonces \\(m_{k,n}=E_{k,n}(Y_i)=E_{n}(X_i^k)=\\frac{1}{n}\\sum_{i=1}^{n}X_i^k=\\frac{1}{n}\\sum_{i=1}^{n}Y_i=\\bar{Y}_n\\).\\\nAplicando la ley fuerte de los grandes n√∫meros se tiene que \\[\\begin{align}\n\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}&=\\lim _{n\\to \\infty }\\frac{\\sum_{i=1}^{n}X_i^k-E(\\sum_{i=1}^{n}X_i^k)}{n}\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\frac{\\sum_{i=1}^{n}X_i^k}{n}-\\frac{E(\\sum_{i=1}^{n}X_i^k)}{n}\\right]\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\bar{Y}_n-\\frac{\\sum_{i=1}^{n}E(X_i^k)}{n}\\right]\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\bar{Y}_n-\\frac{nE(X^k)}{n}\\right]\\mbox{Por ser las $X_i$ una mas de X}\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\bar{Y}_n-\\bar{Y}\\right]=0   \\mbox{ Aplicando L.F.G.N}\n\\end{align}\\]\nPor lo anterior, se tiene que \\(m_{k,n}=\\bar{Y}_n\\xrightarrow{c.s} \\mu_k=\\bar{Y}=E_F(X^k)\\). Por otro lado, veamos \\[\\begin{align}\n\\frac{S_n-E(S_n)}{\\sqrt{Var(S_n)}}=\\frac{m_{k,n}-E(X^k)}{\\sqrt{\\frac{Var(X^k)}{n}}}\\xrightarrow{d}Z\n\\end{align}\\] donde \\(S_n=\\sum_{i=1}^{n}X_i^k\\). Sabemos que \\(E(X^k)=\\mu_k\\) y que \\(Var(X^k)=E[(X^k)^2]-[E(X^k)]^2=\\mu_{2k}-\\mu_k^2\\), de ah√≠ se sigue el resultado.\n\nMuchas caracter√≠sticas poblacionales de inter√©s se pueden expresar como funci√≥n de los momentos no centrados de √≥rdenes \\(1,\\ldots, k\\): \\(\\theta=h(\\mu_1, \\ldots, \\mu_k)\\). Por ejemplo, la varianza de \\(X\\) se expresa como \\(\\sigma^2 = h(\\mu_1, \\mu_2) = \\mu_2-\\mu_1^2\\).\nEl estimador de \\(\\theta\\) basado en el principio de sustituci√≥n se conoce como estimador de los momentos de \\(\\theta\\) y ser√° \\[\\begin{align}\n\\hat{\\theta}_n = h(m_{1,n} ,\\ldots, m_{k,n}).\n    \\end{align}\\] Obs√©rvese que el estimador de los momentos de \\(\\theta\\) puede no ser √∫nico, porque diferentes funciones \\(h\\) pueden conducir al mismo valor \\(\\theta\\).\n\nProposition 3.2 Consideremos la variable aleatoria \\(X\\) con \\(E(X_{2k})&lt; \\infty\\). Sea \\(\\theta=h(\\mu_{n} ,\\ldots, \\mu_{n})\\). Si \\(h\\) es continua en \\((\\mu_{n} ,\\ldots, \\mu_{n})\\), entonces \\(\\hat{\\theta}_n=h(m_{1,n} ,\\ldots, m_{k,n})\\) converge a \\(\\theta\\) casi seguro. Adem√°s, si \\(h\\) es derivable en \\((\\mu_{n} ,\\ldots, \\mu_{n})\\), entonces la distribuci√≥n l√≠mite de \\(\\hat{\\theta}_n\\) es normal: \\[\\begin{align}\n\\sqrt{n}(\\hat{\\theta}_n-\\theta)\\xrightarrow{d} N(0, \\sigma_{h,\\theta}^2)\n\\end{align}\\]\n\n\nExample 3.1 Sea \\(X\\sim U(0,\\theta)\\). Se toma una m.a.s. de \\(X\\) de tama√±o n para estimar \\(\\theta\\). Un estimador de momentos \\(\\hat{\\theta}_M\\) de \\(\\theta\\) viene dado por la siguiente relaci√≥n \\[\\begin{align}\n    E(X)=\\frac{\\theta}{2}\\Longrightarrow m_{1,n}=\\frac{\\hat{\\theta}_M}{2}\\Longrightarrow 2m_{1,n}=\\hat{\\theta}_M\\Longrightarrow 2\\bar{X}=\\hat{\\theta}_M\n    \\end{align}\\]\n\n\nExample 3.2 ¬†\nPara la variable aleatoria \\(X\\) con varianza finita, un estimador para \\(\\theta=Var(X)\\) es \\[\\begin{align}\n\\hat{\\theta}=h(m_{1,n}, m_{2,n})&=m_{2,n}-m_{1,n}^2\\nonumber\\\\\n&=\\frac{1}{n}\\sum_{i=1}^{n}x_i^2-\\bar{x}^2\\nonumber\\\\\n&=\\frac{\\sum_{i=1}^{n}x_i^2-n\\bar{x}^2}{n}\\nonumber\\\\\n&=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n}\\nonumber\\\\\n&=\\frac{(n-1)S_n^2}{n}\\nonumber\\\\\n\\end{align}\\]\n\n\nExample 3.3 ¬†\nSi \\(X\\sim Exp(\\lambda)\\) con \\(E(X)=\\frac{1}{\\lambda}\\), entonces \\(m_{1,n}=\\frac{1}{\\hat{\\lambda}_M}\\) \\(\\Longrightarrow \\hat{\\lambda}_M=\\frac{1}{m_{1,n}}\\Longrightarrow \\hat{\\lambda}_M=\\frac{1}{\\bar{X}}\\).\nSi \\(X\\sim B(n,p)\\), con \\(E(X)=np\\) y \\(Var(X)=npq\\), entonces \\(m_{1,n}=n\\hat{p}\\) \\(\\Longrightarrow\\) \\(\\frac{m_{1,n}}{n}=\\hat{p}\\) \\(\\Longrightarrow\\) \\(\\frac{\\bar{X}}{n}=\\hat{p}\\) \\(\\Longrightarrow\\) \\(\\hat{Var(X)}=n\\hat{p}(1-\\hat{p})\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "index.html#variable-aleatoria",
    "href": "index.html#variable-aleatoria",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.4 VARIABLE ALEATORIA",
    "text": "1.4 VARIABLE ALEATORIA\n\n1.4.1 Variables y vectores aleatorios\nConsideramos un experimento aleatorio cuyos resultados pertenecen al espacio muestral Œ©. Modelamos este proceso suponiendo que existe una terna \\((\\Omega, \\mathcal{A}, P),\\) donde:\n\n\n\\(\\Omega\\) es el espacio muestra,\n\n\n\\(\\mathcal{P}(\\Omega)\\) es el conjunto de partes de Œ©,\n\n\n\\(\\mathcal{A}\\in\\mathcal{P}(\\Omega)\\) es una œÉ-√°lgebra,\n\n\n\\(P\\colon \\mathcal{A} \\to [0,1]\\) es una medida de probabilidad que refleja las caracter√≠sticas aleatorias del experimento realizado.\n\nA esta terna se le llama espacio de probabilidad.\nLos resultados de un experimento aleatorio no son analizados ‚Äúen bruto‚Äù, sino que se les da una representaci√≥n num√©rica que facilita su tratamiento. Esto se logra introduciendo variables aleatorias, que asocian cada resultado \\(\\omega\\in \\Omega\\) con un valor num√©rico o vectorial, y sobre las cuales luego aplicamos t√©cnicas de inferencia estad√≠stica.\nEn todo estudio estad√≠stico partimos de un experimento aleatorio cuyo conjunto de resultados posibles se denomina espacio muestral Œ©. Para cuantificar dichos resultados definimos las siguientes estructuras:\n\nDefinition 1.1 (Variables Aleatorias) Sea \\((\\Omega,\\mathcal{A},P)\\) un espacio de probabilidad. Una variable aleatoria es una funci√≥n \\(X\\colon (\\Omega,\\mathcal{A})\\;\\longrightarrow\\; (\\mathbb{R},\\mathcal{B}),\\) tal que para todo \\(B\\in\\mathcal{B}\\) (la \\(\\sigma\\)-√°lgebra de Borel en ‚Ñù), \\(X^{-1}(B)\\;=\\;\\{\\omega\\in\\Omega : X(\\omega)\\in B\\}\\;\\in\\;\\mathcal{A}.\\)\n\nSi el espacio muestral \\(\\Omega\\) es finito o numerable, diremos que es un espacio discreto y las variables aleatorias asociadas al experimento normalmente estar√°n definidas como \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{Z}.\\)\nSi \\(\\Omega\\) es no numerable, entonces diremos que es un espacio continuo y \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{R}.\\)\n\n\nDefinition 1.2 Un vector aleatorio de dimensi√≥n \\(n\\) es \\(\\mathbf{X} = (X_1,\\dots,X_n)\\colon(\\Omega,\\mathcal{A})\\longrightarrow(\\mathbb{R}^n,\\mathcal{B}^n),\\) donde cada componente \\(X_i\\) es variable aleatoria y \\(\\mathcal{B}^n\\) la \\(\\sigma\\)-√°lgebra de Borel en ‚Ñù‚Åø.\n\n\nEjemplos Lanzamiento de dos monedas\nSea \\(\\Omega =\\{\\,CC,\\;C-,\\;-C,\\;--\\},\\) donde \\(C\\) = ‚Äúcara‚Äù y \\(-\\) = ‚Äúcruz‚Äù. Podemos definir:\\(X_1(\\omega) = \\text{n√∫mero de caras en }\\omega.\\) \\(X_2(\\omega) = 2 - X_1(\\omega)\\;=\\; \\text{n√∫mero de cruces}.\\) \\(X_3(\\omega) = \\bigl(X_1(\\omega)\\bigr)^2.\\)\nEntonces \\((X_1,X_2,X_3)\\) es un vector aleatorio de dimensi√≥n 3.\nTiempos de servicio en un servidor\nSean \\(T_i\\) los tiempos de servicio (en segundos) de las peticiones \\(i=1,2,3\\). Definimos\\(\\mathbf{T}=(T_1,T_2,T_3),\\quad S = T_1 + T_2 + T_3,\\quad M = \\max\\{T_1,T_2,T_3\\}.\\)\nLecturas de sensores en red distribuida\nEn tres nodos \\(i=1,2,3\\) medimos temperatura \\(X_{i,1}\\), presi√≥n \\(X_{i,2}\\) y humedad \\(X_{i,3}\\). El vector global es \\(\\mathbf{X} = (X_{1,1},X_{1,2},X_{1,3},\\,X_{2,1},\\dots,X_{3,3}) \\in \\mathbb{R}^9.\\)\n\nCon estas definiciones rigurosas disponemos ya de los objetos b√°sicos para, en las siguientes secciones, construir estimadores, estudiar su comportamiento asint√≥tico y contrastar hip√≥tesis sobre la distribuci√≥n subyacente \\(P\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "index.html#datos-y-modelos",
    "href": "index.html#datos-y-modelos",
    "title": "Inferencia Estad√≠stica",
    "section": "\n1.3 DATOS Y MODELOS",
    "text": "1.3 DATOS Y MODELOS\nEn esta secci√≥n establecemos la base conceptual para el an√°lisis estad√≠stico, diferenciando claramente entre el fen√≥meno aleatorio observado y la medida de probabilidad que lo describe.\n\n1.3.1 Fen√≥meno aleatorio y variable observada\n‚ÄúSe observa una realizaci√≥n de un fen√≥meno aleatorio, digamos X. Este puede ser un elemento aleatorio de varios tipos: n√∫mero (variable aleatoria), un vector de dimensi√≥n finita (vector aleatorio), una funci√≥n, etc.\nLa premisa principal es que el car√°cter aleatorio de X se concibe como una realizaci√≥n de un fen√≥meno aleatorio que tiene una distribuci√≥n de probabilidad P, donde la distribuci√≥n P es desconocida ya sea en su totalidad o en alg√∫n detalle espec√≠fico (por ejemplo, su soporte, su media, etc.). Es de inter√©s conocer P. Si la medida de probabilidad P fuese conocida, entonces no hay problema estad√≠stico propiamente, pues el problema estad√≠stico tiene que ver con inferir la propiedad desconocida de P con base en X.‚Äù [Ver referencia 1]\n\n\nDefinici√≥n de X\n\n\nX puede ser un valor real \\(X \\in \\mathbb{R}\\), un vector en \\(\\mathbb{R}^n\\), o incluso una funci√≥n \\(\\;X: [0,1]\\to\\mathbb{R}\\).\n\n\n\n\nMedida de probabilidad P\n\nDesconocida: soporte, media, varianza, etc.\n\nObjetivo estad√≠stico: inferir caracter√≠sticas de (P) a partir de la muestra (la realizaci√≥n de X).\n\n\n\n1.3.2 Incertidumbre inductiva vs.¬†estoc√°stica\n‚ÄúLa observaci√≥n X est√° dada, por lo que no hay incertidumbre tal como la hay en la teor√≠a de probabilidad desarrollada anteriormente en el curso. Antes, fue concebida una estructura \\((\\Omega, \\mathcal{F}, P)\\) para enfrentar el que haya incertidumbre acerca del valor de X. En el problema estad√≠stico, el valor de X ha sido observado, y la incertidumbre radica en otro punto: radica en que existe duda acerca de cu√°l P es la que produjo el valor X. En algunas ocasiones se utilizan los t√©rminos incertidumbre estoc√°stica e incertidumbre inductiva para distinguir estos dos tipos. Es com√∫n que estos se confundan entre s√≠, porque en estad√≠stica matem√°tica la teor√≠a de probabilidad constituye tambi√©n una de las maneras naturales de afrontar la cuantificaci√≥n de incertidumbre inductiva. En cualquier caso, el concebir a P como medida de probabilidad es la base para formular soluciones a la incertidumbre inductiva. Con este lenguaje, probabilidad y estad√≠stica son problemas diferentes y de cierta manera inversos. Teor√≠a de probabilidad tiene que ver con cuantificar incertidumbre acerca de X y teor√≠a estad√≠stica con cuantificar incertidumbre acerca de P a la luz de haber ya observado X.‚Äù[Ver referencia 1]\n\n\nIncertidumbre estoc√°stica: duda previa sobre el valor de X, modelada por \\((\\Omega,\\mathcal{F},P)\\).\n\n\nIncertidumbre inductiva: tras observar X, la incertidumbre se desplaza a la ley generadora P.\n\n\n\n1.3.2.1 Ejemplos en Matem√°tica Aplicada e Ingenier√≠a de Sistemas\n\n\nModelado de tiempos de respuesta en redes\n\n\n\\(X\\): tiempo de llegada de paquetes (variable continua).\n\n\n\\(P\\): distribuci√≥n de retardo desconocida; objetivo: estimar par√°metros de una ley de colas M/M/1.\n\n\n\nEstimaci√≥n de par√°metros en ecuaciones diferenciales estoc√°sticas\n\n\n\\(X(t)\\): trayectoria observada de un proceso de It√¥.\n\n\n\\(P\\): ley del proceso (por ejemplo, coeficientes de difusi√≥n y deriva), inferidos a partir de trayectorias discretas.\n\n\n\nCalibraci√≥n de sensores en sistemas de control\n\n\n\\(X\\): lecturas del sensor (vector aleatorio).\n\n\n\\(P\\): distribuci√≥n conjunta desconocida de ruido; se estima para dise√±ar filtros de Kalman √≥ptimos.\n\n\n\n\nCon esta distinci√≥n clara entre dato observado y modelo probabil√≠stico, estamos listos para construir estimadores y desarrollar la inferencia estad√≠stica en las secciones siguientes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>INTRODUCCI√ìN</span>"
    ]
  },
  {
    "objectID": "chapter2.html#estimadores-de-m√°xima-verosimilitud",
    "href": "chapter2.html#estimadores-de-m√°xima-verosimilitud",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.5 Estimadores de m√°xima verosimilitud",
    "text": "3.5 Estimadores de m√°xima verosimilitud",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#c√°lculo-del-estimador-m√°ximo-veros√≠mil",
    "href": "chapter2.html#c√°lculo-del-estimador-m√°ximo-veros√≠mil",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.6 C√°lculo del estimador m√°ximo veros√≠mil",
    "text": "3.6 C√°lculo del estimador m√°ximo veros√≠mil\nSea \\(\\underset{\\sim}{X} =(X_1,\\ldots, X_n)\\) una muestra aleatoria simple de una variable aleatoria \\(X\\) con funci√≥n de densidad (o de masa de probabilidad) \\(f(\\underset{\\sim}{x}|\\theta)\\), con \\(\\theta = (\\theta_1,\\ldots,\\theta_k) \\in \\Theta \\subseteq \\mathbb{R}^k\\) . Sea \\(\\mathcal{X}\\) el espacio muestral, es decir, el conjunto de todos los posibles valores de \\(\\underset{\\sim}{X}\\) . Hemos definido la para \\(\\underset{\\sim}{x} =(x_1,\\ldots, x_n )\\in \\mathcal{X}\\) como \\[\n    \\begin{align}\n    L(\\cdot|\\underset{\\sim}{x}):&\\Theta\\rightarrow \\mathbb{R}^+\\nonumber\\\\\n    &\\theta\\rightarrow L(\\theta|\\underset{\\sim}{x})=f(\\underset{\\sim}{x}|\\theta)=\\prod_{i=1}^{n}f(x_i|\\theta)\n    \\end{align}\n\\]\n\n3.6.1 Preguntas sobre \\(X\\)\n\nPara cada muestra \\(\\underset{\\sim}{x} \\in \\underset{\\sim}{X}\\) , el estimador de m√°xima verosimilitud \\(\\hat{\\theta}\\) de \\(\\theta\\) es el valor de \\(\\Theta\\) que hace m√°xima la verosimilitud \\(L(\\cdot|\\underset{\\sim}{x})\\): \\[\n\\begin{align}\nL(\\hat{\\theta}| \\underset{\\sim}{x} ) = \\max_{\\theta \\in \\Theta} L(\\theta|\\underset{\\sim}{x}).\n\\end{align}\n\\] Intuitivamente \\(\\hat{\\theta}\\) es el valor del par√°metro que hace m√°s veros√≠mil la muestra observada. Veremos m√°s adelante que los estimadores de m√°xima verosimilitud son muy buenos estimadores y que en general tienen propiedades de optimalidad. Adem√°s, en muchas ocasiones el estimador m√°ximo veros√≠mil es el que el sentido com√∫n nos llevar√≠a a proponer.\n\nExample 3.4 Si \\(X\\sim Exp(\\lambda)\\Longrightarrow f(x|\\lambda)=\\lambda\\exp\\{-\\lambda x\\}I_{[0,\\infty)}(x)\\), \\(\\lambda&gt;0\\)\nSe toma una muestra de tama√±o \\(n=1\\) y se observa que \\(x=3\\). Estudiamos la funci√≥n de verosimilitud \\(L(\\lambda|3)=\\lambda\\exp\\{-3\\lambda\\}\\) y buscamos su m√°ximo para \\(\\lambda&gt;0\\).\nBuscamos los valores de \\(\\lambda\\) que hacen la derivada cero de \\(L(\\lambda|3)\\): \\[  \n\\begin{align}\n\\label{maxver_exp}\nL^{'}(\\lambda|3)&=\\exp\\{-3\\lambda\\}(1-3\\lambda)\n\\end{align}\n\\tag{3.1}\\] Igualando a cero la expresi√≥n (Equation¬†3.1) se tiene que \\(\\lambda=\\frac{1}{3}\\). Como \\(L^{'}(\\lambda|3)\\geq 0\\) y \\[\n\\begin{align}\n\\lim _{\\lambda\\to 0}L(\\lambda|3)=\\lim _{\\lambda\\to \\infty}L(\\lambda|3)=0\n\\end{align}\n\\] Se sigue que el punto cr√≠tico de \\(L(\\lambda|3)\\) es un m√°ximo. As√≠, \\(\\hat{\\lambda}=\\frac{1}{3}\\)\n\n\nExample 3.5 Suponga que deseamos estimar \\(\\theta\\), la proporci√≥n de personas con tuberulosis en una gran poblaci√≥n homog√©nea. Para hacer esto, seleccionamos de manera aleatoria \\(n\\) personas para hacer pruebas y encontrar \\(x\\) de estos que tienen la enfermedad.\nYa que la poblaci√≥n es grande y homog√©nea, asumimos que los \\(n\\) individuos observados son independiente y que cada uno tiene probabilidad \\(\\theta\\) de tener tuberculosis.\nSi \\(E\\) es el evento tiene tuberculosis \\[\n\\begin{align}\nP(E;\\theta)&=P(\\mbox{x entre n tienen tuberculosis})\\nonumber\\\\\n&=\\binom{n}{x}\\theta^x(1-\\theta)^{n-x}\n\\end{align}\n\\tag{3.2}\\] Observe que \\(\\binom{n}{x}\\) es un factor constante no tendr√° efecto sobre la maximizaci√≥n de la expresi√≥n (Equation¬†3.2) sobre \\(\\theta\\), ver (kalbfleisch et al.¬†(1985)). La funci√≥n de verosimilitud de \\(\\theta\\) es definida como sigue: \\[\n\\begin{align}\nL(\\theta)=cP(E;\\theta)\n\\end{align}\n\\tag{3.3}\\] Ac√° \\(c\\) es alguna constante positiva con respecto a \\(\\theta\\); esto es, \\(c\\) no es funci√≥n de \\(\\theta\\), sin embargo esta debe ser funci√≥n de los datos. Escogemos \\(c\\) para obtener una expresi√≥n simple para \\(L(\\theta)\\), y resultados subsecuentes no depender√°n de la escogencia espec√≠fica hecha.\nUsualmente \\(P(E;\\theta)\\) y \\(L(\\theta)\\) son productos de t√©rminos y ser√° m√°s conveniente trabajar con logaritmos. La funci√≥n logverosimilitud es el logaritmo de \\(L\\):\n\\[\n\\begin{align}\nl(\\theta)=log L(\\theta)\n\\end{align}\n\\tag{3.4}\\] Observe que, por (Equation¬†3.3) \\[\n\\begin{align}\nl(\\theta)=c^{'}+log P(E;\\theta)\n\\end{align}\n\\tag{3.5}\\] donde \\(c^{'}=log c\\) no es una funci√≥n de \\(\\theta\\).\nPor la expresi√≥n (Equation¬†3.2) se tiene que\n\\[\n\\begin{align}\nc=\\frac{1}{\\binom{n}{x}},\n\\end{align}\n\\] entonces \\[\n\\begin{align}\nL(\\theta)=\\theta^x(1-\\theta)^{n-x}, \\mbox{para } 0\\leq\\theta\\leq1\n\\end{align}\n\\tag{3.6}\\] La funci√≥n de log verosimilitud es ahora \\[\n\\begin{align}\nl(\\theta)=xlog(\\theta)+(n-x)log(1-\\theta), \\mbox{para } 0\\leq\\theta\\leq1\n\\end{align}\n\\tag{3.7}\\] El estimador de m√°xima verosimilitud (MDL) \\(\\hat{\\theta}\\) es el valor de \\(\\theta\\) el cual maximiza \\(l(\\theta)\\).\nTomando la derivada respecto a \\(\\theta\\) de (Equation¬†3.4) se tiene que \\[\n    \\begin{align}\n    S(\\theta)&=\\frac{dl(\\theta)}{d\\theta}\\nonumber\\\\\n    &=\\frac{x}{\\theta}-\\frac{n-x}{1-\\theta}\n    \\end{align}\n\\tag{3.8}\\] Haciendo cero a \\(S(\\theta)\\) tiene una √∫nica soluci√≥n \\(\\theta=\\frac{x}{n}\\), para \\(1\\leq x\\leq n-1\\). Bajo estas mismas condiciones tomamos la segunda derivada y la multiplicamos por \\(-1\\) en la siguiente expresi√≥n\n\\[\n\\begin{align}\n\\mathscr{I}(\\theta)&=-\\frac{dS(\\theta)}{d\\theta}\\nonumber\\\\\n&=\\frac{x}{\\theta^2}+\\frac{n-x}{(1-\\theta)^2}\n\\end{align}\n\\tag{3.9}\\]\nYa que \\(\\mathscr{I}(\\theta)&gt;0\\) en \\(\\theta=\\frac{x}{n}\\), la funci√≥n de verosimilitud tiene un m√°ximo relativo en \\(\\theta=\\frac{x}{n}\\). M√°s a√∫n, \\(L(\\theta)=0\\) para \\(\\theta=0\\) y para \\(\\theta=1\\), hemos encontrado con esto un m√°ximo global en \\(\\hat{\\theta}=\\frac{x}{n}\\).\nA las funciones \\(S(\\theta)\\) y \\(\\mathscr{I}(\\theta)\\) definidas en (Equation¬†3.8}) y (Equation¬†3.9), se les llama funci√≥n Score y funci√≥n de informaci√≥n respectivamente.\n\n\n3.6.2 Principio de invarianza del estimador m√°ximo veros√≠mil\nSea \\(X_1,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim f(x|\\theta)\\) y sea \\(\\hat{\\theta}\\) el estimador m√°ximo veros√≠mil de \\(\\theta\\). Si estamos interesados en estimar una funci√≥n \\(\\tau(\\theta)\\) del par√°metro, podemos hacerlo mediante \\(\\tau(\\hat{\\theta})\\). √âste es el resultado que garantiza el siguiente teorema y se conoce como principio de invariancia.\n\nTheorem 3.3 Si \\(\\hat{\\theta}\\) es el estimador de m√°xima verosimilitud de \\(\\theta\\), entonces para cualquier funci√≥n \\(\\tau\\) el estimador de m√°xima verosimilitud de \\(\\tau(\\theta)\\) es \\(\\tau(\\hat{\\theta})\\).\n\n\nExample 3.6 Sea \\(X_1,\\ldots,X_n\\) una m.a.s de \\(X\\sim N(\\mu,\\sigma^2)\\). Podemos probar que el estimador de m√°xima verosimilitud para \\(\\mu\\), \\(\\hat{\\mu}=\\bar{X}\\). ¬øCu√°l es el estimador de m√°xima verosimilitud de \\(\\theta_1=3\\mu\\), \\(\\theta_2=\\mu^2\\) y \\(\\theta_3=1/\\mu\\)?\nPor el principio de invarianza tenemos que \\(\\hat{\\theta_1}=3\\bar{X}\\), \\(\\hat{\\theta_2}=\\bar{X}^2\\) y \\(\\hat{\\theta_3}=\\frac{1}{\\bar{X}}\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#referencias",
    "href": "chapter2.html#referencias",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.13 Referencias",
    "text": "3.13 Referencias\n\nG√≥mez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisi√≥n. Departament d‚ÄôEstad√≠stica i Investigaci√≥ Operativa, Universitat Polit√®cnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estad√≠stica matem√°tica con aplicaciones (7¬™ ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.\nKalbfleisch, J. G. Probability and Statistical Inference. Springer-Verlag, 1985.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#error-cuadr√°tico-medio",
    "href": "chapter2.html#error-cuadr√°tico-medio",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.7 Error cuadr√°tico medio",
    "text": "3.7 Error cuadr√°tico medio\nUna vez se han presentado diferentes m√©todos de estimaci√≥n surge la necesidad de desarrollar criterios para evaluarlos y compararlos de acuerdo a estos criterios. En este tema estudiaremos medidas de la calidad de un estimador. Lo haremos primero para muestras finitas para pasar despu√©s a proponer medidas asint√≥ticas de calidad.\nSe define el error cuadr√°tico medio (ECM) de un estimador \\(W\\) de un par√°metro \\(\\theta\\) como \\[\n\\begin{align}\n    E_\\theta((W-\\theta)^2)\n\\end{align}\n\\] √âsta es una medida intuitiva del comportamiento de un estimador: cuanto menor sea el error cuadr√°tico medio mejor ser√° el estad√≠stico \\(W\\). De hecho, para cualquier funci√≥n \\(\\phi\\) creciente con \\(\\phi(0) = 0\\), \\(E_\\theta(\\phi(|W- \\theta|))\\) es una medida razonable de lo alejadas que estar√°n, en promedio, las estimaciones de \\(\\theta\\) que proporcione W.\nEn general, se prefiere el error cuadr√°tico medio a otras medidas por ser m√°s tratable anal√≠ticamente. Adem√°s el error cuadr√°tico medio puede descomponerse \\[\\begin{align}\nE_\\theta((W-\\theta)^2)&=E_\\theta((W-E_\\theta(W))^2)+E_\\theta((E_\\theta(W)-\\theta)^2)\\nonumber\\\\\n&=Var_\\theta(W)+(B_\\theta(W))^2\n\\end{align}\\] El t√©rmino \\(B_\\theta(W) = E_\\theta(W)-\\theta\\) se llama (en ingl√©s bias) de \\(W\\) cuando se estima \\(\\theta\\) y es una medida de la desviaci√≥n sistem√°tica que se tiene cuando se estima \\(\\theta\\) por \\(W\\). Si un estimador tiene sesgo nulo para cualquier valor del par√°metro se dice que es un estimador insesgado. En tal caso, \\(E_\\theta((W-\\theta)^2)=Var_\\theta(W)\\).\n\n3.7.1 Observaciones sobre el ECM\n\nAs√≠, el error cuadr√°tico medio de un estimador es la suma de su varianza (una medida de su dispersi√≥n) m√°s el cuadrado de su sesgo (medida de la desviaci√≥n sistem√°tica o de la exactitud del estimador).\nEs una medida conjunta de precisi√≥n y exactitud del estimador.\nPor lo tanto, parece sensato buscar estimadores que tengan error cuadr√°tico medio peque√±o, porque de esta manera controlaremos tanto la dispersi√≥n como la exactitud de las estimaciones.\n\n\n\nFigure¬†3.1: Comparaci√≥n entre precisi√≥n y exactitud\n\n\n\n\n\n(a) Exactitud vs precisi√≥n\n\n\n\n\n\n\n\n\n\n\n\n# install.packages(\"ggplot2\")  # si hace falta\nlibrary(ggplot2)\n\ntheta    &lt;- 0      # valor \"verdadero\"\nthetahat &lt;- 1.2    # estimaci√≥n\n\nx  &lt;- seq(theta - 3, thetahat + 3, length.out = 500)\ndf &lt;- data.frame(x = x,\n                 y = dnorm(x, mean = thetahat, sd = 0.9))\n\nggplot(df, aes(x, y)) +\n  geom_line(linewidth = 1.2) +\n  geom_hline(yintercept = 0, linewidth = 0.8) +\n  # marquitas en el eje para theta y theta-hat\n  geom_segment(aes(x = theta,    xend = theta,    y = 0, yend = max(y)*0.03),\n               inherit.aes = FALSE) +\n  geom_segment(aes(x = thetahat, xend = thetahat, y = 0, yend = max(y)*0.03),\n               inherit.aes = FALSE) +\n  annotate(\"text\", x = theta,    y = -max(df$y)*0.05, label = expression(theta)) +\n  annotate(\"text\", x = thetahat, y = -max(df$y)*0.05, label = expression(hat(theta))) +\n  labs(title = \"Distribuci√≥n de estimaciones\", x = NULL, y = NULL) +\n  coord_cartesian(ylim = c(-max(df$y)*0.08, max(df$y)*1.05), clip = \"off\") +\n  theme_classic(base_size = 14) +\n  theme(\n    axis.text.y  = element_blank(),\n    axis.ticks.y = element_blank(),\n    plot.margin  = margin(10, 20, 25, 20) # deja espacio para las etiquetas bajo el eje\n  )\n\nWarning in geom_segment(aes(x = theta, xend = theta, y = 0, yend = max(y) * : All aesthetics have length 1, but the data has 500 rows.\n‚Ñπ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in geom_segment(aes(x = thetahat, xend = thetahat, y = 0, yend = max(y) * : All aesthetics have length 1, but the data has 500 rows.\n‚Ñπ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\n\n\n\n\n\n\nEstimador de \\(\\theta\\) estar√° indicado por \\(\\hat{\\theta}\\).\nQuisieramos que \\(E(\\hat{\\theta})=\\theta\\).\nLa distribuci√≥n muestral para un estimador puntual sesgado positivamente, para el que \\(E(\\hat{\\theta})&gt;\\theta\\), se muestra en la siguiente figura\n\nlibrary(ggplot2)\n\n# --- Par√°metros editables ---\ntheta       &lt;- 0\nE_thetahat  &lt;- 0.5      # sesgo: centro de la densidad\nthetahat    &lt;- 1.2\nsd0         &lt;- 0.7      # dispersi√≥n\n# ----------------------------\n\n# Curva de densidad (normal centrada en E(\\hat{theta}))\nx_min &lt;- theta - 1.2\nx_max &lt;- thetahat + 1.2\nx  &lt;- seq(x_min, x_max, length.out = 800)\ny  &lt;- dnorm(x, mean = E_thetahat, sd = sd0)\ndf &lt;- data.frame(x, y)\nymax &lt;- max(y)\n\n# Alturas EXACTAS de las barras (tocar la curva)\ny_theta     &lt;- dnorm(theta,      mean = E_thetahat, sd = sd0)  # altura en theta\ny_Ethetahat &lt;- dnorm(E_thetahat, mean = E_thetahat, sd = sd0)  # pico\n\nggplot(df, aes(x, y)) +\n  geom_line(linewidth = 1.1, lineend = \"round\") +\n  # ejes \"a mano\"\n  annotate(\"segment\", x = x_min, xend = x_max, y = 0, yend = 0, linewidth = 0.8) +\n  annotate(\"segment\", x = x_min, xend = x_min, y = 0, yend = 1.05*ymax, linewidth = 0.8) +\n  # barra corta en theta (hasta la curva)\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = y_theta), inherit.aes = FALSE) +\n  # barra larga en E(thetahat) (hasta el pico)\n  geom_segment(aes(x = E_thetahat, xend = E_thetahat, y = 0, yend = y_Ethetahat),\n               inherit.aes = FALSE) +\n  # etiquetas bajo el eje x\n  annotate(\"text\", x = theta,      y = -0.06*ymax, label = expression(theta)) +\n  annotate(\"text\", x = E_thetahat, y = -0.06*ymax, label = expression(E(hat(theta)))) +\n  annotate(\"text\", x = thetahat,   y = -0.06*ymax, label = expression(hat(theta))) +\n  # etiqueta del eje y\n  annotate(\"text\",\n           x = x_min - 0.03*(x_max - x_min), y = 0.9*ymax,\n           label = expression(f(hat(theta))), angle = 90) +\n  labs(x = NULL, y = NULL) +\n  coord_cartesian(xlim = c(x_min, x_max),\n                  ylim = c(-0.10*ymax, 1.08*ymax), clip = \"off\") +\n  theme_void(base_size = 14) +\n  theme(plot.margin = margin(10, 20, 35, 45))\n\nWarning in geom_segment(aes(x = theta, xend = theta, y = 0, yend = y_theta), : All aesthetics have length 1, but the data has 800 rows.\n‚Ñπ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in geom_segment(aes(x = E_thetahat, xend = E_thetahat, y = 0, yend = y_Ethetahat), : All aesthetics have length 1, but the data has 800 rows.\n‚Ñπ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# ===== Panel (a): arco =====\n# soporte con ~5% a la izquierda y 95% a la derecha\nxL &lt;- -0.10\nxR &lt;-  2.10\ntheta     &lt;- (xL + xR)/2    # centro del arco: ah√≠ debe ir la barra\nthetahat1 &lt;- xR\n\n# definir el arco (semicircunferencia escalada)\nc_a  &lt;- (xL + xR)/2\nR_a  &lt;- (xR - xL)/2\nx_a  &lt;- seq(xL, xR, length.out = 700)\nhsca &lt;- 0.95\ny_a  &lt;- hsca * sqrt(pmax(0, R_a^2 - (x_a - c_a)^2))\ndfa  &lt;- data.frame(x = x_a, y = y_a)\nymax_a &lt;- max(dfa$y)\n\n# altura de la curva en theta\ny_theta &lt;- approx(x_a, y_a, xout = theta)$y\n\np_a &lt;-\n  ggplot(dfa, aes(x, y)) +\n  geom_line(linewidth = 1.2, lineend = \"round\") +\n  # ejes\n  annotate(\"segment\", x = xL-0.3, xend = xR+0.3, y = 0, yend = 0, linewidth = 0.8) +\n  annotate(\"segment\", x = 0, xend = 0, y = 0, yend = 1.05*ymax_a, linewidth = 0.8) +\n  # barra en el centro (theta)\n  geom_segment(aes(x = theta, xend = theta, y = 0, yend = y_theta), inherit.aes = FALSE) +\n  # etiquetas\n  annotate(\"text\", x = theta,     y = -0.08*ymax_a, label = expression(theta)) +\n  annotate(\"text\", x = thetahat1, y = -0.08*ymax_a, label = expression(hat(theta)[1])) +\n  annotate(\"text\", x = -0.15, y = 0.9*ymax_a,\n           label = expression(f(hat(theta)[1])), angle = 90) +\n  annotate(\"text\", x = (xL + xR)/2, y = -0.22*ymax_a, label = \"(a)\") +\n  coord_cartesian(xlim = c(xL-0.2, xR+0.2),\n                  ylim = c(-0.25*ymax_a, 1.1*ymax_a), clip = \"off\") +\n  theme_void(base_size = 14) +\n  theme(plot.margin = margin(10, 20, 40, 45))\n\n# ===== Panel (b): normal (sin cambios) =====\ntheta_b    &lt;- 1.00\nthetahat2  &lt;- 1.60\nsd_b       &lt;- 0.25\nx_b &lt;- seq(0, theta_b + 3.2*sd_b, length.out = 700)\ny_b &lt;- dnorm(x_b, mean = theta_b, sd = sd_b)\ndfb &lt;- data.frame(x = x_b, y = y_b)\nymax_b &lt;- max(dfb$y)\n\np_b &lt;-\n  ggplot(dfb, aes(x, y)) +\n  geom_line(linewidth = 1.2, lineend = \"round\") +\n  annotate(\"segment\", x = 0, xend = max(x_b)+0.3, y = 0, yend = 0, linewidth = 0.8) +\n  annotate(\"segment\", x = 0, xend = 0, y = 0, yend = 1.05*ymax_b, linewidth = 0.8) +\n  geom_segment(aes(x = theta_b, xend = theta_b, y = 0, yend = dnorm(theta_b, theta_b, sd_b)),\n               inherit.aes = FALSE) +\n  annotate(\"text\", x = theta_b,   y = -0.08*ymax_b, label = expression(theta)) +\n  annotate(\"text\", x = thetahat2, y = -0.08*ymax_b, label = expression(hat(theta)[2])) +\n  annotate(\"text\", x = -0.15, y = 0.9*ymax_b,\n           label = expression(f(hat(theta)[2])), angle = 90) +\n  annotate(\"text\", x = (min(x_b)+max(x_b))/2, y = -0.22*ymax_b, label = \"(b)\") +\n  coord_cartesian(xlim = c(0, max(x_b)+0.2),\n                  ylim = c(-0.25*ymax_b, 1.1*ymax_b), clip = \"off\") +\n  theme_void(base_size = 14) +\n  theme(plot.margin = margin(10, 20, 40, 45))\n\n# ===== Combinar =====\np_a | p_b\n\nWarning in geom_segment(aes(x = theta, xend = theta, y = 0, yend = y_theta), : All aesthetics have length 1, but the data has 700 rows.\n‚Ñπ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\nWarning in geom_segment(aes(x = theta_b, xend = theta_b, y = 0, yend = dnorm(theta_b, : All aesthetics have length 1, but the data has 700 rows.\n‚Ñπ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\n\n\n\n\n\n\nLa figura (b) es la distribuci√≥n deseada porque una varianza peque√±a garantiza que, en un muestreo repetido, una fracci√≥n m√°s alta de valores \\(\\hat{\\theta}_2\\) estar√° ``cerca‚Äô‚Äô de \\(\\theta\\).\nPor consiguiente, adem√°s de preferir un estimador insesgado, necesitamos que la varianza de la distribuci√≥n del estimador \\(V(\\hat{\\theta})\\) sea lo m√°s peque√±a posible. Dados dos estimadores insesgados de un par√°metro \\(\\theta\\) seleccionamos el estimador con la menor varianza, mientras todos los dem√°s parece igual.\n\nExample 3.7 Suponga que \\(Y_1,Y_2,Y_3\\) denotan una muestra aleatoria ind de una distribuci'on exponencial con funci'on de densidad \\[f(y)=\\left\\{\\begin{array}{ll}\\left(\\frac{1}{\\theta}\\right)e^{-y/\\theta},& y&gt;0,\\\\0,&\\mbox{ en cualquier otro punto}\\end{array}\\right.\\] Considere los siguientes estimadores de \\(\\theta\\): \\[\\hat{\\theta}_1=Y_1,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\hat{\\theta}_2=\\frac{Y_1+Y_2}{2},\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\hat{\\theta}_3=\\frac{Y_1+2Y_2}{3},\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\]\n\\[\\hat{\\theta}_4=\\min(Y_1,\\,Y_2,\\,Y_3),\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\hat{\\theta}_5=\\overline{Y}\\]\n\n¬øCu√°les son insesgados?\n\nSol: Determinemos si \\(\\hat{\\theta}_4=\\min(Y_1,\\,Y_2,\\,Y_3)\\) es insesgado. Para esto, determinemos la distribuci√≥n de \\(\\hat{\\theta}_4\\). Supongamos que \\(Y_i\\sim Exp(\\lambda_i)\\) con \\(i=1,2,3\\). \\[\n        \\begin{align}\n        P(\\hat{\\theta}_4&gt;a)&=P(\\min(Y_1,\\,Y_2,\\,Y_3)&gt;a)\\nonumber\\\\\n        &=P(Y_1&gt;a)P(Y_2&gt;a)P(Y_3&gt;a)\\nonumber\\\\\n        &=\\exp\\{-a\\lambda_1\\}\\exp\\{-a\\lambda_2\\}\\exp\\{-a\\lambda_3\\}\\nonumber\\\\\n        &\\exp\\left\\{-a\\left(\\sum_{i=1}^{3}\\lambda_i\\right)\\right\\}\n        \\end{align}\n\\] As√≠ que \\[\n\\begin{align}\nF_{\\hat{\\theta}_4}(a)&=1-P(\\hat{\\theta}_4&gt;a)\\nonumber\\\\\n&=1-\\exp\\left\\{-a\\left(\\sum_{i=1}^{3}\\lambda_i\\right)\\right\\}\n\\end{align}\n\\] De ah√≠ que \\(\\hat{\\theta}_4\\sim Exp\\left(\\sum_{i=1}^{3}\\lambda_i\\right)\\) entonces, \\(E(\\hat{\\theta}_4)=\\frac{1}{\\sum_{i=1}^{3}\\lambda_i}\\). Pero por hip√≥tesis \\(\\lambda_i=\\frac{1}{\\theta}\\), para todo \\(i=1,2,3\\). Luego,\n\n\\[\n\\begin{align}\n    E(\\hat{\\theta}_4)&=\\frac{1}{\\sum_{i=1}^{3}\\lambda_i}\\nonumber\\\\\n    &=\\frac{1}{3\\lambda} \\mbox{ por ser las $Y_i$ son iid}\\nonumber\\\\\n    &=\\frac{1}{\\frac{3}{\\theta}}\\nonumber\\\\\n    &=\\frac{\\theta}{3}\n    \\end{align}\n\\] Luego \\(\\hat{\\theta}_4\\) no es insesgado, es sesgado.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#eficiencia-relativa",
    "href": "chapter2.html#eficiencia-relativa",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.8 Eficiencia relativa",
    "text": "3.8 Eficiencia relativa\n\nDefinition 3.1 Un estimador \\(W\\) de \\(\\theta\\) se denomina inadmisible si existe otro estimador \\(V\\) de \\(\\theta\\) tal que \\[\n\\begin{align}\nE_\\theta((V-\\theta)^2)\\leq E_\\theta((W-\\theta)^2) \\mbox{ para todo $\\theta \\in \\Theta$}\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#mejor-estimador-insesgado.",
    "href": "chapter2.html#mejor-estimador-insesgado.",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.9 Mejor estimador insesgado.",
    "text": "3.9 Mejor estimador insesgado.\n\nDefinition 3.2 Sean \\(\\hat{\\theta}_1\\) y \\(\\hat{\\theta}_2\\) dos estimadores insesgados de un par√°metro \\(\\theta\\), con varianzas \\(V (\\hat{\\theta}_1)\\) y \\(V (\\hat{\\theta}_2)\\), respectivamente. Entonces la eficiencia de \\(\\hat{\\theta}_1\\) con respecto a \\(\\hat{\\theta}_2\\) denotada como \\(eff(\\hat{\\theta}_1,\\,\\hat{\\theta}_2)\\) se defiene por la expresi√≥n\n\\[eff (\\hat{\\theta}_1,\\, \\hat{\\theta}_2)=\\frac{V(\\hat{\\theta}_1)}{V(\\hat{\\theta}_2)}.\\]\n\n\nExample 3.8 Diremos que \\(\\hat{\\theta}_1\\) es m√°s eficiente que \\(\\hat{\\theta}_2\\) si \\[eff(\\hat{\\theta}_1,\\,\\hat{\\theta}_2)&lt;1\\mbox{ si y s√≥lo si }V(\\hat{\\theta}_2)&gt;V(\\hat{\\theta}_1)\\] luego \\(\\hat{\\theta}_1\\) es un mejor estimador insesgado que \\(\\hat{\\theta}_2\\).\n\n\nExample 3.9 Si \\(eff(\\hat{\\theta}_1,\\,\\hat{\\theta}_2)=1.8\\) entonces \\(V(\\hat{\\theta}_1)=1.8V(\\hat{\\theta}_2)\\) entonces \\(\\hat{\\theta}_2\\) se prefiere a \\(\\hat{\\theta}_1\\).\nSi \\(eff(\\hat{\\theta}_1,\\,\\hat{\\theta}_2)=0.73\\) entonces \\(V(\\hat{\\theta}_1)=0.73V(\\hat{\\theta}_2)\\) entonces \\(\\hat{\\theta}_1\\) se prefiere a \\(\\hat{\\theta}_2\\).\n\n\nTheorem 3.4 Teorema de Lehmann-Scheff√© Si \\(\\hat{\\theta}\\) es un estimador insesgado para \\(\\theta\\) y si \\(U\\) es un estad√≠stico suficiente para \\(\\theta\\), entonces hay una funci√≥n de \\(U\\) que tambi√©n es un estimador insesgado para \\(\\theta\\) y tiene una varianza no mayor que \\(\\hat{\\theta}\\).\nEn s√≠mbolos:\nSi \\(E(\\hat{\\theta})=\\theta\\) y \\(U\\) es suficiente para \\(\\theta\\) entonces existe una \\(f(U)\\) tal que \\[E(f(U))=\\theta\\] y \\[Var(\\hat{\\theta})\\geq Var(f(U))\\]\n\n\nExample 3.10 Contexto del teorema\nUn estimador insesgado de \\(\\theta\\) es una variable aleatoria \\(\\hat{\\theta}\\) que cumple:\n\\[\nE(\\hat{\\theta}) = \\theta.\n\\]\nUn estad√≠stico suficiente \\(U\\) para \\(\\theta\\) contiene toda la informaci√≥n de la muestra acerca de \\(\\theta\\). Es decir, dados \\(U\\), la muestra completa no aporta nada m√°s sobre \\(\\theta\\).\nEl Teorema de Lehmann‚ÄìScheff√© dice que si combinas estos dos elementos:\n\nUn estimador insesgado cualquiera \\(\\hat{\\theta}\\).\nUn estad√≠stico suficiente \\(U\\).\n\nEntonces puedes construir una funci√≥n de \\(U\\), digamos \\(f(U)\\), que:\n\ntambi√©n es insesgado,\ntiene varianza menor o igual a la de \\(\\hat{\\theta}\\).\n\nDe hecho, el resultado formal se apoya en el Teorema de Rao‚ÄìBlackwell:\n\\[\nf(U) = E(\\hat{\\theta} \\mid U).\n\\]\nEsta transformaci√≥n se llama Rao-Blackwellizaci√≥n.\nY el teorema de Lehmann‚ÄìScheff√© a√±ade que, si \\(U\\) adem√°s de suficiente es completo, entonces ese \\(f(U)\\) es el √∫nico estimador insesgado de varianza m√≠nima (UMVUE: Uniformly Minimum Variance Unbiased Estimator).\n\n2. Intuici√≥n\n\nEmpiezas con cualquier estimador insesgado \\(\\hat{\\theta}\\).\nSi ‚Äúcondicionas‚Äù en la estad√≠stica suficiente \\(U\\), eliminas ruido innecesario que no aporta informaci√≥n sobre \\(\\theta\\).\nEso reduce (o al menos no aumenta) la varianza del estimador.\nEl resultado es un estimador m√°s eficiente.\n\n\n3. Ejemplo cl√°sico\nContexto Supongamos que:\n\\[\nX_1, X_2, \\dots, X_n \\overset{iid}{\\sim} \\text{Bernoulli}(p),\n\\]\ndonde el par√°metro de inter√©s es \\(p\\).\n\nPaso 1: un estimador insesgado cualquiera\nConsideremos el estimador basado s√≥lo en el primer dato:\n\\[\n\\hat{p} = X_1.\n\\]\nClaramente:\n\\[\nE(\\hat{p}) = E(X_1) = p.\n\\]\nAs√≠ que es insesgado, pero muy ineficiente (usa un solo dato).\n\nPaso 2: estad√≠stico suficiente\nEl n√∫mero total de √©xitos:\n\\[\nU = \\sum_{i=1}^n X_i\n\\]\nes un estad√≠stico suficiente para \\(p\\) (por factorizaci√≥n de la verosimilitud).\n\nPaso 3: aplicar Rao‚ÄìBlackwell\nConstruimos:\n\\[\nf(U) = E(\\hat{p} \\mid U).\n\\]\nComo \\(\\hat{p} = X_1\\), necesitamos \\(E(X_1 \\mid U)\\).\nPor simetr√≠a, dado que hay \\(U\\) √©xitos en total entre \\(n\\) ensayos, cada \\(X_i\\) tiene la misma probabilidad de ser 1. Entonces:\n\\[\nE(X_1 \\mid U) = \\frac{U}{n}.\n\\]\nAs√≠:\n\\[\nf(U) = \\frac{U}{n}.\n\\]\n\nPaso 4: verificar propiedades\n\nInsesgado:\n\n\\[\nE\\left(\\frac{U}{n}\\right) = \\frac{1}{n}E(U) = \\frac{1}{n}(np) = p.\n\\]\n\nVarianza:\n\n\\[\nVar(X_1) = p(1-p),\n\\]\n\\[\nVar\\left(\\frac{U}{n}\\right) = \\frac{1}{n^2} Var(U) = \\frac{1}{n^2}(np(1-p)) = \\frac{p(1-p)}{n}.\n\\]\nY efectivamente:\n\\[\n\\frac{p(1-p)}{n} \\leq p(1-p).\n\\]\n\n4. Conclusi√≥n\nEl estimador inicial \\(\\hat{p} = X_1\\) era insesgado pero ineficiente.\nRao‚ÄìBlackwellizando con el suficiente \\(U\\), obtuvimos:\n\\[\nf(U) = \\frac{U}{n},\n\\]\nque es la media muestral.\nPor Lehmann‚ÄìScheff√©, como \\(U\\) es suficiente y completo, \\(\\bar{X} = U/n\\) es el UMVUE de \\(p\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#teorema-de-cram√©r-rao.-informaci√≥n-de-fisher",
    "href": "chapter2.html#teorema-de-cram√©r-rao.-informaci√≥n-de-fisher",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.10 Teorema de Cram√©r-Rao. Informaci√≥n de Fisher",
    "text": "3.10 Teorema de Cram√©r-Rao. Informaci√≥n de Fisher\n\nDefinition 3.3 Diremos que un estimador \\(W^{*}\\) es el mejor estimador insesgado de \\(\\tau(\\theta)\\), o el UMVUE (Uniformly Minimum Variance Unbiased Estimator) (estimador insesgado de \\(\\tau(\\theta)\\) uniformemente de m√≠nima varianza) , si \\(E_\\theta(W^{*}) = \\tau(\\theta)\\) para todo \\(\\theta\\in\\Theta\\) y si para cualquier otro estimador \\(W\\) , tal que \\(E_\\theta(W) = \\tau(\\theta)\\) para todo \\(\\theta\\in\\Theta\\), se tiene que \\(V_\\theta(W^{*}) \\leq V_\\theta(W)\\), para todo \\(\\theta\\in\\Theta\\).\n\nLa b√∫squeda del UMVUE no debe consistir en repasar todos los estimadores insesgados posibles. El siguiente resultado aborda el problema de un modo diferente: establece una cota inferior para la varianza de todos los estimadores insesgados de un par√°metro. As√≠, si encontramos un estimador insesgado cuya varianza iguale esa cota podremos concluir que ese estimador es el UMVUE.\n\nTheorem 3.5 Sea \\(\\underset{\\sim}{X} =(X_1,\\ldots, X_n)\\) una variable aleatoria n-dimensional con funci√≥n de densidad conjunta \\(f ( \\underset{\\sim}{x}|\\theta)\\), \\(\\theta\\in\\Theta\\subseteq\\mathbb{R}\\). Sea \\(W(\\underset{\\sim}{X} )\\) un estimador insesgado para \\(\\tau(\\theta)\\), es decir, \\(E_\\theta(W(\\underset{\\sim}{X})) = \\tau(\\theta)\\) para todo \\(\\theta\\), donde \\(\\tau\\) es una funci√≥n de \\(\\theta\\) que cumple:\nH1: \\(\\tau(\\theta)\\) es diferenciable en \\(\\theta\\).\nH2: Se supone adem√°s que la verosimilitud conjunta \\(f(\\underset{\\sim}{x}|\\theta)\\) verifica que para cualquier funci√≥n \\(h(\\underset{\\sim}{x})\\) tal que \\(E_\\theta|h(\\underset{\\sim}{X})| &lt; \\infty\\) se tiene que\n\\[\n\\begin{align}\n&\\frac{d}{d\\theta}\\int\\dotsc\\int h(\\underset{\\sim}{x})f (\\underset{\\sim}{x}|\\theta)dx_1\\ldots dx_n\\nonumber\\\\\n&=\\int\\dotsc\\int h(\\underset{\\sim}{x})\\left[\\frac{\\partial}{\\partial\\theta}f (\\underset{\\sim}{x}|\\theta)\\right]dx_1\\ldots dx_n\n\\end{align}\n\\]\nEntonces, \\[\\begin{align}\nV_\\theta(W(\\underset{\\sim}{X} ))\\geq\\frac{\\left(\\frac{d}{d\\theta}\\tau(\\theta)\\right)^2}{E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f(\\underset{\\sim}{X}|\\theta)\\right)^2\\right]}\n\\end{align}\\] A la cantidad del lado derecho de la desigualdad anterior se la denomina Cota de Cram√©r-Rao.\n\n\n\n\n\n\n\nNote¬†3.2\n\n\n\nNota: El teorema de Cram√©r-Rao es igualmente v√°lido en el caso discreto. En este caso la hip√≥tesis H2 afirma que pueden intercambiarse el sumatorio y la diferenciaci√≥n.\n\n\n\nUn estimador insesgado para \\(\\tau(\\theta)\\) se denomina si su varianza es la m√≠nima posible, es decir, si es igual a la cota de Cram√©r-Rao.\nLa eficiencia de un estimador insesgado se define como el cociente entre la cota de Cram√©r-Rao y su varianza.\nEs un valor menor o igual que 1 si se dan las hip√≥tesis del teorema de Cram√©r-Rao.\n\nEn la demostraci√≥n del teorema de Cram√©r-Rao se ha probado que\n\\[\n\\begin{align}\nE_\\theta(S(\\theta))&=E_\\theta(S(\\theta|\\underset{\\sim}{X}))\\nonumber\\\\\n&=E_\\theta\\left(\\frac{\\partial}{\\partial \\theta}\\log L(\\theta|\\underset{\\sim}{X})\\right)=0\n\\end{align}\n\\] Obs√©rvese que para obtener el estimador m√°ximo veros√≠mil de \\(\\theta\\) lo que se hace es resolver la ecuaci√≥n \\[\\begin{align}\n    S(\\theta|\\underset{\\sim}{X})=0\n\\end{align}\\] lo que equivale a buscar el valor de \\(\\theta\\) para el cual el valor de \\(S(\\theta|\\underset{\\sim}{X})\\) coincide con su valor esperado.\nA la cantidad que aparece en el denominador de la cota de Cram√©r-Rao se le denomina cantidad de informaci√≥n de Fisher que sobre \\(\\theta\\) contiene el vector \\(\\underset{\\sim}{X}\\):\n\\[\n\\begin{align}\n\\mathscr{I}_{E}(\\theta)=\\mathscr{I}_{\\underset{\\sim}{X}}(\\theta)&=E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{X}|\\theta)\\right)^2\\right]\\\\\n&=V\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{X}|\\theta)\\right)\\\\\n&=V(S(\\theta|\\underset{\\sim}{X}))\n\\end{align}\n\\]\nSe denomina cantidad de informaci√≥n de Fisher que sobre \\(\\theta\\) contiene la variable \\(X_i\\) a \\[\n\\begin{align}\n    &=E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(X|\\theta)\\right)^2\\right]\\\\\n    &=V\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(X|\\theta)\\right)\\\\\n    &=V(S(\\theta|X_i))\n    \\end{align}\n\\]\nCuando \\(\\underset{\\sim}{X}=(X_1,\\ldots, X_n)\\) es una muestra aleatoria simple de \\(X\\) se verifica que la informaci√≥n de Fisher contenida en la muestra es la suma de las informaciones contenidas en cada una de las observaciones y, dado que √©stas son id√©nticamente distribuidas, se tiene que\n\\[\n\\begin{align}\n\\mathscr{I}_{E}(\\theta)=\\mathscr{I}_{\\underset{\\sim}{X}}(\\theta)=n\\mathscr{I}_{X}(\\theta)\n\\end{align}\n\\] Este resultado es consecuencia del siguiente corolario del teorema de Cram√©r-Rao:\n\nCorollary 3.1 Bajo las hip√≥tesis del teorema de Cram√©r-Rao, si \\(\\underset{\\sim}{X}=(X_1,\\ldots, X_n)\\) es una muestra aleatoria simple de \\(X\\) con distribuci√≥n dada por \\(f(x|\\theta)\\) entonces \\[\n\\begin{align*}\n\\mathscr{I}_{E}(\\theta)=\\mathscr{I}_{\\underset{\\sim}{X}}(\\theta)&=E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{X}|\\theta)\\right)^2\\right]\\\\\n&=nE_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X}(X|\\theta)\\right)^2\\right]\\\\\n&=n\\mathscr{I}_{X}(\\theta)\n\\end{align*}\n\\]\n\n\nProof. Por independencia, la verosimilitud de \\(\\underset{\\sim}{X}\\) es el producto de verosimilitudes, luego \\[\\begin{align}\n    \\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)&=\\frac{\\partial}{\\partial \\theta}\\sum_{i=1}^{n}\\log f_{X}(x_i|\\theta)\\nonumber\\\\\n    &=\\sum_{i=1}^{n}\\frac{\\partial}{\\partial \\theta}\\log f_{X}(x_i|\\theta)\n    \\end{align}\\] Por lo tanto,\n\\[\n\\begin{align}\nE_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)\\right)^2\\right]&=E_\\theta\\left[\\left(\\sum_{i=1}^{n}\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\right)^2\\right]\\nonumber\\\\\n=&\\sum_{i=1}^{n}E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\right)^2\\right]\\nonumber\\\\\n+&\\sum_{i\\neq j}E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\frac{\\partial}{\\partial \\theta}\\log f_{X_j}(x_j|\\theta)\\right)\\right]\n\\end{align}\n\\tag{3.10}\\]\nLa segunga igualdad de Equation¬†3.10 se tiene por que \\(\\left(\\sum_{i=1}^{n}a_i\\right)^2=\\sum_{i=1}^{n}a_i^2+\\sum_{i\\neq j}a_ia_j\\). Pero la segunda sumatoria es igual a cero debido a la independencia entre \\(X_i\\) y \\(X_j\\) y dado que las funciones score tienen esperanza 0, seg√∫n se vio en la demostraci√≥n del teorema de Cram√©r-Rao. \\[\n\\begin{align}\nE_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)\\right)^2\\right]\n        =&\\sum_{i=1}^{n}E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\right)^2\\right]\\nonumber\\\\\n        +&\\sum_{i\\neq j}E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\right)\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_j}(x_j|\\theta)\\right)\\right]\\nonumber\\\\\n        =&\\sum_{i=1}^{n}E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X_i}(x_i|\\theta)\\right)^2\\right]\\nonumber\\\\\n\\end{align}\n\\tag{3.11}\\]\n\n\nLemma 3.1 Si la funci√≥n de verosimilitud satisface:\nH3: Se supone que la verosimilitud conjunta \\(f (\\underset{\\sim}{x}|\\theta)\\) verifica que para cualquier funci√≥n \\(h(\\underset{\\sim}{x})\\) tal que \\(E_\\theta|h(\\underset{\\sim}{X})| &lt; \\infty\\) se tiene que \\[\n\\begin{align}\n&\\frac{\\partial^2}{\\partial\\theta^2}\\int\\dotsc\\int h(\\underset{\\sim}{x})f (\\underset{\\sim}{x}|\\theta)dx_1\\ldots dx_n\\nonumber\\\\\n&=\\int\\dotsc\\int h(\\underset{\\sim}{x})\\left[\\frac{\\partial^2}{\\partial\\theta^2}f (\\underset{\\sim}{x}|\\theta)\\right]dx_1\\ldots dx_n\n\\end{align}\n\\]\nEntonces \\[\n\\begin{align}\n\\mathscr{I}_{X}(\\theta)=E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X}(x|\\theta)\\right)^2\\right]=-E_\\theta\\left[\\frac{\\partial^2}{\\partial \\theta^2}\\log f_{X}(x|\\theta)\\right]\n\\end{align}\n\\]\n\n\nProof. \\[\n\\begin{align}\n        \\frac{\\partial^2}{\\partial \\theta^2}\\log f_{X}(x|\\theta)&=\\frac{\\partial}{\\partial \\theta}\\left[\\frac{1}{f_{X}(x|\\theta)}\\left(\\frac{\\partial}{\\partial \\theta}f_{X}(x|\\theta)\\right)\\right]\\nonumber\\\\\n        &=-\\frac{1}{f^2_{X}(x|\\theta)}\\left(\\frac{\\partial}{\\partial \\theta}f_{X}(x|\\theta)\\right)^2\\nonumber\\\\\n        &+\\frac{1}{f_{X}(x|\\theta)}\\frac{\\partial^2}{\\partial \\theta^2}f_{X}(x|\\theta)\n\\end{align}\n\\] Por otro lado, \\[\n\\begin{align}\n    E_\\theta\\left[\\frac{1}{f_{X}(x|\\theta)}\\frac{\\partial^2}{\\partial \\theta^2}f_{X}(x|\\theta)\\right]&=\\int\\frac{\\partial^2}{\\partial \\theta^2}f_{X}(x|\\theta)dx\\nonumber\\\\\n    &\\overset{\\text{H3}}{=}\\frac{d^2}{d \\theta^2}\\int f_{X}(x|\\theta)dx\\nonumber\\\\\n    &=\\frac{d^2}{d \\theta^2}1 =0\n\\end{align}\n\\] As√≠ pues, \\[\n\\begin{align}\n        E_\\theta\\left[\\frac{\\partial^2}{\\partial \\theta^2}\\log f_{X}(x|\\theta)\\right]\n        &=-E_\\theta\\left[\\frac{1}{f^2_{X}(x|\\theta)}\\left(\\frac{\\partial}{\\partial \\theta}f_{X}(x|\\theta)\\right)^2\\right]\\nonumber\\\\\n        &=-E_\\theta\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\log f_{X}(x|\\theta)\\right)^2\\right]\\nonumber\\\\\n        &=-\\mathscr{I}_{X}(\\theta)\n        \\end{align}\n\\]\n\n\nEn general, el teorema de Cram√©r-Rao no es aplicable si el soporte de \\(f(x|\\theta)\\) depende del par√°metro \\(\\theta\\) debido a que la derivada y la integral no son intercambiables si los l√≠mites de integraci√≥n dependen de \\(\\theta\\).\nAunque el teorema de Cram√©r-Rao pueda ser aplicado y la cota de Cram√©r-Rao sea efectiva, no hay garant√≠as de que esta cota sea alcanzada por alg√∫n estimador insesgado del par√°metro.\n\n\nCorollary 3.2 Sea \\(X_1 , \\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) con distribuci√≥n dada por \\(f(x|\\theta)\\), \\(\\theta\\in\\mathbb{R}\\), donde \\(f\\) satisface las hip√≥tesis del teorema de Cram√©r-Rao. Sea \\(L(\\theta|\\underset{\\sim}{x}) = \\prod_{i=1}^{n}f(x_i|\\theta)\\) la funci√≥n de verosimilitud. Sea \\(W (\\underset{\\sim}{x}) = W(X_1 , \\ldots, X_n)\\) un estimador insesgado de \\(\\tau(\\theta)\\). Entonces \\(W(\\underset{\\sim}{x})\\) alcanza la cota de Cram√©r-Rao si y s√≥lo si existe una funci√≥n \\(a(\\theta)\\) tal que se tiene la igualdad \\[\n\\begin{align}\na(\\theta)(W(\\underset{\\sim}{x})-\\tau(\\theta))=\\frac{\\partial}{\\partial\\theta}\\log L(\\theta|\\underset{\\sim}{x}) \\mbox{ para todo $\\theta$}\n\\end{align}\n\\]\n\nAdem√°s, el enunciado del corolario Corollary¬†3.2 ocurre s√≠ y s√≥lo s√≠ existen funciones \\(h(\\theta)\\), \\(k(\\theta)\\) y \\(u(\\underset{\\sim}{x})\\) tales que\n\\[\n\\begin{align}\nL(\\theta|\\underset{\\sim}{x})=u(\\underset{\\sim}{x})h(\\theta)\\exp\\{W(\\underset{\\sim}{x})k(\\theta)\\}\n\\end{align}\n\\] es decir, si y s√≥lo si la distribuci√≥n de partida pertenece a la familia exponencial.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#evaluaci√≥n-de-estimadores",
    "href": "chapter2.html#evaluaci√≥n-de-estimadores",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.11 Evaluaci√≥n de estimadores",
    "text": "3.11 Evaluaci√≥n de estimadores\n\n3.11.1 Mejor estimador insesgado.\nTeorema de Rao-Blackwell. Teorema de Lehmann-Scheff√©\nSi buscamos estimadores insesgados con varianzas peque√±as, podemos restringir nuestra b√∫squeda a estimadores que sean funciones de estad√≠sticos suficientes.\n\nTheorem 3.6 Si \\(Y_1\\) y \\(Y_2\\) son dos variables aleatorias, entonces\n\\(E(Y_1) = E[E(Y_1 \\mid Y_2)]\\),\ndonde en el lado derecho de la ecuaci√≥n el valor esperado interior es con respecto a la distribuci√≥n condicional de \\(Y_1\\) dada \\(Y_2\\), y el valor esperado exterior es con respecto a la distribuci√≥n de \\(Y_2\\).\n\n\n\nTheorem 3.7 Si \\(Y_1\\) y \\(Y_2\\) representan variables aleatorias, entonces\n\\(V(Y_1) = E[V(Y_1 \\mid Y_2)] + V[E(Y_1 \\mid Y_2)]\\).\n\n\nTheorem 3.8 El Teorema de Rao-Blackwell Sea \\(\\hat{\\theta}\\) un estimador insesgado para \\(\\theta\\) tal que \\(V (\\hat{\\theta}) &lt;\\infty\\) . Si \\(U\\) es un estad√≠stico suficiente para \\(\\theta\\), definamos \\(\\hat{\\theta}^* = E(\\hat{\\theta} |U)\\). Entonces, para toda \\(\\theta\\), \\[E(\\hat{\\theta}^*) =\\theta\\mbox{ y }V(\\hat{\\theta}^*) \\leq V(\\hat{\\theta})\\].\n\n\nProof. Como \\(U\\) es suficiente para \\(\\theta\\), la distribuci√≥n condicional de cualquier estad√≠stico (incluyendo \\(\\hat{\\theta}\\)), dada \\(U\\) no depende de \\(\\theta\\). Entonces, \\(\\hat{\\theta}^*=E(\\hat{\\theta}|U)\\) no es funci√≥n de \\(\\theta\\) y es por tanto un estad√≠stico.\nComo \\(\\hat{\\theta}\\) es un estimador insesgado para \\(\\theta\\) entonces de los Teoremas Theorem¬†3.6 y Theorem¬†3.7, tenemos \\[E(\\hat{\\theta}^*)=E[E(\\hat{\\theta}|U)]=E(\\hat{\\theta})=\\theta.\\] Entonces \\(\\hat{\\theta}^*\\) es un estimador insesgado para \\(\\theta\\). El Teorema Theorem¬†3.7 implica que \\[\\begin{eqnarray*}\nV(\\hat{\\theta})&=&V[E(\\hat{\\theta}|U)]+E[V(\\hat{\\theta}|U)]\\\\\n            &=&V(\\hat{\\theta}^*)+E[V(\\hat{\\theta}|U)].\n\\end{eqnarray*}\\] Como \\(V(\\hat{\\theta} |U = u) \\geq 0\\) para toda \\(u\\), se deduce que \\(E[V(\\hat{\\theta} |U)]\\geq 0\\) y por lo tanto que \\[\\begin{eqnarray*}\nV(\\hat{\\theta})&=&V(\\hat{\\theta}^*)+E[V(\\hat{\\theta}|U)]\\\\\n&\\geq&V(\\hat{\\theta}^*)+0\n\\end{eqnarray*}\\] luego \\(V (\\hat{\\theta}) \\geq V (\\hat{\\theta}^*)\\).\n\nEl Teorema de Rao-Blackwell implica que un estimador insesgado para \\(\\theta\\) con una varianza peque√±a es, o puede llegar a ser, una funci√≥n de un estad√≠stico suficiente. Si \\(U\\) es un estad√≠stico suficiente para \\(\\theta\\), \\(E(\\hat{\\theta}|U)=\\hat{\\theta}^*\\) entonces \\(E(\\hat{\\theta}^*)=\\theta\\) y \\(V(\\hat{\\theta}^*)\\leq V(\\hat{\\theta})\\). \\(\\theta^*\\) Estimador insesgado, \\(\\hat{\\theta}^*=h(U)\\) entonces \\(E(h(U)|U)=h(U)=\\hat{\\theta}^*\\).\nEn general, \\(E(h(U)|U)=h(U)\\), vemos que usando de nuevo el teorema de Rao-Blackwell nuestro nuevo estimador es simplemente \\(h(U)=\\hat{\\theta}^*\\). No ganamos nada despu√©s de la primera aplicaci√≥n.\nDebido a que numerosos estad√≠sticos son suficientes para un par√°metro \\(\\theta\\) asociado con una distribuci√≥n ¬øqu√© estad√≠stico suficiente debemos usar cuando aplicamos este teorema?\nEl criterio de factorizaci√≥n de manera t√≠pica identifica un estad√≠stico \\(U\\) que mejor resume la informaci√≥n de los datos acerca del par√°metro \\(\\theta\\). Tales estad√≠sticos reciben el nombre de estad√≠sticos suficinetes m√≠nimos.\nSi aplicamos el Teoremo Theorem¬†3.8 usando \\(U\\), no s√≥lo obtenemos un estimador con varianza m√°s peque√±a si no un estimador insesgado para \\(\\theta\\) con varianza m√≠nima, este se le llama Estimador Insesgado de Varianza M√≠nima EIVM (MVUE).\n\n\n\n\n\n\nNote¬†3.3\n\n\n\nEl Teorema de Rao‚ÄìBlackwell es uno de esos resultados hermosos que nos dicen: ‚ÄúSiempre puedes mejorar tus estimadores, si aprovechas la informaci√≥n disponible en un estad√≠stico suficiente‚Äù.\nSupongamos que queremos estimar la media \\(\\theta = \\mu\\) de una distribuci√≥n Bernoulli(\\(p\\)).\nEstimador inicial ingenuo:\nTomemos una muestra de tama√±o \\(n\\) y digamos que solo miramos la primera observaci√≥n \\(X_1\\).\nComo \\(E(X_1) = p\\), este es un estimador insesgado, pero claramente tiene varianza muy grande.\nEstad√≠stico suficiente:\nLa suma \\(U = \\sum_{i=1}^n X_i\\) es suficiente para \\(p\\).\nEstimador Rao‚ÄìBlackwellizado:\nCalculamos:\n\\[\\hat{p}^* = E(X_1 \\mid U) = \\frac{U}{n}.\\]\nEs decir, hemos pasado de un estimador ingenuo (\\(X_1\\)) a la media muestral, que sabemos es mucho m√°s eficiente.\n\n\n\n## Teorema de Rao‚ÄìBlackwell: ejemplo Bernoulli ----\n\nset.seed(123)\n\n# Par√°metros verdaderos\np     &lt;- 0.6\nn     &lt;- 20         # tama√±o de muestra\nNsim  &lt;- 10000      # n√∫mero de simulaciones\n\n# Vectores para guardar los estimadores\nest_naive &lt;- numeric(Nsim)  # usa solo la primera observaci√≥n X1\nest_RB    &lt;- numeric(Nsim)  # E[X1 | U] = U/n  (media muestral)\n\nfor (s in 1:Nsim) {\n  X &lt;- rbinom(n, size = 1, prob = p)\n  U &lt;- sum(X)\n\n  est_naive[s] &lt;- X[1]\n  est_RB[s]    &lt;- U / n\n}\n\n# Resumen emp√≠rico\nmean_naive &lt;- mean(est_naive)\nvar_naive  &lt;- var(est_naive)\n\nmean_RB &lt;- mean(est_RB)\nvar_RB  &lt;- var(est_RB)\n\n# Valores te√≥ricos\nvar_naive_theo &lt;- p * (1 - p)            # Var(X1)\nvar_RB_theo    &lt;- p * (1 - p) / n        # Var(U/n)\n\ncat(\"==== Resultados (emp√≠ricos vs te√≥ricos) ====\\n\")\n\n==== Resultados (emp√≠ricos vs te√≥ricos) ====\n\ncat(sprintf(\"E[X1]            emp√≠rico = %.4f  (te√≥rico = %.4f)\\n\", mean_naive, p))\n\nE[X1]            emp√≠rico = 0.6006  (te√≥rico = 0.6000)\n\ncat(sprintf(\"Var(X1)          emp√≠rico = %.4f  (te√≥rico = %.4f)\\n\\n\", var_naive, var_naive_theo))\n\nVar(X1)          emp√≠rico = 0.2399  (te√≥rico = 0.2400)\n\ncat(sprintf(\"E[U/n]           emp√≠rico = %.4f  (te√≥rico = %.4f)\\n\", mean_RB, p))\n\nE[U/n]           emp√≠rico = 0.6004  (te√≥rico = 0.6000)\n\ncat(sprintf(\"Var(U/n)         emp√≠rico = %.4f  (te√≥rico = %.4f)\\n\\n\", var_RB, var_RB_theo))\n\nVar(U/n)         emp√≠rico = 0.0119  (te√≥rico = 0.0120)\n\ncat(sprintf(\"Reducci√≥n de varianza (emp√≠rica): Var(U/n) / Var(X1) = %.4f\\n\", var_RB / var_naive))\n\nReducci√≥n de varianza (emp√≠rica): Var(U/n) / Var(X1) = 0.0494\n\ncat(sprintf(\"Reducci√≥n de varianza (te√≥rica) : Var(U/n) / Var(X1) = %.4f\\n\", var_RB_theo / var_naive_theo))\n\nReducci√≥n de varianza (te√≥rica) : Var(U/n) / Var(X1) = 0.0500\n\n\nSi empezamos con un estimador insesgado para \\(\\theta\\) y el estad√≠stico suficiente obtenido por medio del criterio de factorizaci√≥n, la aplicaci√≥n del Teorema de Rao-Blackwell en general lleva a un MVUE para el par√°metro.\nSea \\(\\hat{\\theta}\\) el par√°metro insesgado para \\(\\theta\\). \\[E(\\hat{\\theta})=\\theta\\] \\(U\\) igual al obtenido por el m√©todo de factorizaci√≥n \\[\\hat{\\theta}^*=E(\\hat{\\theta}|U)\\] donde \\(\\hat{\\theta}^*\\) es el MVUE (Aplicar Blackwell).\nLa consecuencia fundamental de este teorema es que en la b√∫squeda del estimador UMVUE, basta con restringirnos a aquellos estimadores insesgados que son funci√≥n de un estad√≠stico suficiente: si trabajamos con un estad√≠stico insesgado que no es funci√≥n de uno suficiente, tomando esperanzas condicionadas podemos conseguir otro que sea al menos tan bueno como el anterior y sea funci√≥n del estad√≠stico suficiente. Este proceso se llama a veces Rao-Blackwellizaci√≥n.\n\n3.11.2 Otra versi√≥n del teorema de Rao-Blackwell\n\nTheorem 3.9 Otra versi√≥n del teorema de Rao-Blackwell Sea una m.a.s. de \\(X\\), con densidad (o masa de probabilidad) \\(f(x|\\theta)\\). Sea \\(T(\\underset{\\sim}{X})\\) un estad√≠stico suficiente para \\(\\theta\\) y sea \\(W(\\underset{\\sim}{X})\\) un estimador insesgado de \\(\\tau(\\theta)\\). Definimos \\[\\begin{align}\nW_T=E_\\theta(W|T)\n\\end{align}\\] Entonces,\n\n\n\\(W_T\\) es funci√≥n unicamente de \\(T(\\underset{\\sim}{X})\\) (Es decir, no depende de \\(\\theta\\) y no depende de la muestra \\(\\underset{\\sim}{X}\\) s√≥lo a trav√©s del valor de \\(T(\\underset{\\sim}{X})\\))\n\n\\(E_\\theta(W_T)=\\tau(\\theta)\\).\n\n\\(V_\\theta(W_T)\\leq V_\\theta(W)\\) .\n\n\nLa consecuencia fundamental de este teorema es que en la b√∫squeda del estimador UMVUE, basta con restringirnos a aquellos estimadores insesgados que son funci√≥n de un estad√≠stico suficiente: si trabajamos con un estad√≠stico insesgado que no es funci√≥n de uno suficiente, tomando esperanzas condicionadas podemos conseguir otro que es al menos tan bueno como el anterior y es funci√≥n del estad√≠stico suficiente. Este proceso se llama a veces Rao-Blackwellizaci√≥n.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#comportamiento-asint√≥tico",
    "href": "chapter2.html#comportamiento-asint√≥tico",
    "title": "\n3¬† Estimaci√≥n puntual\n",
    "section": "\n3.12 Comportamiento asint√≥tico",
    "text": "3.12 Comportamiento asint√≥tico\n\n3.12.1 Consistencia\n\nDefinition 3.4 Se dice que el estimador \\(\\hat{\\theta}_n\\) es un estimador consistente de \\(\\theta\\) si, para cualquier n√∫mero positivo \\(\\varepsilon\\), \\[\\lim_{n\\rightarrow\\infty}P(|\\hat{\\theta}_n-\\theta|\\leq\\varepsilon)=1\\] o bien, de forma equivalente, \\[\\lim_{n\\rightarrow\\infty}P(|\\hat{\\theta}_n-\\theta|&gt;\\varepsilon)=0\\]\n\nLa consistencia es la misma convergencia en probabilidad!!\n\nTheorem 3.10 Un estimador insesgado \\(\\hat{\\theta}_n\\) para \\(\\theta\\) es un estimador consistente de \\(\\theta\\) si \\[\\lim_{n\\rightarrow\\infty}V(\\hat{\\theta}_n)=0.\\]\n\n\nProof. \\(E(\\hat{\\theta}_n)=\\theta\\). Sea \\(\\sigma_{\\hat{\\theta}_n}=\\sqrt{V(\\hat{\\theta}_n)}\\) aplicando el Teorema Tchebysheff para la v.a \\(\\hat{\\theta}_n\\), obtenemos \\[P(|\\hat{\\theta}_n-\\theta|&gt;k\\sigma_{\\hat{\\theta}_n}\n    )\\leq \\frac{1}{k^2}\\] Para cualquier n√∫mero positivo \\(\\varepsilon\\), y \\(n\\) cualquier tama√±o muestral \\[\\varepsilon=k\\sigma_{\\hat{\\theta}_n}\\Rightarrow k=\\frac{\\varepsilon}{\\sigma_{\\hat{\\theta}_n}}\\] luego \\(k&gt;0\\).\nLa aplicaci√≥n del teorema de Chebyshev para esta \\(n\\) fija y esta selecci√≥n de \\(k\\) muestra que \\[\\begin{eqnarray*}\n    P(|\\hat{\\theta}_n-\\theta|&gt;\\varepsilon)&=&P\\left(|\\hat{\\theta}_n-\\theta|&gt;\\left[\\frac{\\varepsilon}{\\sigma_{\\hat{\\theta}_n}}\\right]\\sigma_{\\hat{\\theta}_n}\\right)\\\\\n    &\\leq&\\frac{1}{(\\varepsilon/\\sigma_{\\hat{\\theta}_n})^2}\\\\\n    &=&\\frac{V(\\hat{\\theta}_n)}{\\varepsilon^2}\n\\end{eqnarray*}\\] Entonces, para cualquier \\(n\\) fija \\[0\\leq P(|\\hat{\\theta}_n-\\theta|&gt;\\varepsilon)\\leq \\frac{V(\\hat{\\theta}_n)}{\\varepsilon^2}\\] Si \\(\\lim_{n\\rightarrow\\infty}V(\\hat{\\theta}_n)=0\\) entonces \\[\\lim_{n\\rightarrow\\infty}0\\leq \\lim_{n\\rightarrow\\infty}P(|\\hat{\\theta}_n-\\theta|&gt;\\varepsilon)\\leq\\lim_{n\\rightarrow\\infty} \\frac{V(\\hat{\\theta}_n)}{\\varepsilon^2}=0\\] Luego \\[\\lim_{n\\rightarrow\\infty}P(|\\hat{\\theta}_n-\\theta|&gt;\\varepsilon)=0\\] luego \\(\\hat{\\theta}_n\\) es un estimador consistente para \\(\\theta\\).\n\n\nTheorem 3.11 \\(\\displaystyle{\\hat{\\theta}_n \\stackrel{P}{\\rightarrow} \\theta}\\) y \\(\\displaystyle{\\hat{\\theta}'_n \\stackrel{P}{\\rightarrow} \\theta'}\\) entonces\n\n\n\\(\\displaystyle{\\hat{\\theta}_n +\\hat{\\theta}'_n \\stackrel{P}{\\longrightarrow} \\theta+\\theta'}\\).\n\n\\(\\displaystyle{\\hat{\\theta}_n \\times\\hat{\\theta}'_n \\stackrel{P}{\\longrightarrow} \\theta\\times\\theta'}\\).\nSi \\(\\theta'\\neq 0\\), \\(\\displaystyle{\\frac{\\hat{\\theta}_n}{\\hat{\\theta}'_n}\\stackrel{P}{\\longrightarrow} \\frac{\\theta}{\\theta'}}\\).\nSi \\(g (\\cdot)\\) es una funci'on de valor real que es continua en \\(\\theta\\), entonces \\(g (\\hat{\\theta}_n )\\) converge en probabilidad en \\(g (\\theta)\\).\n\n\n\n\n\n\n\n\nTip¬†3.1\n\n\n\n\nEl teorema de Rao-Blackwell establece que basta con buscar el estimador UMVUE entre aquellos estimadores que son funci√≥n de un estad√≠stico suficiente.\nBajo ciertas condiciones (existencia de estad√≠sticos suficientes y completos y de estimadores insesgados), esta combinaci√≥n de los conceptos de estad√≠stico completo y de estad√≠stico suficiente garantiza la existencia de estimadores UMVUE de una funci√≥n \\(\\tau(\\theta)\\) del par√°metro y da un m√©todo para construirlos. El siguiente teorema establece este resultado. Podemos decir que este teorema resuelve te√≥ricamente el problema de la estimaci√≥n puntual, entendida √©sta como la b√∫squeda del UMVUE.\n\n\n\n\n\nDefinition 3.6 (estad√≠stico completo) Sea \\(f_T(t|\\theta)\\) la funci√≥n de densidad (o de masa de probabilidad) de un estad√≠stico \\(T\\) . Diremos que la familia de distribuciones \\({f_T(t|\\theta) : \\theta\\in \\Theta}\\) es completa si se da la implicaci√≥n siguiente: \\[\\begin{align}\nE_\\theta(g(T))=0 \\mbox{para todo $\\theta$ entonces}  P_\\theta(g(T) = 0) = 1 \\mbox{para todo $\\theta$}.\n\\end{align}\\]\nEn ese caso diremos que \\(T\\) es un estad√≠stico completo.\n\n## Completitud para T ~ Binomial(n, p)\nset.seed(1)\n\nn     &lt;- 10\ngridp &lt;- seq(0.1, 0.9, by = 0.1)\nN     &lt;- 100000  # simulaciones por p\n\n# Dos funciones no triviales de T (no dependen de p)\ng1 &lt;- function(T) T - n/2\ng2 &lt;- function(T) (T - n/2) * (T - n/3)\n\n# Funci√≥n trivial (cero) para contraste\ng0 &lt;- function(T) 0 * T\n\nsim_mean_g &lt;- function(gfun) {\n  sapply(gridp, function(p) {\n    T &lt;- rbinom(N, size = n, prob = p)\n    mean(gfun(T))\n  })\n}\n\n# Medias emp√≠ricas\nm0 &lt;- sim_mean_g(g0)\nm1 &lt;- sim_mean_g(g1)\nm2 &lt;- sim_mean_g(g2)\n\n# Valores te√≥ricos (para comparar)\n# E[T] = n p; Var[T] = n p (1-p); E[T^2] = Var[T] + (E[T])^2\ntheo_g1 &lt;- n * (gridp - 1/2)  # E[g1(T)] = n(p - 1/2)\n\nET   &lt;- n * gridp\nVarT &lt;- n * gridp * (1 - gridp)\nET2  &lt;- VarT + ET^2\ntheo_g2 &lt;- ET2 - (n/2 + n/3) * ET + (n^2)/(6)  # expandir (T - n/2)(T - n/3)\n\n# Mostrar resultados\ntab &lt;- data.frame(\n  p = gridp,\n  E_g0_emp = round(m0, 5),\n  E_g1_emp = round(m1, 5),\n  E_g1_teo = round(theo_g1, 5),\n  E_g2_emp = round(m2, 5),\n  E_g2_teo = round(theo_g2, 5)\n)\nprint(tab, row.names = FALSE)\n\n   p E_g0_emp E_g1_emp E_g1_teo E_g2_emp E_g2_teo\n 0.1        0 -4.00184       -4 10.24421 10.23333\n 0.2        0 -2.99891       -3  5.61325  5.60000\n 0.3        0 -2.00216       -2  2.77471  2.76667\n 0.4        0 -1.00631       -1  1.74363  1.73333\n 0.5        0 -0.00727        0  2.50485  2.50000\n 0.6        0  1.00466        1  5.09209  5.06667\n 0.7        0  1.99571        2  9.43229  9.43333\n 0.8        0  3.00090        3 15.55946 15.60000\n 0.9        0  3.99831        4 23.58862 23.56667\n\n\n\n\n\n\n\n\nTip¬†3.2: Qu√© observar\n\n\n\n\nPara \\(g_0(T)\\equiv 0\\), la media emp√≠rica es \\(\\approx 0\\) para todos los \\(p\\).\nPara \\(g_1(T) = T - \\tfrac{n}{2}\\), la esperanza te√≥rica es \\(n(p - \\tfrac{1}{2})\\):\nsolo vale \\(0\\) cuando \\(p = \\tfrac{1}{2}\\); no es \\(0\\) para los dem√°s \\(p\\).\nPara \\(g_2(T) = (T - \\tfrac{n}{2})(T - \\tfrac{n}{3})\\), la esperanza es un polinomio en \\(p\\) que no es id√©nticamente cero; de nuevo, no se anula para todos los \\(p\\).\n\n\nEsto ilustra la completitud: si alguna \\(g(T)\\) (que no depende de \\(p\\)) tuviera\\(E_p[g(T)] = 0\\) para todo \\(p \\in (0,1)\\), entonces esa \\(g\\) debe ser (casi seguro) la funci√≥n cero.\n‚û°Ô∏è De ah√≠ que, con suficiencia + completitud, el estimador insesgado derivado es el √∫nico UMVUE (Teorema de Lehmann‚ÄìScheff√©).\n\n\nLa definici√≥n de completitud refuerza la de suficiencia en el sentido de que si un estad√≠stico es suficiente y completo entonces, es suficiente minimal (el rec√≠proco no es cierto)\n\nTheorem 3.12 (Teorema de Lehmann-Scheff√©) Si \\(T(\\underset{\\sim}{X})\\) es un estad√≠stico suficiente y completo para \\(\\theta\\) y \\(W(\\underset{\\sim}{X})\\) es un estimador insesgado cualquiera de \\(\\tau(\\theta)\\), entonces \\[\\begin{align}\nW_T(\\underset{\\sim}{X})=E_\\theta(W|T)\n\\end{align}\\] es el mejor estimador insesgado (UMVUE) de \\(\\tau(\\theta)\\). Si, adem√°s, \\(V(W_T) &lt; \\infty\\) para todo \\(\\theta\\), entonces \\(W_T\\) es √∫nico.\n\n\nLa demostraci√≥n del teorema de Lehmann-Scheff√© se basa en el hecho de que, si existen estimadores insesgados, esencialmente s√≥lo existe uno que sea funci√≥n del estad√≠stico suficiente y completo, pues condicionando cualquiera de los insesgados al estad√≠stico suficiente y completo se obtiene siempre el mismo resultado.\nEl teorema de Rao-Blackwell garantiza que al tomar esperanzas condicionadas se ha reducido la varianza, llegando as√≠ al UMVUE.\nLa principal conclusi√≥n del teorema de Lehmann-Scheff√© es que si existe un estimador insesgado de \\(\\tau(\\theta)\\) que sea funci√≥n de un estad√≠stico suficiente y completo, entonces es el √∫nico UMVUE de \\(\\tau(\\theta)\\).\n\n\n\n\n\n\n\nTip¬†3.3: Recreando Lehmann‚ÄìScheff√© en R\n\n\n\n¬°Vamos a ‚Äúrecrear‚Äù Lehmann‚ÄìScheff√© en R con un ejemplo cl√°sico y totalmente replicable!\nUsaremos \\(X_1,\\dots,X_n \\sim \\text{i.i.d. Poisson}(\\lambda)\\).\nEntonces\n\\[\nT=\\sum_{i=1}^n X_i \\sim \\text{Poisson}(n\\lambda)\n\\]\nes suficiente y completo para \\(\\lambda\\).\nVeremos dos blancos \\(\\tau(\\theta)\\):\n\n\n\\(\\tau(\\lambda)=\\lambda\\)\n\n\\(\\tau(\\lambda)=e^{-\\lambda}\\)\n\nEn cada caso partimos de un estimador insesgado cualquiera \\(W(\\mathbf X)\\) y lo ‚ÄúRao‚ÄìBlackwellizamos‚Äù con \\(T\\):\n\\[\nW_T(\\mathbf X)=\\mathbb{E}_\\theta[W \\mid T].\n\\]\nPor Lehmann‚ÄìScheff√©, \\(W_T\\) es el UMVUE.\nIdea te√≥rica r√°pida\n\nPara \\(\\tau(\\lambda)=\\lambda\\):\nUn estimador insesgado simple es \\(W=X_1\\) (pues \\(\\mathbb{E}[X_1]=\\lambda\\)).\nCondicionando en \\(T\\):\n\n\\[\n  W_T = \\mathbb{E}[X_1 \\mid T] = \\tfrac{T}{n} \\quad \\Longrightarrow \\quad \\text{UMVUE}.\n\\]\n\nPara \\(\\tau(\\lambda)=e^{-\\lambda}\\):\nUn insesgado simple es \\(W=\\mathbf 1\\{X_1=0\\}\\) (pues \\(\\Pr(X_1=0)=e^{-\\lambda}\\)).\nDado \\(T=t\\),\n\n\\[\n  (X_1,\\dots,X_n)\\mid T=t \\sim \\text{Multinomial}\\Big(t;\\tfrac{1}{n},\\dots,\\tfrac{1}{n}\\Big),\n\\]\nas√≠ que\n\\[\n  \\Pr(X_1=0 \\mid T=t)=\\Big(1-\\tfrac{1}{n}\\Big)^t.\n\\]\nPor ende,\n\\[\n  W_T = \\mathbb{E}[\\,\\mathbf 1\\{X_1=0\\}\\mid T]\n  = \\Big(1-\\tfrac{1}{n}\\Big)^T,\n\\]\nque es el UMVUE de \\(e^{-\\lambda}\\).\n\n\n\n## Lehmann‚ÄìScheff√© con Poisson ----\n## X_i ~ Poisson(lambda).  T = sum X_i ~ Poisson(n*lambda) es suficiente y completo.\n\nset.seed(123)\n\n# Par√°metros\nlambda &lt;- 2\nn      &lt;- 10\nNsim   &lt;- 20000\n\n# Contenedores\nW1_naive  &lt;- numeric(Nsim)  # para tau1(lambda)=lambda, W = X1\nW1_RB     &lt;- numeric(Nsim)  # W_T = E[X1|T] = T/n\n\nW2_naive  &lt;- numeric(Nsim)  # para tau2(lambda)=exp(-lambda), W = 1{X1=0}\nW2_RB     &lt;- numeric(Nsim)  # W_T = E[1{X1=0} | T] = ((n-1)/n)^T\n\nfor (s in 1:Nsim) {\n  X &lt;- rpois(n, lambda)\n  Tsum &lt;- sum(X)\n  \n  # Caso 1: tau(lambda) = lambda\n  W1_naive[s] &lt;- X[1]\n  W1_RB[s]    &lt;- Tsum / n\n  \n  # Caso 2: tau(lambda) = exp(-lambda)\n  W2_naive[s] &lt;- as.numeric(X[1] == 0)\n  W2_RB[s]    &lt;- (1 - 1/n)^Tsum\n}\n\n## Res√∫menes emp√≠ricos\nres &lt;- data.frame(\n  Estimador = c(\"W = X1\", \"W_T = T/n\", \"W = 1{X1=0}\", \"W_T = ((n-1)/n)^T\"),\n  Objetivo  = c(\"lambda\", \"lambda\", \"exp(-lambda)\", \"exp(-lambda)\"),\n  Media     = c(mean(W1_naive), mean(W1_RB), mean(W2_naive), mean(W2_RB)),\n  Varianza  = c(var(W1_naive), var(W1_RB), var(W2_naive), var(W2_RB))\n)\n\nprint(res, row.names = FALSE)\n\n         Estimador     Objetivo    Media    Varianza\n            W = X1       lambda 2.015250 2.036219248\n         W_T = T/n       lambda 1.999100 0.197314056\n       W = 1{X1=0} exp(-lambda) 0.131500 0.114213461\n W_T = ((n-1)/n)^T exp(-lambda) 0.135274 0.003988959\n\n## Valores te√≥ricos para comparaci√≥n\n# Caso 1 (lambda):\nvar_W1_naive_theo &lt;- lambda            # Var(X1)\nvar_W1_RB_theo    &lt;- lambda / n        # Var(T/n)\n\n# Caso 2 (exp(-lambda)):\n# Var(1{X1=0}) = e^{-lambda}(1 - e^{-lambda})\nvar_W2_naive_theo &lt;- exp(-lambda) * (1 - exp(-lambda))\n\n# Var(((n-1)/n)^T) = E[a^{2T}] - (E[a^T])^2, con a = (n-1)/n y T~Poisson(n*lambda)\na &lt;- 1 - 1/n\nE_aT     &lt;- exp(n * lambda * (a - 1))        # = exp(n*lambda*(-1/n)) = exp(-lambda)\nE_a2T    &lt;- exp(n * lambda * (a^2 - 1))      # = exp(-2*lambda + lambda/n)\nvar_W2_RB_theo &lt;- E_a2T - E_aT^2             # = e^{-2lambda}(e^{lambda/n} - 1)\n\ncat(\"\\n--- Te√≥rico ---\\n\")\n\n\n--- Te√≥rico ---\n\ncat(sprintf(\"Var(W=X1)                 = %.5f\\n\", var_W1_naive_theo))\n\nVar(W=X1)                 = 2.00000\n\ncat(sprintf(\"Var(W_T=T/n)              = %.5f\\n\", var_W1_RB_theo))\n\nVar(W_T=T/n)              = 0.20000\n\ncat(sprintf(\"Var(W=1{X1=0})            = %.5f\\n\", var_W2_naive_theo))\n\nVar(W=1{X1=0})            = 0.11702\n\ncat(sprintf(\"Var(W_T=((n-1)/n)^T)      = %.5f\\n\\n\", var_W2_RB_theo))\n\nVar(W_T=((n-1)/n)^T)      = 0.00406\n\ncat(\"Relaciones esperadas (Rao‚ÄìBlackwell):\\n\")\n\nRelaciones esperadas (Rao‚ÄìBlackwell):\n\ncat(sprintf(\"Var(T/n)  &lt;= Var(X1):           %.5f &lt;= %.5f\\n\", var_W1_RB_theo, var_W1_naive_theo))\n\nVar(T/n)  &lt;= Var(X1):           0.20000 &lt;= 2.00000\n\ncat(sprintf(\"Var(((n-1)/n)^T) &lt;= Var(1{X1=0}): %.5f &lt;= %.5f\\n\", var_W2_RB_theo, var_W2_naive_theo))\n\nVar(((n-1)/n)^T) &lt;= Var(1{X1=0}): 0.00406 &lt;= 0.11702\n\n\nQu√© comprueba el script\n\nInsesgadez: las medias emp√≠ricas de \\(W\\) y \\(W_T\\) aproximan \\(\\tau(\\lambda)\\) (ya sea \\(\\lambda\\) o \\(e^{-\\lambda}\\)).\nMejor varianza:\\[\\mathrm{Var}(W_T) \\leq \\mathrm{Var}(W)\\]\nen ambos casos (se ve emp√≠ricamente y con f√≥rmulas te√≥ricas).\n\nForma cerrada del UMVUE:\n\nPara \\(\\tau(\\lambda)=\\lambda\\): \\(W_T = T/n\\).\n\nPara \\(\\tau(\\lambda)=e^{-\\lambda}\\): \\(W_T = \\Big(\\tfrac{n-1}{n}\\Big)^T\\).\n\n\n\nY, por Lehmann‚ÄìScheff√©, como \\(T\\) es suficiente y completo y \\(\\mathrm{Var}(W_T)&lt;\\infty\\), este UMVUE es √∫nico.\n\n# --- Preparaci√≥n ----\n# install.packages(\"ggplot2\") # si no lo tienes\nlibrary(ggplot2)\n\nexplore_LS &lt;- function(lambda = 2, n = 10, Nsim = 20000, seed = 123,\n                       show_plots = TRUE, save_plots = FALSE, prefix = \"LS\") {\n  set.seed(seed)\n\n  # ---- Simulaci√≥n ----\n  # Generamos Nsim muestras, cada una de tama√±o n (Poisson(lambda))\n  # Para eficiencia, simulamos Nsim*n y damos forma de matriz.\n  Xmat &lt;- matrix(rpois(Nsim * n, lambda), nrow = Nsim, ncol = n)\n  Tsum &lt;- rowSums(Xmat)\n\n  # Caso 1: tau(lambda) = lambda\n  W1  &lt;- Xmat[, 1]          # estimador ingenuo: X1\n  WT1 &lt;- Tsum / n           # Rao-Blackwell: E[X1 | T] = T/n  (UMVUE)\n\n  # Caso 2: tau(lambda) = exp(-lambda)\n  W2  &lt;- as.numeric(Xmat[, 1] == 0)        # ingenuo: 1{X1=0}\n  WT2 &lt;- (1 - 1/n)^Tsum                    # RB: ((n-1)/n)^T  (UMVUE)\n\n  # ---- Res√∫menes emp√≠ricos ----\n  tab &lt;- data.frame(\n    Estimador = c(\"W = X1\", \"W_T = T/n\", \"W = 1{X1=0}\", \"W_T = ((n-1)/n)^T\"),\n    Objetivo  = c(\"lambda\", \"lambda\", \"exp(-lambda)\", \"exp(-lambda)\"),\n    Media     = c(mean(W1), mean(WT1), mean(W2), mean(WT2)),\n    Varianza  = c(var(W1),  var(WT1), var(W2), var(WT2))\n  )\n\n  # ---- Valores te√≥ricos ----\n  # Caso 1:\n  var_W1_theo  &lt;- lambda           # Var(X1)\n  var_WT1_theo &lt;- lambda / n       # Var(T/n)\n\n  # Caso 2:\n  # Var(1{X1=0}) = e^{-lambda}(1 - e^{-lambda})\n  var_W2_theo  &lt;- exp(-lambda) * (1 - exp(-lambda))\n\n  # Var(((n-1)/n)^T) = E[a^{2T}] - (E[a^T])^2 con T ~ Poisson(n*lambda), a=(n-1)/n\n  a &lt;- 1 - 1/n\n  E_aT  &lt;- exp(n * lambda * (a - 1))           # = exp(-lambda)\n  E_a2T &lt;- exp(n * lambda * (a^2 - 1))         # = exp(-2*lambda + lambda/n)\n  var_WT2_theo &lt;- E_a2T - E_aT^2               # = e^{-2lambda}(e^{lambda/n} - 1)\n\n  tab_teo &lt;- data.frame(\n    Estimador = c(\"W = X1\", \"W_T = T/n\", \"W = 1{X1=0}\", \"W_T = ((n-1)/n)^T\"),\n    Var_teor  = c(var_W1_theo, var_WT1_theo, var_W2_theo, var_WT2_theo)\n  )\n\n  # ---- Data para gr√°ficas ----\n  df1 &lt;- rbind(\n    data.frame(valor = W1,  tipo = \"W = X1\",        objetivo = \"lambda\"),\n    data.frame(valor = WT1, tipo = \"W_T = T/n\",     objetivo = \"lambda\")\n  )\n\n  df2 &lt;- rbind(\n    data.frame(valor = W2,  tipo = \"W = 1{X1=0}\",           objetivo = \"exp(-lambda)\"),\n    data.frame(valor = WT2, tipo = \"W_T = ((n-1)/n)^T\",     objetivo = \"exp(-lambda)\")\n  )\n\n  # ---- Gr√°ficas ----\n  p_dens_1 &lt;- ggplot(df1, aes(x = valor, fill = tipo)) +\n    geom_density(alpha = 0.35, adjust = 1.1) +\n    geom_vline(xintercept = lambda, linetype = 2) +\n    labs(\n      title = bquote(\"Distribuciones de \" * W ~ \"vs\" ~ W[T] ~ \" para \" ~ tau(lambda) == lambda),\n      subtitle = bquote(lambda == .(lambda) ~ \", \" ~ n == .(n) ~ \", \" ~ N[sim] == .(Nsim)),\n      x = \"valor\", y = \"densidad\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"top\")\n\n  p_box_1 &lt;- ggplot(df1, aes(x = tipo, y = valor, fill = tipo)) +\n    geom_boxplot(alpha = 0.4, width = 0.6, outlier.alpha = 0.25) +\n    geom_hline(yintercept = lambda, linetype = 2) +\n    labs(\n      title   = \"Boxplots: W vs W_T (objetivo: lambda)\",\n      x = NULL, y = \"valor\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"none\")\n\n  # Para el caso indicador es discreto; usamos barras y boxplot (WT2 es continuo en [0,1])\n  p_bar_2 &lt;- ggplot(df2, aes(x = factor(round(valor, 3)), fill = tipo)) +\n    geom_bar(position = \"dodge\") +\n    labs(\n      title = bquote(\"Distribuciones de \" * W ~ \"vs\" ~ W[T] ~ \" para \" ~ tau(lambda) == e^{-lambda}),\n      subtitle = bquote(lambda == .(lambda) ~ \", \" ~ n == .(n) ~ \", \" ~ N[sim] == .(Nsim)),\n      x = \"valor (redondeado a 3 decimales)\", y = \"frecuencia\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"top\")\n\n  p_box_2 &lt;- ggplot(df2, aes(x = tipo, y = valor, fill = tipo)) +\n    geom_boxplot(alpha = 0.4, width = 0.6, outlier.alpha = 0.25) +\n    geom_hline(yintercept = exp(-lambda), linetype = 2) +\n    labs(\n      title = \"Boxplots: W vs W_T (objetivo: exp(-lambda))\",\n      x = NULL, y = \"valor\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"none\")\n\n  if (show_plots) {\n    print(p_dens_1); print(p_box_1)\n    print(p_bar_2);  print(p_box_2)\n  }\n\n  if (save_plots) {\n    ggsave(sprintf(\"%s_dens_lambda.png\", prefix), p_dens_1, width = 7, height = 4.5, dpi = 150)\n    ggsave(sprintf(\"%s_box_lambda.png\",  prefix), p_box_1,  width = 6, height = 4.5, dpi = 150)\n    ggsave(sprintf(\"%s_bar_expl.png\",    prefix), p_bar_2,  width = 7, height = 4.5, dpi = 150)\n    ggsave(sprintf(\"%s_box_expl.png\",    prefix), p_box_2,  width = 6, height = 4.5, dpi = 150)\n  }\n\n  # ---- Salida ----\n  list(\n    resumen_empirico = tab,\n    resumen_teorico  = tab_teo,\n    plots = list(dens_lambda = p_dens_1, box_lambda = p_box_1,\n                 bar_expl = p_bar_2, box_expl = p_box_2)\n  )\n}\n\n# ===== Ejemplo de uso =====\nout &lt;- explore_LS(lambda = 2, n = 10, Nsim = 20000, seed = 123, show_plots = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Mira los res√∫menes:\nout$resumen_empirico\n\n          Estimador     Objetivo     Media    Varianza\n1            W = X1       lambda 1.9870500 1.961480372\n2         W_T = T/n       lambda 1.9991000 0.199480164\n3       W = 1{X1=0} exp(-lambda) 0.1354500 0.117109153\n4 W_T = ((n-1)/n)^T exp(-lambda) 0.1354626 0.004083226\n\nout$resumen_teorico\n\n          Estimador    Var_teor\n1            W = X1 2.000000000\n2         W_T = T/n 0.200000000\n3       W = 1{X1=0} 0.117019644\n4 W_T = ((n-1)/n)^T 0.004055133\n\n\nQu√© muestra\n\nDensidad y boxplot (objetivo \\(\\lambda\\)):\nCompara \\(W = X_1\\) vs \\(W_T = T/n\\).\nAmbos se centran en \\(\\lambda\\), pero ver√°s menor varianza para \\(W_T\\).\nBarras/boxplot (objetivo \\(e^{-\\lambda}\\)):\nCompara \\(W = \\mathbf{1}\\{X_1=0\\}\\) vs \\(W_T = \\Big(\\tfrac{n-1}{n}\\Big)^T\\).\nAmbos centrados en \\(e^{-\\lambda}\\), con varianza menor para \\(W_T\\).\n\n\nSugerencia: juega con \\(\\lambda\\) y \\(n\\) en explore_LS(lambda, n, ...) para ver c√≥mo cambia la varianza.\nPor Lehmann‚ÄìScheff√©, \\(W_T\\) es el UMVUE y √∫nico (bajo varianza finita) cuando \\(T\\) es suficiente y completo.\n\n3.12.2 Normalidad asint√≥tica\nEn muchas ocasiones s√≥lo es posible realizar estudios del comportamiento asint√≥tico (cuando n tiende a infinito) de los estimadores. Ya hemos estudiado una propiedad asint√≥tica: la consistencia. Veremos ahora que es posible medir la velocidad de convergencia de estimadores consistentes y as√≠ seleccionar los que convergen al verdadero valor del par√°metro m√°s r√°pidamente.\n\nExample 3.11 Sea \\(X_1,\\ldots, X_n\\) una m.a.s. de \\(X\\sim Pois(\\lambda)\\), con \\(\\lambda&gt;0\\). En este modelo, el estimador de momentos de \\(\\lambda\\) coincide con el m√°ximo verosimil: \\(\\hat{\\lambda}_n=\\bar{X}_n\\). Para determinar la distribuci√≥n del estimador \\(\\hat{\\lambda}\\) resulta mucho m√°s √∫til aproximarla por una distribuci√≥n m√°s sencilla a la que se acerca asint√≥ticamente.\nLa versi√≥n del teorema central del l√≠mite para variables aleatorias independientes e id√©nticamente distribuidas puede aplicarse porque \\(V(X) = \\lambda &lt; \\infty\\).\n\\[\\begin{align}\n\\frac{\\sqrt{n}(\\hat{\\lambda}_n-\\lambda)}{\\sqrt{\\lambda}}\\longrightarrow N(0,1) \\mbox{ d√©bilmente,}\n\\end{align}\\] es decir, para todo \\(\\lambda\\in \\Theta\\) y para todo \\(w\\in\\mathbb{R}\\), \\[\\begin{align}\nP_\\lambda(\\hat{\\lambda}\\leq w)\\approx \\phi\\left(\\frac{\\sqrt{n}(w-\\lambda)}{\\sqrt{\\lambda}}\\right)\n\\end{align}\\] donde \\(\\phi\\) es la funci√≥n de distribuci√≥n de la normal est√°ndar. La aproximaci√≥n es tanto mejor cuanto mayores son \\(n\\) o \\(\\lambda\\).\nObs√©rvese que \\(\\hat{\\lambda}_n\\) es consistente pues, por las leyes de los grandes n√∫meros, \\[\\hat{\\lambda}_n = \\bar{X}_n \\stackrel{P}{\\longrightarrow} E(X) = \\lambda.\\] As√≠, \\(\\hat{\\lambda}_n -\\lambda \\stackrel{P}{\\longrightarrow} 0\\) y tambi√©n en distribuci√≥n. Esta convergencia a la distribuci√≥n degenerada en 0 no nos informa de la velocidad a la que \\(\\hat{\\lambda}_n\\) se acerca a \\(\\lambda\\) ni de c√≥mo lo hace.\nEl hecho de que \\(V(\\sqrt{n}(\\hat{\\lambda}_n -\\lambda)) = \\lambda\\) para todo n indica que la velocidad a la que \\(\\hat{\\lambda}_n\\) se acerca a \\(\\lambda\\) es la misma con la que \\(\\frac{1}{\\sqrt{n}}\\) se acerca a 0: multiplicar por \\(\\sqrt{n}\\) es la forma de estabilizar las diferencias \\((\\hat{\\lambda}_n-\\lambda)\\), es la estandarizaci√≥n adecuada.\nEl resultado derivado del teorema central del l√≠mite, la distribuci√≥n asint√≥tica de \\(\\sqrt{n}(\\hat{\\lambda}_n -\\lambda)\\) es \\(N(0,\\lambda)\\), responde a la pregunta de c√≥mo es la aproximaci√≥n \\(\\hat{\\lambda}_n\\) a \\(\\lambda\\) : los valores del estimador se distribuyen alrededor del verdadero valor del par√°metro igual que los valores de una variable aleatoria \\(N(0,\\lambda)\\) se distribuyen alrededor de 0.\n\n\nDefinition 3.5 En la pr√°ctica la gran mayor√≠a de los estimadores usuales, convenientemente centrados y normalizados, tienen distribuci√≥n asint√≥tica normal. Se dice que presentan y se denota \\[\\begin{align}\n        \\hat{\\theta}_n\\sim AN(\\theta,v_n)\n    \\end{align}\\] cuando \\[\\begin{align}\n    \\frac{1}{\\sqrt{v_n}}(\\hat{\\theta}_n-\\theta)\\stackrel{d}{\\longrightarrow}N(0,1)\n    \\end{align}\\]\n\nA la cantidad \\(v_n\\) se la llama varianza asint√≥tica de \\(\\hat{\\theta}_n\\). El teorema central del l√≠mite es el responsable de la normalidad asint√≥tica de muchos estimadores.\n\n3.12.3 M√©todo delta\nEn muchos casos, s√≥lo ser√° de inter√©s el comportamiento del estimador alrededor del verdadero valor del par√°metro. Si adem√°s el estimador es una funci√≥n suave de un estad√≠stico cuyo comportamiento asint√≥tico es conocido, esa funci√≥n podr√° linealizarse en un entorno del verdadero valor del par√°metro, lo cu√°l facilitar√° enormemente el estudio asint√≥tico del estimador.\n\nExample 3.12 Queremos estimar \\(\\theta=P(X=0) = \\exp\\{-\\lambda\\}\\). Por el principio de invariancia, el estimador m√°ximo veros√≠mil de \\(\\theta\\) es \\(\\hat{\\theta}_n = \\exp\\{-\\bar{X}_n\\}\\) , dado que \\(\\bar{X}_n\\) es el estimador m√°ximo veros√≠mil de \\(\\lambda\\). Por otro lado, \\(\\bar{X}_n\\) es consistente para \\(\\lambda\\) y \\(g(\\lambda) = \\exp\\{-\\lambda\\}\\) es una funci√≥n continua, luego \\(\\hat{\\theta}_n\\) es consistente para \\(\\theta\\). Estamos interesados ahora en encontrar la distribuci√≥n asint√≥tica de \\[\\begin{align}\n    \\sqrt{n}(\\hat{\\theta}_n-\\theta)=\\sqrt{n}(\\exp\\{-\\bar{X}_n\\}-\\exp\\{-\\lambda\\})\n\\end{align}\\] La herramienta en la que nos basaremos para hallar esa distribuci√≥n asint√≥tica es el m√©todo delta.\n\n\nTheorem 3.13 (M√©todo Delta) Sea \\(\\{a_n\\}_n\\) una sucesi√≥n de n√∫mero reales tales que \\(a_n\\rightarrow\\infty\\) cuando \\(n\\rightarrow\\infty\\) y con \\(a_n\\neq0\\) para todo \\(n\\). Sea \\(\\hat{\\theta}_n\\) una sucesi√≥n de estimadores de \\(\\theta\\) tales que \\[\\begin{align}\na_n(\\hat{\\theta}_n-\\theta)\\stackrel{d}{\\longrightarrow}N(0,\\sigma_\\theta^2)\n\\end{align}\\] y sea \\(g(x)\\) una funci√≥n con primera derivada continua en un intervalo que contiene a \\(\\theta\\). \\[\\begin{align}\na_n(g(\\hat{\\theta}_n)-g(\\theta))\\stackrel{d}{\\longrightarrow}N(0,(g^{'}(\\theta))^2\\sigma_\\theta^2)\n\\end{align}\\]\n\n\nExample 3.13 Estimamos \\(\\theta=P(X=0) = \\exp\\{-\\lambda\\}\\) mediante \\(\\hat{\\theta}_n = \\exp\\{-\\bar{X}_n\\}\\). Por otra parte, \\(\\sqrt{n}(\\hat{\\lambda}_n-\\lambda)\\stackrel{d}{\\longrightarrow}N(0,\\lambda)\\). Adem√°s \\(g(\\lambda)=\\exp\\{-\\lambda\\}\\) es derivable con derivada continua \\(g^{'}(\\lambda)=-\\exp\\{-\\lambda\\}\\)\nAplicando el m√©todo delta. \\[\\begin{align}\n        \\sqrt{n}(\\hat{\\theta}_n-\\theta)=\\sqrt{n}(\\exp\\{-\\bar{X}_n\\}-\\exp\\{-\\lambda\\})\\stackrel{d}{\\longrightarrow}N(0,\\lambda\\exp\\{-2\\lambda\\})\n        \\end{align}\\]\n\n\n3.12.4 Eficiencia relativa asint√≥tica\nSea \\(T_n(\\underset{\\sim}{X}) = T_n(X_1 , \\ldots, X_n)\\) una sucesi√≥n de estimadores de una funci√≥n \\(\\tau(\\theta)\\) que verifica lo siguiente: \\[\\begin{align}\n    \\sqrt{n}(T_n(\\underset{\\sim}{X})-\\tau(\\theta))\\stackrel{d}{\\longrightarrow}N(b(\\theta),\\sigma^2(\\theta))\n    \\end{align}\\] Si \\(b(\\theta) = 0\\) diremos que \\(T_n(\\underset{\\sim}{X})\\) es asint√≥ticamente insesgado. En caso contrario, diremos que \\(T_n(\\underset{\\sim}{X})\\) es asint√≥ticamente sesgado.\nSean dos sucesiones \\(T_n(X)\\) y \\(S_n(X)\\) de estimadores de \\(\\tau(\\theta)\\) asint√≥ticamente normales:\n\\[\\begin{align}\n\\sqrt{n}(T_n(\\underset{\\sim}{X})-\\tau(\\theta))\\stackrel{d}{\\longrightarrow}N(0,\\sigma_T^2(\\theta))\n\\end{align}\\]\n\\[\\begin{align}\n\\sqrt{n}(S_n(\\underset{\\sim}{X})-\\tau(\\theta))\\stackrel{d}{\\longrightarrow}N(0,\\sigma_S^2(\\theta))\n\\end{align}\\] Se define la eficiencia relativa asint√≥tica de \\(S_n(X)\\) respecto a \\(T_n(X)\\) como \\[\\begin{align}\nARE(\\theta, S_n , T_n)=\\frac{\\frac{1}{\\sigma_S^2(\\theta)}}{\\frac{1}{\\sigma_T^2(\\theta)}}=\\frac{\\sigma_T^2(\\theta)}{\\sigma_S^2(\\theta)}\n\\end{align}\\]\nEl valor de la eficiencia relativa asint√≥tica puede interpretarse como el cociente de los tama√±os de muestra necesarios para obtener la misma precisi√≥n asint√≥tica (o la misma varianza asint√≥tica) mediante los dos estimadores en la estimaci√≥n de \\(\\tau(\\theta)\\). En efecto, si elegimos tama√±o muestral m para \\(T\\) y n para \\(S\\), las varianzas asint√≥ticas son, respectivamente, \\(\\frac{\\sigma_T^2(\\theta)}{m}\\) y \\(\\frac{\\sigma_S^2(\\theta)}{n}\\). Si forzamos aque ambas sean iguales, se tiene que \\[\\begin{align}\n\\frac{\\sigma_T^2(\\theta)}{m}=\\frac{\\sigma_S^2(\\theta)}{n}\\Longleftrightarrow\\frac{m}{n}=\\frac{\\sigma_T^2(\\theta)}{\\sigma_S^2(\\theta)}=ARE(\\theta, S_n , T_n)\n\\end{align}\\]\nEs decir, si \\(ARE(\\theta, S_n , T_m) = 0.5\\) entonces \\(S\\) es menos eficiente que \\(T\\) asint√≥ticamente: para tener la misma precisi√≥n con el estimador \\(S\\) hace falta una muestra el doble de grande que si utiliz√°semos \\(T\\) (\\(ARE(\\theta, S_n , T_m)= 0.5=\\frac{m}{n}\\Longrightarrow n = 2m\\)).\n\n3.13 Referencias\n\nG√≥mez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisi√≥n. Departament d‚ÄôEstad√≠stica i Investigaci√≥ Operativa, Universitat Polit√®cnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estad√≠stica matem√°tica con aplicaciones (7¬™ ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.\nKalbfleisch, J. G. Probability and Statistical Inference. Springer-Verlag, 1985.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Estimaci√≥n puntual</span>"
    ]
  },
  {
    "objectID": "chapter3.html",
    "href": "chapter3.html",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "",
    "text": "4.1 Definiciones b√°sicas. Contraste de hip√≥tesis simples\nUna hip√≥tesis estad√≠stica es una conjetura o una afirmaci√≥n sobre la distribuci√≥n de una o m√°s variables aleatorias. Un contraste de hip√≥tesis (o un test de hip√≥tesis o una prueba de hip√≥tesis) es un procedimiento para decidir si se acepta o se rechaza una hip√≥tesis.\nPodemos distinguir tres tipos de pruebas de hip√≥tesis:\nA. Suponemos que \\(F\\) (y \\(f\\) ) pertenecen a una cierta familia param√©trica indexada por un par√°metro \\(\\theta \\in\\Theta\\) y planteamos el contraste\n\\[\\left\\{ \\begin{array}{lcc}\n    H_0 &   :  & \\theta \\in\\Theta_0 \\\\\n    \\\\ H_1 &  : & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\] donde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\)\nB. Contrastes de bondad de ajuste (goodness-of-fit tests, en ingl√©s): \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & f=f_0 \\\\\n\\\\ H_1 &  : & f\\neq f_0  \n\\end{array}\n\\right.\\]\nC. Para dos distribuciones \\(f_0\\) y \\(f_1\\) que no necesariamente pertenecen a la misma familia param√©trica, se plantea el contraste \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & f=f_0 \\\\\n\\\\ H_1 &  : & f= f_1  \n\\end{array}\n\\right.\\]\nUna hip√≥tesis simple es aquella que especifica completamente la distribuci√≥n de \\(X\\). En otro caso, se dice que la afirmaci√≥n es una hip√≥tesis compuesta. Por ejemplo, si \\(f \\in \\{f_\\theta : \\theta \\in \\Theta \\mathbb{R}\\}\\), la hip√≥tesis \\(H : \\theta = \\theta_0\\) es una hip√≥tesis simple. La hip√≥tesis \\(H : \\theta &gt; \\theta_0\\) es compuesta.\nSupongamos que se contrasta \\(H_0\\) frente a \\(H_1\\) . Cuando se observa la muestra \\(\\underset{\\sim}{x} = (x_1 ,\\ldots, x_n )\\) se debe decidir si √©sta presenta o no evidencia suficiente para rechazar \\(H_0\\) . El subconjunto \\(C\\) del espacio muestral \\(\\mathcal{X}^n\\) de muestras para las cu√°les se decide rechazar la hip√≥tesis nula en favor de la alternativa se llama regi√≥n cr√≠tica o regi√≥n de rechazo del contraste. El complementario de \\(C\\) se llama regi√≥n de aceptaci√≥n. Un contraste queda definido por su regi√≥n cr√≠tica \\(C\\).",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#definiciones-b√°sicas.-contraste-de-hip√≥tesis-simples",
    "href": "chapter3.html#definiciones-b√°sicas.-contraste-de-hip√≥tesis-simples",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.2 1. Funci√≥n de potencia",
    "text": "Usualmente se dispone de una muestra \\(X_1 ,\\ldots, X_n\\) de una variable aleatoria \\(X\\) con distribuci√≥n \\(F\\) y funci√≥n de densidad (o funci√≥n de masa) \\(f\\) . Sobre la distribuci√≥n de \\(X\\) se realizan dos afirmaciones entre las que se debe decidir.\nEn general esas dos afirmaciones ser√°n excluyentes.\n\nuna se llama hip√≥tesis nula y la otra hip√≥tesis alternativa. Se denotan por \\(H_0\\) y \\(H_1\\), respectivamente. Se dice que en un test de hip√≥tesis se contrasta \\(H_0\\) frente a \\(H_1\\) .\nLa hip√≥tesis nula es m√°s conservadora en el sentido de que no ser√° rechazada a menos que la evidencia muestral en su contra sea muy clara.\nEsta hip√≥tesis suele establecer un modelo sencillo para la distribuci√≥n de \\(X\\) (por ejemplo, si \\(F\\) pertenece a una familia param√©trica, \\(H_0\\) fija el valor del par√°metro) o bien propone como distribuci√≥n de \\(X\\) aquella que es com√∫nmente aceptada como una buena descripci√≥n del fen√≥meno que modeliza \\(X\\).\nLa hip√≥tesis alternativa especifica el tipo de alejamiento de la hip√≥tesis nula que podr√≠a presentar la distribuci√≥n de \\(X\\).\nSi un investigador considera que un fen√≥meno aleatorio no ha estado adecuadamente modelizado hasta ese momento y cree tener una explicaci√≥n m√°s satisfactoria, propondr√° √©sta como hip√≥tesis alternativa y el modelo vigente como hip√≥tesis nula.\nS√≥lo si hay evidencia muestral suficiente para rechazar la hip√≥tesis nula, ser√° aceptada la hip√≥tesis alternativa.\n\n\n\n\n\n\n\n\n\n4.1.1 Tipos de errores\nEl error de tipo I se considera m√°s grave que el error de tipo II, dado que la hip√≥tesis nula es siempre la m√°s conservadora.\n\n\n\nDECISI√ìN: Aceptar H‚ÇÄ\nDECISI√ìN: Rechazar H‚ÇÄ\n\n\n\nREALIDAD: H‚ÇÄ cierta\nDecisi√≥n correcta\nError de TIPO I\n\n\nREALIDAD: H‚ÇÄ falsa\nError de TIPO II\nDecisi√≥n correcta\n\n\n\n\\[\\begin{eqnarray*}\n    \\alpha&=&P(\\mbox{error tipo I})\\\\\n    &=&P(\\mbox{Rechazar $H_0$ cuando $H_0$ es verdadera})\\\\\n    &=&P(\\underset{\\sim}{x}\\in C\\mid H_0\\mbox{ cierta})\n\\end{eqnarray*}\\]\n\\[\\begin{eqnarray*}\n    \\beta&=&P(\\mbox{error tipo II})\\\\\n    &=&P(\\mbox{No rechazar $H_0$ cuando $H_0$ es falsa})\\\\\n    &=&P(\\underset{\\sim}{x}\\notin C\\mid H_0\\mbox{ falsa})\n\\end{eqnarray*}\\]\n\nGr√°fico de hip√≥tesis\n\n\nObs√©rvese que si se desea reducir la probabilidad del error de tipo I, \\(\\alpha = P_F(\\underset{\\sim}{x}\\in C\\mid H_0\\mbox{ cierta})\\), se habr√°n de reducir los puntos de la regi√≥n cr√≠tica \\(C\\), pero ello implica que el conjunto \\(\\bar{C}\\), complementario de \\(C\\), aumenta y as√≠ la probabilidad de error de tipo II, \\(\\beta=P_F(\\underset{\\sim}{x}\\notin C\\mid H_0\\mbox{ falsa})\\), tambi√©n crecer√° en general.\n\nDado que el error de tipo I se ha considerado m√°s grave que el error de tipo II, la pr√°ctica habitual en el contraste de hip√≥tesis es considerar √∫nicamente pruebas que garantizan que la probabilidad de cometer un error de tipo I ser√° inferior a un valor dado \\(\\alpha\\) suficientemente peque√±o (por ejemplo, \\(\\alpha = 0.01\\); \\(0.05\\); \\(0.1\\)) y\nbuscar entre todas ellas aqu√©lla que hace m√≠nima la probabilidad de cometer un error de tipo II.\nAl valor \\(\\alpha\\) se le llama nivel de significaci√≥n del test.\n\n4.1.2 Algo de interpretaci√≥n con R\nSensibilidad de \\(\\beta\\) respecto a Œ± en una prueba de hip√≥tesis\nCuando se hace una prueba unilateral para la media de una Normal con varianza conocida:\nHip√≥tesis nula\n\\[\nH_0: \\mu = \\mu_0\n\\]\nHip√≥tesis alternativa\n\\[\nH_1: \\mu &gt; \\mu_0\n\\]\n\nPunto cr√≠tico\nComo estamos en una prueba unilateral para la media de una Normal con varianza conocida:\n\nMuestra de tama√±o \\(n\\):\\(\\bar{X} \\sim N\\!\\left(\\mu, \\tfrac{\\sigma^2}{n}\\right)\\).\nBajo \\(H_0: \\mu = \\mu_0\\), rechazamos si\n\n\\[\n\\bar{X} &gt; k, \\quad \\text{donde } k = \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\\] El error de tipo II ocurre cuando no rechazamos \\(H_0\\) a pesar de que \\(\\mu = \\mu_a &gt; \\mu_0\\).\n\\[\n\\beta(\\alpha) = \\Pr(\\bar{X} \\le k \\mid \\mu = \\mu_a).\n\\]\nBajo \\(\\mu = \\mu_a\\):\n\\[\n\\bar{X} \\sim N\\!\\left(\\mu_a, \\tfrac{\\sigma^2}{n}\\right).\n\\]\nEstandarizamos:\n\\[\nZ = \\frac{\\bar{X} - \\mu_a}{\\sigma/\\sqrt{n}} \\sim N(0,1).\n\\]\nEntonces:\n\\[\n\\Pr(\\bar{X} \\le k \\mid \\mu=\\mu_a)\n= \\Pr\\!\\left( \\frac{\\bar{X} - \\mu_a}{\\sigma/\\sqrt{n}} \\le \\frac{k - \\mu_a}{\\sigma/\\sqrt{n}} \\right).\n\\]\nRecordemos:\n\\[\nk = \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPor tanto:\n\\[\n\\frac{k - \\mu_a}{\\sigma/\\sqrt{n}}\n= \\frac{\\mu_0 - \\mu_a}{\\sigma/\\sqrt{n}} + z_{1-\\alpha}.\n\\]\nDefinimos:\n\\[\n\\delta = \\frac{\\mu_a - \\mu_0}{\\sigma/\\sqrt{n}}.\n\\]\nAs√≠:\n\\[\n\\frac{k - \\mu_a}{\\sigma/\\sqrt{n}} = z_{1-\\alpha} - \\delta.\n\\] Dado que \\(Z \\sim N(0,1)\\):\n\\[\n\\Pr(\\bar{X} \\le k \\mid \\mu = \\mu_a) = \\Pr\\!\\big(Z \\le z_{1-\\alpha} - \\delta\\big).\n\\]\nY esa probabilidad se escribe con la funci√≥n de distribuci√≥n acumulada de la Normal est√°ndar (\\(\\Phi\\)):\n\\[\n\\beta(\\alpha) = \\Phi\\!\\left(z_{1-\\alpha} - \\delta\\right).\n\\]\n\nProbabilidad de error de tipo II\nSi en realidad \\(\\mu = \\mu_a &gt; \\mu_0\\), la probabilidad de cometer un error de tipo II es:\n\\[\n\\beta(\\alpha) = \\Pr(\\,\\bar{X} \\leq k \\mid \\mu = \\mu_a\\,)\n= \\Phi\\!\\left(z_{1-\\alpha} - \\delta\\right),\n\\]\ndonde:\n\\[\n\\delta = \\frac{\\mu_a - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\n\nInterpretaci√≥n did√°ctica:\nAl disminuir \\(\\alpha\\) (ser m√°s estricto para rechazar \\(H_0\\)), aumenta \\(\\beta\\) (es m√°s dif√≠cil detectar \\(H_1\\)).\n\n# Par√°metros del problema\nmu0  &lt;- 15\nmua  &lt;- 16              # media bajo H1\nsigma &lt;- 4              # desviaci√≥n conocida\nn     &lt;- 25             # tama√±o de muestra\n\n# Funci√≥n beta(Œ±) para prueba unilateral Z\nbeta_z &lt;- function(alpha, mu0, mua, sigma, n){\n  delta &lt;- (mua - mu0) / (sigma / sqrt(n))\n  pnorm(qnorm(1 - alpha) - delta)\n}\n\n# Curva beta(Œ±) en una malla de Œ±\nalphas &lt;- seq(0.001, 0.20, by = 0.001)\nbetas  &lt;- sapply(alphas, beta_z, mu0=mu0, mua=mua, sigma=sigma, n=n)\n\n# Tabla para valores t√≠picos de Œ±\nalpha_star &lt;- c(0.10, 0.05, 0.01)\nbeta_star  &lt;- sapply(alpha_star, beta_z, mu0=mu0, mua=mua, sigma=sigma, n=n)\ncbind(alpha=alpha_star, beta=round(beta_star, 4))\n\n     alpha   beta\n[1,]  0.10 0.5126\n[2,]  0.05 0.6535\n[3,]  0.01 0.8591\n\n# Gr√°fica en base R\nplot(alphas, betas, type=\"l\", lwd=2,\n     xlab=expression(alpha~\"(nivel de significancia)\"),\n     ylab=expression(beta~\"(error de tipo II)\"),\n     main=expression(paste(\"Sensibilidad de \", beta, \" respecto a \", alpha)))\ngrid()\n\n# A√±adir referencias\nabline(v = alpha_star, lty = 3)\npoints(alpha_star, beta_star, pch = 19)\ntext(alpha_star, beta_star, labels=paste0(\"  Œ≤=\", round(beta_star,3)), pos=4)\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\n\ndiffs &lt;- c(0.5, 1.0, 1.5)       # diferencias mu_a - mu_0\ndf &lt;- do.call(rbind, lapply(diffs, function(dif){\n  mua_i &lt;- mu0 + dif\n  data.frame(\n    alpha = alphas,\n    beta  = sapply(alphas, beta_z, mu0=mu0, mua=mua_i, sigma=sigma, n=n),\n    dif   = paste0(\"Œî = \", dif)\n  )\n}))\n\nggplot(df, aes(alpha, beta, color=dif)) +\n  geom_line(size=1.1) +\n  labs(x=expression(alpha), y=expression(beta),\n       title=\"Œ≤ vs Œ± para distintos tama√±os de efecto (Œî = Œº_a - Œº_0)\") +\n  theme_minimal(base_size = 12)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nCuando el efecto \\((\\Delta = \\mu_a - \\mu_0)\\) es mayor, la curva se desplaza hacia abajo:\npara el mismo \\(\\alpha\\), \\(\\beta\\) es menor \\(\\;\\Rightarrow\\;\\) la potencia \\((1-\\beta)\\) aumenta.\n\nset.seed(123)\nB &lt;- 1e5\nalpha_vec &lt;- c(0.10, 0.05, 0.01)\n\nsim_beta &lt;- function(alpha, mu0, mua, sigma, n, B=1e5){\n  k &lt;- mu0 + qnorm(1 - alpha) * sigma / sqrt(n)\n  xbar &lt;- replicate(B, mean(rnorm(n, mean=mua, sd=sigma)))\n  mean(xbar &lt;= k)  # proporci√≥n de NO-rechazos cuando H1 es verdadera = Œ≤\n}\n\nbeta_sim &lt;- sapply(alpha_vec, sim_beta, mu0=mu0, mua=mua, sigma=sigma, n=n, B=B)\nbeta_the &lt;- sapply(alpha_vec, beta_z, mu0=mu0, mua=mua, sigma=sigma, n=n)\n\ncbind(alpha=alpha_vec,\n      beta_teorico=round(beta_the,4),\n      beta_sim=round(beta_sim,4))\n\n     alpha beta_teorico beta_sim\n[1,]  0.10       0.5126   0.5133\n[2,]  0.05       0.6535   0.6534\n[3,]  0.01       0.8591   0.8606\n\n\n\n\n\n\n\n\n\nTip¬†4.1: Conclusiones\n\n\n\n\nReducir \\(\\alpha\\) implica aumentar \\(\\beta\\).\nUn mayor tama√±o del efecto \\((\\mu_a - \\mu_0)\\) o un mayor tama√±o de muestra \\(n\\) reducen \\(\\beta\\).\nLa pr√°ctica usual es fijar un \\(\\alpha\\) peque√±o (0.01, 0.05, 0.1) y luego buscar el dise√±o que minimice \\(\\beta\\) o equivalga a maximizar la potencia del test.\n\n\n\nSi el menor valor obtenido \\(\\beta\\) para la probabilidad de error de tipo II es inaceptablemente grande, pueden tomarse dos medidas para reducirlo:\n\naumentar la probabilidad de error de tipo I \\(\\alpha\\) permitida, o\naumentar el tama√±o de la muestra.\n\nSupongamos que la distribuci√≥n de \\(X\\) pertenece a una familia param√©trica \\(\\{f_\\theta:\\theta \\in\\Theta\\}\\) y se contrasta\n\\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta \\in\\Theta_0 \\\\\n\\\\ H_1 &  : & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\] donde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\). ::: {#exm-4.1} Suponga que un candidato, Jones, dice que √©l ganar√° m√°s de \\(50\\%\\) de los votos en una elecci√≥n urbana y por tanto saldr√° como ganador. Como buscamos apoyo para la hip√≥tesis alternativa de que lo dicho por Jones es falso, nuestra hip√≥tesis alternativa es que \\(p\\), la probabilidad de seleccionar un votante que est√© a favor de Jones, es menor que \\(0.5\\). Si podemos demostrar que los datos apoyan el rechazo de la hip√≥tesis nula \\(p = 0.5\\) (el valor m√≠nimo necesario para conseguir una mayor√≠a) en favor de la hip√≥tesis alternativa \\(p &lt; 0.5\\), hemos alcanzado nuestro objetivo de investigaci√≥n. Suponga que \\(n = 15\\) votantes se seleccionan aleatoriamente de una ciudad y se registra \\(Y\\), el n√∫mero que est√° a favor de Jones. Calcule \\(\\alpha\\) si seleccionamos \\(C = \\{y \\leq 2\\}\\) como la regi√≥n de rechazo.\nPara la encuesta pol√≠tica de Jones se muestrearon \\(n=15\\) votantes. \\[\\begin{eqnarray*}\n    H_0&:&p=0.5\\\\\n    H_a&:&p&lt;0.5\n\\end{eqnarray*}\\] Estad√≠stico de prueba es \\(Y\\).\n\n\n\\(Y:\\#\\) de votantes a favor. \\(Y\\sim Binom(15,\\,p)\\)\n\nRegi√≥n de rechazo RR: \\[RR=\\{Y\\leq 2\\}\\]\nC'alculo de \\(\\alpha\\): \\[\\begin{eqnarray*}\n      \\alpha&=&P(\\mbox{error tipo I})\\\\\n      &=&P(\\mbox{Rechazar $H_0$ cuando $H_0$ es verdadera})\\\\\n      &=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\n  \\end{eqnarray*}\\]\n\n\n\\[\\begin{eqnarray*}\n        \\alpha&=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\\\\\n        &=&pbinom(2,\\,15,\\,0.5)\\\\\n        &=&0.003692627\n    \\end{eqnarray*}\\]\nAsumimos un riesgo muy peque√±o (\\(\\alpha=0.004\\)), de concluir que Jones perder√° si en realidad es el ganador.\n\\[\\begin{eqnarray*}\n    \\beta(p_1=0.3)&=&P(\\mbox{error tipo II})\\\\\n    &=&P(\\mbox{No rechazar $H_0$ cuando $H_a$ es verdadera})\\\\\n    &=&P(Y&gt; 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-P(Y\\leq 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-pbinom(2,\\,15,\\,0.3)\\\\\n    &=&0.8731723\n\\end{eqnarray*}\\] Esta prueba nos llevar√° a concluir que Jones es ganador, a√∫n cuando \\(p=0.3\\). :::\n\nDefinition 4.1 Se define la funci√≥n de potencia \\(\\eta(\\theta)\\) del contraste como \\[\\eta(\\theta)=P_\\theta(\\underset{\\sim}{x}\\in C)=\\left\\{ \\begin{array}{lcc}\n\\alpha &   si & \\theta \\in\\Theta_0 \\\\\n\\\\ 1-\\beta &  si & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\]\nPara \\(0\\leq\\alpha\\leq1\\), un contraste de hip√≥tesis con funci√≥n de potencia \\(\\eta(\\theta)\\) tiene tama√±o \\(\\alpha\\) si \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)=\\alpha\\] Para \\(0\\leq\\alpha\\leq1\\), un contraste de hip√≥tesis con funci√≥n de potencia \\(\\eta(\\theta)\\) tiene Nivel de significancia \\(\\alpha\\) si \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)\\leq\\alpha\\]\n\nEl conjunto de contrastes con nivel de significaci√≥n \\(\\alpha\\) contiene las pruebas de tama√±o \\(\\alpha\\).\nUn contraste que minimiza \\(\\beta=P_\\theta(\\underset{\\sim}{x}\\in \\bar{C}\\mid H_1\\mbox{ cierta})\\) entre aquellos que tienen tama√±o \\(\\alpha\\) se dice que es el contraste m√°s potente de tama√±o \\(\\alpha\\) o el mejor contraste de tama√±o \\(\\alpha\\).\n\n\n\n\n\n\nTip¬†4.2: Funci√≥n de potencia y contrastes m√°s potentes\n\n\n\n\n4.2 1. Funci√≥n de potencia\nLa funci√≥n de potencia de una prueba mide, para cada valor posible del par√°metro \\(\\theta\\), la probabilidad de rechazar la hip√≥tesis nula:\n\\[\n\\eta(\\theta) = P_\\theta(\\tilde{x} \\in C),\n\\]\ndonde: - \\(\\tilde{x}\\) es la muestra, - \\(C\\) es la regi√≥n cr√≠tica (el conjunto de valores de la muestra que llevan a rechazar \\(H_0\\)).\nEn palabras:La funci√≥n de potencia nos dice qu√© tan probable es rechazar \\(H_0\\), dado que el par√°metro vale \\(\\theta\\).\n\n4.3 2. Casos especiales de la funci√≥n de potencia\n\n\nSi \\(\\theta \\in \\Theta_0\\) (es decir, si \\(H_0\\) es cierta):\n\\[\n\\eta(\\theta) = \\alpha\n\\]\nEsto refleja que, bajo \\(H_0\\), la probabilidad de rechazar \\(H_0\\) es justamente la probabilidad de cometer un error de tipo I.\n\n\nSi \\(\\theta \\in \\Theta_1\\) (es decir, si \\(H_1\\) es cierta):\n\\[\n\\eta(\\theta) = 1 - \\beta\n\\]\nEsto refleja que, bajo \\(H_1\\), la probabilidad de rechazar \\(H_0\\) es la potencia de la prueba.\n\n\n\n4.4 3. Tama√±o y nivel de significaci√≥n\n\n\nTama√±o \\(\\alpha\\):\nUna prueba tiene tama√±o \\(\\alpha\\) si el peor caso (la mayor probabilidad de rechazar \\(H_0\\) cuando es cierta) es exactamente \\(\\alpha\\):\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) = \\alpha\n\\]\n‚Üí El tama√±o es el ‚Äúvalor m√°ximo real‚Äù de error tipo I que puede ocurrir bajo \\(H_0\\).\n\n\nNivel de significaci√≥n \\(\\alpha\\):\nUna prueba tiene nivel de significaci√≥n \\(\\alpha\\) si ese peor caso no excede \\(\\alpha\\):\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) \\leq \\alpha\n\\]\n‚Üí El nivel de significaci√≥n es un l√≠mite superior que ponemos a la probabilidad de error tipo I.\n\n\nNota: Todo contraste de tama√±o \\(\\alpha\\) tiene tambi√©n nivel de significaci√≥n \\(\\alpha\\), pero no todo contraste con nivel de significaci√≥n \\(\\alpha\\) necesariamente alcanza el tama√±o exacto.\n\n4.5 4. Contraste m√°s potente\nEntre todas las pruebas que tienen el mismo tama√±o \\(\\alpha\\), buscamos la que minimiza \\(\\beta\\) (o equivalentemente, la que maximiza la potencia \\(1-\\beta\\)).\nEsa prueba se llama:\n\n\nEl contraste m√°s potente de tama√±o \\(\\alpha\\),\n\no el mejor contraste de tama√±o \\(\\alpha\\).\n\nEs decir, para un mismo control de error tipo I, elegimos la prueba que detecta con mayor eficacia cuando \\(H_1\\) es verdadera.\n\nEn resumen:\n- La funci√≥n de potencia es la herramienta que unifica \\(\\alpha\\) y \\(1-\\beta\\).\n- Tama√±o = probabilidad m√°xima de error tipo I.\n- Nivel de significaci√≥n = restricci√≥n para controlar ese error.\n- El mejor contraste de tama√±o \\(\\alpha\\) es aquel que, manteniendo fijo el error tipo I, maximiza la probabilidad de rechazar \\(H_0\\) cuando realmente es falsa.\n\n\n\n\nExample 4.1 (Problema 1) Sea \\(X \\sim \\mathrm{Bin}(5,\\theta)\\). Considere el contraste \\[\n\\begin{cases}\nH_0:\\ \\theta \\le \\tfrac{1}{2},\\\\[2mm]\nH_1:\\ \\theta &gt; \\tfrac{1}{2}.\n\\end{cases}\n\\]\nEstablezca la funci√≥n de potencia, gr√°fiquela e interprete comparativamente los resultados en las siguientes dos opciones:\n\nConsidere primero el contraste de rechazar \\(H_0\\) si y s√≥lo si se observan todos los √©xitos (es decir, \\(X=5\\)).\n\nOpci√≥n (a):\nRechazar \\(H_0\\) solo si se observan los 5 √©xitos\nModelo. Sea \\(X \\sim \\mathrm{Bin}(5,\\theta)\\) con funci√≥n de probabilidad\\(P_\\theta(X=x)=\\binom{5}{x}\\theta^x(1-\\theta)^{5-x}\\), \\(x=0,1,\\dots,5\\).\nRegi√≥n cr√≠tica La regla propuesta es rechazar \\(H_0\\) √∫nicamente cuando \\(X=5\\). Por tanto, \\[\nC_a=\\{5\\},\\qquad \\bar C_a=\\{0,1,2,3,4\\}.\n\\]\nFunci√≥n de potencia \\(\\eta_a(\\theta)\\) Por definici√≥n, la potencia es la probabilidad de caer en la regi√≥n cr√≠tica: \\[\n\\eta_a(\\theta)=P_\\theta(X\\in C_a)=P_\\theta(X=5)\n=\\binom{5}{5}\\theta^5(1-\\theta)^{0}\n=\\theta^5.\n\\] Es decir, para cualquier \\(0\\le \\theta\\le 1\\), \\[\n\\eta_a(\\theta)=\\theta^5.\n\\]\nTama√±o (m√°ximo error tipo I) El tama√±o del contraste es \\[\n\\alpha_a=\\sup_{\\theta\\in\\Theta_0}\\eta_a(\\theta)\n=\\sup_{\\theta\\le 1/2}\\theta^5.\n\\] Como \\(\\theta^5\\) es estrictamente creciente en \\(\\theta\\) (derivada \\(5\\theta^4&gt;0\\)), el supremo en \\(\\Theta_0=\\{\\theta\\le 1/2\\}\\) se alcanza en el borde \\(\\theta=1/2\\): \\[\n\\alpha_a=\\left(\\tfrac12\\right)^5=\\frac{1}{32}\\approx 0.03125.\n\\]\nLectura e intuici√≥n - La regla \\(C_a=\\{5\\}\\) es muy conservadora: solo rechaza \\(H_0\\) en el caso m√°s extremo. - Por eso, el tama√±o es muy peque√±o (\\(\\alpha_a\\approx 3.1\\%\\)). - La potencia \\(\\eta_a(\\theta)=\\theta^5\\) crece muy lentamente; el test casi nunca rechaza salvo que \\(\\theta\\) sea muy grande.\nEn t√©rminos del error tipo II \\(\\beta_a(\\theta)=1-\\eta_a(\\theta)=1-\\theta^5\\): - Si \\(\\theta=0.6\\), \\(\\beta_a=1-0.6^5\\approx 0.922\\) (muy alto). - Si \\(\\theta=0.9\\), \\(\\beta_a=1-0.9^5\\approx 0.410\\). - Reci√©n cerca de \\(\\theta=0.99\\), \\(\\beta_a\\approx 0.049\\).\n\n\n\n\n\n\n\nConcepto\nExplicaci√≥n\nEjemplos num√©ricos\n\n\n\n\nRegla \\(C_a = \\{5\\}\\)\n\nMuy conservadora: solo rechaza \\(H_0\\) en el caso m√°s extremo.\n-\n\n\n\nTama√±o \\(\\alpha_a\\)\n\nMuy peque√±o (\\(\\alpha_a \\approx 3.1\\%\\)).\n-\n\n\n\nPotencia \\(\\eta_a(\\theta) = \\theta^5\\)\n\nCrece muy lentamente; el test casi nunca rechaza salvo que \\(\\theta\\) sea muy grande.\n-\n\n\n\nError tipo II \\(\\beta_a(\\theta) = 1 - \\eta_a(\\theta) = 1 - \\theta^5\\)\n\nSe mantiene alto para valores de \\(\\theta\\) moderados.\n- Para \\(\\theta=0.6\\): \\(\\beta_a = 1 - 0.6^5 \\approx 0.922\\) (muy alto).  - Para \\(\\theta=0.9\\): \\(\\beta_a = 1 - 0.9^5 \\approx 0.410\\).  - Para \\(\\theta=0.99\\): \\(\\beta_a \\approx 0.049\\).\n\n\n\nConclusi√≥n. Es un contraste con bajo error tipo I pero muy poca potencia, salvo cuando el efecto es extremadamente grande (valores de \\(\\theta\\) muy cercanos a 1).\n\nConsidere en segundo lugar el contraste de rechazar \\(H_0\\) si \\(X \\in \\{3,4,5\\}\\).\n\nOpci√≥n (b):\nRechazar \\(H_0\\) si \\(X\\in\\{3,4,5\\}\\) (equiv. \\(X\\ge 3\\))\nModelo. Sea \\(X\\sim \\mathrm{Bin}(5,\\theta)\\) con \\[\nP_\\theta(X=x)=\\binom{5}{x}\\,\\theta^x(1-\\theta)^{5-x},\\quad x=0,1,\\dots,5.\n\\]\nRegi√≥n cr√≠tica \\[\nC_b=\\{3,4,5\\},\\qquad \\bar C_b=\\{0,1,2\\}.\n\\]\nFunci√≥n de potencia \\(\\eta_b(\\theta)\\) Por definici√≥n, la potencia es la probabilidad de caer en la regi√≥n cr√≠tica: \\[\n\\eta_b(\\theta)=P_\\theta(X\\in C_b)=P_\\theta(X\\ge 3)\n=\\sum_{k=3}^{5}\\binom{5}{k}\\theta^k(1-\\theta)^{5-k}.\n\\]\nSuma directa. \\[\n\\eta_b(\\theta)=10\\,\\theta^3(1-\\theta)^2+5\\,\\theta^4(1-\\theta)+\\theta^5.\n\\]\nV√≠a complemento (√∫til para el tama√±o). \\[\n\\eta_b(\\theta)=1-P_\\theta(X\\le 2)\n=1-\\Big[(1-\\theta)^5+5\\theta(1-\\theta)^4+10\\theta^2(1-\\theta)^3\\Big].\n\\]\nMonoton√≠a. Para la familia binomial, \\(P_\\theta(X\\ge c)\\) es creciente en \\(\\theta\\) (propiedad MLR). Por tanto, \\(\\eta_b(\\theta)\\) aumenta con \\(\\theta\\).\nTama√±o (m√°ximo error tipo I) El tama√±o es \\[\n\\alpha_b=\\sup_{\\theta\\le 1/2}\\eta_b(\\theta).\n\\] Como \\(\\eta_b(\\theta)\\) es creciente, el supremo se alcanza en el borde \\(\\theta=1/2\\): \\[\n\\alpha_b=\\eta_b(1/2)=P_{1/2}(X\\ge 3)=1-P_{1/2}(X\\le 2).\n\\] Con simetr√≠a binomial: \\[\nP_{1/2}(X\\le 2)=\\frac{\\binom50+\\binom51+\\binom52}{2^5}\n=\\frac{1+5+10}{32}=\\frac{16}{32},\n\\] luego \\[\n\\alpha_b=1-\\frac{16}{32}=\\frac{16}{32}=0.5.\n\\]\nLectura num√©rica (potencia y error tipo II) Valores aproximados:\n\\[\n\\begin{array}{c|ccccc}\n\\theta & 0.55 & 0.60 & 0.70 & 0.80 & 0.90\\\\ \\hline\n\\eta_b(\\theta)=P_\\theta(X\\ge 3) & 0.593 & 0.683 & 0.837 & 0.942 & 0.991\\\\\n\\beta_b(\\theta)=1-\\eta_b(\\theta) & 0.407 & 0.317 & 0.163 & 0.058 & 0.009\n\\end{array}\n\\]\n\nPara \\(\\theta&gt;1/2\\), la potencia crece r√°pido y el error tipo II cae pronto: ya con \\(\\theta\\approx 0.7\\) la potencia es alta.\nEl costo es un tama√±o enorme: \\(\\alpha_b=0.5\\) (inaceptable en la pr√°ctica).\n\nObservaci√≥n de dise√±o (c√≥mo fijar \\(\\alpha\\) razonable)\nCon \\(n=5\\) y \\(H_0:\\theta\\le 1/2\\):\n\n\\(X\\ge 5\\) da \\(\\alpha=(1/2)^5=1/32\\approx 0.03125\\).\n\\(X\\ge 4\\) da \\(\\alpha=P_{1/2}(X\\ge 4)=(\\binom54+\\binom55)/32=(5+1)/32=6/32=0.1875\\).\nPara alcanzar, por ejemplo, \\(\\alpha=0.10\\), ser√≠a necesario aleatorizar en \\(X=4\\) (rechazar con cierta probabilidad cuando \\(X=4\\)) o aumentar el tama√±o muestral.\n\n\n\n\ntheta &lt;- seq(0,1,by=0.001)\n\neta_a &lt;- theta^5\neta_b &lt;- 10*theta^3*(1-theta)^2 + 5*theta^4*(1-theta) + theta^5\n\nplot(theta, eta_a, type=\"l\", lwd=2,\n     xlab=expression(theta), ylab=expression(eta(theta)),\n     main=\"Funciones de potencia: regiones cr√≠ticas {5} y {3,4,5}\")\nlines(theta, eta_b, lwd=2, lty=2)\nabline(v=0.5, lty=3); abline(h=c((0.5)^5, 0.5), lty=3)\nlegend(\"topleft\",\n       legend = c(expression(C[a]==5),\n                  expression(C[b] &gt;= 3)),\n       lwd = 2, lty = c(1,2), bty = \"n\")\n\n\n\n\n\n\n\n\n\nExample 4.2 (Problema 2) Apoy√°ndose en el ejercicio anterior, responda claramente a las siguientes preguntas:\nI. A partir del contraste del inciso a, ¬øes falsa o verdadera la afirmaci√≥n: ‚ÄúLa probabilidad del error tipo I es aceptablemente baja para todo \\(\\theta \\le \\tfrac{1}{2}\\)‚Äù? Explique su respuesta.\nS√≠, es verdadera.\nBajo \\(H_0:\\theta\\le \\tfrac12\\), el error tipo I del contraste (a) es \\[\nP_\\theta(\\text{rechazar }H_0)=\\eta_a(\\theta)=\\theta^5.\n\\] Como \\(\\theta^5\\) es creciente en \\(\\theta\\), su m√°ximo sobre \\(\\Theta_0=\\{\\theta\\le \\tfrac12\\}\\) se alcanza en el borde: \\[\n\\alpha_a=\\sup_{\\theta\\le 1/2}\\eta_a(\\theta)=\\eta_a\\!\\left(\\tfrac12\\right)=\\left(\\tfrac12\\right)^5=\\frac{1}{32}\\approx 0.03125.\n\\] Por tanto, para todo \\(\\theta\\le \\tfrac12\\) se tiene \\(\\eta_a(\\theta)\\le 0.03125\\), es decir, un nivel de error tipo I muy bajo.\n\n¬øPara qu√© valores de \\(\\theta\\) el error tipo II es menor que \\(\\tfrac{1}{2}\\) en el contraste del inciso a?\n\nEn (a), bajo \\(H_1\\) el error tipo II es \\[\n\\beta_a(\\theta)=1-\\eta_a(\\theta)=1-\\theta^5.\n\\] La condici√≥n \\(\\beta_a(\\theta)&lt;\\tfrac12\\) equivale a \\[\n1-\\theta^5&lt;\\tfrac12\\quad\\Longleftrightarrow\\quad \\theta^5&gt;\\tfrac12\n\\quad\\Longleftrightarrow\\quad \\theta&gt;(1/2)^{1/5}\\approx 0.87055.\n\\] Luego, para \\(\\theta&gt;0.87055\\) (y, por supuesto, \\(\\theta&gt;1/2\\)), el error tipo II es menor a \\(1/2\\).\n\nEn el contraste del inciso b, ¬øpara qu√© valores de \\(\\theta\\) el error tipo II alcanza valores peque√±os?\n\nEn (b), \\[\n\\beta_b(\\theta)=1-\\eta_b(\\theta)=P_\\theta(X\\le 2)\n=(1-\\theta)^5+5\\theta(1-\\theta)^4+10\\theta^2(1-\\theta)^3,\n\\] funci√≥n decreciente en \\(\\theta\\). Valores representativos: \\[\n\\begin{array}{c|ccccc}\n\\theta & 0.55 & 0.60 & 0.70 & 0.75 & 0.80\\\\ \\hline\n\\beta_b(\\theta) & 0.407 & 0.317 & 0.163 & 0.104 & 0.058\n\\end{array}\n\\] Se observa que \\(\\beta_b(\\theta)\\) ya es peque√±a (por ejemplo \\(&lt;0.10\\)) a partir de \\(\\theta\\gtrsim 0.78\\) (pues en \\(0.75\\) es \\(\\approx 0.104\\) y en \\(0.80\\) es \\(\\approx 0.058\\)).\n\n¬øEs falso o verdadero afirmar que: ‚ÄúLa potencia del contraste del inciso b es mayor que la potencia del otro contraste para valores de \\(\\theta \\le \\tfrac{1}{2}\\). Entonces, la probabilidad del error tipo I del contraste del inciso b es mayor que la del otro contraste para valores de \\(\\theta \\le \\tfrac{1}{2}\\)‚Äù? Explique su respuesta.\n\n\nVerdadero.\nPara \\(\\theta\\le \\tfrac12\\) (regi√≥n nula):\n\nLa ‚Äúpotencia‚Äù \\(\\eta(\\theta)\\) coincide con la probabilidad de error tipo I en ese punto.\nNum√©ricamente (y por la propiedad MLR de la binomial) se verifica que \\[\n\\eta_b(\\theta)=P_\\theta(X\\ge 3)\\;&gt;\\;\\eta_a(\\theta)=\\theta^5\n\\quad \\text{para todo }\\theta\\le \\tfrac12.\n\\] Ejemplos:\\(\\theta=0.5:\\ \\eta_b=0.5\\ \\text{vs}\\ \\eta_a=0.03125\\);\\(\\theta=0.4:\\ \\eta_b\\approx 0.31744\\ \\text{vs}\\ \\eta_a=0.01024\\).\nEn particular, el tama√±o es mayor en (b):\\[\n\\alpha_b=\\eta_b(1/2)=0.5 \\quad\\gg\\quad \\alpha_a=\\eta_a(1/2)=1/32\\approx 0.03125.\n\\]\n\nConclusi√≥n: el contraste (b) rechaza con mucha m√°s frecuencia bajo \\(H_0\\) (mayor error tipo I), lo que explica su mayor potencia bajo \\(H_1\\); el costo es un nivel \\(\\alpha\\) inaceptablemente alto en (b) comparado con (a).\n\nEl siguiente resultado determina cu√°l es el contraste m√°s potente cuando se contrasta una hip√≥tesis nula simple frente a una alternativa simple.\n\n4.5.1 Lema de Neyman-Pearson\nSea \\(X_1 ,\\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) con funci√≥n de densidad (o funci√≥n de masa de probabilidad) \\(f(x; \\theta)\\). Se desea contrastar \\(H_ 0 : \\theta = \\theta_0\\) frente a \\(H_1 : \\theta = \\theta_1\\) . Si \\(L(\\theta\\mid\\underset{\\sim}{x})\\) es la funci√≥n de verosimilitud, el mejor contraste de tama√±o \\(\\alpha\\) tiene regi√≥n cr√≠tica de la forma \\[C=\\left\\{\\underset{\\sim}{x}\\in\\mathcal{X}^n:\\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\geq A\\right\\}\\] para alg√∫n \\(A\\geq 0\\).\nEl contraste que se propone en el Lema de Neyman-Pearson se denomina tambi√©n test de la raz√≥n de verosimilitudes.\n\nExample 4.3 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu, \\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0 : \\mu= \\mu_0\\) frente a \\(H_1: \\mu = \\mu_1\\), con \\(\\mu_1 &gt; \\mu_0\\).\n\nNuestra intuici√≥n nos dice que se debe rechazar \\(H_0\\) si se observan valores grandes de \\(x\\). Veamos que la aplicaci√≥n del Lema de Neyman-Pearson conduce a esta soluci√≥n.\n\nExample 4.4 (Ejemplo anterior) Test Z unilateral por Neyman‚ÄìPearson (varianza conocida)\nSea \\(X_1,\\ldots,X_n\\) una muestra aleatoria simple de \\(X\\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocida.\nSe desea contrastar \\[\nH_0:\\ \\mu=\\mu_0\n\\qquad\\text{frente a}\\qquad\nH_1:\\ \\mu=\\mu_1,\\ \\ \\mu_1&gt;\\mu_0.\n\\]\nLa intuici√≥n sugiere rechazar \\(H_0\\) cuando la media muestral \\(\\bar X\\) tome valores grandes.\nVeremos que el Lema de Neyman‚ÄìPearson conduce exactamente a esta regla.\n\nVerosimilitud y cociente de verosimilitudes\nLa verosimilitud de una muestra \\(x=(x_1,\\dots,x_n)\\) es \\[\nL(\\mu\\mid x)=(2\\pi\\sigma^2)^{-n/2}\\exp\\!\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i-\\mu)^2\\right\\}.\n\\]\nEl cociente de verosimilitudes (likelihood ratio) es \\[\n\\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\n=\\exp\\!\\left\\{\\frac{1}{2\\sigma^2}\\sum_{i=1}^n\\Big[(x_i-\\mu_0)^2-(x_i-\\mu_1)^2\\Big]\\right\\}.\n\\]\nNotemos que \\[\n(x_i-\\mu_0)^2-(x_i-\\mu_1)^2\n=2x_i(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2),\n\\] de modo que, al sumar y usar \\(\\bar x=\\tfrac{1}{n}\\sum x_i\\), \\[\n\\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\n=\\exp\\!\\left\\{\\frac{n}{2\\sigma^2}\\Big(2\\bar x(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2)\\Big)\\right\\}.\n\\]\nPor el Lema de Neyman‚ÄìPearson, la regi√≥n cr√≠tica √≥ptima (para tama√±o dado) es del tipo \\[\nC=\\Big\\{x:\\ \\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\\ge A\\Big\\}\n=\\left\\{x:\\ \\exp\\!\\left\\{\\frac{n}{2\\sigma^2}\\Big(2\\bar x(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2)\\Big)\\right\\}\\ge A\\right\\}.\n\\]\nComo \\(\\mu_1-\\mu_0&gt;0\\), el cociente es funci√≥n creciente de \\(\\bar x\\). Por tanto, la regi√≥n cr√≠tica puede escribirse como \\[\nC=\\{x:\\ \\bar x\\ge B\\}.\n\\]\nLas constantes \\(A\\) y \\(B\\) se relacionan por \\[\nB=\\frac{\\sigma^2\\log A}{n(\\mu_1-\\mu_0)}+\\frac{\\mu_1+\\mu_0}{2}.\n\\]\n\nFijar el tama√±o \\(\\alpha\\) y obtener \\(B\\)\nNo es necesario hallar \\(B\\) a partir de \\(A\\). Basta imponer el tama√±o deseado: \\[\nP(C\\mid H_0)=P(\\bar X\\ge B\\mid H_0)=\\alpha.\n\\] Bajo \\(H_0\\), \\(\\bar X\\sim N(\\mu_0,\\sigma^2/n)\\), as√≠ que \\[\nB=\\mu_0+z_\\alpha\\,\\frac{\\sigma}{\\sqrt{n}},\n\\] donde \\(z_\\alpha\\) satisface \\(P(Z\\ge z_\\alpha)=\\alpha\\) para \\(Z\\sim N(0,1)\\).\nLa regla de decisi√≥n equivalente es: \\[\n\\text{Rechazar }H_0\\ \\ \\Longleftrightarrow\\ \\ Z=\\frac{\\bar X-\\mu_0}{\\sigma/\\sqrt{n}}\\ge z_\\alpha.\n\\]\n\nEjemplo num√©rico\nSupongamos \\(\\mu_0=5\\), \\(\\mu_1=6\\), \\(\\sigma^2=1\\) (luego \\(\\sigma=1\\)), \\(\\alpha=0.05\\) y \\(n=4\\).\n\nUmbral cr√≠tico para \\(\\bar X\\): \\[\nB=\\mu_0+z_{0.05}\\frac{\\sigma}{\\sqrt{n}}\n=5+1.645\\cdot\\frac{1}{2}\n=5+0.8225\n=5.8225.\n\\]\nRegla equivalente con \\(Z\\): \\[\nZ=\\frac{\\bar X-5}{1/\\sqrt{4}}\n=\\frac{\\bar X-5}{0.5}\n\\ge 1.645.\n\\]\nDatos observados: \\(x=(5.1,\\,5.5,\\,4.9,\\,5.3)\\).\nMedia muestral: \\(\\bar x=\\tfrac{5.1+5.5+4.9+5.3}{4}=5.2\\).\nC√°lculo del estad√≠stico: \\[\nz=\\frac{\\bar x-5}{1/\\sqrt{4}}=\\frac{5.2-5}{0.5}=0.4&lt;1.645.\n\\]\n\nDecisi√≥n: no se rechaza \\(H_0\\) al nivel \\(\\alpha=0.05\\).\n\nComentario final\nEste contraste se denomina test Z unilateral porque usa el estad√≠stico \\[\nZ=\\sqrt{n}\\,\\frac{\\bar X-\\mu_0}{\\sigma}\\ \\sim\\ N(0,1)\\ \\ \\text{bajo }H_0.\n\\]\n\n\n\n\n\n\n\nTip¬†4.3: Conclusiones de un contraste: el p-valor.\n\n\n\n\nUna forma de informar de los resultados de un contraste de hip√≥tesis es mediante el tama√±o \\(\\alpha\\) del test usado y la decisi√≥n tomada sobre si se rechaz√≥ o no \\(H_0\\).\nSi \\(\\alpha\\) es peque√±o la decisi√≥n de rechazar \\(H_0\\) es muy convincente, pero si \\(\\alpha\\) es grande la probabilidad de cometer un error de tipo I es grande, lo cu√°l resta fuerza al test si la decisi√≥n adoptada es la de rechazar \\(H_0\\).\nPor otro lado, para \\(\\alpha\\) muy peque√±o, el hecho de no rechazar \\(H_0\\) no se interpretar√° como un apoyo indiscutible a esta hip√≥tesis sino como que no fue posible encontrar evidencia suficiente en su contra como para superar la barrera tan restrictiva impuesta por ese valor de \\(\\alpha\\).\n\n\n\n\nDefinition 4.2 Una forma alternativa de presentar los resultados de un contraste de hip√≥tesis es dar el p-valor o valor de probabilidad del test, definido √©ste como el supremo de los valores \\(\\alpha\\) para los cu√°les se rechazar√≠a la hip√≥tesis nula si √©sta se contrastase a nivel \\(\\alpha\\).\n\nEl p-valor depende de los datos muestrales. Puede interpretarse como la probabilidad de observar otra muestra que sea al menos tan poco favorable a la hip√≥tesis nula como la que se ha observado.\nA partir del p-valor se puede tomar la decisi√≥n de rechazar (respectivamente, aceptar) \\(H_0\\) si el p-valor es peque√±o (respectivamente, grande).\nPor ejemplo, el p-valor de un contraste dado por el Lema de Neyman-Pearson es: \\[p=P_{\\theta_0}\\left\\{\\frac{L(\\theta_1\\mid\\underset{\\sim}{X})}{L(\\theta_0\\mid\\underset{\\sim}{X})}\\geq \\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\right\\}\\] En general, cuando la regi√≥n cr√≠tica de un contraste de tama√±o \\(\\alpha\\) es tal que se rechaza \\(H_0\\) si y s√≥lo si \\(W(\\underset{\\sim}{x})\\geq c_\\alpha\\), donde \\(W(\\underset{\\sim}{x})\\) es un estad√≠stico y \\(c_\\alpha\\) se elige para que el test tenga tama√±o \\(\\alpha\\), entonces el p-valor del contraste para una muestra observada \\(\\underset{\\sim}{x}\\) es \\[p(\\underset{\\sim}{x})=\\sup_{\\theta\\in\\Theta_0}P_{\\theta_0}\\{W(\\underset{\\sim}{X})\\geq W(\\underset{\\sim}{x})\\}\\]",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter4.html",
    "href": "chapter4.html",
    "title": "5¬† Estimaci√≥n por intervalos",
    "section": "",
    "text": "5.1 Intervalos de confianza\nEn este cap√≠tulo se aborda el problema de la estimaci√≥n por conjuntos, donde se estudian estimadores que proporcionan un conjunto como estimaci√≥n de \\(\\theta\\). El resultado de una estimaci√≥n por conjuntos es una afirmaci√≥n del tipo \\(\\theta \\in C\\), donde \\(C = C(\\underset{\\sim}{x})\\) es un subconjunto del espacio param√©trico \\(\\theta\\) que depende de los datos observados \\(x\\). En el caso de que \\(\\Theta \\subseteq \\mathbb{R}\\) los conjuntos que se suelen usar para realizar inferencias sobre \\(\\theta\\) son intervalos.\nUn estimador por intervalos de un par√°metro \\(\\theta\\in\\Theta \\subseteq \\mathbb{R}\\) es cualquier par de funciones reales \\(L(\\underset{\\sim}{x})\\) y \\(U (\\underset{\\sim}{x})\\) definidas en el espacio muestral \\(\\mathcal{X}\\) tales que \\(L(\\underset{\\sim}{x})\\leq U (\\underset{\\sim}{x})\\) para todo \\(\\underset{\\sim}{x} = (x_1 , \\ldots, x_n)\\in \\mathcal{X}\\) . Si se observa el valor \\(\\underset{\\sim}{x}= \\underset{\\sim}{x}\\) , mediante este estimador se hace la inferencia \\(L(\\underset{\\sim}{x})\\leq\\theta\\leq U (\\underset{\\sim}{x})\\). Al intervalo aleatorio \\([L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})]\\) se le llama estimador por intervalos de \\(\\theta\\)(o intervalo estimador de \\(\\theta\\)), mientras que al valor que ha tomado en la muestra observada \\([L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})]\\) se le llama estimaci√≥n por intervalos de \\(\\theta\\) (o intervalo estimaci√≥n de \\(\\theta\\)).\nSi se desea construir un intervalo para una transformaci√≥n invertible \\(\\tau(\\theta)\\) del par√°metro y \\([L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})]\\) es un intervalo de confianza \\((1-\\alpha)\\) para \\(\\theta\\), entonces el intervalo \\([\\tau(L(\\underset{\\sim}{x})),\\tau(U (\\underset{\\sim}{x}))]\\) es un intervalo de confianza \\((1- \\alpha)\\) para \\(\\tau(\\theta)\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Estimaci√≥n por intervalos</span>"
    ]
  },
  {
    "objectID": "chapter4.html#intervalos-de-confianza",
    "href": "chapter4.html#intervalos-de-confianza",
    "title": "5¬† Estimaci√≥n por intervalos",
    "section": "",
    "text": "Example 5.1 Sea \\(X_1 , X_2 , X_3 , X_4\\) una muestra de tama√±o 4 de \\(X \\sim N(\\mu, 1)\\). Un estimador por intervalos de \\(\\mu\\) es \\([\\bar{X}-1, \\bar{X} + 1]\\). Para cada muestra observada \\(x_1 , x_2 , x_3 , x_4\\), la estimaci√≥n por intervalos de \\(\\mu\\) es \\([\\bar{x}-1, \\bar{x} + 1]\\).\n\n\nObs√©rvese que si se estima un par√°metro \\(\\theta\\) mediante un intervalo, la inferencia es menos precisa que si se estima con un estimador puntual:\nahora nos limitamos a afirmar que el par√°metro est√° en un cierto conjunto, mientras que antes d√°bamos un valor concreto como estimaci√≥n suya.\nDado que se pierde en precisi√≥n, cabe preguntarse qu√© se gana al estimar un par√°metro \\(\\theta\\) mediante un intervalo, respecto a hacerlo con un estimador puntual. La respuesta es que se gana en confianza:\nen general, la probabilidad de que un estimador sea exactamente igual al par√°metro que desea estimar es 0, mientras que la probabilidad de que un estimador por intervalos cubra al par√°metro ser√° positiva.\n\n\nExample 5.2 Sea \\(X_1 , X_2 , X_3 , X_4\\) una muestra de tama√±o 4 de \\(X \\sim N(\\mu, 1)\\). Un estimador por intervalos de \\(\\mu\\) es \\([\\bar{X}-1, \\bar{X} + 1]\\). Para cada muestra observada \\(x_1 , x_2 , x_3 , x_4\\), la estimaci√≥n por intervalos de \\(\\mu\\) es \\([\\bar{x}-1, \\bar{x} + 1]\\).\nSea \\(X_1 , X_2 , X_3 , X_4\\) una muestra de tama√±o 4 de \\(X \\sim N(\\mu, 1)\\).\nI. \\(P(\\bar{X}=\\mu)=0\\).\nII.\\(P[\\bar{X}-1, \\bar{X} + 1]=0.9544\\).\nA costa de algo de precisi√≥n, el paso de un estimador puntual a uno por intervalos ha permitido aumentar la confianza que tenemos en que sea correcta la afirmaci√≥n hecha en la inferencia.\n\n\nDefinition 5.1 Se llama probabilidad de cobertura de un estimador por intervalos \\([L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})]\\) del par√°metro \\(\\theta\\) a la probabilidad de que ese intervalo aleatorio cubra al verdadero valor del par√°metro \\(\\theta\\): \\[P_\\theta(\\theta\\in[L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})] )\\] Obs√©rvese que esa probabilidad de cobertura puede variar con \\(\\theta\\). Se llama del intervalo \\([L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})]\\) como estimador del par√°metro \\(\\theta\\) al √≠nfimo de las probabilidades de cobertura: \\[\\inf_{\\theta\\in\\Theta}P_\\theta(\\theta\\in[L(\\underset{\\sim}{x}),U (\\underset{\\sim}{x})] ).\\] Intervalo de confianza es el nombre que recibe usualmente un estimador por intervalos junto con su coeficiente de confianza.\nTambi√©n se nombra as√≠ a veces a la estimaci√≥n a que da lugar el estimador por intervalos aplicado a una muestra concreta.\nAdem√°s de \\(C(\\underset{\\sim}{x})\\), se usar√° tambi√©n la notaci√≥n \\(IC_{1-\\alpha}(\\theta)\\) se usar√° para referirse a un intervalo de confianza \\((1-\\alpha)\\) para \\(\\theta\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Estimaci√≥n por intervalos</span>"
    ]
  },
  {
    "objectID": "chapter4.html#m√©todos-para-construir-intervalos-de-confianza",
    "href": "chapter4.html#m√©todos-para-construir-intervalos-de-confianza",
    "title": "5¬† Estimaci√≥n por intervalos",
    "section": "5.2 M√©todos para construir intervalos de confianza",
    "text": "5.2 M√©todos para construir intervalos de confianza\n\n5.2.1 Inversi√≥n de un contraste de hip√≥tesis\nComo veremos a continuaci√≥n, hay una estrecha relaci√≥n entre la estimaci√≥n por intervalos y los contrastes de hip√≥tesis. En general, se puede decir que cada m√©todo de construcci√≥n de un intervalo de confianza corresponde a un m√©todo de contraste de un hip√≥tesis, y viceversa.\n\nExample 5.3 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0:\\mu = \\mu_0\\) frente a \\(H_1 : \\mu\\neq\\mu_0\\).\nPara hacer el contraste a nivel \\(\\alpha\\) el test insesgado uniformemente de m√°xima potencia rechaza \\(H_0\\) si \\(\\mid \\bar{x}-\\mu_0\\mid &gt; z_{\\alpha/2}\\sigma/\\sqrt{n}\\), es decir, la regi√≥n del espacio muestral \\(\\mathcal{X}\\) en donde se acepta \\(H_0\\) es el conjunto de \\(\\underset{\\sim}{x}\\) tales que \\[\\bar{x}-z_{\\alpha/2}\\sigma/\\sqrt{n}\\leq\\mu_0\\leq \\bar{x}+z_{\\alpha/2}\\sigma/\\sqrt{n}\\]\n\n\n\n5.2.2 Intervalos de confianza para la media\n\n\nIntervalo de confianza para \\(\\mu\\) cuando se conoce \\(\\sigma^2\\)\n\n\n\n \n\n\nIntervalo de predicci√≥n para una observaci√≥n futura cuando se desconoce \\(\\sigma^2\\)\n\n\n\n\n\n5.2.3 Intervalos de confianza para la diferencia de medias\n\n\nIntervalo de confianza para \\(\\mu_1-\\mu_2\\) cuando se conocen \\(\\sigma_1^2\\) y \\(\\sigma_2^2\\)\n\n\n\n\n\nIntervalo de confianza para \\(\\mu_1-\\mu_2\\) cuando se conocen \\(\\sigma_1^2\\) y \\(\\sigma_2^2\\)\n\n\n\n\n\nIntervalo de confianza para \\(\\mu_1-\\mu_2\\) cuando se desconocen \\(\\sigma_1^2\\) y \\(\\sigma_2^2\\)\n\n\n\n\n\nEstimado agrupado de la varianza\n\n\n\n \n ### Intervalos de confianza para proporciones \\(p\\).\n\n\nIntervalos de confianza para \\(p\\) de una muestra grande\n\n\n\n\n\n5.2.4 Intervalos de confianza para diferencia de proporciones.\n\n\nIntervalos de confianza para \\(p_1-p_2\\) de una muestra grande\n\n\n\n\n\n5.2.5 Intervalos de confianza para \\(\\sigma^2\\)\n\n\nIntervalos de confianza para \\(\\sigma^2\\)\n\n\n\n\n\n5.2.6 Intervalos de confianza para comparaci√≥n de varianzas.\n\n\nIntervalos de confianza para \\(\\sigma_1^2/\\sigma_2^2\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Estimaci√≥n por intervalos</span>"
    ]
  },
  {
    "objectID": "chapter4.html#test-de-la-raz√≥n-de-verosimilitudes",
    "href": "chapter4.html#test-de-la-raz√≥n-de-verosimilitudes",
    "title": "5¬† Estimaci√≥n por intervalos",
    "section": "5.3 Test de la raz√≥n de verosimilitudes",
    "text": "5.3 Test de la raz√≥n de verosimilitudes\nSea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\), variable aleatoria con funci√≥n de densidad (o de probabilidad) \\(f(x\\mid \\theta)\\) para alg√∫n \\(\\theta  \\in \\Theta\\). Se desea hacer el contraste\n\\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta \\in\\Theta_0 \\\\\n\\\\ H_1 &  : & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\] donde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset.\\) Se define el estad√≠stico de la como\n\\[\\lambda=\\lambda(\\underset{\\sim}{x})=\\frac{\\max_{\\theta \\in \\Theta_0}L(\\theta \\mid \\underset{\\sim}{x})}{\\max_{\\theta \\in \\Theta}L(\\theta \\mid \\underset{\\sim}{x})}\\]\nEl test de la raz√≥n de verosimilitudes (tambi√©n llamado test de la raz√≥n de verosimilitudes generalizado, para distinguirlo del test de Neyman- Pearson, o test de la raz√≥n de las m√°ximas verosimilitudes) establece una regi√≥n cr√≠tica de la forma \\[C=\\{\\underset{\\sim}{x}:\\lambda(\\underset{\\sim}{x})\\leq A\\}\\] para alguna constante \\(A\\) que se determinar√° para que el test tenga el tama√±o \\(\\alpha\\) deseado.\nLa idea intuitiva que sustenta este m√©todo de contraste es simple. Observe que \\(0 \\leq \\lambda \\leq 1\\) y que cuanto m√°s cercano a \\(1\\) sea el valor de \\(\\lambda\\), m√°s veros√≠mil es que \\(\\theta \\in \\Theta_0\\), mientras que cuanto m√°s se aleje \\(\\lambda\\) de 1, m√°s cre√≠ble ser√° la hip√≥tesis alternativa \\(\\theta \\in \\Theta_1\\).\n\nExample 5.4 Sea \\(\\underset{\\sim}{x}\\sim \\exp\\{\\frac{1}{\\lambda}\\}\\), \\(\\lambda=E(X)\\), se quiere encontrar la forma de la regi√≥n cr√≠tica utilizando el principio de la raz√≥n de verosimilitudes del test \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\lambda=\\lambda_0 \\\\\n\\\\ H_1 &  : & \\lambda\\neq\\lambda_0\n\\end{array}\n\\right.\\]\n\n\nProof. Recordemos que la funci√≥n de verosimilitud es \\[\\begin{align}\n            L(\\lambda\\mid\\underset{\\sim}{x})&=\\prod_{i=1}^{n}\\left(\\frac{1}{\\lambda}\\exp\\left\\{-\\frac{1}{\\lambda}x_i\\right\\}\\right)\\nonumber\\\\\n            &=\\left(\\frac{1}{\\lambda}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda}\\sum_{i=1}^{n}x_i\\right\\}\n        \\end{align}\\] Adem√°s, el estimador de m√°xima verosimilitud (emv) es \\(\\hat{\\lambda}=\\bar{x}\\) Luego, el estad√≠stico por la raz√≥n de verosimilitudes\n\\[\\begin{align}\n        \\Lambda(\\underset{\\sim}{x})&=\\frac{\\max_{\\lambda \\in \\Theta_0}L(\\lambda \\mid \\underset{\\sim}{x})}{\\max_{\\lambda \\in \\Theta}L(\\lambda \\mid \\underset{\\sim}{x})}\\nonumber\\\\\n        &=\\frac{\\left(\\frac{1}{\\lambda_0}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}}{\\left(\\frac{1}{\\bar{x}_n}\\right)^n\\exp\\left\\{-\\frac{1}{\\bar{x}_n}\\sum_{i=1}^{n}x_i\\right\\}}\\nonumber\\\\\n        &=\\frac{\\left(\\frac{1}{\\lambda_0}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}}{\\left(\\frac{1}{\\frac{\\sum_{i=1}^{n}x_i}{n}}\\right)^n\\exp\\left\\{-\\frac{1}{\\frac{\\sum_{i=1}^{n}x_i}{n}}\\sum_{i=1}^{n}x_i\\right\\}}\\nonumber\\\\\n\\end{align}\\]\n\\[\\begin{align}\n\\Lambda(\\underset{\\sim}{x})&=\\frac{\\max_{\\lambda \\in \\Theta_0}L(\\lambda \\mid \\underset{\\sim}{x})}{\\max_{\\lambda \\in \\Theta}L(\\lambda \\mid \\underset{\\sim}{x})}\\nonumber\\\\\n&=\\left(\\frac{\\sum_{i=1}^{n}x_i}{n\\lambda_0}\\right)^n\\frac{\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}}{\\exp\\left\\{-n\\right\\}}\\nonumber\\\\\n&=\\left(\\frac{1}{n}\\right)^n\\left(\\frac{\\sum_{i=1}^{n}x_i}{\\lambda_0}\\right)^n\\frac{\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}}{\\exp\\left\\{-n\\right\\}}\\nonumber\\\\\n\\end{align}\\]\nSi \\(\\Lambda(\\underset{\\sim}{x})\\leq A\\) para alguna constante \\(A\\) que haga el test de tama√±o \\(\\alpha\\), se tiene que\n\\[\\begin{align}\n\\left(\\frac{\\sum_{i=1}^{n}x_i}{\\lambda_0}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}\\leq A^*\n\\end{align}\\]\ndonde \\(A^*=An^n\\exp\\left\\{-n\\right\\}.\\)\nPara un valor fijo \\(\\lambda_0\\), la regi√≥n de NO rechazo del test regi√≥n de aceptaci√≥nes\n\\[\\begin{align}\n        \\label{RA}\n        A(\\lambda_0)=\\left\\{\\underset{\\sim}{x}:\\left(\\frac{\\sum_{i=1}^{n}x_i}{\\lambda_0}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda_0}\\sum_{i=1}^{n}x_i\\right\\}\\geq k^*\\right\\}\n\\end{align} \\tag{5.1}\\]\ndonde la constante \\(k^*\\) se elige para que el test tenga tama√±o \\(\\alpha\\), o lo que es lomismo, para que \\[P_{\\alpha}(\\underset{\\sim}{x}\\in A(\\lambda_0))=1-\\alpha\\]\n\n\n5.3.1 Cantidades pivotales.\nUno de los m√©todos m√°s comunes de construcci√≥n de intervalos de confianza es el uso de cantidades pivotales.\nSea \\(\\underset{\\sim}{x} = (X_1 ,\\ldots , X_n)\\) una m.a.s. de \\(X\\sim F(x;\\theta)\\). Una funci√≥n \\(Q(\\underset{\\sim}{x} , \\theta)\\) de la muestra y del par√°metro es una si la distribuci√≥n de probabilidad de \\(Q(\\underset{\\sim}{x} , \\theta)\\) no depende del par√°metro \\(\\theta\\), es decir, \\(Q(\\underset{\\sim}{x} , \\theta)\\) tiene la misma distribuci√≥n para cualquier valor de \\(\\theta\\).\nDada una cantidad pivotal \\(Q(\\underset{\\sim}{x} , \\theta)\\), para cualquier conjunto \\(A\\) del espacioimagen de \\(Q\\) se tiene que \\(P_\\theta (Q(\\underset{\\sim}{x} , \\theta) \\in A)\\) no depende de \\(\\theta\\). Por lo tanto si se elige un conjunto \\(A_\\alpha\\) tal que\n\\[P_\\theta (Q(\\underset{\\sim}{x} , \\theta) \\in A)=1-\\alpha,\\] para todo \\(\\theta\\), y se observa la muestra \\(\\underset{\\sim}{x} = \\underset{\\sim}{x}\\), entonces el conjunto \\[C(\\underset{\\sim}{x}) = \\{\\theta: Q(\\underset{\\sim}{x} , \\theta) \\in A\\}\\] es un conjunto de confianza \\(1-\\alpha\\) para \\(\\theta\\).\nEn la pr√°ctica, la forma en la que se construye un intervalo de confianza a partir de una cantidad pivotal es la siguiente. Supondremos que \\(Q(\\underset{\\sim}{x}, \\theta) \\in \\mathbb{R}\\) y \\(\\theta \\in \\mathbb{R}\\). Para un valor \\(\\alpha\\) dado, se buscan n√∫meros a y b tales que \\[P_\\theta(a\\leq Q(\\underset{\\sim}{x}, \\theta)\\leq b)=1-\\alpha,\\] Observar que \\(a\\) y \\(b\\) no dependen de \\(\\theta\\) por ser Q cantidad pivotal, y que la elecci√≥n de a y b no ser√° √∫nica en general.\nPara cada \\(\\theta_0\\) , el conjunto \\[A(\\theta_0)=\\{\\underset{\\sim}{x}:a\\leq Q(\\underset{\\sim}{x}, \\theta)\\leq b\\}.\\] es la regi√≥n de aceptaci√≥n de un test de tama√±o \\(\\alpha\\) para contrastar \\(H_0 : \\theta = \\theta_ 0\\) basado en el estad√≠stico \\(T ( \\underset{\\sim}{x}) = Q(\\underset{\\sim}{x}, \\theta_0)\\). Invirtiendo este contraste obtenemos el conjunto de confianza \\(1-\\alpha\\) para \\(\\theta\\): \\[C(\\underset{\\sim}{x})=\\{\\theta:a\\leq Q(\\underset{\\sim}{x}, \\theta)\\leq b\\}.\\]\n\nExample 5.5 Obs√©rvese en Equation¬†5.1 que la expresi√≥n de la regi√≥n de aceptaci√≥n depende de la muestra y del par√°metro s√≥lo a trav√©s de \\(v =\\frac{\\sum_{i=1}^{n} x_i}{\\lambda_0}\\). Adem√°s, la distribuci√≥n de \\(v =\\frac{\\sum_{i=1}^{n}X_i}{\\lambda_0}\\) no depende del par√°metro \\(\\lambda_0\\) : \\(\\sum_{i=1}^{n}X_i\\sim \\gamma(n,\\lambda_0)\\) bajo \\(H_0\\) , luego \\(V\\sim \\gamma(n,\\lambda_0)\\). De esto se sigue que el valor \\(k^{*}\\) es el mismo para todo \\(\\lambda_0\\).\\\nInvirtiendo la regi√≥n de aceptaci√≥n se obtiene el conjunto de confianza \\(1-\\alpha\\): \\[C(\\underset{\\sim}{x})=\\left\\{\\lambda:\\left(\\frac{\\sum_{i=1}^{n}x_i}{\\lambda}\\right)^n\\exp\\left\\{-\\frac{1}{\\lambda}\\sum_{i=1}^{n}x_i\\right\\}\\geq k^*\\right\\}.\\]\n\nSea \\(g(v)=v^n\\exp\\{-v\\}\\)  a. \\(g\\) es positiva en todo \\(\\mathbb{R}^{+}\\). b. \\(g\\) vale cero en \\(v=0\\). c.¬†\\(g\\) tiende a cero si \\(v\\) tiende a infinito. d.¬†\\(g\\) tiene un √∫nico punto cr√≠tico en \\(v=n\\). e. \\(g\\) tiene un √∫nico m√°ximo en \\(v=n\\). f.¬†Los conjuntos de la forma \\(\\{v\\geq0: g(v)\\leq k^*\\}\\), \\(k^*\\leq g(n)=n^n\\exp\\left\\{-n\\right\\}\\), son intervalos de la forma \\([l,u]\\), donde \\(l\\leq n\\leq u\\) y \\(g(l)=g(u)=k^*\\).\nDe ello se deduce que \\(A(\\lambda_0)\\) es un intervalo para cualquier valor de \\(\\lambda_0\\), y que los conjuntos de confianza \\(C(\\underset{\\sim}{x})\\) tambi√©n son intervalos para cualquier valor de \\(\\sum_{i=1}^{n}x_i\\). As√≠ pues, el intervalo de confianza obtenido ser√° de la forma\n\\[\\begin{align}\nC(\\underset{\\sim}{x})&=\\left\\{\\lambda:l\\leq v\\leq u\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:l\\leq \\frac{\\sum_{i=1}^{n}x_i}{\\lambda}\\leq u\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:\\frac{1}{u}\\leq \\frac{\\lambda}{\\sum_{i=1}^{n}x_i}\\leq \\frac{1}{l}\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:L\\left(\\sum_{i=1}^{n}x_i\\right)\\leq \\lambda\\leq U\\left(\\sum_{i=1}^{n}x_i\\right)\\right\\}\\nonumber\\\\\n\\end{align}\\]\ncon\n\n\n\n\n\n\n\nL√≠mite inferior\nL√≠mite superior\n\n\n\n\n\\[L\\!\\left(\\sum_{i=1}^{n}x_i\\right) = \\frac{\\sum_{i=1}^{n}x_i}{u}\\]\n\\[U\\!\\left(\\sum_{i=1}^{n}x_i\\right) = \\frac{\\sum_{i=1}^{n}x_i}{l}\\]\n\n\n\nLos valores \\(l\\) y \\(u\\) son las soluciones del sistema de ecuaciones no lineales\n\\[\\left\\{ \\begin{array}{lcc}\ng(l) =g(u)&     \\\\\n\\\\P(l\\leq V \\leq u)=1-\\alpha &   \n\\end{array}\n\\right.\\]\nSi \\(n = 2\\), \\(V\\sim \\gamma(2, 1)\\) y el sistema se transforma en √©ste: \\[\\left\\{ \\begin{array}{lcc}\n    l^2e^{-l} =u^2e^{-u} &     \\\\\n    \\\\e^{-l}(l+1)-e^{-u}(u+1)=1-\\alpha &   \n    \\end{array}\n    \\right.\\] Si hacemos \\(1-\\alpha = 0.9\\) y resolvemos el sistema, se obtiene \\(l = 0.4386\\) y \\(u =5.4945\\), luego el intervalo de confianza \\(0.90\\) para \\(\\lambda\\) es\n\\[\\left[0.182\\sum_{i=1}^{2} x_i;2.28\\sum_{i=1}^{2} x_i\\right]=\\left[0.364\\bar{X}_2;4.56\\bar{X}_2\\right]\\]  En el ejemplo anterior el intervalo de confianza construido se bas√≥ en\n\\[\\begin{align}\nV=\\frac{\\sum_{i=1}^{n}X_i}{\\lambda}\n\\end{align}\\]\ncuya distribuci√≥n es \\(\\gamma(n, 1)\\) para cualquier valor de \\(\\lambda\\), as√≠ que \\(V\\) es una cantidad pivotal y el intervalo de confianza construido all√≠ es un ejemplo de intervalo basado en una cantidad pivotal.\\ Si se define \\(T = 2V\\) , entonces \\(T\\sim \\gamma(n, 2)\\), es decir \\(T\\sim \\chi^2_{2n}\\) . Es m√°s f√°cil encontrar tabulada la distribuci√≥n \\(\\chi^2_{2n}\\) que la distribuci√≥n gamma, por lo que \\(T\\) resultar√° m√°s √∫til en la pr√°ctica.\n\nExample 5.6 En el ejemplo anteriormente mencionado \\[Q(\\underset{\\sim}{x},\\lambda)=\\frac{2\\sum_{i=1}^{n}X_i}{\\lambda}\\sim\\chi^2_{2n}\\] As√≠ que podemos elegir\n\n\n\n(a)\n(b)\n\n\n\n\n\\[a = \\chi^2_{2n,\\,1-\\alpha/2}\\]\n\\[b = \\chi^2_{2n,\\,\\alpha/2}\\]\n\n\n\nEn este caso \\(g_{\\underset{\\sim}{x}}(\\lambda)=Q(\\underset{\\sim}{x},\\lambda)=\\frac{2\\sum_{i=1}^{n}X_i}{\\lambda}\\). Es decir, \\(g_{\\underset{\\sim}{x}}\\) es invertible y decreciente, luego el intervalo de confianza de \\(1-\\alpha\\) para \\(\\lambda\\) ser√°\n\\[\\begin{align}\nC(\\underset{\\sim}{x})&=\\left\\{\\lambda:a\\leq g_{\\underset{\\sim}{x}}(\\lambda)\\leq b\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:a\\leq \\frac{2\\sum_{i=1}^{n}x_i}{\\lambda}\\leq b\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:\\frac{1}{b}\\leq \\frac{\\lambda}{2\\sum_{i=1}^{n}x_i}\\leq \\frac{1}{a}\\right\\}\\nonumber\\\\\n&=\\left\\{\\lambda:g_{\\underset{\\sim}{x}}^{-1}\\left(b\\right)\\leq \\lambda\\leq g_{\\underset{\\sim}{x}}^{-1}\\left(a\\right)\\right\\}\\nonumber\\\\\n\\end{align}\\]\ncon\n\n\n\n\n\n\n\nExpresi√≥n con (b)\nExpresi√≥n con (a)\n\n\n\n\n\\[g_{\\underset{\\sim}{x}}^{-1}(b) = \\frac{2\\sum_{i=1}^{n} x_i}{\\chi^2_{2n,\\,\\alpha/2}}\\]\n\\[g_{\\underset{\\sim}{x}}^{-1}(a) = \\frac{2\\sum_{i=1}^{n} x_i}{\\chi^2_{2n,\\,1-\\alpha/2}}\\]\n\n\n\nEn el caso de \\(n = 2\\) y \\(\\alpha = 0.1\\), \\(\\chi^2_{4, 0.05} = 9,49\\) y \\(\\chi^2_{4, 0.95} = 0.71\\), luego el intervalo de confianza \\(0.90\\) es\n\\[\\left[\\frac{4\\bar{X}_2}{9.49};\\frac{4\\bar{X}_2}{0.71}\\right]=\\left[0.4215\\bar{X}_2;5.63\\bar{X}_2\\right]\\]\n\n\n\n5.3.2 Intervalos de verosimilitud.\nSupongamos que los datos (eventos observados) \\(E\\) de un experimento tiene probabilidad \\(P(E;\\theta)\\) la cual depende de un par√°metros fijo pero desconocido \\(\\theta\\).\nEl estimador de m√°xima verosimilitud \\(\\hat{\\theta}\\) es el valor de \\(\\theta\\) el cual m√°ximiza \\(P(E;\\theta)\\). Este valor es el m√°s probable o m√°s plausible de \\(\\theta\\) en el sentido de que esto m√°ximiza la probabilidad de que ha sido observado.\nLas probabilidades relativas de otros valores de \\(\\theta\\) tal que \\(P(E;\\theta)\\) es tan cercano o casi tan grande como \\(P(E;\\hat{\\theta})\\) son justamente plausible en que ellos explican los datos casi tan bien como \\(\\hat{\\theta}\\) lo hace.\nValores de \\(\\theta\\) para los cuales \\(P(E;\\theta)\\) es mucho menos que \\(P(E;\\hat{\\theta})\\) son implausibles porque estos hacen que lo que se ha observado sea mucho menos probable que lo que hace \\(\\hat{\\theta}\\).\n\nDefinition 5.2 (Funci√≥n de verosimilutud relativa de \\(\\theta\\)) La Funci√≥n de verosimilutud relativa de \\(\\theta\\) (RLF), est√° definida como el ratio de la funci√≥n de verosimilitud Funci√≥n de verosimilutud relativa de \\(L(\\theta)\\) con el m√°ximo \\(L(\\hat{\\theta})\\): \\[\\begin{align}\nR(\\theta)=\\frac{L(\\theta)}{L(\\hat{\\theta})}\n\\end{align}\\] Ya que \\(L(\\theta)=CP(E;\\theta)\\) donde \\(C\\) no depende de \\(\\theta\\), se sigue\n\\[\\begin{align}\nR(\\theta)=\\frac{CP(E;\\theta)}{CP(E;\\hat{\\theta})}=\\frac{P(E;\\theta)}{P(E;\\hat{\\theta})}\n\\end{align} \\tag{5.2}\\]\n\nLa constante multiplicativa \\(C\\) en la ecuaci√≥n Equation¬†5.2 se cancela, as√≠ que \\(R(\\theta)\\) no se ver√° afectada por esta constante. Observe que \\(L(\\theta)\\leq L(\\hat{\\theta})\\) para todo \\(\\theta\\), as√≠ que se sigue \\(0\\leq R(\\theta)\\leq1\\).\n\nDefinition 5.3 (La funci√≥n Logverosimilitud relativa) \\[\\begin{align}\nr(\\theta)&=\\log\\left(R(\\theta)\\right)\\nonumber\\\\\n&=log\\left(\\frac{P(E;\\theta)}{P(E;\\hat{\\theta})}\\right)\\nonumber\\\\\n&=log\\left(P(E;\\theta)\\right)-log\\left(P(E;\\hat{\\theta})\\right)\\nonumber\\\\\n&=log\\left(\\ell (\\theta)\\right)-log\\left( \\ell(\\hat{\\theta})\\right)\n\\end{align} \\tag{5.3}\\]\n\nDonde \\(\\ell(\\theta)\\) es la funci√≥n logverosimilitud. Ya que \\(0\\leq R(\\theta)\\leq1\\), tenemos que \\(-\\infty\\leq r(\\theta)\\leq 0\\) para todos los valores parametrales posibles. Sea \\(\\theta_1\\) denota alg√∫n valor particular del par√°metro, entonces\n\nSi \\(R(\\theta_1)=0.1\\), entonces \\(\\theta_1\\) es m√°s bien un valor parametral inverosimil, porque los datos son \\(10\\) veces m√°s probables cuando \\(\\theta=\\hat{\\theta}\\) que cuando \\(\\theta=\\theta_1\\).\nSi \\(R(\\theta_1)=0.5\\), entonces \\(\\theta_1\\) es m√°s bien un valor parametral justamente plausible, porque los datos son \\(2\\) veces m√°s probables cuando \\(\\theta=\\hat{\\theta}\\) que cuando \\(\\theta=\\theta_1\\).\n\n\nDefinition 5.4 (Regiones de verosimilitud e intervalos) El conjunto de los valores \\(\\theta\\) para el cual \\(R(\\theta)\\geq p\\) un \\(100\\% p\\) regi√≥n de verosimilitud para \\(\\theta\\). Usualmente el \\(100\\% p\\) regi√≥n verosimil consistir√° de un intervalo de valores reales, y entonces este es llamado para \\(\\theta\\).\n\nUsualmente consideramos \\(50\\%\\), \\(10\\%\\) y \\(1\\%\\) intervalos veros√≠miles o regiones.\n\n\n\n\n\n\n\n\n\\[LI\\]\n\\[\\text{Dentro}\\]\n\\[\\text{Fuera}\\]\n\n\n\n\n\\(50\\%\\)\n\\[\\text{Evento muy probable}\\]\n\n\n\n\\(10\\%\\)\n\\[\\text{Evento posible}\\]\n\\[\\text{Evento imposible}\\]\n\n\n\\(1\\%\\)\n\n\\[\\text{Evento muy imposible}\\]\n\n\n\n\n\nFunci√≥n de verosimilitud del ejemplo\n\n\n\nEl \\(14.7\\%\\) y \\(3.6\\%\\) de los intervalos de verosimilitud son algunas veces calculado por su analog√≠a al \\(95\\%\\) y el \\(99\\%\\) de intervalos de confianza. a. Como \\(log(0.5)=-0.69\\), tenemos que \\(r(\\theta_1) \\geq -0.69\\), \\(logR(\\theta_1)\\geq log(0.5)\\), luego es semejante \\(R(\\theta_1)\\geq 0.5\\), los datos son 2 veces m√°s probables cuando \\(\\theta=\\hat{\\theta}\\), que cuando \\(\\theta=\\theta_1\\) (M√°s del \\(50\\%\\) de la probabilidad m√°xima posible bajo el modelo). b. Como \\(log(0.1)=-2.30\\), tenemos que \\(r(\\theta_1) \\geq -2.30\\), \\(logR(\\theta_1)\\geq log(0.1)\\), luego es semejante \\(R(\\theta_1)\\geq 0.1\\), los datos son 10 veces m√°s probables cuando \\(\\theta=\\hat{\\theta}\\), que cuando \\(\\theta=\\theta_1\\) (M√°s del \\(10\\%\\) de la probabilidad m√°xima posible bajo el modelo). c.¬†Como \\(log(0.01)=-4.61\\), tenemos que \\(r(\\theta_1) \\geq -4.61\\), \\(logR(\\theta_1)\\geq log(0.01)\\), luego es semejante \\(R(\\theta_1)\\geq 0.01\\), los datos son 100 veces m√°s probables cuando \\(\\theta=\\hat{\\theta}\\), que cuando \\(\\theta=\\theta_1\\) (M√°s del \\(1\\%\\) de la probabilidad m√°xima posible bajo el modelo).\n\nExample 5.7 Supongamos que deseamos entimar \\(\\theta\\), la proporci√≥n de personas con tuberculosis en una gran poblaci√≥n homog√©nea.Para esto nosotros seleccionamos aleatoriamente \\(n\\) individuos y encontramos \\(x\\) de ellos que tienen la enfermedad. Ya que la poblaci√≥n es grande y homog√©nea, nosotros asumimos que los \\(n\\) individuos son examinados de manera independiente y que cada uno tiene probabilidad \\(\\theta\\) de tener tuberculosis. La probabilidad del evento observado \\(E\\) es entonces \\[\\begin{align}\nP(E;\\theta)&=P(\\mbox{$x$ de $n$ tienen tuberculosis}) \\nonumber\\\\\n&=\\binom{n}{x}\\theta^x(1-\\theta)^{n-x}\n\\end{align}\\]\ndonde \\(0\\leq \\theta \\leq 1\\). Ver \n\nDetermine el estimador de m√°xima verosimilitud e interprete en el contexto del problema.\nSuponga que de \\(100\\) personas son examinadas, tres son encontrados con tuberculosis. Sobre la base de estas observaciones, ¬øcuales valores de \\(\\theta\\) son plausibles? Para responder, utilice el m√©todo gr√°fico de la funci√≥n de verosimilitud relativa para hallar los intervalos de verosimilitud (IL) del \\(1\\%\\), \\(10\\%\\) y \\(50\\%\\).\nSuponga que de \\(200\\) personas son examinadas, seis son encontrados con tuberculosis. Sobre la base de estas observaciones, ¬øcuales valores de \\(\\theta\\) son plausibles? Para responder, utilice el m√©todo gr√°fico de la funci√≥n de verosimilitud relativa para hallar los intervalos de verosimilitud (IL) del \\(1\\%\\), \\(10\\%\\) y \\(50\\%\\).\nCompare b y c.¬†con las dos gr√°ficas en el mismo cuadro de inspecci√≥n.\n\n\n\n\nContrastes de intervalos de verosimilitud",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Estimaci√≥n por intervalos</span>"
    ]
  },
  {
    "objectID": "chapter3.html#referencias",
    "href": "chapter3.html#referencias",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.7 Referencias",
    "text": "4.7 Referencias\n\nG√≥mez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisi√≥n. Departament d‚ÄôEstad√≠stica i Investigaci√≥ Operativa, Universitat Polit√®cnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estad√≠stica matem√°tica con aplicaciones (7¬™ ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.\nKalbfleisch, J. G. Probability and Statistical Inference. Springer-Verlag, 1985.",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter4.html#referencias",
    "href": "chapter4.html#referencias",
    "title": "5¬† Estimaci√≥n por intervalos",
    "section": "5.4 Referencias",
    "text": "5.4 Referencias\n\nG√≥mez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisi√≥n. Departament d‚ÄôEstad√≠stica i Investigaci√≥ Operativa, Universitat Polit√®cnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estad√≠stica matem√°tica con aplicaciones (7¬™ ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.\nKalbfleisch, J. G. Probability and Statistical Inference. Springer-Verlag, 1985.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Estimaci√≥n por intervalos</span>"
    ]
  },
  {
    "objectID": "chapter3.html#punto-cr√≠tico",
    "href": "chapter3.html#punto-cr√≠tico",
    "title": "4¬† Contrastes de hip√≥tesis",
    "section": "4.2 Punto cr√≠tico",
    "text": "4.2 Punto cr√≠tico\n\\[\nk = \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#probabilidad-de-error-de-tipo-ii",
    "href": "chapter3.html#probabilidad-de-error-de-tipo-ii",
    "title": "4¬† Contrastes de hip√≥tesis",
    "section": "4.3 Probabilidad de error de tipo II",
    "text": "4.3 Probabilidad de error de tipo II\nSi en realidad (= _a &gt; _0), la probabilidad de cometer un error de tipo II es:\n\\[\n\\beta(\\alpha) = \\Pr(\\,\\bar{X} \\leq k \\mid \\mu = \\mu_a\\,)\n= \\Phi\\!\\left(z_{1-\\alpha} - \\delta\\right),\n\\]\ndonde:\n\\[\n\\delta = \\frac{\\mu_a - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\n\nüëâ Interpretaci√≥n did√°ctica:\nAl disminuir () (ser m√°s estricto para rechazar (H_0)), aumenta () (es m√°s dif√≠cil detectar (H_1)).\nSi el menor valor obtenido \\(\\beta\\) para la probabilidad de error de tipo II es inaceptablemente grande, pueden tomarse dos medidas para reducirlo:\n\naumentar la probabilidad de error de tipo I \\(\\alpha\\) permitida, o\naumentar el tama√±o de la muestra.\n\nSupongamos que la distribuci√≥n de \\(X\\) pertenece a una familia param√©trica \\(\\{f_\\theta:\\theta \\in\\Theta\\}\\) y se contrasta\n\\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta \\in\\Theta_0 \\\\\n\\\\ H_1 &  : & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\] donde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\).\\ Se define la funci√≥n de potencia \\(\\eta(\\theta)\\) del contraste como \\[\\eta(\\theta)=P_\\theta(\\underset{\\sim}{x}\\in C)=\\left\\{ \\begin{array}{lcc}\n\\alpha &   si & \\theta \\in\\Theta_0 \\\\\n\\\\ 1-\\beta &  si & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\]\nPara \\(0\\leq\\alpha\\leq1\\), un contraste de hip√≥tesis con funci√≥n de potencia \\(\\eta(\\theta)\\) tiene tama√±o \\(\\alpha\\) si [_{_0}()=] Para \\(0\\leq\\alpha\\leq1\\), un contraste de hip√≥tesis con funci√≥n de potencia \\(\\eta(\\theta)\\) tiene Nivel de significancia \\(\\alpha\\) si \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)\\leq\\alpha\\]\nEl conjunto de contrastes con nivel de significaci√≥n \\(\\alpha\\) contiene las pruebas de tama√±o \\(\\alpha\\).\nUn contraste que minimiza \\(\\beta=P_\\theta(\\underset{\\sim}{x}\\in \\bar{C}\\mid H_1\\mbox{ cierta})\\) entre aquellos que tienen tama√±o \\(\\alpha\\) se dice que es el contraste m√°s potente de tama√±o \\(\\alpha\\) o el mejor contraste de tama√±o \\(\\alpha\\).\n\nExample 4.1 Suponga que un candidato, Jones, dice que √©l ganar√° m√°s de \\(50\\%\\) de los votos en una elecci√≥n urbana y por tanto saldr√° como ganador. Como buscamos apoyo para la hip√≥tesis alternativa de que lo dicho por Jones es falso, nuestra hip√≥tesis alternativa es que \\(p\\), la probabilidad de seleccionar un votante que est√© a favor de Jones, es menor que \\(0.5\\). Si podemos demostrar que los datos apoyan el rechazo de la hip√≥tesis nula \\(p = 0.5\\) (el valor m√≠nimo necesario para conseguir una mayor√≠a) en favor de la hip√≥tesis alternativa \\(p &lt; 0.5\\), hemos alcanzado nuestro objetivo de investigaci√≥n. Suponga que \\(n = 15\\) votantes se seleccionan aleatoriamente de una ciudad y se registra \\(Y\\), el n√∫mero que est√° a favor de Jones. Calcule \\(\\alpha\\) si seleccionamos \\(C = \\{y \\leq 2\\}\\) como la regi√≥n de rechazo.\n\nPara la encuesta pol√≠tica de Jones se muestrearon \\(n=15\\) votantes. \\[\\begin{eqnarray*}\n    H_0&:&p=0.5\\\\\n    H_a&:&p&lt;0.5\n\\end{eqnarray*}\\] Estad√≠stico de prueba es \\(Y\\).\n\n\\(Y:\\#\\) de votantes a favor. \\(Y\\sim Binom(15,\\,p)\\)\nRegi√≥n de rechazo RR: \\[RR=\\{Y\\leq 2\\}\\]\nC'alculo de \\(\\alpha\\): \\[\\begin{eqnarray*}\n      \\alpha&=&P(\\mbox{error tipo I})\\\\\n      &=&P(\\mbox{Rechazar $H_0$ cuando $H_0$ es verdadera})\\\\\n      &=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\n  \\end{eqnarray*}\\]\n\n\\[\\begin{eqnarray*}\n        \\alpha&=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\\\\\n        &=&pbinom(2,\\,15,\\,0.5)\\\\\n        &=&0.003692627\n    \\end{eqnarray*}\\]\nAsumimos un riesgo muy peque√±o (\\(\\alpha=0.004\\)), de concluir que Jones perder√° si en realidad es el ganador.\n\\[\\begin{eqnarray*}\n    \\beta(p_1=0.3)&=&P(\\mbox{error tipo II})\\\\\n    &=&P(\\mbox{No rechazar $H_0$ cuando $H_a$ es verdadera})\\\\\n    &=&P(Y&gt; 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-P(Y\\leq 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-pbinom(2,\\,15,\\,0.3)\\\\\n    &=&0.8731723\n\\end{eqnarray*}\\] Esta prueba nos llevar√° a concluir que Jones es ganador, a√∫n cuando \\(p=0.3\\).\nEl siguiente resultado determina cu√°l es el contraste m√°s potente cuando se contrasta una hip√≥tesis nula simple frente a una alternativa simple.\n\n4.3.1 Lema de Neyman-Pearson\nSea \\(X_1 ,\\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) con funci√≥n de densidad (o funci√≥n de masa de probabilidad) \\(f(x; \\theta)\\). Se desea contrastar \\(H_ 0 : \\theta = \\theta_0\\) frente a \\(H_1 : \\theta = \\theta_1\\) . Si \\(L(\\theta\\mid\\underset{\\sim}{x})\\) es la funci√≥n de verosimilitud, el mejor contraste de tama√±o \\(\\alpha\\) tiene regi√≥n cr√≠tica de la forma \\[C=\\left\\{\\underset{\\sim}{x}\\in\\mathcal{X}^n:\\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\geq A\\right\\}\\] para alg√∫n \\(A\\geq 0\\).\\ El contraste que se propone en el Lema de Neyman-Pearson se denomina tambi√©n test de la raz√≥n de verosimilitudes.\n\nExample 4.2 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu, \\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0 : \\mu= \\mu_0\\) frente a \\(H_1: \\mu = \\mu_1\\), con \\(\\mu_1 &gt; \\mu_0\\).\n\nNuestra intuici√≥n nos dice que se debe rechazar \\(H_0\\) si se observan valores grandes de \\(x\\). Veamos que la aplicaci√≥n del Lema de Neyman-Pearson conduce a esta soluci√≥n.\n\n\n4.3.2 Conclusiones de un contraste: el p-valor.\n\n\n\n\n\n\nTip¬†4.1\n\n\n\n\nUna forma de informar de los resultados de un contraste de hip√≥tesis es mediante el tama√±o \\(\\alpha\\) del test usado y la decisi√≥n tomada sobre si se rechaz√≥ o no \\(H_0\\).\nSi \\(\\alpha\\) es peque√±o la decisi√≥n de rechazar \\(H_0\\) es muy convincente, pero si \\(\\alpha\\) es grande la probabilidad de cometer un error de tipo I es grande, lo cu√°l resta fuerza al test si la decisi√≥n adoptada es la de rechazar \\(H_0\\).\nPor otro lado, para \\(\\alpha\\) muy peque√±o, el hecho de no rechazar \\(H_0\\) no se interpretar√° como un apoyo indiscutible a esta hip√≥tesis sino como que no fue posible encontrar evidencia suficiente en su contra como para superar la barrera tan restrictiva impuesta por ese valor de \\(\\alpha\\).\n\n\n\n\nDefinition 4.1 Una forma alternativa de presentar los resultados de un contraste de hip√≥tesis es dar el p-valor o valor de probabilidad del test, definido √©ste como el supremo de los valores \\(\\alpha\\) para los cu√°les se rechazar√≠a la hip√≥tesis nula si √©sta se contrastase a nivel \\(\\alpha\\).\n\nEl p-valor depende de los datos muestrales. Puede interpretarse como la probabilidad de observar otra muestra que sea al menos tan poco favorable a la hip√≥tesis nula como la que se ha observado.\nA partir del p-valor se puede tomar la decisi√≥n de rechazar (respectivamente, aceptar) \\(H_0\\) si el p-valor es peque√±o (respectivamente, grande).\nPor ejemplo, el p-valor de un contraste dado por el Lema de Neyman-Pearson es: \\[p=P_{\\theta_0}\\left\\{\\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\geq \\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\right\\}\\] En general, cuando la regi√≥n cr√≠tica de un contraste de tama√±o \\(\\alpha\\) es tal que se rechaza \\(H_0\\) si y s√≥lo si \\(W(\\underset{\\sim}{x})\\geq c_\\alpha\\), donde \\(W(\\underset{\\sim}{x})\\) es un estad√≠stico y \\(c_\\alpha\\) se elige para que el test tenga tama√±o \\(\\alpha\\), entonces el p-valor del contraste para una muestra observada \\(\\underset{\\sim}{x}\\) es \\[p(\\underset{\\sim}{x})=\\sup_{\\theta\\in\\Theta_0}P_{\\theta_0}\\{W(\\underset{\\sim}{x})\\geq W(\\underset{\\sim}{x})\\}\\] ## Contrastes uniformemente m√°s potentes\nNos ocuparemos ahora de los contrastes de hip√≥tesis en los que la hip√≥tesis alternativa es compuesta. Queremos contrastar.\n\\[\\left\\{ \\begin{array}{lcc}\n    H_0 &   :  & \\theta \\in\\Theta_0 \\\\\n    \\\\ H_1 &  : & \\theta \\in\\Theta_1  \n    \\end{array}\n    \\right.\\]\ndonde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\)\n\nExample 4.3 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta=\\theta_0 \\\\\n\\\\ H_1 &  : & \\theta&gt;\\theta_1  \n\\end{array}\n\\right.\\] diremos que se trata de un contraste unilateral.\n\n\nExample 4.4 Por ejemplo, si \\(\\Theta=\\mathbb{R}\\), podemos contrastar\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\leq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&gt;\\theta_0  \n        \\end{array}\n        \\right.\\]\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\geq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&lt;\\theta_0  \n        \\end{array}\n        \\right.\\]\ndiremos que se trata de un contraste unilateral.\n\n\nExample 4.5 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta=\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta\\neq\\theta_0  \n        \\end{array}\n        \\right.\\] diremos que se trata de un contraste bilateral.\n\n\nDefinition 4.2 Diremos que un contraste de hip√≥tesis es Uniformemente m√°s potente (UMP) para contrastar \\(H_0:\\theta\\in\\Theta_0\\) frente \\(H_1:\\theta\\in\\Theta_1\\) si su funci√≥n de potencia \\(\\eta(\\theta)\\) verifica que \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)=\\alpha\\] y para cualquier otro contraste con funci√≥n de potencia \\(\\eta^*\\) que sea tambi√©n de tama√±o \\(\\alpha\\), es decir, que cumpla \\[\\sup_{\\theta\\in\\Theta_0}\\eta^*(\\theta)=\\alpha\\] se tiene que \\[\\eta(\\theta)\\geq\\eta^*(\\theta),\\forall\\theta\\in\\Theta_1.\\]\n\n\n\n4.3.3 Raz√≥n de verosimilitud mon√≥tona. Teorema de Karlin-Rubin.\n\nEn esta secci√≥n veremos que bajo determinadas condiciones es posible encontrar tests UMP para contrastes unilaterales cuyas regiones cr√≠ticas son f√°cilmente expresables en funci√≥n de un estad√≠stico suficiente.\nLas condiciones necesarias hacen referencia a la monoton√≠a de la raz√≥n de verosimilitudes como funci√≥n del estad√≠stico suficiente.\nUna familia de funciones de densidad o de probabilidad \\(\\{g(t\\mid\\theta) : \\theta \\in \\Theta\\}\\) para una variable aleatoria \\(T\\) tiene raz√≥n de verosimilitudes mon√≥tona (RVM) si para cada \\(\\theta_2 &gt; \\theta_1\\) el cociente \\(g(t\\mid\\theta_2)/g(t\\mid\\theta_1)\\) es una funci√≥n no decreciente de \\(t\\) para los valores t tales que \\(g(t\\mid\\theta_2) &gt; 0\\) o \\(g(t\\mid\\theta_1) &gt; 0\\).\n\n\nTheorem 4.1 Se desea contrastar \\(H_0: \\theta\\leq \\theta_0\\) frente a \\(H_1: \\theta &gt; \\theta_0\\) . Supongamos que \\(T\\) es un estad√≠stico suficiente para \\(\\theta\\) y que la familia \\(\\{g(t\\mid\\theta): \\theta \\in \\Theta\\}\\) de funciones de densidad de \\(T\\) tiene RVM. Entonces para cada \\(t_0\\) el test que rechaza \\(H_0\\) si y s√≥lo si \\(T&gt;t_0\\) es UMP de tama√±o \\(\\alpha = P_{\\theta_0}(T&gt;t_0 )\\).\n\n\nExample 4.6 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0:\\mu = \\mu_0\\) frente a \\(H_1 : \\mu\\neq\\mu_0\\)\n\nPara contrastar \\(H_0\\) frente a \\(H_1\\) parece razonable rechazar \\(H_0\\) si se observan valores de la media muestral mucho mayores o mucho menores que \\(¬µ_0\\):\n\\[C=\\{\\underset{\\sim}{x}:\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\}\\] donde \\(A_1\\) y \\(A_2\\) se eligen para que el test tenga tama√±o \\(\\alpha\\): \\[\\begin{align}\n\\alpha&=P(C\\mid H_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu0)\\\\\n\\end{align}\\] \\[\\begin{align}\n\\alpha&=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0) + P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\n\\end{align}\\] La forma de fijar \\(A_1\\) y \\(A_2\\) puede atender a distintos criterios. Una posibilidad es elegir \\(A_1\\) y \\(A_2\\) de forma que \\[P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0)= P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)=\\frac{\\alpha}{2}\\]\nes decir, \\(A_1=\\mu_0-\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\), \\(A_2=\\mu_0+\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\)\n\\[\\begin{eqnarray*}\n        \\beta&=&P(\\mbox{error tipo II})\\\\\n        &=&P(\\mbox{No rechazar $H_0$ cuando $H_0$ es falsa})\\\\\n        &=&P(\\underset{\\sim}{x}\\notin C\\mid H_0\\mbox{ falsa})\n    \\end{eqnarray*}\\]\n\n\nGr√°fico de la funci√≥n potencia\n\n\n\nEste contraste no es UMP porque, por ejemplo, si rechazamos \\(H_0\\) cuando \\(\\bar{X}_n\\geq\\mu_0+\\frac{z_\\alpha¬¥\\sigma}{\\sqrt{n}}\\) este contraste tiene potencia superior para \\(\\mu &gt; \\mu_0\\) , como puede verse en la figura anterior (curva de trazo discontinuo).",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#contexto-de-la-prueba-unilateral",
    "href": "chapter3.html#contexto-de-la-prueba-unilateral",
    "title": "4¬† Contrastes de hip√≥tesis",
    "section": "4.2 1. Contexto de la prueba unilateral",
    "text": "4.2 1. Contexto de la prueba unilateral\nEstamos en una prueba unilateral para la media de una Normal con varianza conocida:\n\nMuestra de tama√±o \\(n\\):\n\\(\\bar{X} \\sim N\\!\\left(\\mu, \\tfrac{\\sigma^2}{n}\\right)\\).\nBajo \\(H_0: \\mu = \\mu_0\\), rechazamos si\n\n\\[\n\\bar{X} &gt; k, \\quad \\text{donde } k = \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#definici√≥n-de-error-de-tipo-ii",
    "href": "chapter3.html#definici√≥n-de-error-de-tipo-ii",
    "title": "4¬† Contrastes de hip√≥tesis",
    "section": "4.3 2. Definici√≥n de error de tipo II",
    "text": "4.3 2. Definici√≥n de error de tipo II\nEl error de tipo II ocurre cuando no rechazamos \\(H_0\\) a pesar de que \\(\\mu = \\mu_a &gt; \\mu_0\\).\n\\[\n\\beta(\\alpha) = \\Pr(\\bar{X} \\le k \\mid \\mu = \\mu_a).\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#estandarizaci√≥n-de-barx",
    "href": "chapter3.html#estandarizaci√≥n-de-barx",
    "title": "4¬† Contrastes de hip√≥tesis",
    "section": "4.4 3. Estandarizaci√≥n de \\(\\bar{X}\\)",
    "text": "4.4 3. Estandarizaci√≥n de \\(\\bar{X}\\)\nBajo \\(\\mu = \\mu_a\\):\n\\[\n\\bar{X} \\sim N\\!\\left(\\mu_a, \\tfrac{\\sigma^2}{n}\\right).\n\\]\nEstandarizamos:\n\\[\nZ = \\frac{\\bar{X} - \\mu_a}{\\sigma/\\sqrt{n}} \\sim N(0,1).\n\\]\nEntonces:\n\\[\n\\Pr(\\bar{X} \\le k \\mid \\mu=\\mu_a)\n= \\Pr\\!\\left( \\frac{\\bar{X} - \\mu_a}{\\sigma/\\sqrt{n}} \\le \\frac{k - \\mu_a}{\\sigma/\\sqrt{n}} \\right).\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#sustituci√≥n-del-punto-cr√≠tico-k",
    "href": "chapter3.html#sustituci√≥n-del-punto-cr√≠tico-k",
    "title": "4¬† Contrastes de hip√≥tesis",
    "section": "4.5 4. Sustituci√≥n del punto cr√≠tico \\(k\\)",
    "text": "4.5 4. Sustituci√≥n del punto cr√≠tico \\(k\\)\nRecordemos:\n\\[\nk = \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}.\n\\]\nPor tanto:\n\\[\n\\frac{k - \\mu_a}{\\sigma/\\sqrt{n}}\n= \\frac{\\mu_0 - \\mu_a}{\\sigma/\\sqrt{n}} + z_{1-\\alpha}.\n\\]\nDefinimos:\n\\[\n\\delta = \\frac{\\mu_a - \\mu_0}{\\sigma/\\sqrt{n}}.\n\\]\nAs√≠:\n\\[\n\\frac{k - \\mu_a}{\\sigma/\\sqrt{n}} = z_{1-\\alpha} - \\delta.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#expresi√≥n-final",
    "href": "chapter3.html#expresi√≥n-final",
    "title": "4¬† Contrastes de hip√≥tesis",
    "section": "4.6 5. Expresi√≥n final",
    "text": "4.6 5. Expresi√≥n final\nDado que \\(Z \\sim N(0,1)\\):\n\\[\n\\Pr(\\bar{X} \\le k \\mid \\mu = \\mu_a) = \\Pr\\!\\big(Z \\le z_{1-\\alpha} - \\delta\\big).\n\\]\nY esa probabilidad se escribe con la funci√≥n de distribuci√≥n acumulada de la Normal est√°ndar (\\(\\Phi\\)):\n\\[\n\\beta(\\alpha) = \\Phi\\!\\left(z_{1-\\alpha} - \\delta\\right).\n\\]\n\n‚úÖ Esa es la justificaci√≥n: estandarizamos \\(\\bar{X}\\) bajo \\(H_1\\), sustituimos el punto cr√≠tico y aparece directamente la forma compacta con \\(\\Phi\\).\n\nInterpretaci√≥n did√°ctica:\nAl disminuir \\(\\alpha\\) (ser m√°s estricto para rechazar \\(H_0\\)), aumenta \\(\\beta\\) (es m√°s dif√≠cil detectar \\(H_1\\)).\n\nSi el menor valor obtenido \\(\\beta\\) para la probabilidad de error de tipo II es inaceptablemente grande, pueden tomarse dos medidas para reducirlo:\n\naumentar la probabilidad de error de tipo I \\(\\alpha\\) permitida, o\naumentar el tama√±o de la muestra.\n\nSupongamos que la distribuci√≥n de \\(X\\) pertenece a una familia param√©trica \\(\\{f_\\theta:\\theta \\in\\Theta\\}\\) y se contrasta\n\\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta \\in\\Theta_0 \\\\\n\\\\ H_1 &  : & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\] donde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\).\\ Se define la funci√≥n de potencia \\(\\eta(\\theta)\\) del contraste como \\[\\eta(\\theta)=P_\\theta(\\underset{\\sim}{x}\\in C)=\\left\\{ \\begin{array}{lcc}\n\\alpha &   si & \\theta \\in\\Theta_0 \\\\\n\\\\ 1-\\beta &  si & \\theta \\in\\Theta_1  \n\\end{array}\n\\right.\\]\nPara \\(0\\leq\\alpha\\leq1\\), un contraste de hip√≥tesis con funci√≥n de potencia \\(\\eta(\\theta)\\) tiene tama√±o \\(\\alpha\\) si [_{_0}()=] Para \\(0\\leq\\alpha\\leq1\\), un contraste de hip√≥tesis con funci√≥n de potencia \\(\\eta(\\theta)\\) tiene Nivel de significancia \\(\\alpha\\) si \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)\\leq\\alpha\\]\nEl conjunto de contrastes con nivel de significaci√≥n \\(\\alpha\\) contiene las pruebas de tama√±o \\(\\alpha\\).\nUn contraste que minimiza \\(\\beta=P_\\theta(\\underset{\\sim}{x}\\in \\bar{C}\\mid H_1\\mbox{ cierta})\\) entre aquellos que tienen tama√±o \\(\\alpha\\) se dice que es el contraste m√°s potente de tama√±o \\(\\alpha\\) o el mejor contraste de tama√±o \\(\\alpha\\).\n\nExample 4.1 Suponga que un candidato, Jones, dice que √©l ganar√° m√°s de \\(50\\%\\) de los votos en una elecci√≥n urbana y por tanto saldr√° como ganador. Como buscamos apoyo para la hip√≥tesis alternativa de que lo dicho por Jones es falso, nuestra hip√≥tesis alternativa es que \\(p\\), la probabilidad de seleccionar un votante que est√© a favor de Jones, es menor que \\(0.5\\). Si podemos demostrar que los datos apoyan el rechazo de la hip√≥tesis nula \\(p = 0.5\\) (el valor m√≠nimo necesario para conseguir una mayor√≠a) en favor de la hip√≥tesis alternativa \\(p &lt; 0.5\\), hemos alcanzado nuestro objetivo de investigaci√≥n. Suponga que \\(n = 15\\) votantes se seleccionan aleatoriamente de una ciudad y se registra \\(Y\\), el n√∫mero que est√° a favor de Jones. Calcule \\(\\alpha\\) si seleccionamos \\(C = \\{y \\leq 2\\}\\) como la regi√≥n de rechazo.\n\nPara la encuesta pol√≠tica de Jones se muestrearon \\(n=15\\) votantes. \\[\\begin{eqnarray*}\n    H_0&:&p=0.5\\\\\n    H_a&:&p&lt;0.5\n\\end{eqnarray*}\\] Estad√≠stico de prueba es \\(Y\\).\n\n\\(Y:\\#\\) de votantes a favor. \\(Y\\sim Binom(15,\\,p)\\)\nRegi√≥n de rechazo RR: \\[RR=\\{Y\\leq 2\\}\\]\nC'alculo de \\(\\alpha\\): \\[\\begin{eqnarray*}\n      \\alpha&=&P(\\mbox{error tipo I})\\\\\n      &=&P(\\mbox{Rechazar $H_0$ cuando $H_0$ es verdadera})\\\\\n      &=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\n  \\end{eqnarray*}\\]\n\n\\[\\begin{eqnarray*}\n        \\alpha&=&P(Y\\leq 2\\mbox{ cuando }p=0.5)\\\\\n        &=&pbinom(2,\\,15,\\,0.5)\\\\\n        &=&0.003692627\n    \\end{eqnarray*}\\]\nAsumimos un riesgo muy peque√±o (\\(\\alpha=0.004\\)), de concluir que Jones perder√° si en realidad es el ganador.\n\\[\\begin{eqnarray*}\n    \\beta(p_1=0.3)&=&P(\\mbox{error tipo II})\\\\\n    &=&P(\\mbox{No rechazar $H_0$ cuando $H_a$ es verdadera})\\\\\n    &=&P(Y&gt; 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-P(Y\\leq 2\\mbox{ cuando }p=0.3)\\\\\n    &=&1-pbinom(2,\\,15,\\,0.3)\\\\\n    &=&0.8731723\n\\end{eqnarray*}\\] Esta prueba nos llevar√° a concluir que Jones es ganador, a√∫n cuando \\(p=0.3\\).\nEl siguiente resultado determina cu√°l es el contraste m√°s potente cuando se contrasta una hip√≥tesis nula simple frente a una alternativa simple.\n\n4.6.1 Lema de Neyman-Pearson\nSea \\(X_1 ,\\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) con funci√≥n de densidad (o funci√≥n de masa de probabilidad) \\(f(x; \\theta)\\). Se desea contrastar \\(H_ 0 : \\theta = \\theta_0\\) frente a \\(H_1 : \\theta = \\theta_1\\) . Si \\(L(\\theta\\mid\\underset{\\sim}{x})\\) es la funci√≥n de verosimilitud, el mejor contraste de tama√±o \\(\\alpha\\) tiene regi√≥n cr√≠tica de la forma \\[C=\\left\\{\\underset{\\sim}{x}\\in\\mathcal{X}^n:\\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\geq A\\right\\}\\] para alg√∫n \\(A\\geq 0\\).\\ El contraste que se propone en el Lema de Neyman-Pearson se denomina tambi√©n test de la raz√≥n de verosimilitudes.\n\nExample 4.2 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu, \\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0 : \\mu= \\mu_0\\) frente a \\(H_1: \\mu = \\mu_1\\), con \\(\\mu_1 &gt; \\mu_0\\).\n\nNuestra intuici√≥n nos dice que se debe rechazar \\(H_0\\) si se observan valores grandes de \\(x\\). Veamos que la aplicaci√≥n del Lema de Neyman-Pearson conduce a esta soluci√≥n.\n\n\n4.6.2 Conclusiones de un contraste: el p-valor.\n\n\n\n\n\n\nTip¬†4.1\n\n\n\n\nUna forma de informar de los resultados de un contraste de hip√≥tesis es mediante el tama√±o \\(\\alpha\\) del test usado y la decisi√≥n tomada sobre si se rechaz√≥ o no \\(H_0\\).\nSi \\(\\alpha\\) es peque√±o la decisi√≥n de rechazar \\(H_0\\) es muy convincente, pero si \\(\\alpha\\) es grande la probabilidad de cometer un error de tipo I es grande, lo cu√°l resta fuerza al test si la decisi√≥n adoptada es la de rechazar \\(H_0\\).\nPor otro lado, para \\(\\alpha\\) muy peque√±o, el hecho de no rechazar \\(H_0\\) no se interpretar√° como un apoyo indiscutible a esta hip√≥tesis sino como que no fue posible encontrar evidencia suficiente en su contra como para superar la barrera tan restrictiva impuesta por ese valor de \\(\\alpha\\).\n\n\n\n\nDefinition 4.1 Una forma alternativa de presentar los resultados de un contraste de hip√≥tesis es dar el p-valor o valor de probabilidad del test, definido √©ste como el supremo de los valores \\(\\alpha\\) para los cu√°les se rechazar√≠a la hip√≥tesis nula si √©sta se contrastase a nivel \\(\\alpha\\).\n\nEl p-valor depende de los datos muestrales. Puede interpretarse como la probabilidad de observar otra muestra que sea al menos tan poco favorable a la hip√≥tesis nula como la que se ha observado.\nA partir del p-valor se puede tomar la decisi√≥n de rechazar (respectivamente, aceptar) \\(H_0\\) si el p-valor es peque√±o (respectivamente, grande).\nPor ejemplo, el p-valor de un contraste dado por el Lema de Neyman-Pearson es: \\[p=P_{\\theta_0}\\left\\{\\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\geq \\frac{L(\\theta_1\\mid\\underset{\\sim}{x})}{L(\\theta_0\\mid\\underset{\\sim}{x})}\\right\\}\\] En general, cuando la regi√≥n cr√≠tica de un contraste de tama√±o \\(\\alpha\\) es tal que se rechaza \\(H_0\\) si y s√≥lo si \\(W(\\underset{\\sim}{x})\\geq c_\\alpha\\), donde \\(W(\\underset{\\sim}{x})\\) es un estad√≠stico y \\(c_\\alpha\\) se elige para que el test tenga tama√±o \\(\\alpha\\), entonces el p-valor del contraste para una muestra observada \\(\\underset{\\sim}{x}\\) es \\[p(\\underset{\\sim}{x})=\\sup_{\\theta\\in\\Theta_0}P_{\\theta_0}\\{W(\\underset{\\sim}{x})\\geq W(\\underset{\\sim}{x})\\}\\] ## Contrastes uniformemente m√°s potentes\nNos ocuparemos ahora de los contrastes de hip√≥tesis en los que la hip√≥tesis alternativa es compuesta. Queremos contrastar.\n\\[\\left\\{ \\begin{array}{lcc}\n    H_0 &   :  & \\theta \\in\\Theta_0 \\\\\n    \\\\ H_1 &  : & \\theta \\in\\Theta_1  \n    \\end{array}\n    \\right.\\]\ndonde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\)\n\nExample 4.3 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta=\\theta_0 \\\\\n\\\\ H_1 &  : & \\theta&gt;\\theta_1  \n\\end{array}\n\\right.\\] diremos que se trata de un contraste unilateral.\n\n\nExample 4.4 Por ejemplo, si \\(\\Theta=\\mathbb{R}\\), podemos contrastar\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\leq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&gt;\\theta_0  \n        \\end{array}\n        \\right.\\]\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\geq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&lt;\\theta_0  \n        \\end{array}\n        \\right.\\]\ndiremos que se trata de un contraste unilateral.\n\n\nExample 4.5 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta=\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta\\neq\\theta_0  \n        \\end{array}\n        \\right.\\] diremos que se trata de un contraste bilateral.\n\n\nDefinition 4.2 Diremos que un contraste de hip√≥tesis es Uniformemente m√°s potente (UMP) para contrastar \\(H_0:\\theta\\in\\Theta_0\\) frente \\(H_1:\\theta\\in\\Theta_1\\) si su funci√≥n de potencia \\(\\eta(\\theta)\\) verifica que \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)=\\alpha\\] y para cualquier otro contraste con funci√≥n de potencia \\(\\eta^*\\) que sea tambi√©n de tama√±o \\(\\alpha\\), es decir, que cumpla \\[\\sup_{\\theta\\in\\Theta_0}\\eta^*(\\theta)=\\alpha\\] se tiene que \\[\\eta(\\theta)\\geq\\eta^*(\\theta),\\forall\\theta\\in\\Theta_1.\\]\n\n\n\n4.6.3 Raz√≥n de verosimilitud mon√≥tona. Teorema de Karlin-Rubin.\n\nEn esta secci√≥n veremos que bajo determinadas condiciones es posible encontrar tests UMP para contrastes unilaterales cuyas regiones cr√≠ticas son f√°cilmente expresables en funci√≥n de un estad√≠stico suficiente.\nLas condiciones necesarias hacen referencia a la monoton√≠a de la raz√≥n de verosimilitudes como funci√≥n del estad√≠stico suficiente.\nUna familia de funciones de densidad o de probabilidad \\(\\{g(t\\mid\\theta) : \\theta \\in \\Theta\\}\\) para una variable aleatoria \\(T\\) tiene raz√≥n de verosimilitudes mon√≥tona (RVM) si para cada \\(\\theta_2 &gt; \\theta_1\\) el cociente \\(g(t\\mid\\theta_2)/g(t\\mid\\theta_1)\\) es una funci√≥n no decreciente de \\(t\\) para los valores t tales que \\(g(t\\mid\\theta_2) &gt; 0\\) o \\(g(t\\mid\\theta_1) &gt; 0\\).\n\n\nTheorem 4.1 Se desea contrastar \\(H_0: \\theta\\leq \\theta_0\\) frente a \\(H_1: \\theta &gt; \\theta_0\\) . Supongamos que \\(T\\) es un estad√≠stico suficiente para \\(\\theta\\) y que la familia \\(\\{g(t\\mid\\theta): \\theta \\in \\Theta\\}\\) de funciones de densidad de \\(T\\) tiene RVM. Entonces para cada \\(t_0\\) el test que rechaza \\(H_0\\) si y s√≥lo si \\(T&gt;t_0\\) es UMP de tama√±o \\(\\alpha = P_{\\theta_0}(T&gt;t_0 )\\).\n\n\nExample 4.6 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0:\\mu = \\mu_0\\) frente a \\(H_1 : \\mu\\neq\\mu_0\\)\n\nPara contrastar \\(H_0\\) frente a \\(H_1\\) parece razonable rechazar \\(H_0\\) si se observan valores de la media muestral mucho mayores o mucho menores que \\(¬µ_0\\):\n\\[C=\\{\\underset{\\sim}{x}:\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\}\\] donde \\(A_1\\) y \\(A_2\\) se eligen para que el test tenga tama√±o \\(\\alpha\\): \\[\\begin{align}\n\\alpha&=P(C\\mid H_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu0)\\\\\n\\end{align}\\] \\[\\begin{align}\n\\alpha&=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0) + P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\n\\end{align}\\] La forma de fijar \\(A_1\\) y \\(A_2\\) puede atender a distintos criterios. Una posibilidad es elegir \\(A_1\\) y \\(A_2\\) de forma que \\[P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0)= P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)=\\frac{\\alpha}{2}\\]\nes decir, \\(A_1=\\mu_0-\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\), \\(A_2=\\mu_0+\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\)\n\\[\\begin{eqnarray*}\n        \\beta&=&P(\\mbox{error tipo II})\\\\\n        &=&P(\\mbox{No rechazar $H_0$ cuando $H_0$ es falsa})\\\\\n        &=&P(\\underset{\\sim}{x}\\notin C\\mid H_0\\mbox{ falsa})\n    \\end{eqnarray*}\\]\n\n\nGr√°fico de la funci√≥n potencia\n\n\n\nEste contraste no es UMP porque, por ejemplo, si rechazamos \\(H_0\\) cuando \\(\\bar{X}_n\\geq\\mu_0+\\frac{z_\\alpha¬¥\\sigma}{\\sqrt{n}}\\) este contraste tiene potencia superior para \\(\\mu &gt; \\mu_0\\) , como puede verse en la figura anterior (curva de trazo discontinuo).",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#conclusiones",
    "href": "chapter3.html#conclusiones",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.2 Conclusiones",
    "text": "4.2 Conclusiones\n\nReducir \\(\\alpha\\) implica aumentar \\(\\beta\\).\nUn mayor tama√±o del efecto \\((\\mu_a - \\mu_0)\\) o un mayor tama√±o de muestra \\(n\\) reducen \\(\\beta\\).\nLa pr√°ctica usual es fijar un \\(\\alpha\\) peque√±o (0.01, 0.05, 0.1) y luego buscar el dise√±o que minimice \\(\\beta\\) o equivalga a maximizar la potencia del test.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#funci√≥n-de-potencia",
    "href": "chapter3.html#funci√≥n-de-potencia",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "",
    "text": "La funci√≥n de potencia de una prueba mide, para cada valor posible del par√°metro \\(\\theta\\), la probabilidad de rechazar la hip√≥tesis nula:\n\\[\n\\eta(\\theta) = P_\\theta(\\tilde{x} \\in C),\n\\]\ndonde: - \\(\\tilde{x}\\) es la muestra, - \\(C\\) es la regi√≥n cr√≠tica (el conjunto de valores de la muestra que llevan a rechazar \\(H_0\\)).\nEn palabras:La funci√≥n de potencia nos dice qu√© tan probable es rechazar \\(H_0\\), dado que el par√°metro vale \\(\\theta\\).",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#casos-especiales-de-la-funci√≥n-de-potencia",
    "href": "chapter3.html#casos-especiales-de-la-funci√≥n-de-potencia",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.3 2. Casos especiales de la funci√≥n de potencia",
    "text": "4.3 2. Casos especiales de la funci√≥n de potencia\n\n\nSi \\(\\theta \\in \\Theta_0\\) (es decir, si \\(H_0\\) es cierta):\n\\[\n\\eta(\\theta) = \\alpha\n\\]\nEsto refleja que, bajo \\(H_0\\), la probabilidad de rechazar \\(H_0\\) es justamente la probabilidad de cometer un error de tipo I.\n\n\nSi \\(\\theta \\in \\Theta_1\\) (es decir, si \\(H_1\\) es cierta):\n\\[\n\\eta(\\theta) = 1 - \\beta\n\\]\nEsto refleja que, bajo \\(H_1\\), la probabilidad de rechazar \\(H_0\\) es la potencia de la prueba.",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#tama√±o-y-nivel-de-significaci√≥n",
    "href": "chapter3.html#tama√±o-y-nivel-de-significaci√≥n",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.4 3. Tama√±o y nivel de significaci√≥n",
    "text": "4.4 3. Tama√±o y nivel de significaci√≥n\n\n\nTama√±o \\(\\alpha\\):\nUna prueba tiene tama√±o \\(\\alpha\\) si el peor caso (la mayor probabilidad de rechazar \\(H_0\\) cuando es cierta) es exactamente \\(\\alpha\\):\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) = \\alpha\n\\]\n‚Üí El tama√±o es el ‚Äúvalor m√°ximo real‚Äù de error tipo I que puede ocurrir bajo \\(H_0\\).\n\n\nNivel de significaci√≥n \\(\\alpha\\):\nUna prueba tiene nivel de significaci√≥n \\(\\alpha\\) si ese peor caso no excede \\(\\alpha\\):\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) \\leq \\alpha\n\\]\n‚Üí El nivel de significaci√≥n es un l√≠mite superior que ponemos a la probabilidad de error tipo I.\n\n\nNota: Todo contraste de tama√±o \\(\\alpha\\) tiene tambi√©n nivel de significaci√≥n \\(\\alpha\\), pero no todo contraste con nivel de significaci√≥n \\(\\alpha\\) necesariamente alcanza el tama√±o exacto.",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#contraste-m√°s-potente",
    "href": "chapter3.html#contraste-m√°s-potente",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.5 4. Contraste m√°s potente",
    "text": "4.5 4. Contraste m√°s potente\nEntre todas las pruebas que tienen el mismo tama√±o \\(\\alpha\\), buscamos la que minimiza \\(\\beta\\) (o equivalentemente, la que maximiza la potencia \\(1-\\beta\\)).\nEsa prueba se llama:\n\n\nEl contraste m√°s potente de tama√±o \\(\\alpha\\),\n\no el mejor contraste de tama√±o \\(\\alpha\\).\n\nEs decir, para un mismo control de error tipo I, elegimos la prueba que detecta con mayor eficacia cuando \\(H_1\\) es verdadera.\n\nEn resumen:\n- La funci√≥n de potencia es la herramienta que unifica \\(\\alpha\\) y \\(1-\\beta\\).\n- Tama√±o = probabilidad m√°xima de error tipo I.\n- Nivel de significaci√≥n = restricci√≥n para controlar ese error.\n- El mejor contraste de tama√±o \\(\\alpha\\) es aquel que, manteniendo fijo el error tipo I, maximiza la probabilidad de rechazar \\(H_0\\) cuando realmente es falsa.",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#problema-2",
    "href": "chapter3.html#problema-2",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.6 Problema 2",
    "text": "4.6 Problema 2\nApoy√°ndose en el ejercicio anterior, responda claramente a las siguientes preguntas:\nI. A partir del contraste del inciso a, ¬øes falsa o verdadera la afirmaci√≥n: ‚ÄúLa probabilidad del error tipo I es aceptablemente baja para todo \\(\\theta \\le \\tfrac{1}{2}\\)‚Äù? Explique su respuesta.\nS√≠, es verdadera.\nBajo \\(H_0:\\theta\\le \\tfrac12\\), el error tipo I del contraste (a) es \\[\nP_\\theta(\\text{rechazar }H_0)=\\eta_a(\\theta)=\\theta^5.\n\\] Como \\(\\theta^5\\) es creciente en \\(\\theta\\), su m√°ximo sobre \\(\\Theta_0=\\{\\theta\\le \\tfrac12\\}\\) se alcanza en el borde: \\[\n\\alpha_a=\\sup_{\\theta\\le 1/2}\\eta_a(\\theta)=\\eta_a\\!\\left(\\tfrac12\\right)=\\left(\\tfrac12\\right)^5=\\frac{1}{32}\\approx 0.03125.\n\\] Por tanto, para todo \\(\\theta\\le \\tfrac12\\) se tiene \\(\\eta_a(\\theta)\\le 0.03125\\), es decir, un nivel de error tipo I muy bajo.\n\n¬øPara qu√© valores de \\(\\theta\\) el error tipo II es menor que \\(\\tfrac{1}{2}\\) en el contraste del inciso a?\n\nEn (a), bajo \\(H_1\\) el error tipo II es \\[\n\\beta_a(\\theta)=1-\\eta_a(\\theta)=1-\\theta^5.\n\\] La condici√≥n \\(\\beta_a(\\theta)&lt;\\tfrac12\\) equivale a \\[\n1-\\theta^5&lt;\\tfrac12\\quad\\Longleftrightarrow\\quad \\theta^5&gt;\\tfrac12\n\\quad\\Longleftrightarrow\\quad \\theta&gt;(1/2)^{1/5}\\approx 0.87055.\n\\] Luego, para \\(\\theta&gt;0.87055\\) (y, por supuesto, \\(\\theta&gt;1/2\\)), el error tipo II es menor a \\(1/2\\).\n\nEn el contraste del inciso b, ¬øpara qu√© valores de \\(\\theta\\) el error tipo II alcanza valores peque√±os?\n\nEn (b), \\[\n\\beta_b(\\theta)=1-\\eta_b(\\theta)=P_\\theta(X\\le 2)\n=(1-\\theta)^5+5\\theta(1-\\theta)^4+10\\theta^2(1-\\theta)^3,\n\\] funci√≥n decreciente en \\(\\theta\\). Valores representativos: \\[\n\\begin{array}{c|ccccc}\n\\theta & 0.55 & 0.60 & 0.70 & 0.75 & 0.80\\\\ \\hline\n\\beta_b(\\theta) & 0.407 & 0.317 & 0.163 & 0.104 & 0.058\n\\end{array}\n\\] Se observa que \\(\\beta_b(\\theta)\\) ya es peque√±a (por ejemplo \\(&lt;0.10\\)) a partir de \\(\\theta\\gtrsim 0.78\\) (pues en \\(0.75\\) es \\(\\approx 0.104\\) y en \\(0.80\\) es \\(\\approx 0.058\\)).\n\n¬øEs falso o verdadero afirmar que: ‚ÄúLa potencia del contraste del inciso b es mayor que la potencia del otro contraste para valores de \\(\\theta \\le \\tfrac{1}{2}\\). Entonces, la probabilidad del error tipo I del contraste del inciso b es mayor que la del otro contraste para valores de \\(\\theta \\le \\tfrac{1}{2}\\)‚Äù? Explique su respuesta.\n\n\nVerdadero.\nPara \\(\\theta\\le \\tfrac12\\) (regi√≥n nula):\n\nLa ‚Äúpotencia‚Äù \\(\\eta(\\theta)\\) coincide con la probabilidad de error tipo I en ese punto.\nNum√©ricamente (y por la propiedad MLR de la binomial) se verifica que \\[\n\\eta_b(\\theta)=P_\\theta(X\\ge 3)\\;&gt;\\;\\eta_a(\\theta)=\\theta^5\n\\quad \\text{para todo }\\theta\\le \\tfrac12.\n\\] Ejemplos:\\(\\theta=0.5:\\ \\eta_b=0.5\\ \\text{vs}\\ \\eta_a=0.03125\\);\\(\\theta=0.4:\\ \\eta_b\\approx 0.31744\\ \\text{vs}\\ \\eta_a=0.01024\\).\nEn particular, el tama√±o es mayor en (b):\\[\n\\alpha_b=\\eta_b(1/2)=0.5 \\quad\\gg\\quad \\alpha_a=\\eta_a(1/2)=1/32\\approx 0.03125.\n\\]\n\nConclusi√≥n: el contraste (b) rechaza con mucha m√°s frecuencia bajo \\(H_0\\) (mayor error tipo I), lo que explica su mayor potencia bajo \\(H_1\\); el costo es un nivel \\(\\alpha\\) inaceptablemente alto en (b) comparado con (a).",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#opci√≥n-a-rechazar-h_0-solo-si-se-observan-los-5-√©xitos",
    "href": "chapter3.html#opci√≥n-a-rechazar-h_0-solo-si-se-observan-los-5-√©xitos",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.6 Opci√≥n (a): Rechazar (H_0) solo si se observan los 5 √©xitos",
    "text": "4.6 Opci√≥n (a): Rechazar (H_0) solo si se observan los 5 √©xitos\nModelo. Sea (X (5,)) con funci√≥n de probabilidad\n(P_(X=x)=x(1-){5-x}), (x=0,1,,5).\n\n4.6.1 Regi√≥n cr√≠tica\nLa regla propuesta es rechazar (H_0) √∫nicamente cuando (X=5). Por tanto, \\[\nC_a=\\{5\\},\\qquad \\bar C_a=\\{0,1,2,3,4\\}.\n\\]\n\n4.6.2 Funci√≥n de potencia (_a())\nPor definici√≥n, la potencia es la probabilidad de caer en la regi√≥n cr√≠tica: \\[\n\\eta_a(\\theta)=P_\\theta(X\\in C_a)=P_\\theta(X=5)\n=\\binom{5}{5}\\theta^5(1-\\theta)^{0}\n=\\theta^5.\n\\] Es decir, para cualquier (0), \\[\n\\eta_a(\\theta)=\\theta^5.\n\\]\n\n4.6.3 Tama√±o (m√°ximo error tipo I)\nEl tama√±o del contraste es \\[\n\\alpha_a=\\sup_{\\theta\\in\\Theta_0}\\eta_a(\\theta)\n=\\sup_{\\theta\\le 1/2}\\theta^5.\n\\] Como (^5) es estrictamente creciente en () (derivada (5^4&gt;0)), el supremo en (_0={/2}) se alcanza en el borde (/2): \\[\n\\alpha_a=\\left(\\tfrac12\\right)^5=\\frac{1}{32}\\approx 0.03125.\n\\]\n\n4.6.4 Lectura e intuici√≥n\n\nLa regla (C_a={5}) es muy conservadora: solo rechaza (H_0) en el caso m√°s extremo.\nPor eso, el tama√±o es muy peque√±o ((_a%)).\nLa potencia (_a()=^5) crece muy lentamente; el test casi nunca rechaza salvo que () sea muy grande.\nEn t√©rminos del error tipo II (_a()=1-_a()=1-^5):\n\nSi (), (_a=1-0.6^5) (muy alto).\nSi (), (_a=1-0.9^5).\nReci√©n cerca de (), (_a).\n\n\n\nConclusi√≥n. Es un contraste con bajo error tipo I pero muy poca potencia, salvo cuando el efecto es extremadamente grande (valores de () muy cercanos a 1).\n\nConsidere en segundo lugar el contraste de rechazar \\(H_0\\) si \\(X \\in \\{3,4,5\\}\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#opci√≥n-b-rechazar-h_0-si-xin345-equiv.-xge-3",
    "href": "chapter3.html#opci√≥n-b-rechazar-h_0-si-xin345-equiv.-xge-3",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.6 Opci√≥n (b): Rechazar \\(H_0\\) si \\(X\\in\\{3,4,5\\}\\) (equiv. \\(X\\ge 3\\))",
    "text": "4.6 Opci√≥n (b): Rechazar \\(H_0\\) si \\(X\\in\\{3,4,5\\}\\) (equiv. \\(X\\ge 3\\))\nModelo. Sea \\(X\\sim \\mathrm{Bin}(5,\\theta)\\) con \\[\nP_\\theta(X=x)=\\binom{5}{x}\\,\\theta^x(1-\\theta)^{5-x},\\quad x=0,1,\\dots,5.\n\\]\n\n4.6.1 Regi√≥n cr√≠tica\n\\[\nC_b=\\{3,4,5\\},\\qquad \\bar C_b=\\{0,1,2\\}.\n\\]\n\n4.6.2 Funci√≥n de potencia \\(\\eta_b(\\theta)\\)\n\nPor definici√≥n, la potencia es la probabilidad de caer en la regi√≥n cr√≠tica: \\[\n\\eta_b(\\theta)=P_\\theta(X\\in C_b)=P_\\theta(X\\ge 3)\n=\\sum_{k=3}^{5}\\binom{5}{k}\\theta^k(1-\\theta)^{5-k}.\n\\]\nSuma directa. \\[\n\\eta_b(\\theta)=10\\,\\theta^3(1-\\theta)^2+5\\,\\theta^4(1-\\theta)+\\theta^5.\n\\]\nV√≠a complemento (√∫til para el tama√±o). \\[\n\\eta_b(\\theta)=1-P_\\theta(X\\le 2)\n=1-\\Big[(1-\\theta)^5+5\\theta(1-\\theta)^4+10\\theta^2(1-\\theta)^3\\Big].\n\\]\nMonoton√≠a. Para la familia binomial, \\(P_\\theta(X\\ge c)\\) es creciente en \\(\\theta\\) (propiedad MLR). Por tanto, \\(\\eta_b(\\theta)\\) aumenta con \\(\\theta\\).\n\n4.6.3 Tama√±o (m√°ximo error tipo I)\nEl tama√±o es \\[\n\\alpha_b=\\sup_{\\theta\\le 1/2}\\eta_b(\\theta).\n\\] Como \\(\\eta_b(\\theta)\\) es creciente, el supremo se alcanza en el borde \\(\\theta=1/2\\): \\[\n\\alpha_b=\\eta_b(1/2)=P_{1/2}(X\\ge 3)=1-P_{1/2}(X\\le 2).\n\\] Con simetr√≠a binomial: \\[\nP_{1/2}(X\\le 2)=\\frac{\\binom50+\\binom51+\\binom52}{2^5}\n=\\frac{1+5+10}{32}=\\frac{16}{32},\n\\] luego \\[\n\\alpha_b=1-\\frac{16}{32}=\\frac{16}{32}=0.5.\n\\]\n\n4.6.4 Lectura num√©rica (potencia y error tipo II)\nValores aproximados: \\[\n\\begin{array}{c|ccccc}\n\\theta & 0.55 & 0.60 & 0.70 & 0.80 & 0.90\\\\ \\hline\n\\eta_b(\\theta)=P_\\theta(X\\ge 3) & 0.593 & 0.683 & 0.837 & 0.942 & 0.991\\\\\n\\beta_b(\\theta)=1-\\eta_b(\\theta) & 0.407 & 0.317 & 0.163 & 0.058 & 0.009\n\\end{array}\n\\]\n\nPara \\(\\theta&gt;1/2\\), la potencia crece r√°pido y el error tipo II cae pronto: ya con \\(\\theta\\approx 0.7\\) la potencia es alta.\nEl costo es un tama√±o enorme: \\(\\alpha_b=0.5\\) (inaceptable en la pr√°ctica).\n\n4.6.5 Observaci√≥n de dise√±o (c√≥mo fijar \\(\\alpha\\) razonable)\nCon \\(n=5\\) y \\(H_0:\\theta\\le 1/2\\): - \\(X\\ge 5\\) da \\(\\alpha=(1/2)^5=1/32\\approx 0.03125\\). - \\(X\\ge 4\\) da \\(\\alpha=P_{1/2}(X\\ge 4)=(\\binom54+\\binom55)/32=(5+1)/32=6/32=0.1875\\). - Para alcanzar, por ejemplo, \\(\\alpha=0.10\\), ser√≠a necesario aleatorizar en \\(X=4\\) (rechazar con cierta probabilidad cuando \\(X=4\\)) o aumentar el tama√±o muestral.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#contrastes-uniformemente-m√°s-potentes",
    "href": "chapter3.html#contrastes-uniformemente-m√°s-potentes",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.6 Contrastes uniformemente m√°s potentes",
    "text": "4.6 Contrastes uniformemente m√°s potentes\nNos ocuparemos ahora de los contrastes de hip√≥tesis en los que la hip√≥tesis alternativa es compuesta. Queremos contrastar.\n\\[\\left\\{ \\begin{array}{lcc}\n    H_0 &   :  & \\theta \\in\\Theta_0 \\\\\n    \\\\ H_1 &  : & \\theta \\in\\Theta_1  \n    \\end{array}\n    \\right.\\]\ndonde \\(\\Theta_0\\cup\\Theta_1=\\Theta\\), \\(\\Theta_0\\cap\\Theta_1=\\emptyset\\)\n\nExample 4.5 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\nH_0 &   :  & \\theta=\\theta_0 \\\\\n\\\\ H_1 &  : & \\theta&gt;\\theta_1  \n\\end{array}\n\\right.\\] diremos que se trata de un contraste unilateral.\n\n\nExample 4.6 Por ejemplo, si \\(\\Theta=\\mathbb{R}\\), podemos contrastar\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\leq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&gt;\\theta_0  \n        \\end{array}\n        \\right.\\]\n\\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta\\geq\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta&lt;\\theta_0  \n        \\end{array}\n        \\right.\\]\ndiremos que se trata de un contraste unilateral.\n\n\nExample 4.7 Por ejemplo, si \\(\\Theta=[0,\\infty)\\) podemos contrastar \\[\\left\\{ \\begin{array}{lcc}\n        H_0 &   :  & \\theta=\\theta_0 \\\\\n        \\\\ H_1 &  : & \\theta\\neq\\theta_0  \n        \\end{array}\n        \\right.\\] diremos que se trata de un contraste bilateral.\n\n\nDefinition 4.3 Diremos que un contraste de hip√≥tesis es Uniformemente m√°s potente (UMP) para contrastar \\(H_0:\\theta\\in\\Theta_0\\) frente \\(H_1:\\theta\\in\\Theta_1\\) si su funci√≥n de potencia \\(\\eta(\\theta)\\) verifica que \\[\\sup_{\\theta\\in\\Theta_0}\\eta(\\theta)=\\alpha\\] y para cualquier otro contraste con funci√≥n de potencia \\(\\eta^*\\) que sea tambi√©n de tama√±o \\(\\alpha\\), es decir, que cumpla \\[\\sup_{\\theta\\in\\Theta_0}\\eta^*(\\theta)=\\alpha\\] se tiene que \\[\\eta(\\theta)\\geq\\eta^*(\\theta),\\forall\\theta\\in\\Theta_1.\\]\n\n\n\n\n\n\n\nTip¬†4.4: Test Uniformemente M√°s Potente (UMP)\n\n\n\nDefinici√≥n - La funci√≥n de potencia de un test con regi√≥n cr√≠tica \\(C\\) es:\n\\[\n  \\eta(\\theta) = P_\\theta(X \\in C)\n  \\]\n\n\nUn test es UMP de tama√±o \\(\\alpha\\) para \\(H_0:\\theta \\in \\Theta_0\\) vs \\(H_1:\\theta \\in \\Theta_1\\) si:\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) = \\alpha\n\\]\ny, para cualquier otro test del mismo tama√±o con funci√≥n de potencia \\(\\eta^*(\\theta)\\),\n\\[\n\\eta(\\theta) \\geq \\eta^*(\\theta), \\quad \\forall \\theta \\in \\Theta_1\n\\]\n\n\nLectura intuitiva - Mismo control de falsos positivos: todos los tests comparados tienen el mismo tama√±o \\(\\alpha\\).\n- Mejor detecci√≥n bajo la alternativa: en todo \\(\\Theta_1\\), la probabilidad de rechazar \\(H_0\\) es al menos tan grande como la de cualquier otro test del mismo tama√±o.\nObservaciones - A veces no existe un UMP (por ejemplo, en muchas alternativas bilaterales).\n- S√≠ existe UMP en varios problemas unilaterales cuando la familia tiene raz√≥n de verosimilitudes mon√≥tona (teorema de Karlin‚ÄìRubin).\nMini-ejemplo (binomial unilateral) - Modelo: \\(X \\sim \\text{Bin}(n,p)\\).\n- Contraste: \\(H_0: p \\le p_0\\) vs \\(H_1: p &gt; p_0\\).\n- Regi√≥n cr√≠tica de tama√±o \\(\\alpha\\): \\(C = \\{x : x \\ge c_\\alpha\\}\\) donde\n\\[\n  \\alpha = P_{p_0}(X \\ge c_\\alpha)\n  \\]\n\n\nPotencia para cualquier \\(p\\):\n\\[\n\\eta(p) = P_p(X \\ge c_\\alpha) = \\sum_{k=c_\\alpha}^n \\binom{n}{k} p^k (1-p)^{n-k}\n\\]\n\n\nEste test es UMP de tama√±o \\(\\alpha\\) para \\(H_1: p &gt; p_0\\).\nComparaci√≥n: Test cualquiera vs.¬†Test UMP\n\n\n\n\n\n\n\nCaracter√≠stica\nTest cualquiera\nTest UMP\n\n\n\n\nTama√±o (error Tipo I)\nControlado a nivel \\(\\alpha\\)\n\nControlado a nivel \\(\\alpha\\)\n\n\n\nPotencia en algunos \\(\\theta \\in \\Theta_1\\)\nPuede ser alta o baja, dependiendo del valor de \\(\\theta\\)\n\nSiempre es mayor o igual que la de cualquier otro test del mismo tama√±o\n\n\nComportamiento global\nPuede ser mejor en unos valores de \\(\\theta\\) y peor en otros\nEs el mejor en todos los valores de \\(\\theta \\in \\Theta_1\\)\n\n\n\nAnalog√≠a\nUn detector que funciona bien en ciertos √°ngulos pero falla en otros\nUn detector que funciona igual o mejor en todos los √°ngulos\n\n\n\nExistencia\nSiempre existe un test de tama√±o \\(\\alpha\\), pero no siempre es el mejor\nNo siempre existe un UMP; cuando existe, es la opci√≥n √≥ptima\n\n\n\n\n\n\n# --- Curvas de potencia (Binomial) UMP vs. otros tests del mismo tama√±o ---\n\n# Par√°metros del problema\nn &lt;- 25\np0 &lt;- 0.30\nalpha_target &lt;- 0.05\n\n# Funci√≥n: cola superior P(X &gt;= c) para Binomial(n, p)\nbinom_tail_ge &lt;- function(n, c, p) 1 - pbinom(c - 1, size = n, prob = p)\n\n# 1) UMP: regi√≥n cr√≠tica de cola superior {k &gt;= c_alpha} con tama√±o ‚âà alpha_target\ncandidates &lt;- 0:n\ntails &lt;- sapply(candidates, function(c) binom_tail_ge(n, c, p0))\n\n# Elegimos el menor c tal que P_{p0}(X &gt;= c) &lt;= alpha_target\nc_alpha &lt;- which(tails &lt;= alpha_target)[1]\nif (is.na(c_alpha)) c_alpha &lt;- n  # por si la discretud no permite bajar de alpha\n\nR_UMP &lt;- c_alpha:n\nsize_UMP &lt;- sum(dbinom(R_UMP, n, p0))\n\n# 2) Test A: empezamos m√°s conservador (c_alpha+1) y agregamos un punto interior\nR_A &lt;- (c_alpha + 1):n\nsize_A &lt;- sum(dbinom(R_A, n, p0))\n\n# Apuntamos a un punto interior cerca de la moda ~ n*p0\nmode_approx &lt;- round(n * p0)\nk_star_candidates &lt;- seq(max(0, mode_approx - 4), min(n, mode_approx + 4))\nbest_k &lt;- NA\nbest_diff &lt;- Inf\nfor (k in k_star_candidates) {\n  if (!(k %in% R_A)) {\n    trial &lt;- size_A + dbinom(k, n, p0)\n    diff &lt;- abs(alpha_target - trial)\n    if (diff &lt; best_diff) {\n      best_diff &lt;- diff\n      best_k &lt;- k\n    }\n  }\n}\nif (!is.na(best_k)) {\n  R_A &lt;- sort(unique(c(R_A, best_k)))\n  size_A &lt;- sum(dbinom(R_A, n, p0))\n}\n\n# 3) Test B: a√∫n m√°s conservador (c_alpha+2) y agregamos dos puntos interiores\nR_B &lt;- (c_alpha + 2):n\nsize_B &lt;- sum(dbinom(R_B, n, p0))\nk_cand_B &lt;- c(mode_approx - 3, mode_approx + 3,\n              mode_approx - 4, mode_approx + 4,\n              mode_approx - 2, mode_approx + 2)\n\nfor (k in k_cand_B) {\n  if (k &gt;= 0 && k &lt;= n && !(k %in% R_B)) {\n    trial &lt;- size_B + dbinom(k, n, p0)\n    # Permitimos leve sobrepaso por discretud\n    if (trial &lt;= alpha_target || (trial - alpha_target) &lt; 0.005) {\n      R_B &lt;- sort(unique(c(R_B, k)))\n      size_B &lt;- trial\n    }\n  }\n  if (size_B &gt;= alpha_target - 1e-6) break\n}\n# Si qued√≥ muy por debajo, a√±adimos el k que mejor aproxime alpha\nif (size_B &lt; alpha_target - 0.01) {\n  diffs &lt;- sapply(setdiff(0:n, R_B), function(k) abs(alpha_target - (size_B + dbinom(k, n, p0))))\n  add_k &lt;- setdiff(0:n, R_B)[which.min(diffs)]\n  R_B &lt;- sort(unique(c(R_B, add_k)))\n  size_B &lt;- sum(dbinom(R_B, n, p0))\n}\n\n# --- Curvas de potencia ---\nps &lt;- seq(p0, 1, length.out = 200)\npower_UMP &lt;- sapply(ps, function(p) sum(dbinom(R_UMP, n, p)))\npower_A   &lt;- sapply(ps, function(p) sum(dbinom(R_A,   n, p)))\npower_B   &lt;- sapply(ps, function(p) sum(dbinom(R_B,   n, p)))\n\n# Data frame para graficar\ndf &lt;- data.frame(\n  p = rep(ps, 3),\n  potencia = c(power_UMP, power_A, power_B),\n  test = factor(rep(c(\n    sprintf(\"UMP (k ‚â• %d), tama√±o‚âà%.3f\", c_alpha, size_UMP),\n    sprintf(\"Test A (tama√±o‚âà%.3f)\", size_A),\n    sprintf(\"Test B (tama√±o‚âà%.3f)\", size_B)\n  ), each = length(ps)))\n)\n\n# --- Gr√°fico con ggplot2 ---\nif (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\ng &lt;- ggplot(df, aes(x = p, y = potencia, linetype = test)) +\n  geom_line(size = 1) +\n  geom_vline(xintercept = p0, linetype = \"dotted\") +\n  labs(\n    title = sprintf(\"Curvas de potencia (Binomial n=%d, H0: p ‚â§ p0, p0=%.2f)\", n, p0),\n    x = \"p\",\n    y = \"Potencia  Œ∑(p) = P_p(rechazar H0)\",\n    linetype = NULL\n  ) +\n  theme_minimal(base_size = 12)\n\nprint(g)\n\n\n\n\n\n\n# Guardar PNG\nggplot2::ggsave(\"power_curves_UMP_vs_others.png\", g, width = 8, height = 5, dpi = 150)\ncat(\"Archivo guardado: power_curves_UMP_vs_others.png\\n\")\n\nArchivo guardado: power_curves_UMP_vs_others.png\n\n# --- Opcional: mostrar las regiones cr√≠ticas resultantes ---\ncat(\"Regi√≥n cr√≠tica UMP: {\", paste(R_UMP, collapse = \", \"), \"}\\n\", sep = \"\")\n\nRegi√≥n cr√≠tica UMP: {13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}\n\ncat(\"Regi√≥n cr√≠tica Test A: {\", paste(R_A, collapse = \", \"), \"}\\n\", sep = \"\")\n\nRegi√≥n cr√≠tica Test A: {11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}\n\ncat(\"Regi√≥n cr√≠tica Test B: {\", paste(R_B, collapse = \", \"), \"}\\n\", sep = \"\")\n\nRegi√≥n cr√≠tica Test B: {3, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}\n\n\n\n4.6.1 Raz√≥n de verosimilitud mon√≥tona. Teorema de Karlin-Rubin.\n\nEn esta secci√≥n veremos que bajo determinadas condiciones es posible encontrar tests UMP para contrastes unilaterales cuyas regiones cr√≠ticas son f√°cilmente expresables en funci√≥n de un estad√≠stico suficiente.\nLas condiciones necesarias hacen referencia a la monoton√≠a de la raz√≥n de verosimilitudes como funci√≥n del estad√≠stico suficiente.\nUna familia de funciones de densidad o de probabilidad \\(\\{g(t\\mid\\theta) : \\theta \\in \\Theta\\}\\) para una variable aleatoria \\(T\\) tiene raz√≥n de verosimilitudes mon√≥tona (RVM) si para cada \\(\\theta_2 &gt; \\theta_1\\) el cociente \\(g(t\\mid\\theta_2)/g(t\\mid\\theta_1)\\) es una funci√≥n no decreciente de \\(t\\) para los valores t tales que \\(g(t\\mid\\theta_2) &gt; 0\\) o \\(g(t\\mid\\theta_1) &gt; 0\\).\n\n\nTheorem 4.1 Se desea contrastar \\(H_0: \\theta\\leq \\theta_0\\) frente a \\(H_1: \\theta &gt; \\theta_0\\) . Supongamos que \\(T\\) es un estad√≠stico suficiente para \\(\\theta\\) y que la familia \\(\\{g(t\\mid\\theta): \\theta \\in \\Theta\\}\\) de funciones de densidad de \\(T\\) tiene RVM. Entonces para cada \\(t_0\\) el test que rechaza \\(H_0\\) si y s√≥lo si \\(T&gt;t_0\\) es UMP de tama√±o \\(\\alpha = P_{\\theta_0}(T&gt;t_0 )\\).\n\n\nExample 4.8 Sea \\(X_1 ,\\ldots, X_n\\) muestra aleatoria simple de \\(X\\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocido. Se desea contrastar \\(H_0:\\mu = \\mu_0\\) frente a \\(H_1 : \\mu\\neq\\mu_0\\)\n\nPara contrastar \\(H_0\\) frente a \\(H_1\\) parece razonable rechazar \\(H_0\\) si se observan valores de la media muestral mucho mayores o mucho menores que \\(¬µ_0\\):\n\\[C=\\{\\underset{\\sim}{x}:\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\}\\] donde \\(A_1\\) y \\(A_2\\) se eligen para que el test tenga tama√±o \\(\\alpha\\): \\[\\begin{align}\n\\alpha&=P(C\\mid H_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu0)\\\\\n\\end{align}\\] \\[\\begin{align}\n\\alpha&=P(\\bar{x}_n\\leq A_1 o \\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\\\\\n      &=P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0) + P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)\n\\end{align}\\] La forma de fijar \\(A_1\\) y \\(A_2\\) puede atender a distintos criterios. Una posibilidad es elegir \\(A_1\\) y \\(A_2\\) de forma que \\[P(\\bar{x}_n\\leq A_1\\mid \\mu=\\mu_0)= P(\\bar{x}_n\\geq A_2\\mid \\mu=\\mu_0)=\\frac{\\alpha}{2}\\]\nes decir, \\(A_1=\\mu_0-\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\), \\(A_2=\\mu_0+\\frac{z_{\\frac{\\alpha}{2}}\\sigma}{\\sqrt{n}}\\)\nEntonces se rechazar√° \\(H_0\\) si\n\\[\n\\left| \\overline{X}_n - \\mu_0 \\right| \\geq z_{\\alpha/2} \\, \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nLa funci√≥n de potencia es tal como se refleja en la figura siguiente (curva de trazo continuo).\n\nGr√°fico de la funci√≥n potencia\n\n\nEste contraste no es UMP porque, por ejemplo, si rechazamos \\(H_0\\) cuando \\(\\bar{X}_n\\geq\\mu_0+\\frac{z_\\alpha¬¥\\sigma}{\\sqrt{n}}\\) este contraste tiene potencia superior para \\(\\mu &gt; \\mu_0\\) , como puede verse en la figura anterior (curva de trazo discontinuo).\n\n\n\n\n\n\nTip¬†4.5: Teorema de Karlin‚ÄìRubin aplicado al caso normal\n\n\n\nPlanteamiento - Muestra i.i.d. \\(X_1,\\dots,X_n \\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocida.\n- Estad√≠stico: \\(\\overline{X}_n\\).\n- Queremos contrastar, por ejemplo:\n\\[\n  H_0:\\ \\mu \\le \\mu_0 \\quad \\text{vs} \\quad H_1:\\ \\mu &gt; \\mu_0\n  \\]\nVerificaci√≥n de las hip√≥tesis del teorema 1. Suficiencia: para varianza conocida, \\(\\overline{X}_n\\) es suficiente para \\(\\mu\\).\n2. Raz√≥n de verosimilitudes mon√≥tona (RVM): la familia \\(\\{N(\\mu,\\sigma^2/n): \\mu \\in \\mathbb{R}\\}\\) posee RVM en \\(\\overline{X}_n\\), porque para \\(\\mu_1&gt;\\mu_0\\) la raz√≥n\n\\[\n   \\frac{f_{\\mu_1}(\\overline{x})}{f_{\\mu_0}(\\overline{x})}\n   \\]\nes creciente en \\(\\overline{x}\\).\nPor el teorema, existe un test UMP de tama√±o \\(\\alpha\\) cuya regi√≥n cr√≠tica es de cola superior.\nTest UMP (unilateral a la derecha) - Bajo \\(\\mu=\\mu_0\\):\n\\[\n  Z=\\frac{\\overline{X}_n-\\mu_0}{\\sigma/\\sqrt{n}} \\sim N(0,1)\n  \\]\n\n\nEl test UMP de tama√±o \\(\\alpha\\) rechaza \\(H_0\\) si:\n\\[\n\\overline{X}_n &gt; \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\quad \\Longleftrightarrow \\quad\nZ &gt; z_{1-\\alpha}\n\\]\n\nFunci√≥n de potencia: Como \\(\\overline{X}_n \\sim N(\\mu,\\ \\sigma^2/n)\\), podemos escribir:\n\n\\[\n\\overline{X}_n = \\mu + \\frac{\\sigma}{\\sqrt{n}}\\,W,\n\\]\ndonde \\(W \\sim N(0,1)\\).\nSustituyendo en la definici√≥n de \\(Z\\):\n\\[\nZ = \\frac{\\mu + \\tfrac{\\sigma}{\\sqrt{n}}W - \\mu_0}{\\sigma/\\sqrt{n}}\n= \\frac{\\mu-\\mu_0}{\\sigma/\\sqrt{n}} + W.\n\\]\nPor lo tanto:\n\\[\nZ \\sim N\\!\\left(\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0),\\,1\\right).\n\\]\nEs decir: - Media: \\(\\delta = \\tfrac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\)\n- Varianza: \\(1\\)\nEl estad√≠stico de prueba es:\n\\[\nZ = \\frac{\\overline{X}_n - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\ny bajo el verdadero valor de \\(\\mu\\) se distribuye como:\n\\[\nZ \\sim N\\!\\left(\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0),\\,1\\right).\n\\]\nEs decir, una normal con media desplazada: - Media: \\(\\delta = \\tfrac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\)\n- Varianza: \\(1\\)\n\\[\n\\eta(\\mu) = P_\\mu(\\text{rechazar } H_0)\n= P_\\mu(Z &gt; z_{1-\\alpha}).\n\\]\n\\[\n\\eta(\\mu) = P\\!\\left(Z &gt; z_{1-\\alpha}\\right).\n\\]\nEstandarizando:\n\\[\n\\eta(\\mu) = P\\!\\left(\n\\frac{Z - \\tfrac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)}{1} &gt;\nz_{1-\\alpha} - \\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\n\\right).\n\\] \\[\n  \\eta(\\mu)=1-\\Phi\\!\\left(z_{1-\\alpha}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\right)\n  \\]\nVersi√≥n unilateral a la izquierda Para \\(H_0:\\mu\\ge\\mu_0\\) vs \\(H_1:\\mu&lt;\\mu_0\\), el test UMP es:\n\\[\n\\text{Rechazar }H_0 \\text{ si } \\overline{X}_n &lt; \\mu_0 - z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\]\ncon potencia\n\\[\n\\eta(\\mu)=\\Phi\\!\\left(-z_{1-\\alpha}+\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\right)\n\\]\nCaso bilateral El ejemplo plantea \\(H_0:\\mu=\\mu_0\\) vs \\(H_1:\\mu\\neq\\mu_0\\).\n\nNo existe UMP en general para alternativas bilaterales.\n\nSe usa el test m√°s potente imparcial (MPI):\n\\[\n\\text{Rechazar }H_0 \\text{ si } \\left|\\overline{X}_n-\\mu_0\\right|\n\\ge z_{1-\\alpha/2}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\]\n\n\nSu potencia es:\n\\[\n\\eta(\\mu)=1-\\Big[\\Phi\\!\\Big(z_{1-\\alpha/2}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\Big)\n        -\\Phi\\!\\Big(-z_{1-\\alpha/2}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\Big)\\Big]\n\\]\n\n\nIntuici√≥n clave - Con RVM, ‚Äúvalores grandes de \\(\\overline{X}_n\\) favorecen \\(\\mu\\) grandes‚Äù, por eso la regi√≥n cr√≠tica es de cola y el test es UMP en el caso unilateral.\n- En bilateral no hay un √∫nico sentido de ‚Äúgrande‚Äù, por eso no existe UMP; el test adecuado es MPI.",
    "crumbs": [
      "Inicio",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#verosimilitud-y-cociente-de-verosimilitudes",
    "href": "chapter3.html#verosimilitud-y-cociente-de-verosimilitudes",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n5.1 Verosimilitud y cociente de verosimilitudes",
    "text": "5.1 Verosimilitud y cociente de verosimilitudes\nLa verosimilitud de una muestra \\(x=(x_1,\\dots,x_n)\\) es \\[\nL(\\mu\\mid x)=(2\\pi\\sigma^2)^{-n/2}\\exp\\!\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(x_i-\\mu)^2\\right\\}.\n\\]\nEl cociente de verosimilitudes (likelihood ratio) es \\[\n\\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\n=\\exp\\!\\left\\{\\frac{1}{2\\sigma^2}\\sum_{i=1}^n\\Big[(x_i-\\mu_0)^2-(x_i-\\mu_1)^2\\Big]\\right\\}.\n\\]\nNotemos que \\[\n(x_i-\\mu_0)^2-(x_i-\\mu_1)^2\n=2x_i(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2),\n\\] de modo que, al sumar y usar \\(\\bar x=\\tfrac{1}{n}\\sum x_i\\), \\[\n\\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\n=\\exp\\!\\left\\{\\frac{n}{2\\sigma^2}\\Big(2\\bar x(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2)\\Big)\\right\\}.\n\\]\nPor el Lema de Neyman‚ÄìPearson, la regi√≥n cr√≠tica √≥ptima (para tama√±o dado) es del tipo \\[\nC=\\Big\\{x:\\ \\frac{L(\\mu_1\\mid x)}{L(\\mu_0\\mid x)}\\ge A\\Big\\}\n=\\left\\{x:\\ \\exp\\!\\left\\{\\frac{n}{2\\sigma^2}\\Big(2\\bar x(\\mu_1-\\mu_0)+(\\mu_0^2-\\mu_1^2)\\Big)\\right\\}\\ge A\\right\\}.\n\\]\nComo \\(\\mu_1-\\mu_0&gt;0\\), el cociente es funci√≥n creciente de \\(\\bar x\\). Por tanto, la regi√≥n cr√≠tica puede escribirse como \\[\nC=\\{x:\\ \\bar x\\ge B\\}.\n\\]\nLas constantes \\(A\\) y \\(B\\) se relacionan por \\[\nB=\\frac{\\sigma^2\\log A}{n(\\mu_1-\\mu_0)}+\\frac{\\mu_1+\\mu_0}{2}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#fijar-el-tama√±o-alpha-y-obtener-b",
    "href": "chapter3.html#fijar-el-tama√±o-alpha-y-obtener-b",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n5.2 Fijar el tama√±o \\(\\alpha\\) y obtener \\(B\\)\n",
    "text": "5.2 Fijar el tama√±o \\(\\alpha\\) y obtener \\(B\\)\n\nNo es necesario hallar \\(B\\) a partir de \\(A\\). Basta imponer el tama√±o deseado: \\[\nP(C\\mid H_0)=P(\\bar X\\ge B\\mid H_0)=\\alpha.\n\\] Bajo \\(H_0\\), \\(\\bar X\\sim N(\\mu_0,\\sigma^2/n)\\), as√≠ que \\[\nB=\\mu_0+z_\\alpha\\,\\frac{\\sigma}{\\sqrt{n}},\n\\] donde \\(z_\\alpha\\) satisface \\(P(Z\\ge z_\\alpha)=\\alpha\\) para \\(Z\\sim N(0,1)\\).\nLa regla de decisi√≥n equivalente es: \\[\n\\text{Rechazar }H_0\\ \\ \\Longleftrightarrow\\ \\ Z=\\frac{\\bar X-\\mu_0}{\\sigma/\\sqrt{n}}\\ge z_\\alpha.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#ejemplo-num√©rico",
    "href": "chapter3.html#ejemplo-num√©rico",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n5.3 Ejemplo num√©rico",
    "text": "5.3 Ejemplo num√©rico\nSupongamos \\(\\mu_0=5\\), \\(\\mu_1=6\\), \\(\\sigma^2=1\\) (luego \\(\\sigma=1\\)), \\(\\alpha=0.05\\) y \\(n=4\\).\n\nUmbral cr√≠tico para \\(\\bar X\\): \\[\nB=\\mu_0+z_{0.05}\\frac{\\sigma}{\\sqrt{n}}\n=5+1.645\\cdot\\frac{1}{2}\n=5+0.8225\n=5.8225.\n\\]\nRegla equivalente con \\(Z\\): \\[\nZ=\\frac{\\bar X-5}{1/\\sqrt{4}}\n=\\frac{\\bar X-5}{0.5}\n\\ge 1.645.\n\\]\nDatos observados: \\(x=(5.1,\\,5.5,\\,4.9,\\,5.3)\\).\nMedia muestral: \\(\\bar x=\\tfrac{5.1+5.5+4.9+5.3}{4}=5.2\\).\nC√°lculo del estad√≠stico: \\[\nz=\\frac{\\bar x-5}{1/\\sqrt{4}}=\\frac{5.2-5}{0.5}=0.4&lt;1.645.\n\\]\n\nDecisi√≥n: no se rechaza \\(H_0\\) al nivel \\(\\alpha=0.05\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#comentario-final",
    "href": "chapter3.html#comentario-final",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n5.4 Comentario final",
    "text": "5.4 Comentario final\nEste contraste se denomina test Z unilateral porque usa el estad√≠stico \\[\nZ=\\sqrt{n}\\,\\frac{\\bar X-\\mu_0}{\\sigma}\\ \\sim\\ N(0,1)\\ \\ \\text{bajo }H_0.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#definici√≥n",
    "href": "chapter3.html#definici√≥n",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.7 Definici√≥n",
    "text": "4.7 Definici√≥n\n\n\nLa funci√≥n de potencia de un test con regi√≥n cr√≠tica \\(C\\) es:\n\\[\n\\eta(\\theta) = P_\\theta(X \\in C)\n\\]\n\n\nUn test es UMP de tama√±o \\(\\alpha\\) para \\(H_0:\\theta \\in \\Theta_0\\) vs \\(H_1:\\theta \\in \\Theta_1\\) si:\n\\[\n\\sup_{\\theta \\in \\Theta_0} \\eta(\\theta) = \\alpha\n\\]\ny, para cualquier otro test del mismo tama√±o con funci√≥n de potencia \\(\\eta^\\*(\\theta)\\),\n\\[\n\\eta(\\theta) \\geq \\eta^\\*(\\theta), \\quad \\forall \\theta \\in \\Theta_1\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#lectura-intuitiva",
    "href": "chapter3.html#lectura-intuitiva",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.8 Lectura intuitiva",
    "text": "4.8 Lectura intuitiva\n\n\nMismo control de falsos positivos: todos los tests comparados tienen el mismo tama√±o \\(\\alpha\\).\n\n\nMejor detecci√≥n bajo la alternativa: en todo \\(\\Theta_1\\), la probabilidad de rechazar \\(H_0\\) es al menos tan grande como la de cualquier otro test del mismo tama√±o.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#observaciones",
    "href": "chapter3.html#observaciones",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.9 Observaciones",
    "text": "4.9 Observaciones\n\nA veces no existe un UMP (por ejemplo, en muchas alternativas bilaterales).\n\nS√≠ existe UMP en varios problemas unilaterales cuando la familia tiene raz√≥n de verosimilitudes mon√≥tona (teorema de Karlin‚ÄìRubin).",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#mini-ejemplo-binomial-unilateral",
    "href": "chapter3.html#mini-ejemplo-binomial-unilateral",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.10 Mini-ejemplo (binomial unilateral)",
    "text": "4.10 Mini-ejemplo (binomial unilateral)\n\nModelo: \\(X \\sim \\text{Bin}(n,p)\\).\nContraste: \\(H_0: p \\le p_0\\) vs \\(H_1: p &gt; p_0\\).\n\nRegi√≥n cr√≠tica de tama√±o \\(\\alpha\\): \\(C = \\{x : x \\ge c_\\alpha\\}\\) donde\n\\[\n\\alpha = P_{p_0}(X \\ge c_\\alpha)\n\\]\n\n\nPotencia para cualquier \\(p\\):\n\\[\n\\eta(p) = P_p(X \\ge c_\\alpha) = \\sum_{k=c_\\alpha}^n \\binom{n}{k} p^k (1-p)^{n-k}\n\\]\n\n\nEste test es UMP de tama√±o \\(\\alpha\\) para \\(H_1: p &gt; p_0\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#planteamiento",
    "href": "chapter3.html#planteamiento",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.7 Planteamiento",
    "text": "4.7 Planteamiento\n\nMuestra i.i.d. \\(X_1,\\dots,X_n \\sim N(\\mu,\\sigma^2)\\) con \\(\\sigma^2\\) conocida.\nEstad√≠stico: \\(\\overline{X}_n\\).\n\nQueremos contrastar, por ejemplo:\n\\[\nH_0:\\ \\mu \\le \\mu_0 \\quad \\text{vs} \\quad H_1:\\ \\mu &gt; \\mu_0\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#verificaci√≥n-de-las-hip√≥tesis-del-teorema",
    "href": "chapter3.html#verificaci√≥n-de-las-hip√≥tesis-del-teorema",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.8 Verificaci√≥n de las hip√≥tesis del teorema",
    "text": "4.8 Verificaci√≥n de las hip√≥tesis del teorema\n\nSuficiencia: para varianza conocida, \\(\\overline{X}_n\\) es suficiente para \\(\\mu\\).\n\nRaz√≥n de verosimilitudes mon√≥tona (RVM): la familia \\(\\{N(\\mu,\\sigma^2/n): \\mu \\in \\mathbb{R}\\}\\) posee RVM en \\(\\overline{X}_n\\), porque para \\(\\mu_1&gt;\\mu_0\\) la raz√≥n\n\\[\n\\frac{f_{\\mu_1}(\\overline{x})}{f_{\\mu_0}(\\overline{x})}\n\\]\nes creciente en \\(\\overline{x}\\).\n\n\nPor el teorema, existe un test UMP de tama√±o \\(\\alpha\\) cuya regi√≥n cr√≠tica es de cola superior.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#test-ump-unilateral-a-la-derecha",
    "href": "chapter3.html#test-ump-unilateral-a-la-derecha",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.9 Test UMP (unilateral a la derecha)",
    "text": "4.9 Test UMP (unilateral a la derecha)\n\n\nBajo \\(\\mu=\\mu_0\\):\n\\[\nZ=\\frac{\\overline{X}_n-\\mu_0}{\\sigma/\\sqrt{n}} \\sim N(0,1)\n\\]\n\n\nEl test UMP de tama√±o \\(\\alpha\\) rechaza \\(H_0\\) si:\n\\[\n\\overline{X}_n &gt; \\mu_0 + z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\quad \\Longleftrightarrow \\quad\nZ &gt; z_{1-\\alpha}\n\\]\n\n\nFunci√≥n de potencia:\n\\[\n\\eta(\\mu)=1-\\Phi\\!\\left(z_{1-\\alpha}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\right)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#versi√≥n-unilateral-a-la-izquierda",
    "href": "chapter3.html#versi√≥n-unilateral-a-la-izquierda",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.10 Versi√≥n unilateral a la izquierda",
    "text": "4.10 Versi√≥n unilateral a la izquierda\nPara \\(H_0:\\mu\\ge\\mu_0\\) vs \\(H_1:\\mu&lt;\\mu_0\\), el test UMP es:\n\\[\n\\text{Rechazar }H_0 \\text{ si } \\overline{X}_n &lt; \\mu_0 - z_{1-\\alpha}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\]\ncon potencia\n\\[\n\\eta(\\mu)=\\Phi\\!\\left(-z_{1-\\alpha}+\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\right)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#caso-bilateral",
    "href": "chapter3.html#caso-bilateral",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.11 Caso bilateral",
    "text": "4.11 Caso bilateral\nEl ejemplo plantea \\(H_0:\\mu=\\mu_0\\) vs \\(H_1:\\mu\\neq\\mu_0\\).\n\nNo existe UMP en general para alternativas bilaterales.\n\nSe usa el test m√°s potente imparcial (MPI):\n\\[\n\\text{Rechazar }H_0 \\text{ si } \\left|\\overline{X}_n-\\mu_0\\right|\n\\ge z_{1-\\alpha/2}\\,\\frac{\\sigma}{\\sqrt{n}}\n\\]\n\n\nSu potencia es:\n\\[\n\\eta(\\mu)=1-\\Big[\\Phi\\!\\Big(z_{1-\\alpha/2}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\Big)\n        -\\Phi\\!\\Big(-z_{1-\\alpha/2}-\\frac{\\sqrt{n}}{\\sigma}(\\mu-\\mu_0)\\Big)\\Big]\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  },
  {
    "objectID": "chapter3.html#intuici√≥n-clave",
    "href": "chapter3.html#intuici√≥n-clave",
    "title": "\n4¬† Contrastes de hip√≥tesis\n",
    "section": "\n4.12 Intuici√≥n clave",
    "text": "4.12 Intuici√≥n clave\n\nCon RVM, ‚Äúvalores grandes de \\(\\overline{X}_n\\) favorecen \\(\\mu\\) grandes‚Äù, por eso la regi√≥n cr√≠tica es de cola y el test es UMP en el caso unilateral.\n\nEn bilateral no hay un √∫nico sentido de ‚Äúgrande‚Äù, por eso no existe UMP; el test adecuado es MPI.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Contrastes de hip√≥tesis</span>"
    ]
  }
]