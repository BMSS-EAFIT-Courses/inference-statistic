format:
  html:
    math: mathjax
    mathjax:
      tex:
        macros:
          usim: ["\\underaccent{\\tilde}{#1}", 1]

# 1.2 VARIABLE ALEATORIA
#### 1.2.1 Variables y vectores aleatorios
Consideramos un experimento aleatorio cuyos resultados pertenecen al espacio muestral Œ©. Modelamos este proceso suponiendo que existe una terna $(\Omega, \mathcal{A}, P),$ donde:

- $\Omega$ es el espacio muestra,  
- $\mathcal{P}(\Omega)$ es el conjunto de partes de Œ©,  
- $\mathcal{A}\in\mathcal{P}(\Omega)$ es una œÉ-√°lgebra,  
- $P\colon \mathcal{A} \to [0,1]$ es una medida de probabilidad que refleja las caracter√≠sticas aleatorias del experimento realizado.  

A esta terna se le llama **espacio de probabilidad**.

Los resultados de un experimento aleatorio no son analizados ‚Äúen bruto‚Äù, sino que se les da una representaci√≥n num√©rica que facilita su tratamiento. Esto se logra introduciendo variables aleatorias, que asocian cada resultado $\omega\in \Omega$ con un valor num√©rico o vectorial, y sobre las cuales luego aplicamos t√©cnicas de inferencia estad√≠stica.

En todo estudio estad√≠stico partimos de un **experimento aleatorio** cuyo conjunto de resultados posibles se denomina **espacio muestral** Œ©. Para cuantificar dichos resultados definimos las siguientes estructuras:

**Definici√≥n: Variables Aleatorias**
Sea $(\Omega,\mathcal{A},P)$ un espacio de probabilidad. Una **variable aleatoria** es una funci√≥n $X\colon (\Omega,\mathcal{A})\;\longrightarrow\; (\mathbb{R},\mathcal{B}),$ tal que para todo $B\in\mathcal{B}$ (la $\sigma$-√°lgebra de Borel en ‚Ñù),  $X^{-1}(B)\;=\;\{\omega\in\Omega : X(\omega)\in B\}\;\in\;\mathcal{A}.$

- Si el espacio muestral Œ© es **finito o numerable**, diremos que es un espacio **discreto** y las variables aleatorias asociadas al experimento normalmente estar√°n definidas como $X\colon \Omega \;\longrightarrow\; \mathbb{Z}.$
- Si $\Omega$ es **no numerable**, entonces diremos que es un espacio **continuo** y $X\colon \Omega \;\longrightarrow\; \mathbb{R}.$
---

**Definici√≥n: Vector aleatorio**

Un **vector aleatorio** de dimensi√≥n $n$ es $\mathbf{X} = (X_1,\dots,X_n)\colon(\Omega,\mathcal{A})\longrightarrow(\mathbb{R}^n,\mathcal{B}^n),$ donde cada componente $X_i$ es variable aleatoria y $\mathcal{B}^n$ la $\sigma$-√°lgebra de Borel en ‚Ñù‚Åø.

---

**Ejemplos**
  **Lanzamiento de dos monedas**

Sea $\Omega = \{\,CC,\;C-,\;-C,\;--\},  $ donde $C$ = ‚Äúcara‚Äù y $-$ = ‚Äúcruz‚Äù. Podemos definir:  
$X_1(\omega) = \text{n√∫mero de caras en }\omega.$
$X_2(\omega) = 2 - X_1(\omega)\;=\; \text{n√∫mero de cruces}.$
$X_3(\omega) = \bigl(X_1(\omega)\bigr)^2.$

Entonces $(X_1,X_2,X_3)$ es un vector aleatorio de dimensi√≥n 3.

 **Tiempos de servicio en un servidor**

Sean $T_i$ los tiempos de servicio (en segundos) de las peticiones $i=1,2,3$. Definimos  
$\mathbf{T}=(T_1,T_2,T_3),\quad S = T_1 + T_2 + T_3,\quad M = \max\{T_1,T_2,T_3\}.$

  **Lecturas de sensores en red distribuida**

En tres nodos $i=1,2,3$ medimos temperatura $X_{i,1}$, presi√≥n $X_{i,2}$ y humedad $X_{i,3}$. El vector global es $\mathbf{X} = (X_{1,1},X_{1,2},X_{1,3},\,X_{2,1},\dots,X_{3,3}) \in \mathbb{R}^9.$

---

Con estas definiciones rigurosas disponemos ya de los objetos b√°sicos para, en las siguientes secciones, construir estimadores, estudiar su comportamiento asint√≥tico y contrastar hip√≥tesis sobre la distribuci√≥n subyacente $P$.


#### 1.2.2 Distribuci√≥n de una variable aleatoria. Funciones de distribuci√≥n, de probabilidad y de densidad
  
  **Distribuci√≥n de una Variable Aleatoria**

La realizaci√≥n de un experimento aleatorio da lugar a un resultado $\omega\in\Omega$ que es aleatorio. Por lo tanto, $X(\omega)$ es un valor de $\mathbb{R}$ tambi√©n aleatorio. Es decir, la variable aleatoria $X$ induce una medida de probabilidad en $\mathbb{R}$. A esa medida de probabilidad se le llama **distribuci√≥n de $X$** o **ley de $X$**. Una de las formas de caracterizar la distribuci√≥n de una variable aleatoria es dar su funci√≥n de distribuci√≥n $F_X$, que est√° definida as√≠:

$F_X(x) \;=\; P(X \le x)\;=\; P\bigl(\{\omega \in \Omega : X(\omega) \le x\}\bigr)\;=\; P\bigl(X^{-1}((-\infty, x])\bigr).$$

En el caso de que $X$ sea una **variable aleatoria discreta**, es decir, en el caso de que $X$ solo tome una cantidad finita o numerable de valores de $\mathbb{R}$, su distribuci√≥n tambi√©n puede caracterizarse por su **funci√≥n de probabilidad** (o **funci√≥n de masa de probabilidad**) $f_X$, definida como

$$f_X : \mathbb{R} \longrightarrow [0,1],\qquad f_X(x) = P(X = x).$$

Esa funci√≥n solo es no nula en un conjunto finito o numerable. Supondremos en adelante, sin p√©rdida de generalidad, que ese conjunto est√° contenido en $\mathbb{Z}$.
A partir de la funci√≥n de masa de probabilidad se puede calcular la probabilidad 
de que la variable aleatoria $X$ tome valores en cualquier elemento $A \subseteq \mathbb{B}$:

$P(X \in A) = \sum_{x \in A} f_X(x).$
me


La funci√≥n de distribuci√≥n y la funci√≥n de masa de probabilidad se relacionan 
de la siguiente forma:

$F_X(x) = \sum_{u \leq x} f_X(u), \quad f_X(x) = F_X(x) - F_X(x^-),$ donde $F_X(x^-) = \lim_{h \to 0^+} F_X(x - h)$.

Una clase relevante de variables aleatorias no discretas son las que poseen **funci√≥n de densidad**, es decir, aquellas cuya distribuci√≥n de probabilidad puede caracterizarse por una funci√≥n $f_X(x) \geq 0$ que cumple que:

$P(X \in A) = \int_{x \in A} f_X(x) \, dx, \quad \text{para todo } A \subseteq \mathbb{B}.$

La relaci√≥n entre $F_X$ y $f_X$ es la siguiente:

$F_X(x) = \int_{-\infty}^{x} f_X(u) \, du, \quad f_X(x) = \frac{d}{dx} F_X(x),$

salvo quiz√°s en un n√∫mero finito de puntos $x \in \mathbb{R}$. Las variables aleatorias que poseen funci√≥n de densidad se llaman **variables aleatorias absolutamente continuas**. Abusando del lenguaje, aqu√≠ nos referiremos a ellas como variables aleatorias continuas.



#### 1.2.3 Esperanza y varianza
Si se desea describir totalmente la distribuci√≥n de probabilidad de una variable aleatoria $X$ acabamos de ver que podemos dar su funci√≥n de distribuci√≥n o su funci√≥n de masa o de densidad, seg√∫n el caso. Una descripci√≥n parcial puede efectuarse calculando algunas caracter√≠sticas de la variable aleatoria $X$, como por ejemplo medidas de posici√≥n o de dispersi√≥n. Estudiaremos algunas de ellas.

Se define la **esperanza** de una variable aleatoria $X$ como la integral de Lebesgue de $X$:

$E(X) = \int_{\Omega} X(w) dP(w).$

En el caso de variables aleatorias discretas la esperanza puede calcularse como:

$E(X) = \sum_{w \in \Omega} X(w) P(w) = \sum_{k \in \mathbb{Z}} k P(X = k) = \sum_{k \in \mathbb{Z}} k f_X(k).$

Por otro lado, la esperanza de una variable aleatoria continua se puede calcular as√≠:

$E(X) = \int_{\mathbb{R}} x f_X(x) dx.$

La esperanza de una variable aleatoria $X$ es una medida de posici√≥n de $X$: es el centro de gravedad de la distribuci√≥n de probabilidad de $X$.

Si $h$ es una funci√≥n medible $h : \mathbb{R} \rightarrow \mathbb{R}$, entonces $Y = h(X)$ es tambi√©n variable aleatoria y su esperanza se puede calcular a partir de la distribuci√≥n de $X$:

$E(h(X)) = \int_{\Omega} h(X(w)) dP(w)$ que en el caso de que $X$ sea discreta puede reescribirse como

$E(h(X)) = \sum_{k \in \mathbb{Z}} h(k) f_X(k).$

Si $X$ es una variable aleatoria continua entonces

$E(h(X)) = \int_{\mathbb{R}} h(x) f_X(x) dx.$

Si existe $\mu = E(X)$ y es finita puede definirse una medida de dispersi√≥n de la variable aleatoria $X$ a partir de una transformaci√≥n $h$ de $X$. Es lo que se denomina **varianza** de $X$ y se define as√≠:

$V(X) = E((X - \mu)^2) = E(X^2) - \mu^2 = E(X^2) - (E(X))^2.$

#### 1.2.4 Funci√≥n generadora de momentos 
Dada una variable aleatoria $X$, o su funci√≥n de distribuci√≥n $F$, vamos a definir otra funci√≥n generadora, como

$M_X(t) = \mathbb{E}(e^{tX}),$ siempre que este valor esperado exista.

Notemos que cuando $X$ toma valores en los enteros no-negativos, $M_X(t) = \phi_X(e^t)$, donde $\phi_X(s)=E[s^X]=\sum_{k=0}^{\infty}p_ks^k$ para $s\in[0,1]$ es la funci√≥n generadora de probabilidad (f.g.p.) de la variable $X$, con $p_k=P(X=k)$. Si $X$ est√° acotada, $M_X$ est√° bien definida para todo $t$ real; en cambio, si $X$ no est√° acotada, es posible que el dominio de $M_X$ no sea el conjunto de todos los reales. En todo caso, $\phi$ siempre est√° definida en cero, y $M(0) = 1$.

Es posible demostrar que si la f.g.m. de la v.a. $X$ existe en un entorno de 0, entonces para todo $k > 0$,

$\mathbb{E}[|X|^k] < \infty.$

M√°s a√∫n, la serie

$M_X(t) = 
\mathbb{E}(e^{tX}) 
= \mathbb{E}\left(1 + \sum_{k=1}^{\infty} \frac{t^k X^k}{k!}\right) 
= 1 + \sum_{n=1}^{\infty} \frac{t^k}{k!} \mathbb{E}(X^k)
\tag{5.1}$

es convergente y se puede derivar t√©rmino a t√©rmino. Obtenemos

$M'_X(0) = \mathbb{E}(X); \quad M''_X(0) = \mathbb{E}(X^2)$

y en general

$M_X^{(k)}(0) = \mathbb{E}(X^k).$

Es por esta √∫ltima propiedad que esta funci√≥n se conoce como **funci√≥n generadora de momentos** (f.g.m.).

üé≤ Ejemplo: f.g.m. de la distribuci√≥n Binomial

Sea $X \sim \text{Binomial}(n, p)$, es decir, la suma de $n$ ensayos de Bernoulli con probabilidad de √©xito $p$. La funci√≥n generadora de momentos es: [Ejemplo fgm binomial](https://github.com/BMSS-EAFIT-Courses/inference-statistic/blob/main/mgf_binomial.r)

$M_X(t) = \mathbb{E}[e^{tX}] = (1 - p + p e^t)^n$

<pre> ```r #
mgf_binomial <- function(t, n = 10, p = 0.3) {
  (1 - p + p * exp(t))^n
}

t_vals <- seq(-3, 3, length.out = 300)
mgf_vals <- sapply(t_vals, mgf_binomial)

plot(t_vals, mgf_vals, type = "l", lwd = 2,
     main = expression("F.G.M. para X ~ Binomial(10, 0.3)"),
     xlab = "t", ylab = expression(M[X](t)))
grid()
``` </pre>
üìà Ejemplo: f.g.m. de la distribuci√≥n Normal Est√°ndar

Sea $X \sim \mathcal{N}(0, 1)$. Su funci√≥n generadora de momentos es:

$M_X(t) = \mathbb{E}[e^{tX}] = e^{\frac{t^2}{2}}$

Esta expresi√≥n se obtiene usando la forma cerrada del momento de una normal est√°ndar.
<pre> ```r #
mgf_normal <- function(t) {
  exp(t^2 / 2)
}

t_vals <- seq(-3, 3, length.out = 300)
mgf_vals <- sapply(t_vals, mgf_normal)

plot(t_vals, mgf_vals, type = "l", lwd = 2,
     main = expression("F.G.M. para X ~ N(0, 1)"),
     xlab = "t", ylab = expression(M[X](t)))
grid()
``` </pre>

 **‚ùì Preguntas gu√≠a sobre la gr√°fica de la funci√≥n generadora de momentos**

  **üìå ¬øQu√© representa la gr√°fica de la f.g.m. $M_X(t)$?**

La gr√°fica muestra c√≥mo evoluciona el valor esperado de $e^{tX}$ cuando $t$ var√≠a. Esta funci√≥n codifica **todos los momentos de la variable aleatoria** $X$, y por tanto, contiene informaci√≥n completa sobre su distribuci√≥n (si existe un entorno donde la f.g.m. es finita).

---

  **üß≠ ¬øQu√© se observa en la f.g.m. de una distribuci√≥n Binomial?**
<img width="480" height="480" alt="mgf_binomial" src="https://github.com/user-attachments/assets/8524edee-0b5c-4938-a9e8-8af0e8c5840c" />

![Gr√°fica MGF Binomial]

  #Preguntas y respuestas

- **¬øC√≥mo es el comportamiento de la f.g.m. cerca de $t = 0$?**

  En $t = 0$, siempre se cumple que $M_X(0) = 1$, ya que:

  $M_X(0) = \mathbb{E}[e^{0 \cdot X}] = \mathbb{E}[1] = 1$

- **¬øQu√© indica la curvatura de la gr√°fica?**

   La curvatura refleja el crecimiento exponencial de los momentos. Si la curva crece r√°pidamente hacia la derecha, significa que los momentos (media, varianza, etc.) tambi√©n crecen con rapidez.

- **¬øPor qu√© la gr√°fica es convexa?**

  Todas las funciones generadoras de momentos son **estrictamente convexas** en el intervalo donde est√°n definidas. Esto es una consecuencia de que derivadas sucesivas representan momentos positivos.

- **¬øQu√© pasa si cambio los par√°metros $n$ y $p$?**

  Aumentar $ n $ o $p$ tiende a **elevar** la f.g.m. en el lado derecho, reflejando una mayor media y varianza.

---

  **üìà ¬øC√≥mo se comporta la f.g.m. para la Normal Est√°ndar?**
<img width="480" height="480" alt="mgf_normal" src="https://github.com/user-attachments/assets/e877129d-4235-42d9-baff-7f29d3afc4a7" />

![Gr√°fica MGF Normal]

  **Preguntas y respuestas**

- **¬øPor qu√© es sim√©trica respecto al eje $ t = 0 $?**

  Porque la normal est√°ndar es sim√©trica alrededor de su media $ \mu = 0 $, y su f.g.m. tiene la forma:

 $M_X(t) = e^{t^2 / 2}$

  lo cual es una funci√≥n par: $M_X(-t)= M_X(t)$.

- **¬øQu√© tan r√°pido crece la funci√≥n?**

  Muy r√°pido. El crecimiento es exponencial cuadr√°tico. Esto implica que los momentos de la normal crecen r√°pidamente en magnitud.

- **¬øC√≥mo se relaciona esta gr√°fica con los momentos de la normal?**

  Derivando sucesivamente la f.g.m. en $ t = 0 $, se obtiene:

  $\mathbb{E}[X^k] = M_X^{(k)}(0)$

  Por tanto, la gr√°fica "encierra" toda la informaci√≥n sobre los momentos.

---

  **üß† Conclusi√≥n**

Estas gr√°ficas te permiten **visualizar la informaci√≥n estad√≠stica codificada en una variable aleatoria**. La f.g.m. no es solo una herramienta algebraica para obtener momentos, sino una forma poderosa de describir el comportamiento global de la variable.

> **¬øQu√© pasa si dos variables tienen la misma f.g.m.?**  
> ¬°Tienen la misma distribuci√≥n! (si la f.g.m. est√° definida en un entorno de 0).

  **Ejemplo: Distribuci√≥n uniforme $U(a,b)$**

Si 
$$X \sim U(a,b),$$  
su densidad es  
$$f(x) = \frac{1}{b - a}\quad\text{para }a < x < b,$$  
y su funci√≥n generadora de momentos viene dada por 

<a id="eq:5.2"></a> 
<table align="center">
  <tr>
    <td align="center">
$$M(t)= \int_a^b \frac{e^{t x}}{b - a}\,dx= \frac{e^{b t} - e^{a t}}{t\,(b - a)}.$$  
    </td>
    <td valign="bottom">
      (5.2)
    </td>
  </tr>
</table>

En el caso particular de la distribuci√≥n uniforme en $(0,1)$ se obtiene  
$$M(t) = \frac{e^t - 1}{t}.$$

---

Para derivar la f√≥rmula [#(5.2)](#eq:5.2) y obtener los momentos, podemos usar el desarrollo en serie de la funci√≥n exponencial:

$$M(t)= \frac{1}{t\,(b - a)}\bigl(e^{b t} - e^{a t}\bigr) \\
= \frac{1}{t\,(b - a)}\Bigl[\bigl(1 + \sum_{n=1}^\infty \tfrac{(b t)^n}{n!}\bigr)
                    -\bigl(1 + \sum_{n=1}^\infty \tfrac{(a t)^n}{n!}\bigr)\Bigr] \\
= \frac{1}{b - a}\sum_{n=1}^\infty \frac{b^n - a^n}{n!}\,t^{n-1}.
$$

Este es el desarrollo de Maclaurin de $M(t)$ en $t=0$; por tanto, sus derivadas en cero satisfacen

<table align="center">
  <tr>
    <td align="center">
$$M^{(k)}(0)= \frac{b^{k+1} - a^{k+1}}{(k+1)\,(b - a)}.$$
    </td>
    <td valign="bottom">
      (5.3)
    </td>
  </tr>
</table>
En particular:

-  $$M'(0)= \frac{b^2 - a^2}{2\,(b - a)}= \frac{a + b}{2},$$
  que coincide con $\mathbb{E}(X)$.

-  $$M''(0)= \frac{b^3 - a^3}{3\,(b - a)}= \frac{a^2 + a b + b^2}{3},$$

y un c√°lculo directo muestra que la varianza es

$$\mathrm{Var}(X)= \mathbb{E}(X^2) - \bigl(\mathbb{E}(X)\bigr)^2= \frac{(a + b)^2}{12}.$$

  **Observaci√≥n importante** 
Sea $X$ una v.a. con f.g.m. $M_X$ y sea $Y=aX+b$ una transformaci√≥n lineal de $X$, entonces

$$M_Y(t)=E(e^{tY})=E(e^{t(aX+b)})=E(e^{taX}e^{tb})=e^{tb}E(e^{taX})=e^{tb}M_X(at)$$



  **Teorema (fgm de suma de v.a.s)**

Si $X$ tiene funci√≥n generadora de momentos $M(t)$ que est√° definida en un entorno $(-a,a)$ de 0, entonces $M(t)$ caracteriza a la distribuci√≥n de $X$; es decir, si otra variable $Y$ tiene la misma funci√≥n generadora de momentos, las distribuciones de $X$ e $Y$ coinciden.

---

Si $X,Y$ son variables aleatorias con funciones generadoras de momentos respectivas $M_X$ y $M_Y$ que existen en un dominio com√∫n $|t| < d$, entonces la f.g.m. de la suma $X+Y$ est√° dada por
<a id="eq:5.5"></a> 
<table align="center">
  <tr>
    <td align="center">
$$M_{X+Y}(t)= \mathbb{E}\bigl[e^{t(X+Y)}\bigr]= \mathbb{E}\bigl[e^{tX}\,e^{tY}\bigr]=\mathbb{E}\bigl[e^{tX}\bigr]\;\mathbb{E}\bigl[e^{tY}\bigr]= M_X(t)\,M_Y(t).
\tag{5.5}
$$
  </td>
    <td valign="bottom">
      (5.5)
    </td>
  </tr>
</table>

Este resultado se extiende a la suma de $n$ variables aleatorias independientes. Si

$$S_n = X_1 + \cdots + X_n,$$

entonces

$$M_{S_n}(t)= \mathbb{E}\bigl[e^{tS_n}\bigr]= \mathbb{E}\Bigl[e^{t\sum_{i=1}^n X_i}\Bigr]= \prod_{i=1}^n\mathbb{E}\bigl[e^{tX_i}\bigr]= \prod_{i=1}^n M_{X_i}(t).$$

La funci√≥n generadora de momentos resulta particularmente √∫til cuando consideramos sucesiones de variables aleatorias, como lo muestra el siguiente teorema que enunciamos sin demostraci√≥n:

---

  **Teorema (de Continuidad)**

Sea $F_n(x)$, $n\ge1$, una sucesi√≥n de funciones de distribuci√≥n con funciones generadoras de momentos respectivas $M_n(t)$, definidas en $|t|<b$. Supongamos que cuando $n\to\infty$,

$$
M_n(t)\,\longrightarrow\,M(t)
\quad\text{para }|t|\le a,
$$

donde $M(t)$ es la funci√≥n generadora de momentos de la distribuci√≥n l√≠mite $F(x)$. Entonces

$$
F_n(x)\,\longrightarrow\,F(x)
\quad\text{cuando }n\to\infty
$$

para todo punto $x$ en el cual $F$ es continua.

  **Teorema de Laplace‚ÄìMoivre**

Sea $X_1, X_2, \ldots, X_n$ una sucesi√≥n de variables aleatorias **i.i.d.** con distribuci√≥n \( \text{Bernoulli}(p) \), donde \( 0 < p < 1 \). Sea:

$$
S_n = X_1 + X_2 + \cdots + X_n \sim \text{Binomial}(n, p)
$$

y consideremos la variable tipificada:

$$
Z_n = \frac{S_n - np}{\sqrt{np(1 - p)}}
$$

Entonces, cuando \( n \to \infty \), se tiene convergencia en distribuci√≥n a una normal est√°ndar:

$$
Z_n \xrightarrow{d} \mathcal{N}(0, 1)
$$

es decir,

$$
\lim_{n \to \infty} \mathbb{P}(Z_n \leq z) = \Phi(z), \quad \text{para todo } z \in \mathbb{R}
$$

donde \( \Phi(z) \) es la funci√≥n de distribuci√≥n acumulada de la normal est√°ndar.

---

  **Demostraci√≥n usando funciones generadoras de momentos**

La funci√≥n generadora de momentos (mgf) de $S_n \sim \text{Binomial}(n, p)$ es:

$$
M_{S_n}(t) = \left(1 - p + p e^t\right)^n
$$

Queremos obtener la mgf de la variable tipificada \( Z_n \). Usamos la propiedad de cambio de variable de la mgf:

$$
M_{Z_n}(t) = \mathbb{E}\left[ e^{t Z_n} \right]
= \mathbb{E}\left[ e^{t \cdot \frac{S_n - np}{\sqrt{np(1 - p)}}} \right]
= e^{-t \cdot \frac{np}{\sqrt{np(1 - p)}}} \cdot M_{S_n}\left( \frac{t}{\sqrt{np(1 - p)}} \right)
$$

Sustituimos la mgf de \( S_n \):

$$
M_{Z_n}(t) = \exp\left( -t \cdot \frac{np}{\sqrt{np(1 - p)}} \right)
\cdot \left( 1 - p + p e^{t / \sqrt{np(1 - p)}} \right)^n
$$

---

  **Aproximaci√≥n por series de Taylor**

Expandimos  $e^{t / \sqrt{np(1 - p)}}$ para $n$ grande:

$$
e^{t / \sqrt{np(1 - p)}} = 1 + \frac{t}{\sqrt{np(1 - p)}} + \frac{t^2}{2np(1 - p)} + \cdots
$$

Entonces:

$$
1 - p + p e^{t / \sqrt{np(1 - p)}} \approx 1 + \frac{pt}{\sqrt{np(1 - p)}} + \frac{pt^2}{2np(1 - p)} + \cdots
$$

Usamos que $\log(1 + x) \approx x - \frac{x^2}{2} + \cdots$ para $x \approx 0$:

$$\log M_{Z_n}(t) \approx -t \cdot \frac{np}{\sqrt{np(1 - p)}}+ n \left( \frac{pt}{\sqrt{np(1 - p)}} + \frac{pt^2}{2np(1 - p)} \right)$$

Simplificamos:

- El t√©rmino lineal se cancela:

$$
-t \cdot \frac{np}{\sqrt{np(1 - p)}} + n \cdot \frac{pt}{\sqrt{np(1 - p)}} = 0
$$

- Queda:

$$
\log M_{Z_n}(t) \to \frac{t^2}{2}, \quad \text{cuando } n \to \infty
$$

Por tanto:

$$
M_{Z_n}(t) \to e^{t^2 / 2}
$$

---

  **Conclusi√≥n**

Como $e^{t^2/2}$ es la mgf de $\mathcal{N}(0, 1)$, y por el teorema de unicidad de la funci√≥n generadora de momentos:

$$
Z_n \xrightarrow{d} \mathcal{N}(0, 1)
$$

Esto concluye la demostraci√≥n del **Teorema de Laplace‚ÄìMoivre** utilizando funciones generadoras de momentos.


#### 1.2.5 Muestra aleatoria simple

Sea $\underset{\sim}{X} =(X_1 ,..., X_n)$ un vector aleatorio. Se dice que sus componentes $X_1 ,..., X_n$ son \textcolor{red}{independientes} si $P(X_1\leq x_1 ,..., X_n\leq x_n)=P(X_1\leq x_1)...P(X_n\leq x_n)$ para cualesquiera valores $x_1,..., x_n$ .
	
Si adem√°s la distribuci√≥n de las $n$ variables aleatorias $X_i$ es la misma, se dice que $X_1 ,...,X_n$ son variables aleatorias **independientes e id√©nticamente distribuidas**, o bien que son v.a.i.i.d o simplemente i.i.d.
	
Si $\underset{\sim}{X} =(X_1 ,..., X_n)$ y $X_1 ,..., X_n$ son i.i.d. con funci√≥n de densidad (en su caso, de masa) $f_X$ , la distribuci√≥n conjunta de $\underset{\sim}{X}$ viene dada por la funci√≥n de densidad (en su caso, de masa) conjunta
$$
\begin{align*}
f_{\underset{\sim}{X}}(\underset{\sim}{x})&=f_{(X_1 ,..., X_n)}(x_1 ,..., x_n)\\
&=f_{(X_1)}(x_1)...f_{(X_n)}(x_n)\\
&=\prod_{i=1}^{n}f_{(X_i)}(x_i)
\end{align*}
$$

A un vector $\underset{\sim}{X} =(X_1 ,..., X_n)$ de v.a.i.i.d. con distribuci√≥n igual a la de la variable aleatoria $X$ se le denomina tambi√©n **muestra aleatoria simple** de $X$ (m.a.s de $X$).

Esto responde al hecho siguiente. Supongamos que se desea estudiar la caracter√≠stica $X$ de los individuos de una poblaci√≥n de tama√±o infinito. Definimos el experimento consistente en elegir aleatoriamente un individuo de la poblaci√≥n y llamamos $X$ al valor de la caracter√≠stica de inter√©s en ese individuo. X es una variable aleatoria.


Si definimos un nuevo experimento consistente en elegir una muestra aleatoria de n individuos y se anota $X_i$, el valor de la caracter√≠stica en el individuo i-√©simo, entonces **X** $=(X_1 ,..., X_n)$ es una colecci√≥n de n v.a.i.i.d. con distribuci√≥n igual a la de la variable aleatoria $X$, es decir, $X_1 ,..., X_n$ es una m.a.s. de X.

#### 1.2.6 Modelo param√©trico
Usualmente la ley de probabilidad de una variable aleatoria se supone perteneciente a un modelo matem√°tico que depende s√≥lo de un n√∫mero finito de par√°metros:
	$f_X \in\{f(x|\theta):\theta \in \Theta \subseteq \mathbb{R}^k\}$.
	Escribiremos alternativamente $f(x;\theta)$, $f(x|\theta)$ o $f_\theta(x)$.

**Definici√≥n**
		El conjunto de distribuciones dadas por $f_\theta(x)$, $\theta \in \Theta$ se llama familia param√©trica de distribuciones. $\Theta$ es el conjunto de par√°metros.
	

**Definici√≥n**
	La correspondiente distribuci√≥n conjunta de una muestra aleatoria simple de $X$ viene dada por la funci√≥n de densidad (o funci√≥n de masa de probabilidad, seg√∫n el caso)

$$
f_{X_{\sim}}(x_{\sim} \mid \theta) = \prod_{i=1}^{n} f_{\theta}(x_i)
$$

A esta funci√≥n la llamaremos **funci√≥n de verosimilitud** de la muestra $X_{\sim}$. Utilizaremos este t√©rmino para referirnos indistintamente a la funci√≥n de densidad conjunta (si las variables aleatorias son continuas) o a la funci√≥n de masa conjunta (si son discretas).
	

#### 1.2.7 Sumas de variables aleatorias
Cuando se obtiene una muestra aleatoria simple $X_{1},X_{2},\ldots,X_{n}$ normalmente se calculan a partir de ellas cantidades que resumen los valores observados. Cualquiera de estos res√∫menes se puede expresar como una funci√≥n $T(x_1,\ldots,x_n)$ definida en el espacio $\mathcal{X}^n\subseteq\mathbb{R}^n$ donde est√°n las im√°genes del vector $(X_{1},X_{2},\ldots,X_{n})$.

Esta funci√≥n $T$ puede devolver valores de $\mathbb{R}$, $\mathbb{R}^2$ o, en general, $\mathbb{R}^k$.

$$T(X_1 , \ldots, X_n)=\sum_{i=1}^{n}X_i,\bar{X},\bar{X}+3, \min{X_1 , \ldots, X_n},$$ 
$$T(X_1 , \ldots, X_n)=\left(\sum_{i=1}^{n}X_i,\sum_{i=1}^{n}(X_i-\bar{X})^2\right),$$
$$T(X_1 , \ldots, X_n)=\left(\min\{X_1 , \ldots, X_n\},\sum_{i=1}^{n}X_i,\sum_{i=1}^{n}(X_i-\bar{X})^2\right),$$
$$T(X_1 , \ldots, X_n)= (X_1 , \ldots, X_n)$$



