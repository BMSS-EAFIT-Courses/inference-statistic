[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inferencia Estadística",
    "section": "",
    "text": "1 INTRODUCCIÓN\nEste libro ha sido concebido como un recurso integral para el estudio riguroso y aplicado de la inferencia estadística. Está dirigido a estudiantes de programas de estadística, matemáticas aplicadas y disciplinas afines, y busca fortalecer la comprensión conceptual y técnica de los fundamentos que sustentan el análisis estadístico moderno.\nA lo largo de sus capítulos, el lector encontrará un desarrollo progresivo de los siguientes temas:\nEl material combina el rigor formal con ejemplos y aplicaciones que ilustran cómo los métodos estadísticos permiten extraer conclusiones válidas a partir de datos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#cómo-navegar-este-libro",
    "href": "index.html#cómo-navegar-este-libro",
    "title": "Inferencia Estadística",
    "section": "\n1.1 ¿Cómo navegar este libro?",
    "text": "1.1 ¿Cómo navegar este libro?\n\nUsa el índice lateral izquierdo para acceder a cada capítulo y subcapítulo.\nHaz uso del buscador para encontrar conceptos o términos clave.\nRevisa los apartados de “Lista de problemas” incluidos al final de cada sección para practicar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#bienvenidao",
    "href": "index.html#bienvenidao",
    "title": "Inferencia Estadística",
    "section": "\n1.2 ¡Bienvenida/o!",
    "text": "1.2 ¡Bienvenida/o!\nTe invito a recorrer este texto con atención, curiosidad y sentido crítico.\nEspero que este libro te acompañe, rete y apoye en tu formación como profesional en ciencias de datos o áreas relacionadas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#fenómeno-aleatorio-y-variable-observada",
    "href": "index.html#fenómeno-aleatorio-y-variable-observada",
    "title": "Inferencia Estadística",
    "section": "\n2.1 Fenómeno aleatorio y variable observada",
    "text": "2.1 Fenómeno aleatorio y variable observada\n“Se observa una realización de un fenómeno aleatorio, digamos X. Este puede ser un elemento aleatorio de varios tipos: número (variable aleatoria), un vector de dimensión finita (vector aleatorio), una función, etc.\nLa premisa principal es que el carácter aleatorio de X se concibe como una realización de un fenómeno aleatorio que tiene una distribución de probabilidad P, donde la distribución P es desconocida ya sea en su totalidad o en algún detalle específico (por ejemplo, su soporte, su media, etc.). Es de interés conocer P. Si la medida de probabilidad P fuese conocida, entonces no hay problema estadístico propiamente, pues el problema estadístico tiene que ver con inferir la propiedad desconocida de P con base en X.” [Ver referencia 1]\n\n\nDefinición de X\n\n\nX puede ser un valor real \\(X \\in \\mathbb{R}\\), un vector en \\(\\mathbb{R}^n\\), o incluso una función \\(\\;X: [0,1]\\to\\mathbb{R}\\).\n\n\n\n\nMedida de probabilidad P\n\nDesconocida: soporte, media, varianza, etc.\n\nObjetivo estadístico: inferir características de (P) a partir de la muestra (la realización de X).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#incertidumbre-inductiva-vs.-estocástica",
    "href": "index.html#incertidumbre-inductiva-vs.-estocástica",
    "title": "Inferencia Estadística",
    "section": "\n2.2 Incertidumbre inductiva vs. estocástica",
    "text": "2.2 Incertidumbre inductiva vs. estocástica\n“La observación X está dada, por lo que no hay incertidumbre tal como la hay en la teoría de probabilidad desarrollada anteriormente en el curso. Antes, fue concebida una estructura \\((\\Omega, \\mathcal{F}, P)\\) para enfrentar el que haya incertidumbre acerca del valor de X. En el problema estadístico, el valor de X ha sido observado, y la incertidumbre radica en otro punto: radica en que existe duda acerca de cuál P es la que produjo el valor X. En algunas ocasiones se utilizan los términos incertidumbre estocástica e incertidumbre inductiva para distinguir estos dos tipos. Es común que estos se confundan entre sí, porque en estadística matemática la teoría de probabilidad constituye también una de las maneras naturales de afrontar la cuantificación de incertidumbre inductiva. En cualquier caso, el concebir a P como medida de probabilidad es la base para formular soluciones a la incertidumbre inductiva. Con este lenguaje, probabilidad y estadística son problemas diferentes y de cierta manera inversos. Teoría de probabilidad tiene que ver con cuantificar incertidumbre acerca de X y teoría estadística con cuantificar incertidumbre acerca de P a la luz de haber ya observado X.”[Ver referencia 1]\n\n\nIncertidumbre estocástica: duda previa sobre el valor de X, modelada por \\((\\Omega,\\mathcal{F},P)\\).\n\n\nIncertidumbre inductiva: tras observar X, la incertidumbre se desplaza a la ley generadora P.\n\n\n\n2.2.0.1 Ejemplos en Matemática Aplicada e Ingeniería de Sistemas\n\n\nModelado de tiempos de respuesta en redes\n\n\n\\(X\\): tiempo de llegada de paquetes (variable continua).\n\n\n\\(P\\): distribución de retardo desconocida; objetivo: estimar parámetros de una ley de colas M/M/1.\n\n\n\nEstimación de parámetros en ecuaciones diferenciales estocásticas\n\n\n\\(X(t)\\): trayectoria observada de un proceso de Itô.\n\n\n\\(P\\): ley del proceso (por ejemplo, coeficientes de difusión y deriva), inferidos a partir de trayectorias discretas.\n\n\n\nCalibración de sensores en sistemas de control\n\n\n\\(X\\): lecturas del sensor (vector aleatorio).\n\n\n\\(P\\): distribución conjunta desconocida de ruido; se estima para diseñar filtros de Kalman óptimos.\n\n\n\n\nCon esta distinción clara entre dato observado y modelo probabilístico, estamos listos para construir estimadores y desarrollar la inferencia estadística en las secciones siguientes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#variables-y-vectores-aleatorios",
    "href": "index.html#variables-y-vectores-aleatorios",
    "title": "Inferencia Estadística",
    "section": "\n3.1 Variables y vectores aleatorios",
    "text": "3.1 Variables y vectores aleatorios\nConsideramos un experimento aleatorio cuyos resultados pertenecen al espacio muestral Ω. Modelamos este proceso suponiendo que existe una terna \\((\\Omega, \\mathcal{A}, P),\\) donde:\n\n\n\\(\\Omega\\) es el espacio muestra,\n\n\n\\(\\mathcal{P}(\\Omega)\\) es el conjunto de partes de Ω,\n\n\n\\(\\mathcal{A}\\in\\mathcal{P}(\\Omega)\\) es una σ-álgebra,\n\n\n\\(P\\colon \\mathcal{A} \\to [0,1]\\) es una medida de probabilidad que refleja las características aleatorias del experimento realizado.\n\nA esta terna se le llama espacio de probabilidad.\nLos resultados de un experimento aleatorio no son analizados “en bruto”, sino que se les da una representación numérica que facilita su tratamiento. Esto se logra introduciendo variables aleatorias, que asocian cada resultado \\(\\omega\\in \\Omega\\) con un valor numérico o vectorial, y sobre las cuales luego aplicamos técnicas de inferencia estadística.\nEn todo estudio estadístico partimos de un experimento aleatorio cuyo conjunto de resultados posibles se denomina espacio muestral Ω. Para cuantificar dichos resultados definimos las siguientes estructuras:\n\nDefinition 3.1 (Variables Aleatorias) Sea \\((\\Omega,\\mathcal{A},P)\\) un espacio de probabilidad. Una variable aleatoria es una función \\(X\\colon (\\Omega,\\mathcal{A})\\;\\longrightarrow\\; (\\mathbb{R},\\mathcal{B}),\\) tal que para todo \\(B\\in\\mathcal{B}\\) (la \\(\\sigma\\)-álgebra de Borel en ℝ), \\(X^{-1}(B)\\;=\\;\\{\\omega\\in\\Omega : X(\\omega)\\in B\\}\\;\\in\\;\\mathcal{A}.\\)\n\nSi el espacio muestral \\(\\Omega\\) es finito o numerable, diremos que es un espacio discreto y las variables aleatorias asociadas al experimento normalmente estarán definidas como \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{Z}.\\)\nSi \\(\\Omega\\) es no numerable, entonces diremos que es un espacio continuo y \\(X\\colon \\Omega \\;\\longrightarrow\\; \\mathbb{R}.\\)\n\n\nDefinition 3.2 Un vector aleatorio de dimensión \\(n\\) es \\(\\mathbf{X} = (X_1,\\dots,X_n)\\colon(\\Omega,\\mathcal{A})\\longrightarrow(\\mathbb{R}^n,\\mathcal{B}^n),\\) donde cada componente \\(X_i\\) es variable aleatoria y \\(\\mathcal{B}^n\\) la \\(\\sigma\\)-álgebra de Borel en ℝⁿ.\n\n\nEjemplos Lanzamiento de dos monedas\nSea \\(\\Omega =\\{\\,CC,\\;C-,\\;-C,\\;--\\},\\) donde \\(C\\) = “cara” y \\(-\\) = “cruz”. Podemos definir:\\(X_1(\\omega) = \\text{número de caras en }\\omega.\\) \\(X_2(\\omega) = 2 - X_1(\\omega)\\;=\\; \\text{número de cruces}.\\) \\(X_3(\\omega) = \\bigl(X_1(\\omega)\\bigr)^2.\\)\nEntonces \\((X_1,X_2,X_3)\\) es un vector aleatorio de dimensión 3.\nTiempos de servicio en un servidor\nSean \\(T_i\\) los tiempos de servicio (en segundos) de las peticiones \\(i=1,2,3\\). Definimos\\(\\mathbf{T}=(T_1,T_2,T_3),\\quad S = T_1 + T_2 + T_3,\\quad M = \\max\\{T_1,T_2,T_3\\}.\\)\nLecturas de sensores en red distribuida\nEn tres nodos \\(i=1,2,3\\) medimos temperatura \\(X_{i,1}\\), presión \\(X_{i,2}\\) y humedad \\(X_{i,3}\\). El vector global es \\(\\mathbf{X} = (X_{1,1},X_{1,2},X_{1,3},\\,X_{2,1},\\dots,X_{3,3}) \\in \\mathbb{R}^9.\\)\n\nCon estas definiciones rigurosas disponemos ya de los objetos básicos para, en las siguientes secciones, construir estimadores, estudiar su comportamiento asintótico y contrastar hipótesis sobre la distribución subyacente \\(P\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#distribución-de-una-variable-aleatoria.-funciones-de-distribución-de-probabilidad-y-de-densidad",
    "href": "index.html#distribución-de-una-variable-aleatoria.-funciones-de-distribución-de-probabilidad-y-de-densidad",
    "title": "Inferencia Estadística",
    "section": "\n3.2 Distribución de una variable aleatoria. Funciones de distribución, de probabilidad y de densidad",
    "text": "3.2 Distribución de una variable aleatoria. Funciones de distribución, de probabilidad y de densidad\nDistribución de una Variable Aleatoria\nLa realización de un experimento aleatorio da lugar a un resultado \\(\\omega\\in\\Omega\\) que es aleatorio. Por lo tanto, \\(X(\\omega)\\) es un valor de \\(\\mathbb{R}\\) también aleatorio. Es decir, la variable aleatoria \\(X\\) induce una medida de probabilidad en \\(\\mathbb{R}\\). A esa medida de probabilidad se le llama distribución de \\(X\\) o ley de \\(X\\). Una de las formas de caracterizar la distribución de una variable aleatoria es dar su función de distribución \\(F_X\\), que está definida así:\n\\(F_X(x) \\;=\\; P(X \\le x)\\;=\\; P\\bigl(\\{\\omega \\in \\Omega : X(\\omega) \\le x\\}\\bigr)\\;=\\; P\\bigl(X^{-1}((-\\infty, x])\\bigr).\\)$\nEn el caso de que \\(X\\) sea una variable aleatoria discreta, es decir, en el caso de que \\(X\\) solo tome una cantidad finita o numerable de valores de \\(\\mathbb{R}\\), su distribución también puede caracterizarse por su función de probabilidad (o función de masa de probabilidad) \\(f_X\\), definida como\n\\[f_X : \\mathbb{R} \\longrightarrow [0,1],\\qquad f_X(x) = P(X = x).\\]\nEsa función solo es no nula en un conjunto finito o numerable. Supondremos en adelante, sin pérdida de generalidad, que ese conjunto está contenido en \\(\\mathbb{Z}\\). A partir de la función de masa de probabilidad se puede calcular la probabilidad de que la variable aleatoria \\(X\\) tome valores en cualquier elemento \\(A \\subseteq \\mathbb{B}\\):\n\\(P(X \\in A) = \\sum_{x \\in A} f_X(x).\\) me\nLa función de distribución y la función de masa de probabilidad se relacionan de la siguiente forma:\n\\(F_X(x) = \\sum_{u \\leq x} f_X(u), \\quad f_X(x) = F_X(x) - F_X(x^-),\\) donde \\(F_X(x^-) = \\lim_{h \\to 0^+} F_X(x - h)\\).\nUna clase relevante de variables aleatorias no discretas son las que poseen función de densidad, es decir, aquellas cuya distribución de probabilidad puede caracterizarse por una función \\(f_X(x) \\geq 0\\) que cumple que:\n\\(P(X \\in A) = \\int_{x \\in A} f_X(x) \\, dx, \\quad \\text{para todo } A \\subseteq \\mathbb{B}.\\)\nLa relación entre \\(F_X\\) y \\(f_X\\) es la siguiente:\n\\(F_X(x) = \\int_{-\\infty}^{x} f_X(u) \\, du, \\quad f_X(x) = \\frac{d}{dx} F_X(x),\\)\nsalvo quizás en un número finito de puntos \\(x \\in \\mathbb{R}\\). Las variables aleatorias que poseen función de densidad se llaman variables aleatorias absolutamente continuas. Abusando del lenguaje, aquí nos referiremos a ellas como variables aleatorias continuas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#esperanza-y-varianza",
    "href": "index.html#esperanza-y-varianza",
    "title": "Inferencia Estadística",
    "section": "\n3.3 Esperanza y varianza",
    "text": "3.3 Esperanza y varianza\nSi se desea describir totalmente la distribución de probabilidad de una variable aleatoria \\(X\\) acabamos de ver que podemos dar su función de distribución o su función de masa o de densidad, según el caso. Una descripción parcial puede efectuarse calculando algunas características de la variable aleatoria \\(X\\), como por ejemplo medidas de posición o de dispersión. Estudiaremos algunas de ellas.\nSe define la esperanza de una variable aleatoria \\(X\\) como la integral de Lebesgue de \\(X\\):\n\\(E(X) = \\int_{\\Omega} X(w) dP(w).\\)\nEn el caso de variables aleatorias discretas la esperanza puede calcularse como:\n\\(E(X) = \\sum_{w \\in \\Omega} X(w) P(w) = \\sum_{k \\in \\mathbb{Z}} k P(X = k) = \\sum_{k \\in \\mathbb{Z}} k f_X(k).\\)\nPor otro lado, la esperanza de una variable aleatoria continua se puede calcular así:\n\\(E(X) = \\int_{\\mathbb{R}} x f_X(x) dx.\\)\nLa esperanza de una variable aleatoria \\(X\\) es una medida de posición de \\(X\\): es el centro de gravedad de la distribución de probabilidad de \\(X\\).\nSi \\(h\\) es una función medible \\(h : \\mathbb{R} \\rightarrow \\mathbb{R}\\), entonces \\(Y = h(X)\\) es también variable aleatoria y su esperanza se puede calcular a partir de la distribución de \\(X\\):\n\\(E(h(X)) = \\int_{\\Omega} h(X(w)) dP(w)\\) que en el caso de que \\(X\\) sea discreta puede reescribirse como\n\\(E(h(X)) = \\sum_{k \\in \\mathbb{Z}} h(k) f_X(k).\\)\nSi \\(X\\) es una variable aleatoria continua entonces\n\\(E(h(X)) = \\int_{\\mathbb{R}} h(x) f_X(x) dx.\\)\nSi existe \\(\\mu = E(X)\\) y es finita puede definirse una medida de dispersión de la variable aleatoria \\(X\\) a partir de una transformación \\(h\\) de \\(X\\). Es lo que se denomina varianza de \\(X\\) y se define así:\n\\(V(X) = E((X - \\mu)^2) = E(X^2) - \\mu^2 = E(X^2) - (E(X))^2.\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#función-generadora-de-momentos",
    "href": "index.html#función-generadora-de-momentos",
    "title": "Inferencia Estadística",
    "section": "\n3.4 Función generadora de momentos",
    "text": "3.4 Función generadora de momentos\nDada una variable aleatoria \\(X\\), o su función de distribución \\(F\\), vamos a definir otra función generadora, como\n\\(M_X(t) = \\mathbb{E}(e^{tX}),\\) siempre que este valor esperado exista.\nNotemos que cuando \\(X\\) toma valores en los enteros no-negativos, \\(M_X(t) = \\phi_X(e^t)\\), donde \\(\\phi_X(s)=E[s^X]=\\sum_{k=0}^{\\infty}p_ks^k\\) para \\(s\\in[0,1]\\) es la función generadora de probabilidad (f.g.p.) de la variable \\(X\\), con \\(p_k=P(X=k)\\). Si \\(X\\) está acotada, \\(M_X\\) está bien definida para todo \\(t\\) real; en cambio, si \\(X\\) no está acotada, es posible que el dominio de \\(M_X\\) no sea el conjunto de todos los reales. En todo caso, \\(\\phi\\) siempre está definida en cero, y \\(M(0) = 1\\).\nEs posible demostrar que si la f.g.m. de la v.a. \\(X\\) existe en un entorno de 0, entonces para todo \\(k &gt; 0\\),\n\\(\\mathbb{E}[|X|^k] &lt; \\infty.\\)\nMás aún, la serie\n\\(M_X(t) =\n\\mathbb{E}(e^{tX})\n= \\mathbb{E}\\left(1 + \\sum_{k=1}^{\\infty} \\frac{t^k X^k}{k!}\\right)\n= 1 + \\sum_{n=1}^{\\infty} \\frac{t^k}{k!} \\mathbb{E}(X^k)\n\\tag{5.1}\\)\nes convergente y se puede derivar término a término. Obtenemos\n\\(M'_X(0) = \\mathbb{E}(X); \\quad M''_X(0) = \\mathbb{E}(X^2)\\)\ny en general\n\\(M_X^{(k)}(0) = \\mathbb{E}(X^k).\\)\nEs por esta última propiedad que esta función se conoce como función generadora de momentos (f.g.m.).\n🎲 Ejemplo: f.g.m. de la distribución Binomial\nSea \\(X \\sim \\text{Binomial}(n, p)\\), es decir, la suma de \\(n\\) ensayos de Bernoulli con probabilidad de éxito \\(p\\). La función generadora de momentos es: Ejemplo fgm binomial\n\\(M_X(t) = \\mathbb{E}[e^{tX}] = (1 - p + p e^t)^n\\)\n ```` \n📈 Ejemplo: f.g.m. de la distribución Normal Estándar\nSea \\(X \\sim \\mathcal{N}(0, 1)\\). Su función generadora de momentos es:\n\\(M_X(t) = \\mathbb{E}[e^{tX}] = e^{\\frac{t^2}{2}}\\)\nEsta expresión se obtiene usando la forma cerrada del momento de una normal estándar.\n ```` \n❓ Preguntas guía sobre la gráfica de la función generadora de momentos\n📌 ¿Qué representa la gráfica de la f.g.m. \\(M_X(t)\\)?\nLa gráfica muestra cómo evoluciona el valor esperado de \\(e^{tX}\\) cuando \\(t\\) varía. Esta función codifica todos los momentos de la variable aleatoria \\(X\\), y por tanto, contiene información completa sobre su distribución (si existe un entorno donde la f.g.m. es finita).\n\n🧭 ¿Qué se observa en la f.g.m. de una distribución Binomial? \n![Gráfica MGF Binomial]\n#Preguntas y respuestas\n\n\n¿Cómo es el comportamiento de la f.g.m. cerca de \\(t = 0\\)?\nEn \\(t = 0\\), siempre se cumple que \\(M_X(0) = 1\\), ya que:\n\\(M_X(0) = \\mathbb{E}[e^{0 \\cdot X}] = \\mathbb{E}[1] = 1\\)\n\n\n¿Qué indica la curvatura de la gráfica?\nLa curvatura refleja el crecimiento exponencial de los momentos. Si la curva crece rápidamente hacia la derecha, significa que los momentos (media, varianza, etc.) también crecen con rapidez.\n\n\n¿Por qué la gráfica es convexa?\nTodas las funciones generadoras de momentos son estrictamente convexas en el intervalo donde están definidas. Esto es una consecuencia de que derivadas sucesivas representan momentos positivos.\n\n\n¿Qué pasa si cambio los parámetros \\(n\\) y \\(p\\)?\nAumentar $ n $ o \\(p\\) tiende a elevar la f.g.m. en el lado derecho, reflejando una mayor media y varianza.\n\n\n\n📈 ¿Cómo se comporta la f.g.m. para la Normal Estándar? \n![Gráfica MGF Normal]\nPreguntas y respuestas\n\n\n¿Por qué es simétrica respecto al eje $ t = 0 $?\nPorque la normal estándar es simétrica alrededor de su media $ = 0 $, y su f.g.m. tiene la forma:\n\n\n\\(M_X(t) = e^{t^2 / 2}\\)\nlo cual es una función par: \\(M_X(-t)= M_X(t)\\).\n\n\n¿Qué tan rápido crece la función?\nMuy rápido. El crecimiento es exponencial cuadrático. Esto implica que los momentos de la normal crecen rápidamente en magnitud.\n\n\n¿Cómo se relaciona esta gráfica con los momentos de la normal?\nDerivando sucesivamente la f.g.m. en $ t = 0 $, se obtiene:\n\\(\\mathbb{E}[X^k] = M_X^{(k)}(0)\\)\nPor tanto, la gráfica “encierra” toda la información sobre los momentos.\n\n\n\n🧠 Conclusión\nEstas gráficas te permiten visualizar la información estadística codificada en una variable aleatoria. La f.g.m. no es solo una herramienta algebraica para obtener momentos, sino una forma poderosa de describir el comportamiento global de la variable.\n\n¿Qué pasa si dos variables tienen la misma f.g.m.?\n¡Tienen la misma distribución! (si la f.g.m. está definida en un entorno de 0).\n\nEjemplo: Distribución uniforme \\(U(a,b)\\)\nSi \\[X \\sim U(a,b),\\]\nsu densidad es\\[f(x) = \\frac{1}{b - a}\\quad\\text{para }a &lt; x &lt; b,\\]\ny su función generadora de momentos viene dada por\n\n\n\n\\[M(t)= \\int_a^b \\frac{e^{t x}}{b - a}\\,dx= \\frac{e^{b t} - e^{a t}}{t\\,(b - a)}.\\]\n\n\n(5.2)\n\n\nEn el caso particular de la distribución uniforme en \\((0,1)\\) se obtiene\\[M(t) = \\frac{e^t - 1}{t}.\\]\n\nPara derivar la fórmula #(5.2) y obtener los momentos, podemos usar el desarrollo en serie de la función exponencial:\n\\[M(t)= \\frac{1}{t\\,(b - a)}\\bigl(e^{b t} - e^{a t}\\bigr) \\\\\n= \\frac{1}{t\\,(b - a)}\\Bigl[\\bigl(1 + \\sum_{n=1}^\\infty \\tfrac{(b t)^n}{n!}\\bigr)\n                    -\\bigl(1 + \\sum_{n=1}^\\infty \\tfrac{(a t)^n}{n!}\\bigr)\\Bigr] \\\\\n= \\frac{1}{b - a}\\sum_{n=1}^\\infty \\frac{b^n - a^n}{n!}\\,t^{n-1}.\n\\]\nEste es el desarrollo de Maclaurin de \\(M(t)\\) en \\(t=0\\); por tanto, sus derivadas en cero satisfacen\n\n\n\\[M^{(k)}(0)= \\frac{b^{k+1} - a^{k+1}}{(k+1)\\,(b - a)}.\\]\n\n\n(5.3)\n\n\nEn particular:\n\n\\[M'(0)= \\frac{b^2 - a^2}{2\\,(b - a)}= \\frac{a + b}{2},\\] que coincide con \\(\\mathbb{E}(X)\\).\n\\[M''(0)= \\frac{b^3 - a^3}{3\\,(b - a)}= \\frac{a^2 + a b + b^2}{3},\\]\n\ny un cálculo directo muestra que la varianza es\n\\[\\mathrm{Var}(X)= \\mathbb{E}(X^2) - \\bigl(\\mathbb{E}(X)\\bigr)^2= \\frac{(a + b)^2}{12}.\\]\nObservación importante Sea \\(X\\) una v.a. con f.g.m. \\(M_X\\) y sea \\(Y=aX+b\\) una transformación lineal de \\(X\\), entonces\n\\[M_Y(t)=E(e^{tY})=E(e^{t(aX+b)})=E(e^{taX}e^{tb})=e^{tb}E(e^{taX})=e^{tb}M_X(at)\\]\n\nTheorem 3.1 (fgm de suma de v.a.s) Si \\(X\\) tiene función generadora de momentos \\(M(t)\\) que está definida en un entorno \\((-a,a)\\) de 0, entonces \\(M(t)\\) caracteriza a la distribución de \\(X\\); es decir, si otra variable \\(Y\\) tiene la misma función generadora de momentos, las distribuciones de \\(X\\) e \\(Y\\) coinciden.\n\n\nSi \\(X,Y\\) son variables aleatorias con funciones generadoras de momentos respectivas \\(M_X\\) y \\(M_Y\\) que existen en un dominio común \\(|t| &lt; d\\), entonces la f.g.m. de la suma \\(X+Y\\) está dada por     \\[\n\\begin{align}\nM_{X+Y}(t)&= \\mathbb{E}\\bigl[e^{t(X+Y)}\\bigr]\\\\\n&= \\mathbb{E}\\bigl[e^{tX}\\,e^{tY}\\bigr]\\\\\n&=\\mathbb{E}\\bigl[e^{tX}\\bigr]\\mathbb{E}\\bigl[e^{tY}\\bigr]\\\\\n&= M_X(t)\\,M_Y(t).\n\\end{align}\n\\tag{1}\n\\]      \nEste resultado se extiende a la suma de \\(n\\) variables aleatorias independientes. Si\n\\[S_n = X_1 + \\cdots + X_n,\\]\nentonces\n\\[M_{S_n}(t)= \\mathbb{E}\\bigl[e^{tS_n}\\bigr]= \\mathbb{E}\\Bigl[e^{t\\sum_{i=1}^n X_i}\\Bigr]= \\prod_{i=1}^n\\mathbb{E}\\bigl[e^{tX_i}\\bigr]= \\prod_{i=1}^n M_{X_i}(t).\\]\nLa función generadora de momentos resulta particularmente útil cuando consideramos sucesiones de variables aleatorias, como lo muestra el siguiente teorema que enunciamos sin demostración:\n\n\nTheorem 3.2 (de Continuidad) Sea \\(F_n(x)\\), \\(n\\ge1\\), una sucesión de funciones de distribución con funciones generadoras de momentos respectivas \\(M_n(t)\\), definidas en \\(|t|&lt;b\\). Supongamos que cuando \\(n\\to\\infty\\),\n\\[\nM_n(t)\\,\\longrightarrow\\,M(t)\n\\quad\\text{para }|t|\\le a,\n\\]\ndonde \\(M(t)\\) es la función generadora de momentos de la distribución límite \\(F(x)\\). Entonces\n\\[\nF_n(x)\\,\\longrightarrow\\,F(x)\n\\quad\\text{cuando }n\\to\\infty\n\\]\npara todo punto \\(x\\) en el cual \\(F\\) es continua.\n\n\nTheorem 3.3 Laplace–Moivre Sea \\(X_1, X_2, \\ldots, X_n\\) una sucesión de variables aleatorias i.i.d. con distribución ( (p) ), donde ( 0 &lt; p &lt; 1 ). Sea:\n\\[\nS_n = X_1 + X_2 + \\cdots + X_n \\sim \\text{Binomial}(n, p)\n\\]\ny consideremos la variable tipificada:\n\\[\nZ_n = \\frac{S_n - np}{\\sqrt{np(1 - p)}}\n\\]\nEntonces, cuando ( n ), se tiene convergencia en distribución a una normal estándar:\n\\[\nZ_n \\xrightarrow{d} \\mathcal{N}(0, 1)\n\\]\nes decir,\n\\[\n\\lim_{n \\to \\infty} \\mathbb{P}(Z_n \\leq z) = \\Phi(z), \\quad \\text{para todo } z \\in \\mathbb{R}\n\\]\ndonde ( (z) ) es la función de distribución acumulada de la normal estándar.\n\n\nProof. Demostración usando funciones generadoras de momentos\nLa función generadora de momentos (mgf) de \\(S_n \\sim \\text{Binomial}(n, p)\\) es:\n\\[\nM_{S_n}(t) = \\left(1 - p + p e^t\\right)^n\n\\]\nQueremos obtener la mgf de la variable tipificada ( Z_n ). Usamos la propiedad de cambio de variable de la mgf:\n\\[\nM_{Z_n}(t) = \\mathbb{E}\\left[ e^{t Z_n} \\right]\n= \\mathbb{E}\\left[ e^{t \\cdot \\frac{S_n - np}{\\sqrt{np(1 - p)}}} \\right]\n= e^{-t \\cdot \\frac{np}{\\sqrt{np(1 - p)}}} \\cdot M_{S_n}\\left( \\frac{t}{\\sqrt{np(1 - p)}} \\right)\n\\]\nSustituimos la mgf de ( S_n ):\n\\[\nM_{Z_n}(t) = \\exp\\left( -t \\cdot \\frac{np}{\\sqrt{np(1 - p)}} \\right)\n\\cdot \\left( 1 - p + p e^{t / \\sqrt{np(1 - p)}} \\right)^n\n\\]\nAproximación por series de Taylor\nExpandimos \\(e^{t / \\sqrt{np(1 - p)}}\\) para \\(n\\) grande:\n\\[\ne^{t / \\sqrt{np(1 - p)}} = 1 + \\frac{t}{\\sqrt{np(1 - p)}} + \\frac{t^2}{2np(1 - p)} + \\cdots\n\\]\nEntonces:\n\\[\n1 - p + p e^{t / \\sqrt{np(1 - p)}} \\approx 1 + \\frac{pt}{\\sqrt{np(1 - p)}} + \\frac{pt^2}{2np(1 - p)} + \\cdots\n\\]\nUsamos que \\(\\log(1 + x) \\approx x - \\frac{x^2}{2} + \\cdots\\) para \\(x \\approx 0\\):\n\\[\\log M_{Z_n}(t) \\approx -t \\cdot \\frac{np}{\\sqrt{np(1 - p)}}+ n \\left( \\frac{pt}{\\sqrt{np(1 - p)}} + \\frac{pt^2}{2np(1 - p)} \\right)\\]\nSimplificamos:\n\nEl término lineal se cancela:\n\n\\[\n-t \\cdot \\frac{np}{\\sqrt{np(1 - p)}} + n \\cdot \\frac{pt}{\\sqrt{np(1 - p)}} = 0\n\\]\n\nQueda:\n\n\\[\n\\log M_{Z_n}(t) \\to \\frac{t^2}{2}, \\quad \\text{cuando } n \\to \\infty\n\\]\nPor tanto:\n\\[\nM_{Z_n}(t) \\to e^{t^2 / 2}\n\\] Conclusión\nComo \\(e^{t^2/2}\\) es la mgf de \\(\\mathcal{N}(0, 1)\\), y por el teorema de unicidad de la función generadora de momentos:\n\\[\nZ_n \\xrightarrow{d} \\mathcal{N}(0, 1)\n\\]\nEsto concluye la demostración del Teorema de Laplace–Moivre utilizando funciones generadoras de momentos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#muestra-aleatoria-simple",
    "href": "index.html#muestra-aleatoria-simple",
    "title": "Inferencia Estadística",
    "section": "\n3.5 Muestra aleatoria simple",
    "text": "3.5 Muestra aleatoria simple\nSea \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) un vector aleatorio. Se dice que sus componentes \\(X_1 ,..., X_n\\) son si \\(P(X_1\\leq x_1 ,..., X_n\\leq x_n)=P(X_1\\leq x_1)...P(X_n\\leq x_n)\\) para cualesquiera valores \\(x_1,..., x_n\\) .\nSi además la distribución de las \\(n\\) variables aleatorias \\(X_i\\) es la misma, se dice que \\(X_1 ,...,X_n\\) son variables aleatorias independientes e idénticamente distribuidas, o bien que son v.a.i.i.d o simplemente i.i.d.\nSi \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) y \\(X_1 ,..., X_n\\) son i.i.d. con función de densidad (en su caso, de masa) \\(f_X\\) , la distribución conjunta de \\(\\underset{\\sim}{X}\\) viene dada por la función de densidad (en su caso, de masa) conjunta \\[\n\\begin{align*}\nf_{\\underset{\\sim}{X}}(\\underset{\\sim}{x})&=f_{(X_1 ,..., X_n)}(x_1 ,..., x_n)\\\\\n&=f_{(X_1)}(x_1)...f_{(X_n)}(x_n)\\\\\n&=\\prod_{i=1}^{n}f_{(X_i)}(x_i)\n\\end{align*}\n\\]\nA un vector \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) de v.a.i.i.d. con distribución igual a la de la variable aleatoria \\(X\\) se le denomina también muestra aleatoria simple de \\(X\\) (m.a.s de \\(X\\)).\nEsto responde al hecho siguiente. Supongamos que se desea estudiar la característica \\(X\\) de los individuos de una población de tamaño infinito. Definimos el experimento consistente en elegir aleatoriamente un individuo de la población y llamamos \\(X\\) al valor de la característica de interés en ese individuo. X es una variable aleatoria.\nSi definimos un nuevo experimento consistente en elegir una muestra aleatoria de n individuos y se anota \\(X_i\\), el valor de la característica en el individuo i-ésimo, entonces X \\(=(X_1 ,..., X_n)\\) es una colección de n v.a.i.i.d. con distribución igual a la de la variable aleatoria \\(X\\), es decir, \\(X_1 ,..., X_n\\) es una m.a.s. de X.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#modelo-paramétrico",
    "href": "index.html#modelo-paramétrico",
    "title": "Inferencia Estadística",
    "section": "\n3.6 Modelo paramétrico",
    "text": "3.6 Modelo paramétrico\nUsualmente la ley de probabilidad de una variable aleatoria se supone perteneciente a un modelo matemático que depende sólo de un número finito de parámetros: \\(f_X \\in\\{f(x|\\theta):\\theta \\in \\Theta \\subseteq \\mathbb{R}^k\\}\\). Escribiremos alternativamente \\(f(x;\\theta)\\), \\(f(x|\\theta)\\) o \\(f_\\theta(x)\\).\n\nDefinition 3.3 El conjunto de distribuciones dadas por \\(f_\\theta(x)\\), \\(\\theta \\in \\Theta\\) se llama familia paramétrica de distribuciones. \\(\\Theta\\) es el conjunto de parámetros.\n\n\nDefinition 3.4 La correspondiente distribución conjunta de una muestra aleatoria simple de \\(X\\) viene dada por la función de densidad (o función de masa de probabilidad, según el caso)\n\\[\nf_{\\underset{\\sim}{X}}(\\underset{\\sim}{x} \\mid \\theta) = \\prod_{i=1}^{n} f_{\\theta}(x_i)\n\\]\nA esta función la llamaremos función de verosimilitud de la muestra \\(X_{\\sim}\\). Utilizaremos este término para referirnos indistintamente a la función de densidad conjunta (si las variables aleatorias son continuas) o a la función de masa conjunta (si son discretas).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#sumas-de-variables-aleatorias",
    "href": "index.html#sumas-de-variables-aleatorias",
    "title": "Inferencia Estadística",
    "section": "\n3.7 Sumas de variables aleatorias",
    "text": "3.7 Sumas de variables aleatorias\nCuando se obtiene una muestra aleatoria simple \\(X_{1},X_{2},\\ldots,X_{n}\\) normalmente se calculan a partir de ellas cantidades que resumen los valores observados. Cualquiera de estos resúmenes se puede expresar como una función \\(T(x_1,\\ldots,x_n)\\) definida en el espacio \\(\\mathcal{X}^n\\subseteq\\mathbb{R}^n\\) donde están las imágenes del vector \\((X_{1},X_{2},\\ldots,X_{n})\\).\nEsta función \\(T\\) puede devolver valores de \\(\\mathbb{R}\\), \\(\\mathbb{R}^2\\) o, en general, \\(\\mathbb{R}^k\\).\n\\[T(X_1 , \\ldots, X_n)=\\sum_{i=1}^{n}X_i,\\bar{X},\\bar{X}+3, \\min{X_1 , \\ldots, X_n},\\] \\[T(X_1 , \\ldots, X_n)=\\left(\\sum_{i=1}^{n}X_i,\\sum_{i=1}^{n}(X_i-\\bar{X})^2\\right),\\] \\[T(X_1 , \\ldots, X_n)=\\left(\\min\\{X_1 , \\ldots, X_n\\},\\sum_{i=1}^{n}X_i,\\sum_{i=1}^{n}(X_i-\\bar{X})^2\\right),\\] \\[T(X_1 , \\ldots, X_n)= (X_1 , \\ldots, X_n)\\]\n\nDefinition 3.5 (Definición de estadísticos) Las funciones \\(T\\) que dependen de una muestra aleatoria simple \\(X_1 , \\ldots, X_n\\) se llaman estadísticos. Dependen de los valores observados, pero no de los parámetros desconocidos que determinan la distribución de \\(X_i\\) .\n\nCuando un estadístico \\(T\\) es utilizado con el propósito de estimar un parámetro \\(\\theta\\) diremos que \\(T\\) es un estimador de \\(\\theta\\).\nEjemplo de estadístico\n\\(T(X_1 , \\ldots, X_n)=\\bar{X}\\) es un estimador de \\(E(X)=\\mu\\).\nEn inferencia estadística interesa saber qué estadísticos son suficientes para recoger toda la información que la muestra aporta sobre la distribución de la variable aleatoria X muestreada. La respuesta depende de la distribución de X.\n\nDefinition 3.6 (Definición distribución en el muestreo) Dado que \\(\\underset{\\sim}{X} =(X_1 ,..., X_n)\\) es una variable aleatoria, se tiene que \\(Y=T(\\underset{\\sim}{X})=T(X_1 ,..., X_n)\\) será también una variable aleatoria. La ley de probabilidad de \\(Y\\) se denomina distribución en el muestreo de \\(Y\\) (o distribución muestral). Los siguientes resultados dan información sobre algunas características de estadísticos definidos a partir de sumas de variables aleatorias.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#estadísticos-definidos-a-partir-de-sumas-de-variables-aleatorias",
    "href": "index.html#estadísticos-definidos-a-partir-de-sumas-de-variables-aleatorias",
    "title": "Inferencia Estadística",
    "section": "\n3.8 Estadísticos definidos a partir de sumas de variables aleatorias",
    "text": "3.8 Estadísticos definidos a partir de sumas de variables aleatorias\n\nTheorem 3.4 Sean \\(X_1,\\ldots, X_n\\),n números reales, sea \\(\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n}x_i\\) su media aritmética y sea \\(S_n^2=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n-1}\\) su varianza muestral.\n\n\\(\\min_a\\sum_{i=1}^{n}(x_i-a)^2=\\sum_{i=1}^{n}(x_i-\\bar{x})^2\\)\n\\((n-1)S_n^2=\\sum_{i=1}^{n}(x_i-\\bar{x})^2=\\sum_{i=1}^{n}x_i^2-n\\bar{x}^2\\)\n\n\n\nLemma 3.1 Sea \\(X_1,\\ldots, X_n\\) una muestra aleatoria simple de \\(X\\) y sea \\(g(x)\\) una función tal que \\(E(g(X))\\) y \\(Var(g(X))\\) existen. Entonces,\n\n\n\\(E(\\sum_{i=1}^{n}g(X_i))=nE(g(X))\\),\n\n\\(Var(\\sum_{i=1}^{n}g(X_i))=nVar(g(X))\\).\n\n\n\nProof. Para la demostración ver Gómez et al. (2006)\n\n\nTheorem 3.5 Sea \\(X 1,\\ldots, X_n\\) una muestra aleatoria simple de una población \\(X\\) con esperanza \\(\\mu\\) y varianza \\(\\sigma^2 &lt; \\infty\\). Sean \\[\n        \\begin{align*}\n        &\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_i,\\ \\\n        S^2=\\frac{\\sum_{i=1}^{n}(X_i-\\bar{X})^2}{n-1},\n        \\end{align*}    \n\\] la media y la varianza muestrales, respectivamente. Entonces,\n\n\\(E(\\bar{X}) = \\mu,\\)\n\\(Var(\\bar{X}) = \\frac{\\sigma^2}{n},\\)\n\n\\(E(S^2) = \\sigma^2\\).\n\n\n\nTheorem 3.6 Sea \\(X 1,\\ldots, X_n\\) una muestra aleatoria simple de una población \\(X\\) con función generadora de momentos \\(M_X(t)\\). La función generatriz de momentos de \\(X\\) es \\[\\begin{align*}\n        &M_{\\bar{X}}(t)=\\left(M_X\\left(\\frac{t}{n}\\right)\\right)^n\n        \\end{align*}\n\\]\n\n\nTheorem 3.7 (Combinación lineal de normales es normal) (Wackerly et al. (2008)) Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) variables aleatorias independientes normalmente distribuidas \\(E(Y_i)=\\mu_i\\) y \\(V(Y_i)=\\sigma_i^2\\)ara \\(i=1,\\cdots,\\,n\\) y sean \\(a_1,\\,a_2,\\cdots,\\,a_n\\) constantes. Si \\[U=\\sum_{i=1}^na_iY_i\\]\nentonces \\(U\\) es una variable aleatoria normalmente distribuida con \\[E(U)=\\sum_{i=1}^na_i\\mu_i\\] y \\[V(U)=\\sum_{i=1}^na_i^2\\sigma^2_i\\]\n\nEjemplo \\(X 1,\\ldots, X_n\\) m.a.s. de \\(X \\sim N(\\mu,\\sigma^2)\\). Entonces, \\(M_{X}(t)=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2}\\right\\}\\). De ahí que\n\\[\n    \\begin{align*}\n    M_{\\bar{X}}(t)\n    &=\\left(\\exp\\left\\{\\mu \\frac{t}{n}+ \\frac{\\sigma^2\\left(\\frac{t}{n}\\right)^2}{2}\\right\\}\\right)^n\n    \\end{align*}\n\\]\n\\(X 1,\\ldots, X_n\\) m.a.s. de \\(X \\sim N(\\mu,\\sigma^2)\\). Entonces, \\(M_{X}(t)=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2}\\right\\}\\). De ahí que \\[\n        \\begin{align*}\n        M_{\\bar{X}}(t)&=\\exp\\left\\{\\mu t+ \\frac{\\sigma^2t^2}{2n}\\right\\}\n        \\end{align*}\n\\] De ahí que \\(\\bar{X}\\sim N(\\mu,\\frac{\\sigma^2}{n})\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#muestreo-de-una-distribución-normal",
    "href": "index.html#muestreo-de-una-distribución-normal",
    "title": "Inferencia Estadística",
    "section": "\n3.9 Muestreo de una distribución normal",
    "text": "3.9 Muestreo de una distribución normal\n\n3.9.1 Definición de distribución Chi cuadrada\n\nDefinition 3.7 (Wackerly et al. (2008)) Sea \\(\\nu\\) un entero positivo. Se dice que una v.a \\(Y\\) tiene distribuci'on chi cuadrada con \\(\\nu\\) grados de libertad si y sólo si \\(Y\\) es una vriable aleatoria con distribución gamma y parámetros \\(\\alpha=\\nu/2\\) y \\(\\beta=2\\).\n\n\nTheorem 3.8 (Teorema de Fisher) En el resto del tema supondremos que \\(X 1,\\ldots, X_n\\) m.a.s. de una \\(N(\\mu, \\sigma^2)\\).\n\n\n\\(\\bar{X}\\) y \\(S_n^2\\) son variables aleatorias independientes.\n\\(\\bar{X}\\sim N(\\mu, \\frac{\\sigma^2}{n})\\)\n\\(\\frac{(n-1)S_n^2}{\\sigma^2}\\sim \\mathcal{X}^2_{n-1}.\\)\n\n\n\n3.9.2 Distribuciones asociadas a la normal\n\nTheorem 3.9 (Wackerly et al. (2008)) Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) definidas como en el Teorema Theorem 3.7 de Wackerly et al. (2008) y definimos \\(Z_i\\) por \\[Z_i=\\frac{Y_i-\\mu_i}{\\sigma_i}\\] con \\(i=1,\\,2,\\cdots,\\,n\\). Entonces \\(\\sum_{i=1}^nZ_i^2\\) tiene distribuici'on \\(\\chi^2\\) con \\(n\\) grados de libertad.\n\n\nTheorem 3.10 (Wackerly et al. (2008)) Si \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) es una muestra aleatoria de una distribuci'on normal con media \\(\\mu\\) y varianza \\(\\sigma^2\\), \\(Y_i\\), \\(i=1,\\,2,\\cdots,n\\) son v.a’s independientes distribu'idas normalmente, con \\(E(Y_i)=\\mu\\) y \\(V(Y_i)=\\sigma^2\\).\nEntonces \\[Z_i=\\frac{Y_i-\\mu}{\\sigma}\\] son v.a’s independientes, \\(i=1,\\,2,\\cdots,n\\) y \\[\\sum_{i=1}^nZ_i^2=\\sum_{i=1}^n\\left(\\frac{Y_i-\\mu}{\\sigma}\\right)^2\\]tienen una distribuci'on \\(\\chi^2\\) con \\(n\\) grados de libertad (gl).\n\n\nTheorem 3.11 (Wackerly et al. (2008)) Sea \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) una muestra aleatoria con media \\(\\mu\\) y varianza \\(\\sigma^2\\). Entonces \\[\\frac{(n-1)S^2}{\\sigma^2}=\\frac{1}{\\sigma^2}\\sum_{i=1}^n(Y_i-\\overline{Y})^2\\] tiene una distribuci'on \\(\\chi^2\\) con \\((n-1)\\) gl. \\(\\overline{Y}\\) y \\(S^2\\) son v.a independientes.\n\n\nDefinition 3.8 (Wackerly et al. (2008)) Sea \\(Z\\) una v.a normal est'andar y sea \\(W\\) una v.a con distribuci'on \\(\\chi^2_\\nu\\). Entonces, si \\(W\\) y \\(Z\\) son ind \\[T=\\frac{Z}{\\sqrt{W/\\nu}}\\] se dice que tiene una distribuci'on \\(t\\) con \\(\\nu\\) grados de libertad.\n\n\n\n\n\n\n\nObservación 1\n\n\n\nSi \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\sim N(\\mu,\\sigma^2)\\) del Teorema (Combinación lineal de normales es normal) \\[Z=\\frac{\\sqrt{n}(\\overline{Y}-\\mu)}{\\sigma}\\sim N(0,1)\\] El teorema Observación 1 nos dice que \\[W=\\frac{(n-1)S^2}{\\sigma^2}\\sim\\chi^2_{n-1}\\] y que \\(Z\\) y \\(W\\) son ind.\n\n\n\n\n\n\n\n\nObservación 2\n\n\n\nPor tanto, de la definición 7.2 se tiene la siguiente expresión: \\[\n\\begin{aligned}\nT &= \\frac{Z}{\\sqrt{W/\\nu}} \\\\\n  &= \\frac{\\sqrt{n}(\\overline{Y}-\\mu)/\\sigma}{\\sqrt{\\left[\\frac{(n-1)S^2}{\\sigma^2}\\right]/(n-1)}} \\\\\n  &= \\sqrt{n}\\left(\\frac{\\overline{Y}-\\mu}{S}\\right)\n\\end{aligned}\n\\]\nTiene distribución \\(t\\) con \\((n-1)\\) grados de libertad.\n\n\nComo se indica en la Observación 7.1, esta propiedad…\n\nDefinition 3.9 Sean \\(W_1\\) y \\(W_2\\) v.a’s independientes con distribución \\(\\chi^2\\), con \\(\\nu_1\\) y \\(\\nu_2\\) grados de libertad respectivamente. Entonces se dice que: \\[F=\\frac{W_1/\\nu_1}{W_2/\\nu_2}\\] tiene una distribuc'on \\(F\\) con \\(\\nu_1\\) grados de libertad en el numerador y \\(\\nu_2\\) grados de libertad en el denominador.\n\n\nRemark 3.1. Considerando dos muestras aleatorias independientes tomadas de distribuiciones normales \\[W_1=\\frac{(n_1-1)S_1^2}{\\sigma_1^2}\\sim\\chi^2_{n_1-1}\\] \\[W_1=\\frac{(n_2-1)S_2^2}{\\sigma_2^2}\\sim\\chi^2_{n_2-1}\\] \\(W_1\\bot W_2\\).\n\n\nRemark 3.2. \\[\n\\begin{eqnarray*}\n            F&=&\\frac{W_1/\\nu_1}{W_2/\\nu_2}\\\\\n            &=&\\frac{[(n_1-1)S_1^2/\\sigma_1^2]/(n_1-1)}{[(n_2-1)S_2^2/\\sigma_2^2]/(n_2-1)}\\\\\n            &=&\\frac{S_1^2/\\sigma_1^2}{S_2^2/\\sigma_2^2}\n        \\end{eqnarray*}\n\\] tiene distribuci'on \\(F\\) con \\((n_1-1)\\) gl en el numerador y \\((n_2-1)\\) gl en el denominador\n\n\nlibrary(ggplot2)\n\nfigura_densidad_asimetrica &lt;- function(alpha = 0.05) {\n  shape &lt;- 2\n  rate &lt;- 1\n  \n  # Cuantil de interés\n  F_alpha &lt;- qgamma(1 - alpha, shape = shape, rate = rate)\n  \n  # Datos para la densidad\n  x_vals &lt;- seq(0, 10, length.out = 1000)\n  df &lt;- data.frame(\n    x = x_vals,\n    y = dgamma(x_vals, shape = shape, rate = rate)\n  )\n  \n  # Datos para el sombreado\n  df_shaded &lt;- subset(df, x &gt;= F_alpha)\n  \n  # Altura de la flecha\n  y_arrow &lt;- dgamma(F_alpha, shape, rate)\n  \n  ggplot(df, aes(x, y)) +\n    geom_line(linewidth = 1.2) +\n    geom_area(data = df_shaded, aes(x, y), fill = \"black\", alpha = 0.3) +\n    \n    # Flecha vertical\n    annotate(\"segment\", x = F_alpha, xend = F_alpha, y = 0, yend = y_arrow,\n             arrow = arrow(length = unit(0.15, \"cm\")), color = \"black\") +\n    \n    # Etiqueta F_α\n    annotate(\"text\", x = F_alpha, y = 0, label = expression(F[alpha]),\n             vjust = 1.5, hjust = 1.1, size = 5) +\n    \n    # Etiqueta α\n    annotate(\"text\", x = F_alpha, y = y_arrow, label = expression(alpha),\n             vjust = -1, size = 5) +\n    \n    labs(x = \"u\", y = expression(f(u))) +\n    theme_minimal(base_size = 14)\n}\nfigura_densidad_asimetrica()\n\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\nWarning in is.na(x): is.na() aplicado a un objeto que no es (lista o vector) de\ntipo 'expression\n\n\n\n\n\n\n\n\nEjercicios con la distribución F en R\nA continuación se presentan dos ejercicios típicos en los que anteriormente se utilizaban tablas de valores críticos de la distribución F. Ahora, gracias a funciones como qf() y var.test() en R, estos análisis pueden hacerse de manera precisa y automática.\n\nEjercicio 1: Contrastar dos varianzas\nEnunciado:\nSe tienen dos muestras independientes con: - Tamaños: \\(n_1 = 6\\), \\(n_2 = 10\\) - Varianzas muestrales: \\(s_1^2 = 25\\), \\(s_2^2 = 10\\)\n¿Existe evidencia para afirmar que las varianzas poblacionales son diferentes al nivel de significancia del 5%?\nSolución en R:\n\n# Datos\ns1_sq &lt;- 25\ns2_sq &lt;- 10\nn1 &lt;- 6\nn2 &lt;- 10\n\n# Estadístico F observado (mayor varianza sobre menor)\nF_obs &lt;- s1_sq / s2_sq\ngl1 &lt;- n1 - 1\ngl2 &lt;- n2 - 1\n\n# Cuantiles críticos para prueba bilateral al 5%\nalpha &lt;- 0.05\nF_inf &lt;- qf(alpha / 2, df1 = gl1, df2 = gl2)\nF_sup &lt;- qf(1 - alpha / 2, df1 = gl1, df2 = gl2)\n\n# Decisión\ncat(\"F observado:\", round(F_obs, 3), \"\\n\")\n\nF observado: 2.5 \n\ncat(\"Intervalo de aceptación: [\", round(F_inf, 3), \",\", round(F_sup, 3), \"]\\n\")\n\nIntervalo de aceptación: [ 0.15 , 4.484 ]\n\nif (F_obs &lt; F_inf || F_obs &gt; F_sup) {\n  cat(\"Se rechaza H0: las varianzas son significativamente diferentes.\\n\")\n} else {\n  cat(\"No se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.\\n\")\n}\n\nNo se rechaza H0: no hay evidencia suficiente para afirmar diferencia de varianzas.\n\n\nEjercicio 2: Obtener un valor crítico F directamente\nEnunciado:\nCalcular el valor crítico \\(F_{0.05,\\,5,\\,9}\\) para una prueba unilateral con nivel de significancia del 5%.\nEste valor se usa, por ejemplo, cuando se contrasta si una varianza es significativamente mayor que otra, con: - \\(\\alpha = 0.05\\) - \\(\\text{gl}_1 = 5\\) (grados de libertad del numerador) - \\(\\text{gl}_2 = 9\\) (grados de libertad del denominador)\nCálculo en R:\n\n# Valor crítico F para prueba unilateral con alpha = 0.05\nqf(0.95, df1 = 5, df2 = 9)\n\n[1] 3.481659\n\n\nEl valor crítico es \\(F_{0.05,\\,5,\\,9}=3.478\\). Si el estadístico F observado es mayor que este valor, se rechaza la hipótesis nula de igualdad de varianzas a favor de que la varianza del numerador es mayor.\n\nExample 3.1 \\[Y_1^1,\\,Y_2^1\\,\\cdots,\\,Y_{n_1}^1\\sim N(\\mu_1,\\,\\sigma^2)\\] \\[Y_1^2,\\,Y_2^2\\,\\cdots,\\,Y_{n_2}^2\\sim N(\\mu_2,\\,\\sigma^2)\\] \\(P\\left(\\frac{S_1^2}{S_2^2}\\leq b\\right)=0.95\\) con \\(n_1=6\\) y \\(n_2=10\\), ?`\\(b\\)?\nComo \\(n_1=6\\) y \\(n_2=10\\) y las varianzas poblacionales son iguales, entonces \\(\\frac{S_1^2/\\sigma_1^2}{S_2^2/\\sigma_2^2}=\\frac{S_1^2}{S_2^2}\\sim F_{5,9}\\) \\[P\\left(\\frac{S_1^2}{S_2^2}\\leq b\\right)= F_{5,9}(b)=0.95\\] entonces \\(qf(0.95,\\,5,\\,9)=b\\), \\(b=3.48\\).\n\nSimulación del comportamiento del promedio muestral\nSimulamos 1000 repeticiones del promedio muestral a partir de una distribución exponencial con media ( = 10 ), para distintos tamaños de muestra ( n ).\n\nsimular_promedios &lt;- function(n, repeticiones = 1000, media = 10) {\n  promedios &lt;- replicate(repeticiones, mean(rexp(n, rate = 1 / media)))\n  data.frame(\n    `n` = n,\n    `Promedio repetido` = mean(promedios),\n    `Media teórica` = media,\n    `Varianza repetida` = var(promedios),\n    `Varianza teórica` = media^2 / n\n  )\n}\n\n# Evaluar para varios tamaños\ntamaños &lt;- c(5, 10, 25, 50, 100)\nresultados &lt;- do.call(rbind, lapply(tamaños, simular_promedios))\nknitr::kable(resultados, digits = 5)\n\n\n\n\n\n\n\n\n\n\nn\nPromedio.repetido\nMedia.teórica\nVarianza.repetida\nVarianza.teórica\n\n\n\n5\n10.05745\n10\n20.54672\n20\n\n\n10\n10.03966\n10\n9.68542\n10\n\n\n25\n9.96320\n10\n3.94066\n4\n\n\n50\n10.04156\n10\n2.12393\n2\n\n\n100\n9.98516\n10\n0.98940\n1\n\n\n\n\n\n\nTheorem 3.12 Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) v.a’s con funciones generadoras de momentos \\(m(t)\\) y \\(m_1(t),\\,m_2(t),\\cdots,\\) respectivamente. Si \\[\\lim_{n\\rightarrow\\infty}m_n(t)=m(t)\\mbox{ para toda $t$ real,}\\] entonces la funci'on de distribuci'on de \\(Y_n\\) converge hacia la funci'on de distribuci'on de \\(Y\\) cuando \\(n\\rightarrow\\infty\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#leyes-de-los-grandes-números-y-teorema-central-del-límite",
    "href": "index.html#leyes-de-los-grandes-números-y-teorema-central-del-límite",
    "title": "Inferencia Estadística",
    "section": "\n3.10 Leyes de los Grandes Números y Teorema Central del Límite",
    "text": "3.10 Leyes de los Grandes Números y Teorema Central del Límite\n\n3.10.1 Leyes de los grandes números\n\nDefinition 3.10 Una sucesión de variables aleatorias converge en media a \\(X\\), y se denota por \\(X_{n}\\xrightarrow{cm}X\\) , si para cualquier \\(\\epsilon&gt;0\\) se tiene que:\n[{n}E(|X{n}-X|)=0,] siempre que dicha esperanza exista.\\\nDe forma análoga se define convergencia en media de orden r si: \\[\\lim _{n\\to \\infty }E(\\left|X_{n}-X\\right|^r)=0,\\]\nCuando \\(r=2\\) se dice que se tiene convergencia en media cuadrática\n\\[\\lim _{n\\to \\infty }E(\\left|X_{n}-X\\right|^2)=0,\\]\n\n\n3.10.2 Relaciones entre tipos de convergencias",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#diagrama-de-convergencias",
    "href": "index.html#diagrama-de-convergencias",
    "title": "Inferencia Estadística",
    "section": "\n3.11 Diagrama de convergencias",
    "text": "3.11 Diagrama de convergencias\n\n3.11.1 Diagrama de relaciones entre tipos de convergencia\n\nDiagrama de convergencias\n\n\n\n3.11.2 Ley débil de los grandes números\n\nTheorem 3.13 Sea \\(X 1,\\ldots, X_n\\) una sucesión de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante \\(C\\), independiente de \\(n\\). Sea \\(S_n = \\sum_{i=1  }^{n}X_i\\). Entonces \\[\n\\begin{align}\nE\\left(\\left|\\frac{S_n-E(S_n)}{n}\\right|^2\\right)\\leq \\frac{C}{n}\n\\end{align}\n\\] y, como consecuencia \\[\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}=0\\] en el sentido de la convergencia en media cuadrática.\n\nLos resultados que garantizan la convergencia casi segura de la media muestral se conocen como leyes fuertes de los grandes números. Se enuncia a continuación una ley fuerte para variables con segundos momentos finitos e incorreladas.\n\n3.11.3 Ley fuerte de los grandes números\n\nTheorem 3.14 Sea \\(X 1,\\ldots, X_n\\) una sucesión de variables aleatorias incorreladas con momentos de segundo orden acotados por una constante \\(C\\), independiente de \\(n\\). Sea \\(S_n = \\sum_{i=1  }^{n}X_i\\). Entonces \\[\n        \\begin{align}\n        E\\left(\\left|\\frac{S_n-E(S_n)}{n}\\right|^2\\right)\\leq \\frac{C}{n}\n        \\end{align}\n        \\] y, como consecuencia \\[\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}=0\\] en el sentido de la casi segura.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#teorema-central-del-límite",
    "href": "index.html#teorema-central-del-límite",
    "title": "Inferencia Estadística",
    "section": "\n3.12 Teorema central del límite",
    "text": "3.12 Teorema central del límite\n\nTheorem 3.15 Central de Límite Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) v.a’s iid ( no se precisa de que distribuci'on se generan) con \\(E[Y_i]=\\mu\\) y \\(V[Y_i]=\\sigma^2&lt;\\infty\\). Definamos \\[U_n=\\frac{\\sum_{i=1}^nY_i-n\\mu}{\\sigma\\sqrt{n}}=\\frac{\\overline{Y}-\\mu}{\\sigma/\\sqrt{n}}\\mbox{ donde} \\overline{Y}=\\frac{1}{n}\\sum_{i=1}^nY_i\\] Entonces la función de distribución de \\(U_n\\) converge hacia la función de distribución normal estándar cuando n tiende a infinito . Esto es, \\[\\lim_{n\\rightarrow\\infty}P(U_n\\leq u)=\\int_{-\\infty}^u\\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2}dt, \\forall u\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "index.html#referencias",
    "href": "index.html#referencias",
    "title": "Inferencia Estadística",
    "section": "\n3.13 Referencias",
    "text": "3.13 Referencias\n\nGómez, Guadalupe, & Delicado, Pedro (2006). Curso de Inferencia y Decisión. Departament d’Estadística i Investigació Operativa, Universitat Politècnica de Catalunya.\nWackerly, D. D., Mendenhall, W., & Scheaffer, R. L. (2008). Estadística matemática con aplicaciones (7ª ed.). Cengage Learning.\nRoussas, G. G. (1997). A Course in Mathematical Statistics (2nd ed.). Academic Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>INTRODUCCIÓN</span>"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "2  Principios para reducir los datos",
    "section": "",
    "text": "2.1 Principio de suficiencia",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#principio-de-suficiencia",
    "href": "chapter1.html#principio-de-suficiencia",
    "title": "2  Principios para reducir los datos",
    "section": "",
    "text": "2.1.1 Estadísticos suficientes minimales\n¿Este proceso de resumir los datos a los dos estadísticos \\(\\overline{Y}\\) y \\(S^2\\) conserva la información de \\(\\mu\\) y \\(\\sigma^2\\) en el conjunto original de \\(n\\) observaciones muestrales? O bien ¿Se ha perdido u ocultado alguna información acerca de estos parámetros en el proceso de reducir los datos?\nPresentamos métodos para hallar estadísticos que en cierto sentido resumen toda la información de una muestra acerca de un parámetro objetivo. Se dice que estos estadísticos tienen la propiedad de suficiencia o son estadísticos suficientes.\n\nExample 2.1 Sean \\(n\\) experimentos binomiales, \\(X_1,\\,X_2,\\cdots,\\,X_n\\), donde \\[\n\\begin{eqnarray*}\n        X_i&=&\\left\\{\\begin{array}{ll}1,&\\mbox{si el $i$-\\'esimo intento es un \\'exito,}\\\\0,&\\mbox{si el $i$-\\'esimo intento es un fracaso.}\\end{array}\\right.\\\\\n        X_i&=&\\left\\{\\begin{array}{ll}1,&\\mbox{con probabilidad $p$,}\\\\0,&\\mbox{con probabilidad $q=1-p$.}\\end{array}\\right.\n    \\end{eqnarray*}\n\\] Sea \\(Y=\\sum_{i=1}^n X_i\\) el número de éxitos en los \\(n\\) intentos. Si conocemos el valor de \\(Y\\), ¿Podemos obtener alguna información adicional acerca de \\(p\\) al ver otras funciones de \\(X_1,\\,X_2,\\cdots,\\,X_n\\)?\n\\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n|Y=y)\\\\\n&=\\frac{P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)}{P(Y=y)}\n\\end{align*}\n\\] El numerador es \\(0\\) si \\(\\sum_{i=1}^nx_i\\neq y\\) dado que no pueden suceder los eventos al mismo tiempo.\nSi \\(\\sum_{i=1}^nx_i= y\\) entonces \\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)\\\\\n&=P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n)\n\\end{align*}\n\\] Por tanto el numerador queda \\(p^y(1-p)^{n-y}\\), dado que hay \\(y\\) unos y \\(n-y\\) ceros.\nEl denominador \\[P(Y=y)=\\displaystyle{a\\choose b} p^y(1-p)^{n-y}\\] porque \\(Y\\sim Bin(n,p)\\). \\[\n\\begin{align*}\n&P(X_1=x_1,\\,X_2=x_2,\\cdots,\\,X_n=x_n,\\,Y=y)\\\\\n&=\\left\\{\\begin{array}{ll}\\frac{p^y(1-p)^{n-y}}{\\left({n \\atop y}\\right) p^y(1-p)^{n-y}}=\\frac{1}{\\left({n \\atop y}\\right)},& si\\sum_{i=1}^nx_i= y\\\\0,&\\mbox{ en cualquier otro punto.}\\end{array}\\right.\n\\end{align*}\n\\] \\(\\frac{1}{\\left({n \\atop y}\\right)}\\) no depende de \\(p\\)\n\nUna vez que se conozca \\(Y\\), ninguna otra función de \\(X_1,\\,X_2,\\cdots,\\,X_n\\) proporcionara más información sobre el posible valor de \\(p\\). En este sentido, \\(Y\\) contiene toda la información acerca de \\(p\\).\n\nDefinition 2.1 Sean \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\) una muestra aleatoria de una distribución de probabilidad con parámetro desconocido \\(\\theta\\). Entonces se dice que el estadístico \\(U = T(Y_1,\\, Y_2,\\cdots,\\, Y_n)\\) es suficiente para \\(\\theta\\) si la distribución condicional de \\(Y_1,\\,Y_2,\\cdots,\\,Y_n\\), dada \\(U\\), no depende de \\(\\theta\\).\n\n\nRemark 2.1. El uso de cualquier estadístico \\(T(\\underset{\\sim}{X})\\) implica una reducción de los datos muestrales. Sea \\(\\underset{\\sim}{X} =(X_1 ,\\ldots, X_n)\\) una muestra aleatoria simple (un vector aleatorio) y sean \\(\\underset{\\sim}{x} = (x_1 ,\\ldots, x_n)\\), y \\(\\underset{\\sim}{y} = (y_1 ,\\ldots, y_n)\\) muestras observadas (realizaciones de \\(X\\)). Si decidimos usar el estadístico \\(T(\\underset{\\sim}{X})\\) en vez de toda la muestra, serán tratadas igual dos muestras observadas cualesquiera \\(\\underset{\\sim}{x}\\), \\(\\underset{\\sim}{y}\\), siempre que \\(T(\\underset{\\sim}{x})=T(\\underset{\\sim}{y})\\). Es decir, al usar el estadístico \\(T\\), en lugar de toda la muestra, se pierde información.\nSe plantea así el problema de buscar estadísticos \\(T\\) tales que la información que se pierde al usarlos sea irrelevante para los fines que nos hayamos marcado.\n\n\nRemark 2.2. Igualdad de estadísticos = Tratamiento indistinguible\nLa afirmación:\n\n“Serán tratadas igual dos muestras observadas cualesquiera \\(\\underset{\\sim}{x}\\) y \\(\\underset{\\sim}{y}\\), siempre que \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\)”\n\nsignifica que si solo observamos el valor de \\(T\\), entonces no podemos distinguir entre dos muestras diferentes que arrojen el mismo valor de ese estadístico.\nPor ejemplo:\nSupongamos que \\(\\bar{x} = \\bar{y} = 5\\), pero los vectores muestrales son diferentes:\n\\[\n\\underset{\\sim}{x} = (3,\\ 5,\\ 7), \\quad \\underset{\\sim}{y} = (4,\\ 5,\\ 6).\n\\]\nAmbos tienen la misma media, pero claramente no son la misma muestra. Sin embargo, si solo usamos la media como resumen, tratamos a ambas muestras como si fueran “iguales”.\n\n¿Qué se pierde?\nSe pierde la estructura interna de la muestra, incluyendo:\n\nLa variabilidad.\nEl sesgo o simetría.\nLa existencia de valores extremos.\nLa información sobre la distribución conjunta de los datos.\n\nTodo eso queda oculto si solo consideramos el estadístico \\(T(\\underset{\\sim}{X})\\).\n\nTodo estadístico implica una compresión de la muestra, y con ello una pérdida de información.\nPor eso, en inferencia estadística buscamos estadísticos que sean:\n\nSuficientes: capturan toda la información relevante sobre un parámetro.\nEficientes: minimizan la pérdida de información.\nInsesgados: representan fielmente el parámetro que estiman.\n\n\nNotación \\[\n    \\begin{eqnarray*}\n        p(y|\\theta)&:&\\mbox{ función de masa de probabilidad}\\\\\n        f(y|\\theta)&:&\\mbox{ función de densidad}\n    \\end{eqnarray*}\n\\]\n\nLa definicion Definition 2.1 nos dice como comprobar que un estadístico es suficiente pero no nos dice cómo calcularlo.\n\n\n\n\n\n\nTip 2.1\n\n\n\n\\(p(y_1,\\, y_2,\\cdots,\\, y_n)\\) función de probabilidad de v.a’s discretas.\n\\(p(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) función de probabilidad o verosimilitud de observar el evento \\(Y_1=y_1,\\, Y_2=y_2,\\cdots,\\, Y_n=y_n\\) cuando el valor del par'ametro es \\(\\theta\\).\n\\(f(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) caso continuo.\n\n\n\nDefinition 2.2 Sean \\(y_1,\\, y_2,\\cdots,\\, y_n\\) observaciones muestrales tomadas de variables aleatorias correspondientes \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) cuya distribución depende de un parámetro \\(\\theta\\). Entonces, si \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) son variables aleatorias discretas, la verosimilitud de la muestra, \\(L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\), se define como la probabilidad conjunta de \\(y_1,\\, y_2,\\cdots,\\, y_n\\).\nSi \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) son v.a’s continuas, la verosimilitud \\(L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) se define como la densidad conjunta evaluada en \\(y_1,\\, y_2,\\cdots,\\, y_n\\)\n\n\n\n\n\n\n\nImportant 2.1\n\n\n\nSi el conjunto de v.a’s iid \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) denota una muestra aleatoria de distribución discreta con función de probabilidad \\(p(y|\\theta)\\) entonces \\[\n\\begin{eqnarray*}\n    L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&p (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\\\\n    &=&p(y_1|\\theta)p(y_2|\\theta)\\cdots p(y_n|\\theta)\n\\end{eqnarray*}\n\\] Mientras que si \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) iid tienen distribución continua con función de densidad \\(f(y|\\theta)\\) entonces \\[\\begin{eqnarray*}\n    L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&f (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\\\\n    &=&f(y_1|\\theta)f(y_2|\\theta)\\cdots f(y_n|\\theta)\n\\end{eqnarray*}\\]\n\n\n\nTheorem 2.1 Si \\(f(\\underset{\\sim}{x}|\\theta)\\) es la verosimilitud de un vector aleatorio \\(X\\) y \\(q(t|\\theta)\\) es la verosimilitud (función de densidad o de masa) de un estadístico \\(T(\\underset{\\sim}{X})\\), se tiene la siguiente equivalencia. \\(T(\\underset{\\sim}{X})\\) es un estadístico suficiente para \\(\\theta\\) si y sólo si para cada \\(\\underset{\\sim}{x}\\) del espacio muestral \\(\\mathcal{X}\\) el cociente \\[\\begin{align}\n\\frac{f(\\underset{\\sim}{x}|\\theta)}{q(T(\\underset{\\sim}{x})|\\theta)}\n\\end{align}\\] no depende de \\(\\theta\\).\n\n\nRemark. El cociente del teorema\nEl cociente\n\\[\n\\frac{f(\\underset{\\sim}{x} \\mid \\theta)}{q(T(\\underset{\\sim}{x}) \\mid \\theta)}\n\\]\ncompara cuánta verosimilitud aporta la muestra completa respecto a la verosimilitud que se concentra solamente en el estadístico.\n🔁 Si este cociente no depende de \\(\\theta\\), eso significa que toda la información sobre \\(\\theta\\) contenida en \\(f(\\underset{\\sim}{x} \\mid \\theta)\\) ya está contenida en \\(q(T(\\underset{\\sim}{x}) \\mid \\theta)\\).\n\n\nTheorem 2.2 Sea \\(U\\) un estadístico basado en la muestra aleatoria \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\). Entonces \\(U\\) es un estadístico suficiente para la estimación de un parámetro \\(\\theta\\) sí y sólo si la verosimilitud \\(L(\\theta)=L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)\\) se puede factorizar en dos funciones no negativas, \\[L (y_1,\\, y_2,\\cdots,\\, y_n|\\theta)=g(u,\\,\\theta)\\times h(y_1,\\, y_2,\\cdots,\\, y_n)\\] donde \\(g(u,\\,\\theta)\\) es una función sólo de \\(u\\) y \\(\\theta\\) y \\(h(y_1,\\, y_2,\\cdots,\\, y_n)\\) no es una función de \\(\\theta\\)\n\n\nRemark (Interpretación: ¿Por qué esto implica suficiencia?). Cuando se cumple la factorización:\n\nLa función \\(g(u, \\theta)\\) contiene toda la información sobre \\(\\theta\\).\nEl resto de la muestra solo afecta a \\(h(\\cdot)\\), que no contiene ninguna información sobre \\(\\theta\\).\n\nPor lo tanto, si ya conocemos \\(u\\), no necesitamos el resto de la muestra para inferir \\(\\theta\\).\n\n🧩 Conclusión:\n\\(U\\) es suficiente ⇔ no se pierde información sobre \\(\\theta\\) al reemplazar la muestra por \\(U\\).\n\n\nExample 2.2 Sean \\(Y_1,\\, Y_2,\\cdots,\\, Y_n\\) una muestra aleatoria en la que \\(Y_i\\) posee la función de densidad de probabilidad \\[f(y_i|\\theta)=\\left\\{\\begin{array}{ll}(1/\\theta)e^{-y_i/\\theta},& 0\\leq y_i&lt;\\infty\\\\0,&\\mbox{ en cualquier otro punto.}\\end{array}\\right.\\] donde \\(\\theta&gt;0,\\,i=1,\\cdots,\\,n\\). Demuestre que \\(\\overline{Y}\\) es un estadístico suficiente para el parámetro \\(\\theta\\).\n\n\nProof. \\[\\begin{eqnarray*}\n    L(y_1,\\, y_2,\\cdots,\\, y_n|\\theta)&=&f(y_1|\\theta)f(y_2|\\theta)\\cdots f(y_n|\\theta)\\\\\n    &=&\\frac{1}{\\theta}e^{-y_1/\\theta}\\frac{1}{\\theta}e^{-y_2/\\theta}\\cdots\\frac{1}{\\theta}e^{-y_n/\\theta}\\\\\n    &=&\\left(\\frac{1}{\\theta}\\right)^ne^{-\\sum_{i=1}^ny_i/\\theta}\\\\\n    &=&\\left(\\frac{1}{\\theta}\\right)^ne^{-n\\overline{y}/\\theta}\\\\\n\\end{eqnarray*}\\] Así que \\(g(\\overline{y},\\,\\theta)=\\frac{e^{-n\\overline{y}/\\theta}}{\\theta^n}\\) y \\(h(y_1,\\, y_2,\\cdots,\\, y_n)=1\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#notación",
    "href": "chapter1.html#notación",
    "title": "2  Principios para reducir los datos",
    "section": "2.2 Notación",
    "text": "2.2 Notación\n\\[\n    \\begin{eqnarray*}\n        p(y|\\theta)&:&\\mbox{ función de masa de probabilidad}\\\\\n        f(y|\\theta)&:&\\mbox{ función de densidad}\n    \\end{eqnarray*}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter1.html#estadísticos-suficientes-minimales-1",
    "href": "chapter1.html#estadísticos-suficientes-minimales-1",
    "title": "2  Principios para reducir los datos",
    "section": "2.2 Estadísticos suficientes minimales",
    "text": "2.2 Estadísticos suficientes minimales\nLa factorización de la función de verosimilitud no es única y como consecuencia de ello, tampoco es único el estadístico suficiente para un parámetro.\nYa vimos que cualquier transformación biyectiva de un estadístico suficiente da lugar a otro estadístico suficiente. Pero aún hay muchos más estadísticos suficientes. Por ejemplo, la muestra completa \\(X\\) también es estadístico suficiente para el parámetro: \\[\n\\begin{align*}\nf(x|\\theta)=g(x|\\theta)h(x)\n\\end{align*}\n\\]\ndonde \\(h( x )=1\\), \\(T(x)=x\\) y \\(g(x|\\theta)=f(x|\\theta)\\).\n\n2.2.1 Estadístico minimal\nUn estadístico suficiente \\(T(\\underset{\\sim}{X})\\) se llama minimal si para cualquier otro estadístico \\(S(\\underset{\\sim}{X})\\) se tiene que \\(T(\\underset{\\sim}{X})\\) es función de \\(S(\\underset{\\sim}{X})\\). Es decir, si ocurre que \\(S( \\underset{\\sim}{x}) = S(\\underset{\\sim}{y})\\) entonces forzosamente se tiene que \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\).\nEl siguiente teorema proporciona un método para encontrar el estadístico suficiente minimal.\n\nTheorem 2.3 Sea \\(f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)\\) la función de verosimilitud conjunta de \\(\\underset{\\sim}{X}\\) (discreta o continua). Supongamos que existe una función \\(T(\\underset{\\sim}{x})\\) tal que para cualquier par de elementos del espacio muestral \\(\\underset{\\sim}{x}\\) , \\(\\underset{\\sim}{y}\\) , el cociente \\[\n\\begin{align}\n\\frac{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)}{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{y}|\\theta)}\n\\end{align}\n\\] es constante como función de \\(\\theta\\), si y sólo si \\(T(\\underset{\\sim}{x}) = T(\\underset{\\sim}{y})\\). Entonces \\(T(\\underset{\\sim}{x})\\) es estadístico suficiente minimal para \\(\\theta\\).\n\n\nExample 2.3 Determinar un estadístico minimal para el parámetro \\(\\theta\\), cuando \\(X_1,\\, X_2,\\cdots,\\, X_n\\) es una muestra aleatoria de una población con distribución de Poisson. \\[\n\\begin{align*}\n\\frac{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{x}|\\theta)}{f_{\\underset{\\sim}{X}}(\\underset{\\sim}{y}|\\theta)}\n&=\\frac{\\prod_{i=1}^{n}\\frac{\\theta^{x_i} e^{-\\theta}}{x_i!}}{\\prod_{i=1}^{n}\\frac{\\theta^{y_i} e^{-\\theta}}{y_i!}}\\\\\n&=\\frac{e^{-n\\theta}\\prod_{i=1}^{n}\\frac{\\theta^{x_i} }{x_i!}}{e^{-n\\theta}\\prod_{i=1}^{n}\\frac{\\theta^{y_i} }{y_i!}}\\\\\n&=\\frac{\\frac{\\theta^{\\sum_{i=1}^{n}x_i} }{\\prod_{i=1}^{n}x_i!}}{\\frac{\\theta^{\\sum_{i=1}^{n}y_i} }{\\prod_{i=1}^{n}y_i!}}\\\\\n&=\\frac{\\frac{\\theta^{n\\bar{x}} }{\\prod_{i=1}^{n}x_i!}}{\\frac{\\theta^{n\\bar{y}} }{\\prod_{i=1}^{n}y_i!}}\\\\\n&=\\theta^{n(\\bar{x}-\\bar{y})}\\frac{\\prod_{i=1}^{n}y_i!}{\\prod_{i=1}^{n}x_i!}\n\\end{align*}\n\\]\n\nEl cociente de la última igualdad no depende de \\(\\theta\\), sí y sólo si \\(\\bar{x}-\\bar{y}=0\\); es decir si \\(\\bar{X}_n\\) es un estadística suficiente minimal para \\(\\theta\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Principios para reducir los datos</span>"
    ]
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "\n3  Estimación puntual\n",
    "section": "",
    "text": "3.1 La función de distribución empírica y el método de los momentos\nSea la variable aleatoria \\(X\\) con función de distribución \\(F\\). Consideramos una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\), es decir, \\(X_1 ,\\ldots, X_n\\) v.a.i.i.d. con distribución dada por \\(F\\) . Sea \\(x_1 ,\\ldots, x_n\\) una realización de esa m.a.s. Se llama función de distribución empírica a la función \\[\n\\begin{align}\nF_{n}(x)=\\dfrac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\mathbf{I}_{(-\\infty,x]}(x_{i})¸\n\\end{align}\n\\] que a cada número real x le asigna la proporción de valores observados que son menores o iguales que x.\nEs inmediato comprobar que la función \\(F_n\\) así definida es una función de distribución:\nConcretamente, \\(F_n\\) es la función de distribución de una variable aleatoria discreta (que podemos llamar \\(X_e\\) ) que pone masa \\(\\frac{1}{n}\\) en cada uno de los n puntos \\(x_i\\) observados:\nA la distribución de \\(X_e\\) e se le llama distribución empírica asociada al conjunto de valores \\({x_1 ,\\ldots, x_n}\\).\nObsérvese que si fijamos el valor de \\(x\\) y dejamos variar la muestra, lo que obtenemos es una variable aleatoria. En efecto, se tiene entonces que\n\\[\n\\begin{align}\nF_{n}(x)=\\dfrac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\mathbf{I}_{(-\\infty,x]}(x_{i})¸\n\\end{align}\n\\]\ndonde\n\\[\n\\begin{align}\n\\mathbf{I}_{(-\\infty,x]}(X_{i})= \\left\\{ \\begin{array}{lcc}\n1 &   si  & X_{i}\\leq x \\\\\n\\\\ 0 &  si &X_{i}&gt; x\\\\\n\\end{array}\n\\right.\n\\end{align}\n\\] y, por lo tanto, cada término \\(\\mathbf{I}_{(-\\infty,x]}(X_{i})\\) es una variable aleatoria de Bernoulli con probabilidad de éxito\n\\[\n\\begin{align}\np&=P(\\mathbf{I}_{(-\\infty,x]}(X_{i})=1)\\\\\n&=P(X_{i}\\leq x)\\\\\n&=F(x)\n\\end{align}\n\\] De ahí se deduce que \\(F_n\\) es una variable aleatoria y que \\(nF_n(x)\\) tiene distribución binomial con parámetros \\(n\\) y \\(p = F(x)\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#la-función-de-distribución-empírica-y-el-método-de-los-momentos",
    "href": "chapter2.html#la-función-de-distribución-empírica-y-el-método-de-los-momentos",
    "title": "\n3  Estimación puntual\n",
    "section": "",
    "text": "\\(F_n(x) \\in [0, 1]\\) para todo \\(x \\in \\mathbb{R}\\).\n\n\\(F_n\\) es continua por la derecha.\n\n\\(F_n\\) es no decreciente.\n\\(\\lim _{x\\to -\\infty }F_{n}(x)=0\\)\n\\(\\lim _{x\\to \\infty }F_{n}(x)=1\\)\n\n\n\n\n\\(x_i\\)\n\\(1\\)\n\\(2\\)\n\\(\\ldots\\)\n\\(n\\)\n\n\n\\(p_i = P(X_e = x_i)\\)\n\\(1/n\\)\n\\(1/n\\)\n\\(\\ldots\\)\n\\(1/n\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#teorema-de-glivenko-cantelli",
    "href": "chapter2.html#teorema-de-glivenko-cantelli",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.2 Teorema de Glivenko-Cantelli",
    "text": "3.2 Teorema de Glivenko-Cantelli\nEl siguiente teorema recoge algunas de las propiedades de la función de distribución empírica.\n\nTheorem 3.1 Sea \\(\\{X_n\\}\\) para \\(n\\geq 1\\) , sucesión de variables aleatorias independientes e idénticamente distribuidas definidas en el espacio de probabilidad \\((\\Omega, \\mathcal{A}, P)\\) con función de distribución común \\(F\\) . Se denota por \\(F_n\\) la función de distribución empírica obtenida de las \\(n\\) primeras variables aleatorias \\(X_1 ,\\ldots, X_n\\) . Sea \\(x\\in\\mathbb{R}\\). Se verifica lo siguiente:\n\n\n\n\\(P(nF_n(x)=j)=P(F_n(x)=\\frac{j}{n})=\\binom{n}{j}(F(x))^j(1-F(x))^{n-j}\\), \\(j=1,\\ldots,n\\)\\\n\n\\(E(F_n(x))=F(x)\\); \\(Var(F_n(x))=\\frac{1}{n}F(x)(1-F(x))\\).\n\\(\\lim _{n\\to \\infty }F_{n}(x)=F(x)\\)\n\n\\(\\lim _{n\\to \\infty }\\frac{F_{n}(x)-F(x)}{\\sqrt{\\frac{F(x)(1-F(x))}{n}}}=Z\\), donde \\(Z\\) es una variable aleatoria con distribución normal estándar y la convergencia es convergencia en distribución.\n\nEl siguiente teorema refuerza el resultado (c) anterior, puesto que afirma que la convergencia de \\(F_n(x)\\) a \\(F(x)\\) se da uniformemente.\n\nTheorem 3.2 Sea \\(\\{X_n\\}\\) para \\(n\\geq 1\\) , sucesión de variables aleatorias independientes e idénticamente distribuidas definidas en el espacio de probabilidad \\((\\Omega, \\mathcal{A}, P)\\) con función de distribución común \\(F\\) . Se denota por \\(F_n\\) la función de distribución empírica obtenida de las \\(n\\) primeras variables aleatorias \\(X_1 ,\\ldots, X_n\\) . Sea \\(x\\in\\mathbb{R}\\). Entonces \\[Sup_{x\\in\\mathbb{R}} |F_{n}(x)-F(x)|\\xrightarrow{c.s}0\\]\n\n\n\n\n\n\n\nNote 3.1\n\n\n\nObsérvese que según el apartado (c) del teorema Theorem 3.1, las distribuciones empíricas asociadas a muestras de tamaño n convergen débilmente a la distribución de probabilidad teórica identificada por \\(F\\), para casi todas las muestras de tamaño infinito que se extraigan de \\(F\\) . Ésta es una de las consecuencias más importantes del citado teorema: la distribución empírica converge débilmente con probabilidad 1 a la poblacional cuando el tamaño de la muestra tiende a infinito: \\[F_{n}(x)\\xrightarrow{c.s}F(x)\\] Esto garantiza la posibilidad de realizar inferencia estadística:\n\nLos aspectos probabilísticos de una característica \\(X\\), medida en una población, se resumen de forma estilizada en una distribución de probabilidad \\(F\\).\nLa distribución de probabilidad \\(F\\), puede ser aproximada mediante las distribuciones empíricas \\(F_n\\) obtenidas por muestreo de la población en estudio.\nEl teorema de Glivenko-Cantelli afirma que esas aproximaciones son uniformes en x.\nPor esta razón el teorema de Glivenko-Cantelli se llama a veces Teorema Fundamental de la Estadística Matemática.\n\n\n\nPodemos ver a continuación cómo, a medida que aumentamos el tamaño de la muestra (n=10,30,100,1000), la función de distribución empírica se ajusta cada vez mejor a la distribución teórica normal estándar N(0,1), tal como afirma el teorema.\n\n# Cargar librería para gráficos\nlibrary(ggplot2)\n\n# Definir función para graficar ECDF vs distribución teórica\ncomparar_ecdf_teorica &lt;- function(n, distribucion = \"normal\") {\n  set.seed(123)  # Para reproducibilidad\n\n  # Muestra de tamaño n desde N(0,1)\n  muestra &lt;- rnorm(n)\n  \n  # Dominio común\n  x_vals &lt;- seq(-3, 3, length.out = 1000)\n\n  # Distribución teórica\n  F_teorica &lt;- pnorm(x_vals)\n\n  # Distribución empírica\n  ecdf_muestra &lt;- ecdf(muestra)\n  F_empirica &lt;- ecdf_muestra(x_vals)\n\n  # Construir data frame para ggplot\n  df &lt;- data.frame(\n    x = rep(x_vals, 2),\n    F = c(F_empirica, F_teorica),\n    Tipo = rep(c(\"Empírica\", \"Teórica\"), each = length(x_vals))\n  )\n\n  # Graficar\n  ggplot(df, aes(x = x, y = F, color = Tipo, linetype = Tipo)) +\n    geom_line(size = 1) +\n    labs(\n      title = paste(\"ECDF vs F(x) — Tamaño de muestra n =\", n),\n      x = \"x\", y = \"Probabilidad acumulada\"\n    ) +\n    theme_minimal() +\n    scale_color_manual(values = c(\"Empírica\" = \"red\", \"Teórica\" = \"black\")) +\n    scale_linetype_manual(values = c(\"Empírica\" = \"dashed\", \"Teórica\" = \"solid\"))\n}\n\n# Generar gráficos para diferentes tamaños de muestra\ncomparar_ecdf_teorica(10)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\ncomparar_ecdf_teorica(30)\n\n\n\n\n\n\ncomparar_ecdf_teorica(100)\n\n\n\n\n\n\ncomparar_ecdf_teorica(1000)\n\n\n\n\n\n\n\nEl Teorema Fundamental de la Estadística Matemática: da una fundamentación de la inferencia estadística, cuyo objetivo principal consiste en extraer información sobre \\(F\\) a partir de las observaciones muestrales.\n¿Por qué esto es importante?\nPorque sin conocer \\(F(x)\\) explícitamente, podemos estimarla a partir de los datos.\nEsto es la base de:\n\nlos histogramas acumulados,\nlas pruebas no paramétricas,\nlos intervalos de confianza empíricos, y\ntoda la inferencia estadística basada en datos reales.\n\n🎯 Ejemplo: Estimación del percentil 90 del ingreso mensual\n📌 Contexto Supón que quieres estimar el ingreso mensual por debajo del cual se encuentran el 90% de las personas en una ciudad.\nNo conoces la distribución real del ingreso ( F(x) ), pero tienes una muestra de datos.\n\nPaso a paso\n\nSimulamos una población Vamos a suponer que el ingreso sigue una distribución log-normal:\n\n\nset.seed(123)\npoblacion &lt;- rlnorm(1e6, meanlog = 10, sdlog = 0.5)\n\n\nTomamos una muestra aleatoria\n\n\nmuestra &lt;- sample(poblacion, size = 20000, replace = FALSE)\n\n\nEstimamos la distribución empírica\n\n\nFn &lt;- ecdf(muestra)\n\n\nEstimamos el percentil 90 (cuantil 0.9)\n\n\ncuantil_90_empirico &lt;- quantile(muestra, probs = 0.9)\n\n\nComparamos con el valor verdadero en la población\n\n\ncuantil_90_real &lt;- quantile(poblacion, probs = 0.9)\n\n\nResultado\n\n\ncat(\"Cuantil 90 estimado (empírico):\", round(cuantil_90_empirico, 2), \"\\n\")\n\nCuantil 90 estimado (empírico): 41926.83 \n\ncat(\"Cuantil 90 real (poblacional):\", round(cuantil_90_real, 2), \"\\n\")\n\nCuantil 90 real (poblacional): 41805.56",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#ejemplo-estimación-del-percentil-90-del-ingreso-mensual",
    "href": "chapter2.html#ejemplo-estimación-del-percentil-90-del-ingreso-mensual",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.3 🎯 Ejemplo: Estimación del percentil 90 del ingreso mensual",
    "text": "3.3 🎯 Ejemplo: Estimación del percentil 90 del ingreso mensual\n\n3.3.1 📌 Contexto\nSupón que quieres estimar el ingreso mensual por debajo del cual se encuentran el 90% de las personas en una ciudad.\nNo conoces la distribución real del ingreso ( F(x) ), pero tienes una muestra de datos.\n\n3.3.2 ⚙️ Paso a paso\n\n3.3.2.1 1. Simulamos una población\nVamos a suponer que el ingreso sigue una distribución log-normal:\n\nset.seed(123)\npoblacion &lt;- rlnorm(1e6, meanlog = 10, sdlog = 0.5)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#la-función-de-distribución-empírica-y-el-método-de-los-momentos-1",
    "href": "chapter2.html#la-función-de-distribución-empírica-y-el-método-de-los-momentos-1",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.3 La función de distribución empírica y el método de los momentos",
    "text": "3.3 La función de distribución empírica y el método de los momentos\n\n3.3.1 Principio de sustitución\nEn esta sección presentamos una consecuencia importante de la convergencia de \\(F_n\\) a \\(F\\) , la definición de estimadores mediante el principio de sustitución.\n\nLa convergencia de \\(F_n\\) a \\(F\\) permite construir versiones factibles de características poblacionales desconocidas.\nSupongamos que estudiamos una característica \\(X\\) en una población y que el resultado de la observación de \\(X\\) puede ser modelado como una variable aleatoria con distribución desconocida, digamos \\(F\\).\nMuchas de las preguntas relevantes acerca de la característica \\(X\\) podrían ser contestadas si su función de distribución \\(F\\) fuese conocida.\n\n\n\n\n\n\n\nImportant 3.1\n\n\n\nPreguntas sobre \\(X\\)\n\nel valor esperado,\nel número de modas de la distribución o\nla probabilidad de que \\(X\\) sea negativa\n\nPara fijar ideas podemos pensar que nos interesa conocer cantidades numéricas (parámetros) que dependen únicamente de la función de distribución desconocida \\(F\\):\n\\[\n    \\begin{align}\n    \\theta=\\psi(F)\n    \\end{align}\n\\] El teorema de Glivenko-Cantelli nos dice que \\(F_n\\) se acerca a \\(F\\), a medida que el tamaño muestral crece. Así, podemos esperar que también se verifique que \\[\n    \\begin{align}\n    \\hat{\\theta}_n=\\psi(F_n)\\rightarrow\\theta=\\psi(F)\n    \\end{align}\n    \\]\nEs decir, esperamos que las cantidades numéricas calculadas para la distribución empírica (estimadores) se aproximen a las cantidades desconocidas a medida que el tamaño muestral crezca.\nEsta forma de obtener estimadores de parámetros poblacionales desconocidos se denomina principio de sustitución (plug-in principle en inglés). Es un procedimiento muy general de obtención de estimadores.\n\n\nSea \\(X\\sim U(0,\\theta)\\). Se toma una m.a.s. de \\(X\\) de tamaño n para estimar \\(\\theta\\). Un estimador razonable de \\(\\theta\\) es el máximo de las observaciones, que es estadístico minimal suficiente para \\(\\theta\\): \\[\n\\begin{align}\n    \\hat{\\theta}_2 = \\max_i {X_i}.\n\\end{align}\n\\] El siguiente código muestra:\n\nPara cada tamaño de muestra n, simula valores de \\(X_i\\)∼U(0,θ),\nCalcula \\[\\hat{\\theta} = \\max_i {X_i}\\]\nCompara con el valor real de \\(\\theta=10\\).\nMuestra cómo, al aumentar n, el estimador se acerca a \\(\\theta\\).\n\n\n# Simulación para estimar theta en una uniforme (0, theta)\nset.seed(42)\ntheta_real &lt;- 10\n\n# Tamaños de muestra\nn_vals &lt;- c(5, 10, 30, 100)\n\n# Simular y comparar\nestimadores &lt;- sapply(n_vals, function(n) {\n  muestra &lt;- runif(n, min = 0, max = theta_real)\n  max(muestra)\n})\n\n# Mostrar resultados\ndata.frame(\n  Tamaño_muestra = n_vals,\n  Estimador_maximo = round(estimadores, 3),\n  Error = round(theta_real - estimadores, 3)\n)\n\n  Tamaño_muestra Estimador_maximo Error\n1              5            9.371 0.629\n2             10            9.347 0.653\n3             30            9.889 0.111\n4            100            9.828 0.172\n\n\nConvergencia del estimador plug-in en la distribución uniforme\nEn este ejemplo, estimamos el parámetro \\(\\theta\\) de una distribución \\(X \\sim \\mathcal{U}(0, \\theta)\\) usando el estimador \\(\\hat{\\theta}_n = \\max(X_i)\\). Este es un estimador tipo plug-in: se usa la distribución empírica para estimar una característica de la distribución teórica.\nA continuación, simulamos cómo este estimador converge al verdadero valor \\(\\theta = 10\\) a medida que el tamaño de muestra \\(n\\) crece.\n\n# Chunk de R — solo código\n#| label: fig-convergencia-max\n#| fig-cap: 'Convergencia del estimador plug-in $ \\hat{\\theta}_n = \\max X_i $ hacia el valor real $ \\theta = 10 $'\n#| fig-align: center\n#| message: false\n#| warning: false\n\nset.seed(42)\ntheta_real &lt;- 10\n\n# Vector de tamaños de muestra crecientes\nn_seq &lt;- seq(5, 500, by = 5)\n\n# Calcular el estimador para cada n\nestimadores &lt;- sapply(n_seq, function(n) {\n  muestra &lt;- runif(n, min = 0, max = theta_real)\n  max(muestra)\n})\n\n# Crear data frame para graficar\ndf_estimacion &lt;- data.frame(\n  n = n_seq,\n  estimador = estimadores\n)\n\n# Graficar\nlibrary(ggplot2)\nggplot(df_estimacion, aes(x = n, y = estimador)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_hline(yintercept = theta_real, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = expression(\"Convergencia de \" * hat(theta)[n] * \" al valor real \" * theta),\n    x = \"Tamaño de muestra (n)\",\n    y = expression(hat(theta)[n])\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#convergencia-del-estimador-plug-in-en-la-distribución-uniforme",
    "href": "chapter2.html#convergencia-del-estimador-plug-in-en-la-distribución-uniforme",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.4 📊 Convergencia del estimador plug-in en la distribución uniforme",
    "text": "3.4 📊 Convergencia del estimador plug-in en la distribución uniforme\nEn este ejemplo, estimamos el parámetro () de una distribución (X (0, )) usando el estimador (_n = (X_i)). Este es un estimador tipo plug-in: se usa la distribución empírica para estimar una característica de la distribución teórica.\nA continuación, simulamos cómo este estimador converge al verdadero valor (= 10) a medida que el tamaño de muestra (n) crece.\n\n# Chunk de R — solo código\n#| label: fig-convergencia-max\n#| fig-cap: 'Convergencia del estimador plug-in $ \\hat{\\theta}_n = \\max X_i $ hacia el valor real $ \\theta = 10 $'\n#| fig-align: center\n#| message: false\n#| warning: false\n\nset.seed(42)\ntheta_real &lt;- 10\n\n# Vector de tamaños de muestra crecientes\nn_seq &lt;- seq(5, 200, by = 5)\n\n# Calcular el estimador para cada n\nestimadores &lt;- sapply(n_seq, function(n) {\n  muestra &lt;- runif(n, min = 0, max = theta_real)\n  max(muestra)\n})\n\n# Crear data frame para graficar\ndf_estimacion &lt;- data.frame(\n  n = n_seq,\n  estimador = estimadores\n)\n\n# Graficar\nlibrary(ggplot2)\nggplot(df_estimacion, aes(x = n, y = estimador)) +\n  geom_line(color = \"steelblue\", size = 1) +\n  geom_hline(yintercept = theta_real, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = expression(\"Convergencia de \" * hat(theta)[n] * \" al valor real \" * theta),\n    x = \"Tamaño de muestra (n)\",\n    y = expression(hat(theta)[n])\n  ) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  },
  {
    "objectID": "chapter2.html#método-de-momentos",
    "href": "chapter2.html#método-de-momentos",
    "title": "\n3  Estimación puntual\n",
    "section": "\n3.4 Método de momentos",
    "text": "3.4 Método de momentos\nUna aplicación del principio de sustitución es la definición de los estimadores basados en momentos. El momento no centrado de orden \\(k\\) de una variable aleatoria \\(X\\) con distribución \\(F\\) se define como \\[\n\\begin{align}\n\\mu_k=E_F(X^k)=\\int x^kdF(x)\n    \\end{align}\n\\] Si \\(X_e\\) es una variable aleatoria con función de distribución igual a \\(F_n\\) , la función de distribución empírica de una m.a.s. de tamaño \\(n\\) de \\(X\\), se tiene que sus (a los que llamaremos \\(m_{k,n}\\)) son de la forma \\[\\begin{align}\n    m_{k,n}=E_{F_n}(X_e^k)=\\int x^kdF_n(x)=\\frac{1}{n}\\sum_{i=1}^{n}X_i^k,\n    \\end{align}\\] y se denominan momentos muestrales no centrados de orden \\(k\\). Por ejemplo, \\(µ_1\\) es la esperanza poblacional y \\(m_{1,n}\\) la media muestral.\nLa siguiente proposición garantiza que los momentos muestrales convergen a los poblacionales.\n\nProposition 3.1 Sea \\(X\\) variable aleatoria con \\(E(X^{2k}) &lt; \\infty\\). Entonces se verifica que \\(m_{k,n} \\rightarrow \\mu_k\\) casi seguro. Además, \\[\n\\begin{align}\n\\frac{\\sqrt{n}(m_{k,n}-\\mu_k)}{\\sqrt{\\mu_{2k}-\\mu_k^2}}\\xrightarrow{d}Z,\n\\end{align}\n\\] con \\(Z\\sim N(0,1)\\).\n\n\nProof. Si \\(Y_i=X_i^k\\) entonces \\(m_{k,n}=E_{k,n}(Y_i)=E_{n}(X_i^k)=\\frac{1}{n}\\sum_{i=1}^{n}X_i^k=\\frac{1}{n}\\sum_{i=1}^{n}Y_i=\\bar{Y}_n\\).\\\nAplicando la ley fuerte de los grandes números se tiene que \\[\\begin{align}\n\\lim _{n\\to \\infty }\\frac{S_n-E(S_n)}{n}&=\\lim _{n\\to \\infty }\\frac{\\sum_{i=1}^{n}X_i^k-E(\\sum_{i=1}^{n}X_i^k)}{n}\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\frac{\\sum_{i=1}^{n}X_i^k}{n}-\\frac{E(\\sum_{i=1}^{n}X_i^k)}{n}\\right]\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\bar{Y}_n-\\frac{\\sum_{i=1}^{n}E(X_i^k)}{n}\\right]\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\bar{Y}_n-\\frac{nE(X^k)}{n}\\right]\\mbox{Por ser las $X_i$ una mas de X}\\nonumber\\\\\n&=\\lim _{n\\to \\infty }\\left[\\bar{Y}_n-\\bar{Y}\\right]=0   \\mbox{ Aplicando L.F.G.N}\n\\end{align}\\]\nPor lo anterior, se tiene que \\(m_{k,n}=\\bar{Y}_n\\xrightarrow{c.s} \\mu_k=\\bar{Y}=E_F(X^k)\\). Por otro lado, veamos \\[\\begin{align}\n\\frac{S_n-E(S_n)}{\\sqrt{Var(S_n)}}=\\frac{m_{k,n}-E(X^k)}{\\sqrt{\\frac{Var(X^k)}{n}}}\\xrightarrow{d}Z\n\\end{align}\\] donde \\(S_n=\\sum_{i=1}^{n}X_i^k\\). Sabemos que \\(E(X^k)=\\mu_k\\) y que \\(Var(X^k)=E[(X^k)^2]-[E(X^k)]^2=\\mu_{2k}-\\mu_k^2\\), de ahí se sigue el resultado.\n\nMuchas características poblacionales de interés se pueden expresar como función de los momentos no centrados de órdenes \\(1,\\ldots, k\\): \\(\\theta=h(\\mu_1, \\ldots, \\mu_k)\\). Por ejemplo, la varianza de \\(X\\) se expresa como \\(\\sigma^2 = h(\\mu_1, \\mu_2) = \\mu_2-\\mu_1^2\\).\nEl estimador de \\(\\theta\\) basado en el principio de sustitución se conoce como estimador de los momentos de \\(\\theta\\) y será \\[\\begin{align}\n\\hat{\\theta}_n = h(m_{1,n} ,\\ldots, m_{k,n}).\n    \\end{align}\\] Obsérvese que el estimador de los momentos de \\(\\theta\\) puede no ser único, porque diferentes funciones \\(h\\) pueden conducir al mismo valor \\(\\theta\\).\n\nProposition 3.2 Consideremos la variable aleatoria \\(X\\) con \\(E(X_{2k})&lt; \\infty\\). Sea \\(\\theta=h(\\mu_{n} ,\\ldots, \\mu_{n})\\). Si \\(h\\) es continua en \\((\\mu_{n} ,\\ldots, \\mu_{n})\\), entonces \\(\\hat{\\theta}_n=h(m_{1,n} ,\\ldots, m_{k,n})\\) converge a \\(\\theta\\) casi seguro. Además, si \\(h\\) es derivable en \\((\\mu_{n} ,\\ldots, \\mu_{n})\\), entonces la distribución límite de \\(\\hat{\\theta}_n\\) es normal: \\[\\begin{align}\n\\sqrt{n}(\\hat{\\theta}_n-\\theta)\\xrightarrow{d} N(0, \\sigma_{h,\\theta}^2)\n\\end{align}\\]\n\n\nExample 3.1 Sea \\(X\\sim U(0,\\theta)\\). Se toma una m.a.s. de \\(X\\) de tamaño n para estimar \\(\\theta\\). Un estimador de momentos \\(\\hat{\\theta}_M\\) de \\(\\theta\\) viene dado por la siguiente relación \\[\\begin{align}\n    E(X)=\\frac{\\theta}{2}\\Longrightarrow m_{1,n}=\\frac{\\hat{\\theta}_M}{2}\\Longrightarrow 2m_{1,n}=\\hat{\\theta}_M\\Longrightarrow 2\\bar{X}=\\hat{\\theta}_M\n    \\end{align}\\]\n\n\nExample 3.2  \nPara la variable aleatoria \\(X\\) con varianza finita, un estimador para \\(\\theta=Var(X)\\) es \\[\\begin{align}\n\\hat{\\theta}=h(m_{1,n}, m_{2,n})&=m_{2,n}-m_{1,n}^2\\nonumber\\\\\n&=\\frac{1}{n}\\sum_{i=1}^{n}x_i^2-\\bar{x}^2\\nonumber\\\\\n&=\\frac{\\sum_{i=1}^{n}x_i^2-n\\bar{x}^2}{n}\\nonumber\\\\\n&=\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}{n}\\nonumber\\\\\n&=\\frac{(n-1)S_n^2}{n}\\nonumber\\\\\n\\end{align}\\]\n\n\nExample 3.3  \nSi \\(X\\sim Exp(\\lambda)\\) con \\(E(X)=\\frac{1}{\\lambda}\\), entonces \\(m_{1,n}=\\frac{1}{\\hat{\\lambda}_M}\\) \\(\\Longrightarrow \\hat{\\lambda}_M=\\frac{1}{m_{1,n}}\\Longrightarrow \\hat{\\lambda}_M=\\frac{1}{\\bar{X}}\\).\nSi \\(X\\sim B(n,p)\\), con \\(E(X)=np\\) y \\(Var(X)=npq\\), entonces \\(m_{1,n}=n\\hat{p}\\) \\(\\Longrightarrow\\) \\(\\frac{m_{1,n}}{n}=\\hat{p}\\) \\(\\Longrightarrow\\) \\(\\frac{\\bar{X}}{n}=\\hat{p}\\) \\(\\Longrightarrow\\) \\(\\hat{Var(X)}=n\\hat{p}(1-\\hat{p})\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estimación puntual</span>"
    ]
  }
]